{"text": " Looking at this from the angle, how can I manage such a large graph in a good way, and moving forward to that, so Nikolai. Thanks for the introduction. We have to speak up because the audience only for the- Okay. So my name is Nikolai Kondashov. I work at Red Hat on the CKI project, which has built in one of those Linux kernel testing systems for Red Hat and for Upstream. I also work in the kernel, louder? Okay. I also work with the Kernel CI Upstream Community on the KCI DB project, which is the source of this presentation, and I do electronics and embedded as a hobby. Okay. So I'm going to walk you quickly through the kernel contribution workflow, through the testing systems, then what we are trying to do with KCI DB at Kernel CI, and then how we want to solve the problem, and what the actual problem is with the Kernel CI process in general. Then I go briefly through the data model, and what kind of a few questions, what a few queries that we need, and how it went with Neo4j, and what we can do instead. So the kernel contribution workflow, I don't know if everybody's familiar with that. I hope not because it's not very pleasant. But basically, you do your changes, you commit your changes, then you make an email out of that and send it to a mail list and to a maintainer for them to review, to give you feedback, then you repeat that again until everybody's satisfied, including maintainer, whoever is concerned with that change. After this, your patches get merged into a sub-tree for the particular subsystem that you were changing, and then sometime later, this is getting merged into the mainline which Linus maintains, and you're done basically. But at any point in that process, you can get some test results for your change. It could be if you're lucky, you can get it before it even gets reviewed, or sometime it gets reviewed, or after it was merged, any time. So there's a whole bunch of kernel testing systems, this is just a sample. Each of them is trying to solve their own problem. For example, CKI is a Red Hat system, they would test particular hardware that our customers use, particular features that our customers request, to make sure that they work, that the distribution works, Intel tests their hardware, their graphics cards, and make sure that those work. Google fuzzer system calls, SysColor and SysBot, LKFT from Linaro, they test ARM boards, and finally, kernel CI is aiming to be the official CI system for the Linux kernel, it's supported by Linux Foundation, and they're trying to run tests on the whatever hardware others can provide, we can have. You can see everybody has their own interest in that game. So this is how your various email reports can look from those systems correspondingly, and this is their dashboards from different systems. So kernel CI, as I said, is striving to be the DCI system, and we have a testing system and the hardware management and the framework and everything to run the tests in various labs, and these labs can be located in different premises by people who have some hardware to run them on the test zone, and then that gets collected and put into the database, and then we have various other CI systems collecting their results and sending them to the KCIW database, and KCIW was conceived as a system to try to reduce the effort that all CI systems have to put into their dashboards, into their reports, and instead have one dashboard and one report if possible or close to that, and as well to save the developer's attention, which is a precious resource because as you see, it's not so easy to investigate every report and from different CI systems because they are differently formatted emails, different data, different dashboards, you have to look at them this way, that way, and you have to figure it out. So that's case IDB is the effort to bring this one into all the wall. So conceptually, it's very simple, these are systems and JSON which can consist like various objects in any combination, and we have the database we put them in, we have the dashboard to display that, and we have a subscription system where you can give some rules and say like, okay, I want to see these results from this test and from this tree or for this architecture or whatever, and we can generate the reports based on that whenever you need it as the data comes in. One important note about this is that compared to our regular CI system where you control everything, in this system, the data can come in in any order. In a regular CI system, you have the results come in the same order as commits come in. So if you tested something earlier, that means for an earlier commit, if you tested something later, it's for a later commit, and you can have a line of history with those results. But for case IDB, since various different CI systems, they get in any order you wish. So we have about 100,000 test results per day, a few thousands of builds, and hundreds of 100 revisions per day tests that received by the case IDB database. Well, actually, I think, yeah, that's correct. That's the correct scale. So it looks something like this as Grafana is like a prototype dashboard. We're thinking about building a new one, but I don't know how soon that's going to happen. So graphs, tables, all that jazz. This is our prototype reports look like this. So what's the problem with the kernel CI in general, not with the kernel CI, the project? So first of all, kernel is intended to be an obstruction layer for hardware. That's this whole purpose, and to make it easier to write software. So in theory, to make sure that it works, you have to test it with every piece that you're abstract away from. But that's not possible, of course, and hardware is expensive, so it's a natural scarcity in this whole system. Then the tests, since you cannot get all the hardware at the same time, and you cannot possibly run all the tests on all the hardware for every commit that people post, it means that sometimes the tests run on this hardware, sometimes on that hardware, sometimes they don't run, and the tests themselves are not so reliable because there's a lot of concurrency management in the kernel, and that's hard to get right, and in general, things happen at the same time in the operating system, so then sometimes they're not so reliable. So you can get a pass on your change, even if it's broken or get a fail on your change, even if it's not broken, or even if it's somebody else's change that broke it, basically, hell. So it's hard to remove noise from those results, and for developers, it's hard to investigate even a valid change. While it's a kernel, you have to meet all the conditions, and well, sometimes you have to get the right hardware, or ask people for the right hardware, or ask them to actually run the test and send you results, like you know, over email takes a while. So if we start sending people emails with results that are not valid, false positive, false negatives, then people kind of get pissed because of that, because it takes such a long time to reproduce them. So a lot of CI systems resort to human review before sending those reports, like they see the failures, they say, okay, well, let's send this to this mail list and then they send them, and only a few manage without that so far. So obviously, nobody stops the development to fix CI, because there's just so many developers, and if one system breaks something, like another subsystem doesn't want to care about that, and the feedback loop is just too long. So tests keep running, keep failing, and it takes a while to fix them. So instead of the ideal case where you can move past, only move past the tests if they pass, and then do all the stages, like a review, and then it's merged, and it's test, and it's fine, and then you can upstream it, you get something like this where all tests fail, okay, it's probably not our problem, not have time to investigate it, or we just didn't get any test result with new one. So what we're trying to do is we got to fix this, right? So we got to fix the test results. So we fix the test result. We look at the test output conditions, et cetera, and we add a rule to the database saying like, okay, well, this failed, but we know about this, here's the bug that was open, so don't complain to developers, don't waste their attention, and it looks like this, shiny and sparkly, but after a while, we get this fix into the test, and we repeat the process with another issue. So these things are already working in separate CI systems like the CKI. There's a UI screen for an issue in the kernel, it says like, okay, look for this output in the test, for this string in the test output, if you see it for this test, then we consider it a kernel bug and don't raise the problem. Okay, so or bug log CI, Intel's CI system, they have like a huge form. For file in this, you can see another string that is you're supposed to look in the error output and the conditions and what kind of status you want to assign to the test, et cetera. So here's a dog tags for you to take a breath, and for me to take a drink. So I'll dive into the model. We start with checkouts which basically just specify what kind of revision you're checking out, we have taken it from repository branch and which commit, and if you have patches applied on top, and the patch log and everything like that, then we aggregate that to get the revision data, like from multiple checkouts of the same revision, they get the same single revision, and they have builds which link to the checkouts, to say like, oh, we just tested this check out, and therefore link to the revision. The builds describe which architecture, compiler and configuration, output files and logs and everything, and we get the test results finally, and yeah, builds can fail, they have failed builds all the time and it stops nobody. So we have kind of test which we are running the environment to train on, what kind of result it was, the status result, pass, fail, et cetera, and the output files logs and stuff like that, very typical. Then we get the issues which describe like which bug it is, and who is to blame like the kernel, the test or the framework, and we will have the pattern there matching the test results, okay, this test, this output, what you saw on that screen. The status that it should have and the issue version, because we want to change those issues over time, and finally have the incidents which are linked in those builds and issues together, so saying like, oh, this is the issue with this build, and things like that. So that's all we keep in the relational database, but then we got to talk about the revisions. So revisions could be just a commit to get history, and here's your graph. So that's the basic thing that we've tried to do, but we also need to have revisions of patches applied on top and somebody posts the patch on the main list. We take it, apply it to some commit, which is pointed to and we test it, we get the results, and we know it was applied to this commit. Then somebody reworks that patch and posts a new version, they got a link, both the commit we tested upon and to the previous revision of the patch set. Then there is this weird thing when maintainers keep a special branch for CI for the testing systems to pick up their work and test and send them results, and they just keep pushing there like they're working on something, they push there, they get results after a while from testing, then they push a new version, and then they get new results and they got to say like, okay, this is the Git commit history, but we also know that we checked this branch out previously, so this is the child of that branch, of that previous revision. This basically it. Well, as you probably all know, this is a directed acyclic graph, so test directed edges and it doesn't loop on itself. So that's about what I know about graphs. So bear with me. Finally, I think that there's just too many build and test results to put them all into a graph database at least so far. I might be wrong, but that's my idea. We obviously need to keep the graph of the revisions to be able to reason about them, but we might be able to put issues there as well in the same database if it saves us something. So this is just a short list. Basically, what we want to know, okay, as the data commit comes in, the test results you got to try them and match them against the issue. So we can say, okay, we found an issue here, so don't raise the flag or something like that, like similar, okay. There is no issue here on test result, but we want to raise the flag because there's actually an issue. We cannot possibly try all the issues against all test results because there's going to be a lot. So we have to build a priority for those issues, and then we have to cut off that priority somehow, and say like, okay, at this moment, we can tell the developer that we've basically tried these results, you can go take a look, but we can still continue and try those issues as the time goes on. So we have to base that on one of the criteria that we might need is how far, for example, that revision is from the current situation, like if this issue only appeared somewhere, I don't know, like 1,000 commits ago, or 1,000 is not that much for the Linux kernel, okay, 10,000 commits ago, then we don't need to try it right now. We can tell the developer, okay, it's fine, and then we'll go and continue try it and if we find something, then we can raise the alarm. Okay, then we can ask, like what were the last X-test results, like for this particular test, for this number of commits to be able to say, okay, this test wasn't often failing, okay, it was failing sometimes, but that's okay, but if it suddenly starts failing more often, we got to raise the alarm, or if it stops failing so often, we got to also raise the alarm and see what's changed. Then we need to track the performance trends, of course, over the history of the development, and once again, we cannot do this just based on time, because some systems move at a different speed and some systems might start to decide to, okay, we're going to test this old branch because somebody if some of our clients wants to base their BSP on it, wants to base the release some software with that kernel, and we got to start testing it, and it starts coming in like the last year's release or something, and we cannot just take that data into account for testing the current releases or vice versa. So, or for stable kernel maintainer, if Greg wants to release a branch, he might want to see like, okay, which issues were discovered starting from the previous release in this branch, and finally, yeah, like just for the dashboard, like, okay, I want to see issues in this branch, or which branches contain this issue. So, that's what we tried to do with Neo4j. I did basic things, so I wrote a little script to get the Git log in a particular format, and then generate the data for commits and for relations. It was a little over a million commits look like this, and it was a little more relations, because as you probably know, a commit can have more than one parent in Git, and it looks like this, very simple. So, I loaded this into Neo4j with something like this. This is updated to the latest release. It was different than created an index for hashes and then loaded the relations, and it worked fine, but not a few days ago when I tried the Thresh Neo4j release, it just hung like this forever. So, I don't know, I could not give you a fresh data how it works right now, but I tried it last year, and I couldn't get answer a simple question if these two commits are connected. It was just go on forever, then run out of RAM. But with Epoch, I could do that. I could get the answer. It was okay, but if I wanted to get the nodes between those two commits, it would do the same thing. But with Git, I complete that in milliseconds. So, here you go. I think the problem, well, in my opinion, is that the graph management databases and software there aimed at a general graph problem, and not tuned to DAGs. How Git does that, Git is tuned to DAG, they have a lot of optimizations for that, and there are streaks to make like repositories like the Linux kernel work. So, I don't know nothing how you do this. This is magic to me, and this would be new to me in this book. But from a purely engineering perspective, I would have liked to see something like a support for databases that are restricted for DAGs only, and that apparently could be done with not so much computation. Then, once you have that, then you can do some branching and say like, okay, if we are DAG database, then we can do the optimizations and do the fast thing with them. So, the full back plan is obviously just put everything in Git, put the commits, and the patches, and all the branches, and all the subsystems, it's going to be giant repo. Maybe we can manage that, and then query it with libGit2, which is the library that Git uses to work with the data. Then, well, shuttle the commits with the relational database. Okay, we want to see if between those releases, we have issues and we take the commit hashes from Git and then query the database with that. That's all. Thanks. So, we can help you with the Neo4j things. It's just like literally this string, this length. No, it's text index is for full text back for. Okay. Well, it was just this one thing. So, do you have the data somewhere to try it out? Of course. Of course. There's a link from the slides to the script that you can use yourself on any Git repo. Yeah. Any more questions? Yes? Did you try any other graph databases? Well, I looked at the question is, did I try any other graph databases? Yeah, I looked at a bunch of them. Some of them require so much setup that I was just floored, but I read the documentation. I couldn't see any indication that it would be any different because nobody says anything about DAGs, any optimizations or anything. I tried memgraph before this talk, but I had the same problem with loading revisions, I think for some reason. Because previously, I could load revisions. I guess in Neo4j, the syntax for indexes has changed since then. Maybe I did create indexing correctly as I was just hinted at. But I could load them in reasonable time before in Neo4j and everything fine and like in query and except that thing. In memgraph, I just hit the wall because it's a different syntax slightly, it was slow. But yeah, no such luck and it took like four gigabytes of disk space. So, not too bad, okay. What version of Neo4j was successful? I don't remember now. I think it was, if I take a look now, I think I- The version will also be successful, it's just research. I tried one Neo4j desktop 1.4 before, 1.415 and that worked. I don't know which one, which version it was included. Any other questions? Thank you so much, Nikolaj. Thank you. Thank you, everyone. I'm still looking forward to work with data in the graph database. Because I think that's actually good for the graph database. And so we can make it work and then Dexter, you can come back and do some large scale analysis on the data. Okay, that would be great. That's what you can do. Yes, thank you. Thank you. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 6.5200000000000005, "text": " Looking at this from the angle,", "tokens": [11053, 412, 341, 490, 264, 5802, 11], "temperature": 0.0, "avg_logprob": -0.2979844978877476, "compression_ratio": 1.502008032128514, "no_speech_prob": 0.13157731294631958}, {"id": 1, "seek": 0, "start": 6.5200000000000005, "end": 9.28, "text": " how can I manage such a large graph in a good way,", "tokens": [577, 393, 286, 3067, 1270, 257, 2416, 4295, 294, 257, 665, 636, 11], "temperature": 0.0, "avg_logprob": -0.2979844978877476, "compression_ratio": 1.502008032128514, "no_speech_prob": 0.13157731294631958}, {"id": 2, "seek": 0, "start": 9.28, "end": 12.48, "text": " and moving forward to that, so Nikolai.", "tokens": [293, 2684, 2128, 281, 300, 11, 370, 13969, 401, 1301, 13], "temperature": 0.0, "avg_logprob": -0.2979844978877476, "compression_ratio": 1.502008032128514, "no_speech_prob": 0.13157731294631958}, {"id": 3, "seek": 0, "start": 12.48, "end": 14.64, "text": " Thanks for the introduction.", "tokens": [2561, 337, 264, 9339, 13], "temperature": 0.0, "avg_logprob": -0.2979844978877476, "compression_ratio": 1.502008032128514, "no_speech_prob": 0.13157731294631958}, {"id": 4, "seek": 0, "start": 14.64, "end": 17.2, "text": " We have to speak up because the audience only for the-", "tokens": [492, 362, 281, 1710, 493, 570, 264, 4034, 787, 337, 264, 12], "temperature": 0.0, "avg_logprob": -0.2979844978877476, "compression_ratio": 1.502008032128514, "no_speech_prob": 0.13157731294631958}, {"id": 5, "seek": 0, "start": 17.2, "end": 20.56, "text": " Okay. So my name is Nikolai Kondashov.", "tokens": [1033, 13, 407, 452, 1315, 307, 13969, 401, 1301, 591, 684, 296, 28057, 13], "temperature": 0.0, "avg_logprob": -0.2979844978877476, "compression_ratio": 1.502008032128514, "no_speech_prob": 0.13157731294631958}, {"id": 6, "seek": 0, "start": 20.56, "end": 22.92, "text": " I work at Red Hat on the CKI project,", "tokens": [286, 589, 412, 4477, 15867, 322, 264, 383, 27731, 1716, 11], "temperature": 0.0, "avg_logprob": -0.2979844978877476, "compression_ratio": 1.502008032128514, "no_speech_prob": 0.13157731294631958}, {"id": 7, "seek": 0, "start": 22.92, "end": 24.0, "text": " which has built in one of", "tokens": [597, 575, 3094, 294, 472, 295], "temperature": 0.0, "avg_logprob": -0.2979844978877476, "compression_ratio": 1.502008032128514, "no_speech_prob": 0.13157731294631958}, {"id": 8, "seek": 0, "start": 24.0, "end": 29.2, "text": " those Linux kernel testing systems for Red Hat and for Upstream.", "tokens": [729, 18734, 28256, 4997, 3652, 337, 4477, 15867, 293, 337, 5858, 9291, 13], "temperature": 0.0, "avg_logprob": -0.2979844978877476, "compression_ratio": 1.502008032128514, "no_speech_prob": 0.13157731294631958}, {"id": 9, "seek": 2920, "start": 29.2, "end": 32.0, "text": " I also work in the kernel, louder?", "tokens": [286, 611, 589, 294, 264, 28256, 11, 22717, 30], "temperature": 0.0, "avg_logprob": -0.26291168567746187, "compression_ratio": 1.5097087378640777, "no_speech_prob": 0.0001446634705644101}, {"id": 10, "seek": 2920, "start": 32.0, "end": 38.64, "text": " Okay. I also work with the Kernel CI Upstream Community on", "tokens": [1033, 13, 286, 611, 589, 365, 264, 40224, 338, 37777, 5858, 9291, 10421, 322], "temperature": 0.0, "avg_logprob": -0.26291168567746187, "compression_ratio": 1.5097087378640777, "no_speech_prob": 0.0001446634705644101}, {"id": 11, "seek": 2920, "start": 38.64, "end": 40.16, "text": " the KCI DB project,", "tokens": [264, 591, 25240, 26754, 1716, 11], "temperature": 0.0, "avg_logprob": -0.26291168567746187, "compression_ratio": 1.5097087378640777, "no_speech_prob": 0.0001446634705644101}, {"id": 12, "seek": 2920, "start": 40.16, "end": 44.36, "text": " which is the source of this presentation,", "tokens": [597, 307, 264, 4009, 295, 341, 5860, 11], "temperature": 0.0, "avg_logprob": -0.26291168567746187, "compression_ratio": 1.5097087378640777, "no_speech_prob": 0.0001446634705644101}, {"id": 13, "seek": 2920, "start": 44.36, "end": 47.72, "text": " and I do electronics and embedded as a hobby.", "tokens": [293, 286, 360, 20611, 293, 16741, 382, 257, 18240, 13], "temperature": 0.0, "avg_logprob": -0.26291168567746187, "compression_ratio": 1.5097087378640777, "no_speech_prob": 0.0001446634705644101}, {"id": 14, "seek": 2920, "start": 47.72, "end": 50.4, "text": " Okay. So I'm going to walk you", "tokens": [1033, 13, 407, 286, 478, 516, 281, 1792, 291], "temperature": 0.0, "avg_logprob": -0.26291168567746187, "compression_ratio": 1.5097087378640777, "no_speech_prob": 0.0001446634705644101}, {"id": 15, "seek": 2920, "start": 50.4, "end": 53.519999999999996, "text": " quickly through the kernel contribution workflow,", "tokens": [2661, 807, 264, 28256, 13150, 20993, 11], "temperature": 0.0, "avg_logprob": -0.26291168567746187, "compression_ratio": 1.5097087378640777, "no_speech_prob": 0.0001446634705644101}, {"id": 16, "seek": 2920, "start": 53.519999999999996, "end": 56.72, "text": " through the testing systems,", "tokens": [807, 264, 4997, 3652, 11], "temperature": 0.0, "avg_logprob": -0.26291168567746187, "compression_ratio": 1.5097087378640777, "no_speech_prob": 0.0001446634705644101}, {"id": 17, "seek": 5672, "start": 56.72, "end": 59.6, "text": " then what we are trying to do with KCI DB at Kernel CI,", "tokens": [550, 437, 321, 366, 1382, 281, 360, 365, 591, 25240, 26754, 412, 40224, 338, 37777, 11], "temperature": 0.0, "avg_logprob": -0.2043671174482866, "compression_ratio": 1.6818181818181819, "no_speech_prob": 6.362871499732137e-05}, {"id": 18, "seek": 5672, "start": 59.6, "end": 63.18, "text": " and then how we want to solve the problem,", "tokens": [293, 550, 577, 321, 528, 281, 5039, 264, 1154, 11], "temperature": 0.0, "avg_logprob": -0.2043671174482866, "compression_ratio": 1.6818181818181819, "no_speech_prob": 6.362871499732137e-05}, {"id": 19, "seek": 5672, "start": 63.18, "end": 65.68, "text": " and what the actual problem is with", "tokens": [293, 437, 264, 3539, 1154, 307, 365], "temperature": 0.0, "avg_logprob": -0.2043671174482866, "compression_ratio": 1.6818181818181819, "no_speech_prob": 6.362871499732137e-05}, {"id": 20, "seek": 5672, "start": 65.68, "end": 68.48, "text": " the Kernel CI process in general.", "tokens": [264, 40224, 338, 37777, 1399, 294, 2674, 13], "temperature": 0.0, "avg_logprob": -0.2043671174482866, "compression_ratio": 1.6818181818181819, "no_speech_prob": 6.362871499732137e-05}, {"id": 21, "seek": 5672, "start": 68.48, "end": 70.6, "text": " Then I go briefly through the data model,", "tokens": [1396, 286, 352, 10515, 807, 264, 1412, 2316, 11], "temperature": 0.0, "avg_logprob": -0.2043671174482866, "compression_ratio": 1.6818181818181819, "no_speech_prob": 6.362871499732137e-05}, {"id": 22, "seek": 5672, "start": 70.6, "end": 73.36, "text": " and what kind of a few questions,", "tokens": [293, 437, 733, 295, 257, 1326, 1651, 11], "temperature": 0.0, "avg_logprob": -0.2043671174482866, "compression_ratio": 1.6818181818181819, "no_speech_prob": 6.362871499732137e-05}, {"id": 23, "seek": 5672, "start": 73.36, "end": 75.8, "text": " what a few queries that we need,", "tokens": [437, 257, 1326, 24109, 300, 321, 643, 11], "temperature": 0.0, "avg_logprob": -0.2043671174482866, "compression_ratio": 1.6818181818181819, "no_speech_prob": 6.362871499732137e-05}, {"id": 24, "seek": 5672, "start": 75.8, "end": 79.03999999999999, "text": " and how it went with Neo4j,", "tokens": [293, 577, 309, 1437, 365, 24458, 19, 73, 11], "temperature": 0.0, "avg_logprob": -0.2043671174482866, "compression_ratio": 1.6818181818181819, "no_speech_prob": 6.362871499732137e-05}, {"id": 25, "seek": 5672, "start": 79.03999999999999, "end": 81.6, "text": " and what we can do instead.", "tokens": [293, 437, 321, 393, 360, 2602, 13], "temperature": 0.0, "avg_logprob": -0.2043671174482866, "compression_ratio": 1.6818181818181819, "no_speech_prob": 6.362871499732137e-05}, {"id": 26, "seek": 5672, "start": 81.6, "end": 85.48, "text": " So the kernel contribution workflow,", "tokens": [407, 264, 28256, 13150, 20993, 11], "temperature": 0.0, "avg_logprob": -0.2043671174482866, "compression_ratio": 1.6818181818181819, "no_speech_prob": 6.362871499732137e-05}, {"id": 27, "seek": 8548, "start": 85.48, "end": 88.2, "text": " I don't know if everybody's familiar with that.", "tokens": [286, 500, 380, 458, 498, 2201, 311, 4963, 365, 300, 13], "temperature": 0.0, "avg_logprob": -0.2056551846590909, "compression_ratio": 1.7813620071684588, "no_speech_prob": 0.00015737091598566622}, {"id": 28, "seek": 8548, "start": 88.2, "end": 90.4, "text": " I hope not because it's not very pleasant.", "tokens": [286, 1454, 406, 570, 309, 311, 406, 588, 16232, 13], "temperature": 0.0, "avg_logprob": -0.2056551846590909, "compression_ratio": 1.7813620071684588, "no_speech_prob": 0.00015737091598566622}, {"id": 29, "seek": 8548, "start": 90.4, "end": 93.84, "text": " But basically, you do your changes,", "tokens": [583, 1936, 11, 291, 360, 428, 2962, 11], "temperature": 0.0, "avg_logprob": -0.2056551846590909, "compression_ratio": 1.7813620071684588, "no_speech_prob": 0.00015737091598566622}, {"id": 30, "seek": 8548, "start": 93.84, "end": 94.60000000000001, "text": " you commit your changes,", "tokens": [291, 5599, 428, 2962, 11], "temperature": 0.0, "avg_logprob": -0.2056551846590909, "compression_ratio": 1.7813620071684588, "no_speech_prob": 0.00015737091598566622}, {"id": 31, "seek": 8548, "start": 94.60000000000001, "end": 97.04, "text": " then you make an email out of that and send it to", "tokens": [550, 291, 652, 364, 3796, 484, 295, 300, 293, 2845, 309, 281], "temperature": 0.0, "avg_logprob": -0.2056551846590909, "compression_ratio": 1.7813620071684588, "no_speech_prob": 0.00015737091598566622}, {"id": 32, "seek": 8548, "start": 97.04, "end": 100.12, "text": " a mail list and to a maintainer for them to review,", "tokens": [257, 10071, 1329, 293, 281, 257, 6909, 260, 337, 552, 281, 3131, 11], "temperature": 0.0, "avg_logprob": -0.2056551846590909, "compression_ratio": 1.7813620071684588, "no_speech_prob": 0.00015737091598566622}, {"id": 33, "seek": 8548, "start": 100.12, "end": 101.12, "text": " to give you feedback,", "tokens": [281, 976, 291, 5824, 11], "temperature": 0.0, "avg_logprob": -0.2056551846590909, "compression_ratio": 1.7813620071684588, "no_speech_prob": 0.00015737091598566622}, {"id": 34, "seek": 8548, "start": 101.12, "end": 104.28, "text": " then you repeat that again until everybody's satisfied,", "tokens": [550, 291, 7149, 300, 797, 1826, 2201, 311, 11239, 11], "temperature": 0.0, "avg_logprob": -0.2056551846590909, "compression_ratio": 1.7813620071684588, "no_speech_prob": 0.00015737091598566622}, {"id": 35, "seek": 8548, "start": 104.28, "end": 106.80000000000001, "text": " including maintainer, whoever is concerned with that change.", "tokens": [3009, 6909, 260, 11, 11387, 307, 5922, 365, 300, 1319, 13], "temperature": 0.0, "avg_logprob": -0.2056551846590909, "compression_ratio": 1.7813620071684588, "no_speech_prob": 0.00015737091598566622}, {"id": 36, "seek": 8548, "start": 106.80000000000001, "end": 110.56, "text": " After this, your patches get merged into", "tokens": [2381, 341, 11, 428, 26531, 483, 36427, 666], "temperature": 0.0, "avg_logprob": -0.2056551846590909, "compression_ratio": 1.7813620071684588, "no_speech_prob": 0.00015737091598566622}, {"id": 37, "seek": 8548, "start": 110.56, "end": 113.48, "text": " a sub-tree for the particular subsystem that you were changing,", "tokens": [257, 1422, 12, 83, 701, 337, 264, 1729, 2090, 9321, 300, 291, 645, 4473, 11], "temperature": 0.0, "avg_logprob": -0.2056551846590909, "compression_ratio": 1.7813620071684588, "no_speech_prob": 0.00015737091598566622}, {"id": 38, "seek": 11348, "start": 113.48, "end": 116.24000000000001, "text": " and then sometime later, this is getting merged into", "tokens": [293, 550, 15053, 1780, 11, 341, 307, 1242, 36427, 666], "temperature": 0.0, "avg_logprob": -0.27866108600909895, "compression_ratio": 1.6529680365296804, "no_speech_prob": 5.2846127800876275e-05}, {"id": 39, "seek": 11348, "start": 116.24000000000001, "end": 118.84, "text": " the mainline which Linus maintains,", "tokens": [264, 2135, 1889, 597, 9355, 301, 33385, 11], "temperature": 0.0, "avg_logprob": -0.27866108600909895, "compression_ratio": 1.6529680365296804, "no_speech_prob": 5.2846127800876275e-05}, {"id": 40, "seek": 11348, "start": 118.84, "end": 121.32000000000001, "text": " and you're done basically.", "tokens": [293, 291, 434, 1096, 1936, 13], "temperature": 0.0, "avg_logprob": -0.27866108600909895, "compression_ratio": 1.6529680365296804, "no_speech_prob": 5.2846127800876275e-05}, {"id": 41, "seek": 11348, "start": 121.32000000000001, "end": 124.28, "text": " But at any point in that process,", "tokens": [583, 412, 604, 935, 294, 300, 1399, 11], "temperature": 0.0, "avg_logprob": -0.27866108600909895, "compression_ratio": 1.6529680365296804, "no_speech_prob": 5.2846127800876275e-05}, {"id": 42, "seek": 11348, "start": 124.28, "end": 126.64, "text": " you can get some test results for your change.", "tokens": [291, 393, 483, 512, 1500, 3542, 337, 428, 1319, 13], "temperature": 0.0, "avg_logprob": -0.27866108600909895, "compression_ratio": 1.6529680365296804, "no_speech_prob": 5.2846127800876275e-05}, {"id": 43, "seek": 11348, "start": 126.64, "end": 128.08, "text": " It could be if you're lucky,", "tokens": [467, 727, 312, 498, 291, 434, 6356, 11], "temperature": 0.0, "avg_logprob": -0.27866108600909895, "compression_ratio": 1.6529680365296804, "no_speech_prob": 5.2846127800876275e-05}, {"id": 44, "seek": 11348, "start": 128.08, "end": 130.28, "text": " you can get it before it even gets reviewed,", "tokens": [291, 393, 483, 309, 949, 309, 754, 2170, 18429, 11], "temperature": 0.0, "avg_logprob": -0.27866108600909895, "compression_ratio": 1.6529680365296804, "no_speech_prob": 5.2846127800876275e-05}, {"id": 45, "seek": 11348, "start": 130.28, "end": 132.52, "text": " or sometime it gets reviewed,", "tokens": [420, 15053, 309, 2170, 18429, 11], "temperature": 0.0, "avg_logprob": -0.27866108600909895, "compression_ratio": 1.6529680365296804, "no_speech_prob": 5.2846127800876275e-05}, {"id": 46, "seek": 11348, "start": 132.52, "end": 135.32, "text": " or after it was merged, any time.", "tokens": [420, 934, 309, 390, 36427, 11, 604, 565, 13], "temperature": 0.0, "avg_logprob": -0.27866108600909895, "compression_ratio": 1.6529680365296804, "no_speech_prob": 5.2846127800876275e-05}, {"id": 47, "seek": 11348, "start": 136.8, "end": 140.68, "text": " So there's a whole bunch of", "tokens": [407, 456, 311, 257, 1379, 3840, 295], "temperature": 0.0, "avg_logprob": -0.27866108600909895, "compression_ratio": 1.6529680365296804, "no_speech_prob": 5.2846127800876275e-05}, {"id": 48, "seek": 14068, "start": 140.68, "end": 144.16, "text": " kernel testing systems, this is just a sample.", "tokens": [28256, 4997, 3652, 11, 341, 307, 445, 257, 6889, 13], "temperature": 0.0, "avg_logprob": -0.21283696361423768, "compression_ratio": 1.76036866359447, "no_speech_prob": 0.0002994579554069787}, {"id": 49, "seek": 14068, "start": 144.64000000000001, "end": 147.44, "text": " Each of them is trying to solve their own problem.", "tokens": [6947, 295, 552, 307, 1382, 281, 5039, 641, 1065, 1154, 13], "temperature": 0.0, "avg_logprob": -0.21283696361423768, "compression_ratio": 1.76036866359447, "no_speech_prob": 0.0002994579554069787}, {"id": 50, "seek": 14068, "start": 147.44, "end": 150.8, "text": " For example, CKI is a Red Hat system,", "tokens": [1171, 1365, 11, 383, 27731, 307, 257, 4477, 15867, 1185, 11], "temperature": 0.0, "avg_logprob": -0.21283696361423768, "compression_ratio": 1.76036866359447, "no_speech_prob": 0.0002994579554069787}, {"id": 51, "seek": 14068, "start": 150.8, "end": 155.72, "text": " they would test particular hardware that our customers use,", "tokens": [436, 576, 1500, 1729, 8837, 300, 527, 4581, 764, 11], "temperature": 0.0, "avg_logprob": -0.21283696361423768, "compression_ratio": 1.76036866359447, "no_speech_prob": 0.0002994579554069787}, {"id": 52, "seek": 14068, "start": 155.72, "end": 158.64000000000001, "text": " particular features that our customers request,", "tokens": [1729, 4122, 300, 527, 4581, 5308, 11], "temperature": 0.0, "avg_logprob": -0.21283696361423768, "compression_ratio": 1.76036866359447, "no_speech_prob": 0.0002994579554069787}, {"id": 53, "seek": 14068, "start": 158.64000000000001, "end": 159.60000000000002, "text": " to make sure that they work,", "tokens": [281, 652, 988, 300, 436, 589, 11], "temperature": 0.0, "avg_logprob": -0.21283696361423768, "compression_ratio": 1.76036866359447, "no_speech_prob": 0.0002994579554069787}, {"id": 54, "seek": 14068, "start": 159.60000000000002, "end": 161.4, "text": " that the distribution works,", "tokens": [300, 264, 7316, 1985, 11], "temperature": 0.0, "avg_logprob": -0.21283696361423768, "compression_ratio": 1.76036866359447, "no_speech_prob": 0.0002994579554069787}, {"id": 55, "seek": 14068, "start": 161.4, "end": 163.56, "text": " Intel tests their hardware,", "tokens": [19762, 6921, 641, 8837, 11], "temperature": 0.0, "avg_logprob": -0.21283696361423768, "compression_ratio": 1.76036866359447, "no_speech_prob": 0.0002994579554069787}, {"id": 56, "seek": 14068, "start": 163.56, "end": 166.56, "text": " their graphics cards, and make sure that those work.", "tokens": [641, 11837, 5632, 11, 293, 652, 988, 300, 729, 589, 13], "temperature": 0.0, "avg_logprob": -0.21283696361423768, "compression_ratio": 1.76036866359447, "no_speech_prob": 0.0002994579554069787}, {"id": 57, "seek": 16656, "start": 166.56, "end": 171.48, "text": " Google fuzzer system calls, SysColor and SysBot,", "tokens": [3329, 283, 3334, 4527, 1185, 5498, 11, 318, 749, 34, 36182, 293, 318, 749, 33, 310, 11], "temperature": 0.0, "avg_logprob": -0.2971453116490291, "compression_ratio": 1.5127118644067796, "no_speech_prob": 0.00016806088387966156}, {"id": 58, "seek": 16656, "start": 171.48, "end": 174.84, "text": " LKFT from Linaro, they test ARM boards,", "tokens": [441, 42, 25469, 490, 441, 6470, 78, 11, 436, 1500, 45209, 13293, 11], "temperature": 0.0, "avg_logprob": -0.2971453116490291, "compression_ratio": 1.5127118644067796, "no_speech_prob": 0.00016806088387966156}, {"id": 59, "seek": 16656, "start": 174.84, "end": 178.52, "text": " and finally, kernel CI is aiming to be", "tokens": [293, 2721, 11, 28256, 37777, 307, 20253, 281, 312], "temperature": 0.0, "avg_logprob": -0.2971453116490291, "compression_ratio": 1.5127118644067796, "no_speech_prob": 0.00016806088387966156}, {"id": 60, "seek": 16656, "start": 178.52, "end": 180.52, "text": " the official CI system for the Linux kernel,", "tokens": [264, 4783, 37777, 1185, 337, 264, 18734, 28256, 11], "temperature": 0.0, "avg_logprob": -0.2971453116490291, "compression_ratio": 1.5127118644067796, "no_speech_prob": 0.00016806088387966156}, {"id": 61, "seek": 16656, "start": 180.52, "end": 182.6, "text": " it's supported by Linux Foundation,", "tokens": [309, 311, 8104, 538, 18734, 10335, 11], "temperature": 0.0, "avg_logprob": -0.2971453116490291, "compression_ratio": 1.5127118644067796, "no_speech_prob": 0.00016806088387966156}, {"id": 62, "seek": 16656, "start": 182.6, "end": 184.76, "text": " and they're trying to run tests on", "tokens": [293, 436, 434, 1382, 281, 1190, 6921, 322], "temperature": 0.0, "avg_logprob": -0.2971453116490291, "compression_ratio": 1.5127118644067796, "no_speech_prob": 0.00016806088387966156}, {"id": 63, "seek": 16656, "start": 184.76, "end": 188.76, "text": " the whatever hardware others can provide, we can have.", "tokens": [264, 2035, 8837, 2357, 393, 2893, 11, 321, 393, 362, 13], "temperature": 0.0, "avg_logprob": -0.2971453116490291, "compression_ratio": 1.5127118644067796, "no_speech_prob": 0.00016806088387966156}, {"id": 64, "seek": 16656, "start": 190.12, "end": 194.04, "text": " You can see everybody has their own interest in that game.", "tokens": [509, 393, 536, 2201, 575, 641, 1065, 1179, 294, 300, 1216, 13], "temperature": 0.0, "avg_logprob": -0.2971453116490291, "compression_ratio": 1.5127118644067796, "no_speech_prob": 0.00016806088387966156}, {"id": 65, "seek": 19404, "start": 194.04, "end": 197.16, "text": " So this is how your various email reports can look from", "tokens": [407, 341, 307, 577, 428, 3683, 3796, 7122, 393, 574, 490], "temperature": 0.0, "avg_logprob": -0.2119319874753234, "compression_ratio": 1.6666666666666667, "no_speech_prob": 7.450870180036873e-05}, {"id": 66, "seek": 19404, "start": 197.16, "end": 199.2, "text": " those systems correspondingly,", "tokens": [729, 3652, 11760, 356, 11], "temperature": 0.0, "avg_logprob": -0.2119319874753234, "compression_ratio": 1.6666666666666667, "no_speech_prob": 7.450870180036873e-05}, {"id": 67, "seek": 19404, "start": 199.2, "end": 204.72, "text": " and this is their dashboards from different systems.", "tokens": [293, 341, 307, 641, 8240, 17228, 490, 819, 3652, 13], "temperature": 0.0, "avg_logprob": -0.2119319874753234, "compression_ratio": 1.6666666666666667, "no_speech_prob": 7.450870180036873e-05}, {"id": 68, "seek": 19404, "start": 204.72, "end": 209.04, "text": " So kernel CI, as I said,", "tokens": [407, 28256, 37777, 11, 382, 286, 848, 11], "temperature": 0.0, "avg_logprob": -0.2119319874753234, "compression_ratio": 1.6666666666666667, "no_speech_prob": 7.450870180036873e-05}, {"id": 69, "seek": 19404, "start": 209.04, "end": 212.32, "text": " is striving to be the DCI system,", "tokens": [307, 36582, 281, 312, 264, 9114, 40, 1185, 11], "temperature": 0.0, "avg_logprob": -0.2119319874753234, "compression_ratio": 1.6666666666666667, "no_speech_prob": 7.450870180036873e-05}, {"id": 70, "seek": 19404, "start": 212.32, "end": 215.12, "text": " and we have a testing system and", "tokens": [293, 321, 362, 257, 4997, 1185, 293], "temperature": 0.0, "avg_logprob": -0.2119319874753234, "compression_ratio": 1.6666666666666667, "no_speech_prob": 7.450870180036873e-05}, {"id": 71, "seek": 19404, "start": 215.12, "end": 217.32, "text": " the hardware management and", "tokens": [264, 8837, 4592, 293], "temperature": 0.0, "avg_logprob": -0.2119319874753234, "compression_ratio": 1.6666666666666667, "no_speech_prob": 7.450870180036873e-05}, {"id": 72, "seek": 19404, "start": 217.32, "end": 221.35999999999999, "text": " the framework and everything to run the tests in various labs,", "tokens": [264, 8388, 293, 1203, 281, 1190, 264, 6921, 294, 3683, 20339, 11], "temperature": 0.0, "avg_logprob": -0.2119319874753234, "compression_ratio": 1.6666666666666667, "no_speech_prob": 7.450870180036873e-05}, {"id": 73, "seek": 19404, "start": 221.35999999999999, "end": 222.88, "text": " and these labs can be located in", "tokens": [293, 613, 20339, 393, 312, 6870, 294], "temperature": 0.0, "avg_logprob": -0.2119319874753234, "compression_ratio": 1.6666666666666667, "no_speech_prob": 7.450870180036873e-05}, {"id": 74, "seek": 22288, "start": 222.88, "end": 225.35999999999999, "text": " different premises by people who", "tokens": [819, 34266, 538, 561, 567], "temperature": 0.0, "avg_logprob": -0.1912413204417509, "compression_ratio": 1.8341013824884793, "no_speech_prob": 0.00010904017108259723}, {"id": 75, "seek": 22288, "start": 225.35999999999999, "end": 230.16, "text": " have some hardware to run them on the test zone,", "tokens": [362, 512, 8837, 281, 1190, 552, 322, 264, 1500, 6668, 11], "temperature": 0.0, "avg_logprob": -0.1912413204417509, "compression_ratio": 1.8341013824884793, "no_speech_prob": 0.00010904017108259723}, {"id": 76, "seek": 22288, "start": 230.16, "end": 234.0, "text": " and then that gets collected and put into the database,", "tokens": [293, 550, 300, 2170, 11087, 293, 829, 666, 264, 8149, 11], "temperature": 0.0, "avg_logprob": -0.1912413204417509, "compression_ratio": 1.8341013824884793, "no_speech_prob": 0.00010904017108259723}, {"id": 77, "seek": 22288, "start": 234.0, "end": 237.4, "text": " and then we have various other CI systems", "tokens": [293, 550, 321, 362, 3683, 661, 37777, 3652], "temperature": 0.0, "avg_logprob": -0.1912413204417509, "compression_ratio": 1.8341013824884793, "no_speech_prob": 0.00010904017108259723}, {"id": 78, "seek": 22288, "start": 237.4, "end": 241.92, "text": " collecting their results and sending them to the KCIW database,", "tokens": [12510, 641, 3542, 293, 7750, 552, 281, 264, 591, 25240, 54, 8149, 11], "temperature": 0.0, "avg_logprob": -0.1912413204417509, "compression_ratio": 1.8341013824884793, "no_speech_prob": 0.00010904017108259723}, {"id": 79, "seek": 22288, "start": 241.92, "end": 245.07999999999998, "text": " and KCIW was conceived as a system to try to", "tokens": [293, 591, 25240, 54, 390, 34898, 382, 257, 1185, 281, 853, 281], "temperature": 0.0, "avg_logprob": -0.1912413204417509, "compression_ratio": 1.8341013824884793, "no_speech_prob": 0.00010904017108259723}, {"id": 80, "seek": 22288, "start": 245.07999999999998, "end": 247.96, "text": " reduce the effort that all CI systems", "tokens": [5407, 264, 4630, 300, 439, 37777, 3652], "temperature": 0.0, "avg_logprob": -0.1912413204417509, "compression_ratio": 1.8341013824884793, "no_speech_prob": 0.00010904017108259723}, {"id": 81, "seek": 22288, "start": 247.96, "end": 249.35999999999999, "text": " have to put into their dashboards,", "tokens": [362, 281, 829, 666, 641, 8240, 17228, 11], "temperature": 0.0, "avg_logprob": -0.1912413204417509, "compression_ratio": 1.8341013824884793, "no_speech_prob": 0.00010904017108259723}, {"id": 82, "seek": 22288, "start": 249.35999999999999, "end": 251.84, "text": " into their reports, and instead have", "tokens": [666, 641, 7122, 11, 293, 2602, 362], "temperature": 0.0, "avg_logprob": -0.1912413204417509, "compression_ratio": 1.8341013824884793, "no_speech_prob": 0.00010904017108259723}, {"id": 83, "seek": 25184, "start": 251.84, "end": 255.28, "text": " one dashboard and one report if possible or close to that,", "tokens": [472, 18342, 293, 472, 2275, 498, 1944, 420, 1998, 281, 300, 11], "temperature": 0.0, "avg_logprob": -0.20658229424701474, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.0002163277822546661}, {"id": 84, "seek": 25184, "start": 255.28, "end": 258.12, "text": " and as well to save the developer's attention,", "tokens": [293, 382, 731, 281, 3155, 264, 10754, 311, 3202, 11], "temperature": 0.0, "avg_logprob": -0.20658229424701474, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.0002163277822546661}, {"id": 85, "seek": 25184, "start": 258.12, "end": 261.28000000000003, "text": " which is a precious resource because as you see,", "tokens": [597, 307, 257, 12406, 7684, 570, 382, 291, 536, 11], "temperature": 0.0, "avg_logprob": -0.20658229424701474, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.0002163277822546661}, {"id": 86, "seek": 25184, "start": 261.28000000000003, "end": 264.36, "text": " it's not so easy to investigate every report", "tokens": [309, 311, 406, 370, 1858, 281, 15013, 633, 2275], "temperature": 0.0, "avg_logprob": -0.20658229424701474, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.0002163277822546661}, {"id": 87, "seek": 25184, "start": 264.36, "end": 267.68, "text": " and from different CI systems", "tokens": [293, 490, 819, 37777, 3652], "temperature": 0.0, "avg_logprob": -0.20658229424701474, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.0002163277822546661}, {"id": 88, "seek": 25184, "start": 267.68, "end": 270.44, "text": " because they are differently formatted emails,", "tokens": [570, 436, 366, 7614, 1254, 32509, 12524, 11], "temperature": 0.0, "avg_logprob": -0.20658229424701474, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.0002163277822546661}, {"id": 89, "seek": 25184, "start": 270.44, "end": 272.44, "text": " different data, different dashboards,", "tokens": [819, 1412, 11, 819, 8240, 17228, 11], "temperature": 0.0, "avg_logprob": -0.20658229424701474, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.0002163277822546661}, {"id": 90, "seek": 25184, "start": 272.44, "end": 273.52, "text": " you have to look at them this way,", "tokens": [291, 362, 281, 574, 412, 552, 341, 636, 11], "temperature": 0.0, "avg_logprob": -0.20658229424701474, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.0002163277822546661}, {"id": 91, "seek": 25184, "start": 273.52, "end": 275.68, "text": " that way, and you have to figure it out.", "tokens": [300, 636, 11, 293, 291, 362, 281, 2573, 309, 484, 13], "temperature": 0.0, "avg_logprob": -0.20658229424701474, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.0002163277822546661}, {"id": 92, "seek": 25184, "start": 275.68, "end": 278.28000000000003, "text": " So that's case IDB is the effort to bring", "tokens": [407, 300, 311, 1389, 7348, 33, 307, 264, 4630, 281, 1565], "temperature": 0.0, "avg_logprob": -0.20658229424701474, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.0002163277822546661}, {"id": 93, "seek": 25184, "start": 278.28000000000003, "end": 280.72, "text": " this one into all the wall.", "tokens": [341, 472, 666, 439, 264, 2929, 13], "temperature": 0.0, "avg_logprob": -0.20658229424701474, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.0002163277822546661}, {"id": 94, "seek": 28072, "start": 280.72, "end": 285.44000000000005, "text": " So conceptually, it's very simple,", "tokens": [407, 3410, 671, 11, 309, 311, 588, 2199, 11], "temperature": 0.0, "avg_logprob": -0.23211724196023087, "compression_ratio": 1.7389705882352942, "no_speech_prob": 5.3915009630145505e-05}, {"id": 95, "seek": 28072, "start": 285.44000000000005, "end": 287.84000000000003, "text": " these are systems and JSON which can consist", "tokens": [613, 366, 3652, 293, 31828, 597, 393, 4603], "temperature": 0.0, "avg_logprob": -0.23211724196023087, "compression_ratio": 1.7389705882352942, "no_speech_prob": 5.3915009630145505e-05}, {"id": 96, "seek": 28072, "start": 287.84000000000003, "end": 291.36, "text": " like various objects in any combination,", "tokens": [411, 3683, 6565, 294, 604, 6562, 11], "temperature": 0.0, "avg_logprob": -0.23211724196023087, "compression_ratio": 1.7389705882352942, "no_speech_prob": 5.3915009630145505e-05}, {"id": 97, "seek": 28072, "start": 291.36, "end": 293.0, "text": " and we have the database we put them in,", "tokens": [293, 321, 362, 264, 8149, 321, 829, 552, 294, 11], "temperature": 0.0, "avg_logprob": -0.23211724196023087, "compression_ratio": 1.7389705882352942, "no_speech_prob": 5.3915009630145505e-05}, {"id": 98, "seek": 28072, "start": 293.0, "end": 295.04, "text": " we have the dashboard to display that,", "tokens": [321, 362, 264, 18342, 281, 4674, 300, 11], "temperature": 0.0, "avg_logprob": -0.23211724196023087, "compression_ratio": 1.7389705882352942, "no_speech_prob": 5.3915009630145505e-05}, {"id": 99, "seek": 28072, "start": 295.04, "end": 298.48, "text": " and we have a subscription system where you can give", "tokens": [293, 321, 362, 257, 17231, 1185, 689, 291, 393, 976], "temperature": 0.0, "avg_logprob": -0.23211724196023087, "compression_ratio": 1.7389705882352942, "no_speech_prob": 5.3915009630145505e-05}, {"id": 100, "seek": 28072, "start": 298.48, "end": 299.56, "text": " some rules and say like, okay,", "tokens": [512, 4474, 293, 584, 411, 11, 1392, 11], "temperature": 0.0, "avg_logprob": -0.23211724196023087, "compression_ratio": 1.7389705882352942, "no_speech_prob": 5.3915009630145505e-05}, {"id": 101, "seek": 28072, "start": 299.56, "end": 301.52000000000004, "text": " I want to see these results from this test and from", "tokens": [286, 528, 281, 536, 613, 3542, 490, 341, 1500, 293, 490], "temperature": 0.0, "avg_logprob": -0.23211724196023087, "compression_ratio": 1.7389705882352942, "no_speech_prob": 5.3915009630145505e-05}, {"id": 102, "seek": 28072, "start": 301.52000000000004, "end": 303.76000000000005, "text": " this tree or for this architecture or whatever,", "tokens": [341, 4230, 420, 337, 341, 9482, 420, 2035, 11], "temperature": 0.0, "avg_logprob": -0.23211724196023087, "compression_ratio": 1.7389705882352942, "no_speech_prob": 5.3915009630145505e-05}, {"id": 103, "seek": 28072, "start": 303.76000000000005, "end": 306.04, "text": " and we can generate the reports based on", "tokens": [293, 321, 393, 8460, 264, 7122, 2361, 322], "temperature": 0.0, "avg_logprob": -0.23211724196023087, "compression_ratio": 1.7389705882352942, "no_speech_prob": 5.3915009630145505e-05}, {"id": 104, "seek": 28072, "start": 306.04, "end": 309.32000000000005, "text": " that whenever you need it as the data comes in.", "tokens": [300, 5699, 291, 643, 309, 382, 264, 1412, 1487, 294, 13], "temperature": 0.0, "avg_logprob": -0.23211724196023087, "compression_ratio": 1.7389705882352942, "no_speech_prob": 5.3915009630145505e-05}, {"id": 105, "seek": 30932, "start": 309.32, "end": 312.15999999999997, "text": " One important note about this is that", "tokens": [1485, 1021, 3637, 466, 341, 307, 300], "temperature": 0.0, "avg_logprob": -0.20002226829528807, "compression_ratio": 1.8523206751054853, "no_speech_prob": 6.334564386634156e-05}, {"id": 106, "seek": 30932, "start": 312.15999999999997, "end": 316.56, "text": " compared to our regular CI system where you control everything,", "tokens": [5347, 281, 527, 3890, 37777, 1185, 689, 291, 1969, 1203, 11], "temperature": 0.0, "avg_logprob": -0.20002226829528807, "compression_ratio": 1.8523206751054853, "no_speech_prob": 6.334564386634156e-05}, {"id": 107, "seek": 30932, "start": 316.56, "end": 320.59999999999997, "text": " in this system, the data can come in in any order.", "tokens": [294, 341, 1185, 11, 264, 1412, 393, 808, 294, 294, 604, 1668, 13], "temperature": 0.0, "avg_logprob": -0.20002226829528807, "compression_ratio": 1.8523206751054853, "no_speech_prob": 6.334564386634156e-05}, {"id": 108, "seek": 30932, "start": 320.59999999999997, "end": 322.36, "text": " In a regular CI system, you have", "tokens": [682, 257, 3890, 37777, 1185, 11, 291, 362], "temperature": 0.0, "avg_logprob": -0.20002226829528807, "compression_ratio": 1.8523206751054853, "no_speech_prob": 6.334564386634156e-05}, {"id": 109, "seek": 30932, "start": 322.36, "end": 324.88, "text": " the results come in the same order as commits come in.", "tokens": [264, 3542, 808, 294, 264, 912, 1668, 382, 48311, 808, 294, 13], "temperature": 0.0, "avg_logprob": -0.20002226829528807, "compression_ratio": 1.8523206751054853, "no_speech_prob": 6.334564386634156e-05}, {"id": 110, "seek": 30932, "start": 324.88, "end": 327.15999999999997, "text": " So if you tested something earlier,", "tokens": [407, 498, 291, 8246, 746, 3071, 11], "temperature": 0.0, "avg_logprob": -0.20002226829528807, "compression_ratio": 1.8523206751054853, "no_speech_prob": 6.334564386634156e-05}, {"id": 111, "seek": 30932, "start": 327.15999999999997, "end": 328.56, "text": " that means for an earlier commit,", "tokens": [300, 1355, 337, 364, 3071, 5599, 11], "temperature": 0.0, "avg_logprob": -0.20002226829528807, "compression_ratio": 1.8523206751054853, "no_speech_prob": 6.334564386634156e-05}, {"id": 112, "seek": 30932, "start": 328.56, "end": 329.68, "text": " if you tested something later,", "tokens": [498, 291, 8246, 746, 1780, 11], "temperature": 0.0, "avg_logprob": -0.20002226829528807, "compression_ratio": 1.8523206751054853, "no_speech_prob": 6.334564386634156e-05}, {"id": 113, "seek": 30932, "start": 329.68, "end": 331.2, "text": " it's for a later commit,", "tokens": [309, 311, 337, 257, 1780, 5599, 11], "temperature": 0.0, "avg_logprob": -0.20002226829528807, "compression_ratio": 1.8523206751054853, "no_speech_prob": 6.334564386634156e-05}, {"id": 114, "seek": 30932, "start": 331.2, "end": 335.24, "text": " and you can have a line of history with those results.", "tokens": [293, 291, 393, 362, 257, 1622, 295, 2503, 365, 729, 3542, 13], "temperature": 0.0, "avg_logprob": -0.20002226829528807, "compression_ratio": 1.8523206751054853, "no_speech_prob": 6.334564386634156e-05}, {"id": 115, "seek": 30932, "start": 335.24, "end": 336.96, "text": " But for case IDB,", "tokens": [583, 337, 1389, 7348, 33, 11], "temperature": 0.0, "avg_logprob": -0.20002226829528807, "compression_ratio": 1.8523206751054853, "no_speech_prob": 6.334564386634156e-05}, {"id": 116, "seek": 33696, "start": 336.96, "end": 340.03999999999996, "text": " since various different CI systems,", "tokens": [1670, 3683, 819, 37777, 3652, 11], "temperature": 0.0, "avg_logprob": -0.30258260170618695, "compression_ratio": 1.5136363636363637, "no_speech_prob": 9.556997247273102e-05}, {"id": 117, "seek": 33696, "start": 340.03999999999996, "end": 343.28, "text": " they get in any order you wish.", "tokens": [436, 483, 294, 604, 1668, 291, 3172, 13], "temperature": 0.0, "avg_logprob": -0.30258260170618695, "compression_ratio": 1.5136363636363637, "no_speech_prob": 9.556997247273102e-05}, {"id": 118, "seek": 33696, "start": 343.28, "end": 349.52, "text": " So we have about 100,000 test results per day,", "tokens": [407, 321, 362, 466, 2319, 11, 1360, 1500, 3542, 680, 786, 11], "temperature": 0.0, "avg_logprob": -0.30258260170618695, "compression_ratio": 1.5136363636363637, "no_speech_prob": 9.556997247273102e-05}, {"id": 119, "seek": 33696, "start": 349.52, "end": 351.4, "text": " a few thousands of builds,", "tokens": [257, 1326, 5383, 295, 15182, 11], "temperature": 0.0, "avg_logprob": -0.30258260170618695, "compression_ratio": 1.5136363636363637, "no_speech_prob": 9.556997247273102e-05}, {"id": 120, "seek": 33696, "start": 351.4, "end": 354.15999999999997, "text": " and hundreds of 100 revisions per day tests", "tokens": [293, 6779, 295, 2319, 3698, 4252, 680, 786, 6921], "temperature": 0.0, "avg_logprob": -0.30258260170618695, "compression_ratio": 1.5136363636363637, "no_speech_prob": 9.556997247273102e-05}, {"id": 121, "seek": 33696, "start": 354.15999999999997, "end": 357.28, "text": " that received by the case IDB database.", "tokens": [300, 4613, 538, 264, 1389, 7348, 33, 8149, 13], "temperature": 0.0, "avg_logprob": -0.30258260170618695, "compression_ratio": 1.5136363636363637, "no_speech_prob": 9.556997247273102e-05}, {"id": 122, "seek": 33696, "start": 357.28, "end": 360.88, "text": " Well, actually, I think, yeah, that's correct.", "tokens": [1042, 11, 767, 11, 286, 519, 11, 1338, 11, 300, 311, 3006, 13], "temperature": 0.0, "avg_logprob": -0.30258260170618695, "compression_ratio": 1.5136363636363637, "no_speech_prob": 9.556997247273102e-05}, {"id": 123, "seek": 33696, "start": 360.88, "end": 362.47999999999996, "text": " That's the correct scale.", "tokens": [663, 311, 264, 3006, 4373, 13], "temperature": 0.0, "avg_logprob": -0.30258260170618695, "compression_ratio": 1.5136363636363637, "no_speech_prob": 9.556997247273102e-05}, {"id": 124, "seek": 33696, "start": 362.47999999999996, "end": 364.47999999999996, "text": " So it looks something like this as", "tokens": [407, 309, 1542, 746, 411, 341, 382], "temperature": 0.0, "avg_logprob": -0.30258260170618695, "compression_ratio": 1.5136363636363637, "no_speech_prob": 9.556997247273102e-05}, {"id": 125, "seek": 36448, "start": 364.48, "end": 367.8, "text": " Grafana is like a prototype dashboard.", "tokens": [8985, 69, 2095, 307, 411, 257, 19475, 18342, 13], "temperature": 0.0, "avg_logprob": -0.21036946332013165, "compression_ratio": 1.5864978902953586, "no_speech_prob": 0.0001579449890414253}, {"id": 126, "seek": 36448, "start": 367.8, "end": 369.16, "text": " We're thinking about building a new one,", "tokens": [492, 434, 1953, 466, 2390, 257, 777, 472, 11], "temperature": 0.0, "avg_logprob": -0.21036946332013165, "compression_ratio": 1.5864978902953586, "no_speech_prob": 0.0001579449890414253}, {"id": 127, "seek": 36448, "start": 369.16, "end": 371.88, "text": " but I don't know how soon that's going to happen.", "tokens": [457, 286, 500, 380, 458, 577, 2321, 300, 311, 516, 281, 1051, 13], "temperature": 0.0, "avg_logprob": -0.21036946332013165, "compression_ratio": 1.5864978902953586, "no_speech_prob": 0.0001579449890414253}, {"id": 128, "seek": 36448, "start": 371.88, "end": 375.24, "text": " So graphs, tables, all that jazz.", "tokens": [407, 24877, 11, 8020, 11, 439, 300, 15066, 13], "temperature": 0.0, "avg_logprob": -0.21036946332013165, "compression_ratio": 1.5864978902953586, "no_speech_prob": 0.0001579449890414253}, {"id": 129, "seek": 36448, "start": 375.24, "end": 379.88, "text": " This is our prototype reports look like this.", "tokens": [639, 307, 527, 19475, 7122, 574, 411, 341, 13], "temperature": 0.0, "avg_logprob": -0.21036946332013165, "compression_ratio": 1.5864978902953586, "no_speech_prob": 0.0001579449890414253}, {"id": 130, "seek": 36448, "start": 379.88, "end": 384.0, "text": " So what's the problem with the kernel CI in general,", "tokens": [407, 437, 311, 264, 1154, 365, 264, 28256, 37777, 294, 2674, 11], "temperature": 0.0, "avg_logprob": -0.21036946332013165, "compression_ratio": 1.5864978902953586, "no_speech_prob": 0.0001579449890414253}, {"id": 131, "seek": 36448, "start": 384.0, "end": 386.48, "text": " not with the kernel CI, the project?", "tokens": [406, 365, 264, 28256, 37777, 11, 264, 1716, 30], "temperature": 0.0, "avg_logprob": -0.21036946332013165, "compression_ratio": 1.5864978902953586, "no_speech_prob": 0.0001579449890414253}, {"id": 132, "seek": 36448, "start": 386.48, "end": 389.8, "text": " So first of all,", "tokens": [407, 700, 295, 439, 11], "temperature": 0.0, "avg_logprob": -0.21036946332013165, "compression_ratio": 1.5864978902953586, "no_speech_prob": 0.0001579449890414253}, {"id": 133, "seek": 36448, "start": 389.8, "end": 392.28000000000003, "text": " kernel is intended to be", "tokens": [28256, 307, 10226, 281, 312], "temperature": 0.0, "avg_logprob": -0.21036946332013165, "compression_ratio": 1.5864978902953586, "no_speech_prob": 0.0001579449890414253}, {"id": 134, "seek": 36448, "start": 392.28000000000003, "end": 393.68, "text": " an obstruction layer for hardware.", "tokens": [364, 49711, 4583, 337, 8837, 13], "temperature": 0.0, "avg_logprob": -0.21036946332013165, "compression_ratio": 1.5864978902953586, "no_speech_prob": 0.0001579449890414253}, {"id": 135, "seek": 39368, "start": 393.68, "end": 395.08, "text": " That's this whole purpose,", "tokens": [663, 311, 341, 1379, 4334, 11], "temperature": 0.0, "avg_logprob": -0.17211984649417908, "compression_ratio": 1.8, "no_speech_prob": 9.598107862984762e-05}, {"id": 136, "seek": 39368, "start": 395.08, "end": 397.36, "text": " and to make it easier to write software.", "tokens": [293, 281, 652, 309, 3571, 281, 2464, 4722, 13], "temperature": 0.0, "avg_logprob": -0.17211984649417908, "compression_ratio": 1.8, "no_speech_prob": 9.598107862984762e-05}, {"id": 137, "seek": 39368, "start": 397.36, "end": 401.16, "text": " So in theory, to make sure that it works,", "tokens": [407, 294, 5261, 11, 281, 652, 988, 300, 309, 1985, 11], "temperature": 0.0, "avg_logprob": -0.17211984649417908, "compression_ratio": 1.8, "no_speech_prob": 9.598107862984762e-05}, {"id": 138, "seek": 39368, "start": 401.16, "end": 402.36, "text": " you have to test it with every piece", "tokens": [291, 362, 281, 1500, 309, 365, 633, 2522], "temperature": 0.0, "avg_logprob": -0.17211984649417908, "compression_ratio": 1.8, "no_speech_prob": 9.598107862984762e-05}, {"id": 139, "seek": 39368, "start": 402.36, "end": 403.84000000000003, "text": " that you're abstract away from.", "tokens": [300, 291, 434, 12649, 1314, 490, 13], "temperature": 0.0, "avg_logprob": -0.17211984649417908, "compression_ratio": 1.8, "no_speech_prob": 9.598107862984762e-05}, {"id": 140, "seek": 39368, "start": 403.84000000000003, "end": 405.8, "text": " But that's not possible, of course,", "tokens": [583, 300, 311, 406, 1944, 11, 295, 1164, 11], "temperature": 0.0, "avg_logprob": -0.17211984649417908, "compression_ratio": 1.8, "no_speech_prob": 9.598107862984762e-05}, {"id": 141, "seek": 39368, "start": 405.8, "end": 407.40000000000003, "text": " and hardware is expensive,", "tokens": [293, 8837, 307, 5124, 11], "temperature": 0.0, "avg_logprob": -0.17211984649417908, "compression_ratio": 1.8, "no_speech_prob": 9.598107862984762e-05}, {"id": 142, "seek": 39368, "start": 407.40000000000003, "end": 411.08, "text": " so it's a natural scarcity in this whole system.", "tokens": [370, 309, 311, 257, 3303, 44181, 294, 341, 1379, 1185, 13], "temperature": 0.0, "avg_logprob": -0.17211984649417908, "compression_ratio": 1.8, "no_speech_prob": 9.598107862984762e-05}, {"id": 143, "seek": 39368, "start": 411.08, "end": 414.04, "text": " Then the tests, since you cannot get", "tokens": [1396, 264, 6921, 11, 1670, 291, 2644, 483], "temperature": 0.0, "avg_logprob": -0.17211984649417908, "compression_ratio": 1.8, "no_speech_prob": 9.598107862984762e-05}, {"id": 144, "seek": 39368, "start": 414.04, "end": 416.24, "text": " all the hardware at the same time,", "tokens": [439, 264, 8837, 412, 264, 912, 565, 11], "temperature": 0.0, "avg_logprob": -0.17211984649417908, "compression_ratio": 1.8, "no_speech_prob": 9.598107862984762e-05}, {"id": 145, "seek": 39368, "start": 416.24, "end": 418.6, "text": " and you cannot possibly run all the tests on", "tokens": [293, 291, 2644, 6264, 1190, 439, 264, 6921, 322], "temperature": 0.0, "avg_logprob": -0.17211984649417908, "compression_ratio": 1.8, "no_speech_prob": 9.598107862984762e-05}, {"id": 146, "seek": 39368, "start": 418.6, "end": 422.64, "text": " all the hardware for every commit that people post,", "tokens": [439, 264, 8837, 337, 633, 5599, 300, 561, 2183, 11], "temperature": 0.0, "avg_logprob": -0.17211984649417908, "compression_ratio": 1.8, "no_speech_prob": 9.598107862984762e-05}, {"id": 147, "seek": 42264, "start": 422.64, "end": 425.24, "text": " it means that sometimes the tests run on this hardware,", "tokens": [309, 1355, 300, 2171, 264, 6921, 1190, 322, 341, 8837, 11], "temperature": 0.0, "avg_logprob": -0.17516190296894796, "compression_ratio": 2.0346153846153845, "no_speech_prob": 0.00011319992336211726}, {"id": 148, "seek": 42264, "start": 425.24, "end": 426.28, "text": " sometimes on that hardware,", "tokens": [2171, 322, 300, 8837, 11], "temperature": 0.0, "avg_logprob": -0.17516190296894796, "compression_ratio": 2.0346153846153845, "no_speech_prob": 0.00011319992336211726}, {"id": 149, "seek": 42264, "start": 426.28, "end": 428.0, "text": " sometimes they don't run,", "tokens": [2171, 436, 500, 380, 1190, 11], "temperature": 0.0, "avg_logprob": -0.17516190296894796, "compression_ratio": 2.0346153846153845, "no_speech_prob": 0.00011319992336211726}, {"id": 150, "seek": 42264, "start": 428.0, "end": 431.47999999999996, "text": " and the tests themselves are not so reliable", "tokens": [293, 264, 6921, 2969, 366, 406, 370, 12924], "temperature": 0.0, "avg_logprob": -0.17516190296894796, "compression_ratio": 2.0346153846153845, "no_speech_prob": 0.00011319992336211726}, {"id": 151, "seek": 42264, "start": 431.47999999999996, "end": 432.36, "text": " because there's a lot of", "tokens": [570, 456, 311, 257, 688, 295], "temperature": 0.0, "avg_logprob": -0.17516190296894796, "compression_ratio": 2.0346153846153845, "no_speech_prob": 0.00011319992336211726}, {"id": 152, "seek": 42264, "start": 432.36, "end": 433.91999999999996, "text": " concurrency management in the kernel,", "tokens": [23702, 10457, 4592, 294, 264, 28256, 11], "temperature": 0.0, "avg_logprob": -0.17516190296894796, "compression_ratio": 2.0346153846153845, "no_speech_prob": 0.00011319992336211726}, {"id": 153, "seek": 42264, "start": 433.91999999999996, "end": 435.44, "text": " and that's hard to get right,", "tokens": [293, 300, 311, 1152, 281, 483, 558, 11], "temperature": 0.0, "avg_logprob": -0.17516190296894796, "compression_ratio": 2.0346153846153845, "no_speech_prob": 0.00011319992336211726}, {"id": 154, "seek": 42264, "start": 435.44, "end": 437.03999999999996, "text": " and in general, things happen at", "tokens": [293, 294, 2674, 11, 721, 1051, 412], "temperature": 0.0, "avg_logprob": -0.17516190296894796, "compression_ratio": 2.0346153846153845, "no_speech_prob": 0.00011319992336211726}, {"id": 155, "seek": 42264, "start": 437.03999999999996, "end": 438.56, "text": " the same time in the operating system,", "tokens": [264, 912, 565, 294, 264, 7447, 1185, 11], "temperature": 0.0, "avg_logprob": -0.17516190296894796, "compression_ratio": 2.0346153846153845, "no_speech_prob": 0.00011319992336211726}, {"id": 156, "seek": 42264, "start": 438.56, "end": 441.64, "text": " so then sometimes they're not so reliable.", "tokens": [370, 550, 2171, 436, 434, 406, 370, 12924, 13], "temperature": 0.0, "avg_logprob": -0.17516190296894796, "compression_ratio": 2.0346153846153845, "no_speech_prob": 0.00011319992336211726}, {"id": 157, "seek": 42264, "start": 441.64, "end": 444.88, "text": " So you can get a pass on your change,", "tokens": [407, 291, 393, 483, 257, 1320, 322, 428, 1319, 11], "temperature": 0.0, "avg_logprob": -0.17516190296894796, "compression_ratio": 2.0346153846153845, "no_speech_prob": 0.00011319992336211726}, {"id": 158, "seek": 42264, "start": 444.88, "end": 447.03999999999996, "text": " even if it's broken or get a fail on your change,", "tokens": [754, 498, 309, 311, 5463, 420, 483, 257, 3061, 322, 428, 1319, 11], "temperature": 0.0, "avg_logprob": -0.17516190296894796, "compression_ratio": 2.0346153846153845, "no_speech_prob": 0.00011319992336211726}, {"id": 159, "seek": 42264, "start": 447.03999999999996, "end": 449.03999999999996, "text": " even if it's not broken,", "tokens": [754, 498, 309, 311, 406, 5463, 11], "temperature": 0.0, "avg_logprob": -0.17516190296894796, "compression_ratio": 2.0346153846153845, "no_speech_prob": 0.00011319992336211726}, {"id": 160, "seek": 42264, "start": 449.03999999999996, "end": 451.68, "text": " or even if it's somebody else's change that broke it,", "tokens": [420, 754, 498, 309, 311, 2618, 1646, 311, 1319, 300, 6902, 309, 11], "temperature": 0.0, "avg_logprob": -0.17516190296894796, "compression_ratio": 2.0346153846153845, "no_speech_prob": 0.00011319992336211726}, {"id": 161, "seek": 45168, "start": 451.68, "end": 452.92, "text": " basically, hell.", "tokens": [1936, 11, 4921, 13], "temperature": 0.0, "avg_logprob": -0.26467100240416447, "compression_ratio": 1.7634854771784232, "no_speech_prob": 5.638235961669125e-05}, {"id": 162, "seek": 45168, "start": 452.92, "end": 457.40000000000003, "text": " So it's hard to remove noise from those results,", "tokens": [407, 309, 311, 1152, 281, 4159, 5658, 490, 729, 3542, 11], "temperature": 0.0, "avg_logprob": -0.26467100240416447, "compression_ratio": 1.7634854771784232, "no_speech_prob": 5.638235961669125e-05}, {"id": 163, "seek": 45168, "start": 457.40000000000003, "end": 460.64, "text": " and for developers,", "tokens": [293, 337, 8849, 11], "temperature": 0.0, "avg_logprob": -0.26467100240416447, "compression_ratio": 1.7634854771784232, "no_speech_prob": 5.638235961669125e-05}, {"id": 164, "seek": 45168, "start": 460.64, "end": 463.0, "text": " it's hard to investigate even a valid change.", "tokens": [309, 311, 1152, 281, 15013, 754, 257, 7363, 1319, 13], "temperature": 0.0, "avg_logprob": -0.26467100240416447, "compression_ratio": 1.7634854771784232, "no_speech_prob": 5.638235961669125e-05}, {"id": 165, "seek": 45168, "start": 463.0, "end": 464.12, "text": " While it's a kernel,", "tokens": [3987, 309, 311, 257, 28256, 11], "temperature": 0.0, "avg_logprob": -0.26467100240416447, "compression_ratio": 1.7634854771784232, "no_speech_prob": 5.638235961669125e-05}, {"id": 166, "seek": 45168, "start": 464.12, "end": 465.68, "text": " you have to meet all the conditions,", "tokens": [291, 362, 281, 1677, 439, 264, 4487, 11], "temperature": 0.0, "avg_logprob": -0.26467100240416447, "compression_ratio": 1.7634854771784232, "no_speech_prob": 5.638235961669125e-05}, {"id": 167, "seek": 45168, "start": 465.68, "end": 467.64, "text": " and well, sometimes you have to get the right hardware,", "tokens": [293, 731, 11, 2171, 291, 362, 281, 483, 264, 558, 8837, 11], "temperature": 0.0, "avg_logprob": -0.26467100240416447, "compression_ratio": 1.7634854771784232, "no_speech_prob": 5.638235961669125e-05}, {"id": 168, "seek": 45168, "start": 467.64, "end": 469.04, "text": " or ask people for the right hardware,", "tokens": [420, 1029, 561, 337, 264, 558, 8837, 11], "temperature": 0.0, "avg_logprob": -0.26467100240416447, "compression_ratio": 1.7634854771784232, "no_speech_prob": 5.638235961669125e-05}, {"id": 169, "seek": 45168, "start": 469.04, "end": 471.68, "text": " or ask them to actually run the test and send you results,", "tokens": [420, 1029, 552, 281, 767, 1190, 264, 1500, 293, 2845, 291, 3542, 11], "temperature": 0.0, "avg_logprob": -0.26467100240416447, "compression_ratio": 1.7634854771784232, "no_speech_prob": 5.638235961669125e-05}, {"id": 170, "seek": 45168, "start": 471.68, "end": 474.88, "text": " like you know, over email takes a while.", "tokens": [411, 291, 458, 11, 670, 3796, 2516, 257, 1339, 13], "temperature": 0.0, "avg_logprob": -0.26467100240416447, "compression_ratio": 1.7634854771784232, "no_speech_prob": 5.638235961669125e-05}, {"id": 171, "seek": 45168, "start": 474.88, "end": 478.72, "text": " So if we start sending people emails with", "tokens": [407, 498, 321, 722, 7750, 561, 12524, 365], "temperature": 0.0, "avg_logprob": -0.26467100240416447, "compression_ratio": 1.7634854771784232, "no_speech_prob": 5.638235961669125e-05}, {"id": 172, "seek": 47872, "start": 478.72, "end": 482.24, "text": " results that are not valid,", "tokens": [3542, 300, 366, 406, 7363, 11], "temperature": 0.0, "avg_logprob": -0.2083916530430874, "compression_ratio": 1.6553191489361703, "no_speech_prob": 0.00017776270397007465}, {"id": 173, "seek": 47872, "start": 482.24, "end": 484.28000000000003, "text": " false positive, false negatives,", "tokens": [7908, 3353, 11, 7908, 40019, 11], "temperature": 0.0, "avg_logprob": -0.2083916530430874, "compression_ratio": 1.6553191489361703, "no_speech_prob": 0.00017776270397007465}, {"id": 174, "seek": 47872, "start": 484.28000000000003, "end": 487.8, "text": " then people kind of get pissed because of that,", "tokens": [550, 561, 733, 295, 483, 23795, 570, 295, 300, 11], "temperature": 0.0, "avg_logprob": -0.2083916530430874, "compression_ratio": 1.6553191489361703, "no_speech_prob": 0.00017776270397007465}, {"id": 175, "seek": 47872, "start": 487.8, "end": 490.76000000000005, "text": " because it takes such a long time to reproduce them.", "tokens": [570, 309, 2516, 1270, 257, 938, 565, 281, 29501, 552, 13], "temperature": 0.0, "avg_logprob": -0.2083916530430874, "compression_ratio": 1.6553191489361703, "no_speech_prob": 0.00017776270397007465}, {"id": 176, "seek": 47872, "start": 490.76000000000005, "end": 494.92, "text": " So a lot of CI systems resort to", "tokens": [407, 257, 688, 295, 37777, 3652, 19606, 281], "temperature": 0.0, "avg_logprob": -0.2083916530430874, "compression_ratio": 1.6553191489361703, "no_speech_prob": 0.00017776270397007465}, {"id": 177, "seek": 47872, "start": 494.92, "end": 497.16, "text": " human review before sending those reports,", "tokens": [1952, 3131, 949, 7750, 729, 7122, 11], "temperature": 0.0, "avg_logprob": -0.2083916530430874, "compression_ratio": 1.6553191489361703, "no_speech_prob": 0.00017776270397007465}, {"id": 178, "seek": 47872, "start": 497.16, "end": 498.84000000000003, "text": " like they see the failures,", "tokens": [411, 436, 536, 264, 20774, 11], "temperature": 0.0, "avg_logprob": -0.2083916530430874, "compression_ratio": 1.6553191489361703, "no_speech_prob": 0.00017776270397007465}, {"id": 179, "seek": 47872, "start": 498.84000000000003, "end": 500.36, "text": " they say, okay, well, let's send this to", "tokens": [436, 584, 11, 1392, 11, 731, 11, 718, 311, 2845, 341, 281], "temperature": 0.0, "avg_logprob": -0.2083916530430874, "compression_ratio": 1.6553191489361703, "no_speech_prob": 0.00017776270397007465}, {"id": 180, "seek": 47872, "start": 500.36, "end": 502.48, "text": " this mail list and then they send them,", "tokens": [341, 10071, 1329, 293, 550, 436, 2845, 552, 11], "temperature": 0.0, "avg_logprob": -0.2083916530430874, "compression_ratio": 1.6553191489361703, "no_speech_prob": 0.00017776270397007465}, {"id": 181, "seek": 47872, "start": 502.48, "end": 506.76000000000005, "text": " and only a few manage without that so far.", "tokens": [293, 787, 257, 1326, 3067, 1553, 300, 370, 1400, 13], "temperature": 0.0, "avg_logprob": -0.2083916530430874, "compression_ratio": 1.6553191489361703, "no_speech_prob": 0.00017776270397007465}, {"id": 182, "seek": 50676, "start": 506.76, "end": 511.4, "text": " So obviously, nobody stops the development to fix CI,", "tokens": [407, 2745, 11, 5079, 10094, 264, 3250, 281, 3191, 37777, 11], "temperature": 0.0, "avg_logprob": -0.22625673862925746, "compression_ratio": 1.6923076923076923, "no_speech_prob": 1.8118669686373323e-05}, {"id": 183, "seek": 50676, "start": 511.4, "end": 513.28, "text": " because there's just so many developers,", "tokens": [570, 456, 311, 445, 370, 867, 8849, 11], "temperature": 0.0, "avg_logprob": -0.22625673862925746, "compression_ratio": 1.6923076923076923, "no_speech_prob": 1.8118669686373323e-05}, {"id": 184, "seek": 50676, "start": 513.28, "end": 515.76, "text": " and if one system breaks something,", "tokens": [293, 498, 472, 1185, 9857, 746, 11], "temperature": 0.0, "avg_logprob": -0.22625673862925746, "compression_ratio": 1.6923076923076923, "no_speech_prob": 1.8118669686373323e-05}, {"id": 185, "seek": 50676, "start": 515.76, "end": 519.16, "text": " like another subsystem doesn't want to care about that,", "tokens": [411, 1071, 2090, 9321, 1177, 380, 528, 281, 1127, 466, 300, 11], "temperature": 0.0, "avg_logprob": -0.22625673862925746, "compression_ratio": 1.6923076923076923, "no_speech_prob": 1.8118669686373323e-05}, {"id": 186, "seek": 50676, "start": 519.16, "end": 523.52, "text": " and the feedback loop is just too long.", "tokens": [293, 264, 5824, 6367, 307, 445, 886, 938, 13], "temperature": 0.0, "avg_logprob": -0.22625673862925746, "compression_ratio": 1.6923076923076923, "no_speech_prob": 1.8118669686373323e-05}, {"id": 187, "seek": 50676, "start": 523.52, "end": 524.72, "text": " So tests keep running,", "tokens": [407, 6921, 1066, 2614, 11], "temperature": 0.0, "avg_logprob": -0.22625673862925746, "compression_ratio": 1.6923076923076923, "no_speech_prob": 1.8118669686373323e-05}, {"id": 188, "seek": 50676, "start": 524.72, "end": 526.8, "text": " keep failing, and it takes a while to fix them.", "tokens": [1066, 18223, 11, 293, 309, 2516, 257, 1339, 281, 3191, 552, 13], "temperature": 0.0, "avg_logprob": -0.22625673862925746, "compression_ratio": 1.6923076923076923, "no_speech_prob": 1.8118669686373323e-05}, {"id": 189, "seek": 50676, "start": 526.8, "end": 529.36, "text": " So instead of the ideal case where you can move", "tokens": [407, 2602, 295, 264, 7157, 1389, 689, 291, 393, 1286], "temperature": 0.0, "avg_logprob": -0.22625673862925746, "compression_ratio": 1.6923076923076923, "no_speech_prob": 1.8118669686373323e-05}, {"id": 190, "seek": 50676, "start": 529.36, "end": 533.88, "text": " past, only move past the tests if they pass,", "tokens": [1791, 11, 787, 1286, 1791, 264, 6921, 498, 436, 1320, 11], "temperature": 0.0, "avg_logprob": -0.22625673862925746, "compression_ratio": 1.6923076923076923, "no_speech_prob": 1.8118669686373323e-05}, {"id": 191, "seek": 50676, "start": 533.88, "end": 535.28, "text": " and then do all the stages,", "tokens": [293, 550, 360, 439, 264, 10232, 11], "temperature": 0.0, "avg_logprob": -0.22625673862925746, "compression_ratio": 1.6923076923076923, "no_speech_prob": 1.8118669686373323e-05}, {"id": 192, "seek": 53528, "start": 535.28, "end": 537.12, "text": " like a review, and then it's merged, and it's test,", "tokens": [411, 257, 3131, 11, 293, 550, 309, 311, 36427, 11, 293, 309, 311, 1500, 11], "temperature": 0.0, "avg_logprob": -0.29337123555874606, "compression_ratio": 1.7061611374407584, "no_speech_prob": 2.0082217815797776e-05}, {"id": 193, "seek": 53528, "start": 537.12, "end": 538.8, "text": " and it's fine, and then you can upstream it,", "tokens": [293, 309, 311, 2489, 11, 293, 550, 291, 393, 33915, 309, 11], "temperature": 0.0, "avg_logprob": -0.29337123555874606, "compression_ratio": 1.7061611374407584, "no_speech_prob": 2.0082217815797776e-05}, {"id": 194, "seek": 53528, "start": 538.8, "end": 543.36, "text": " you get something like this where all tests fail,", "tokens": [291, 483, 746, 411, 341, 689, 439, 6921, 3061, 11], "temperature": 0.0, "avg_logprob": -0.29337123555874606, "compression_ratio": 1.7061611374407584, "no_speech_prob": 2.0082217815797776e-05}, {"id": 195, "seek": 53528, "start": 543.36, "end": 545.8, "text": " okay, it's probably not our problem,", "tokens": [1392, 11, 309, 311, 1391, 406, 527, 1154, 11], "temperature": 0.0, "avg_logprob": -0.29337123555874606, "compression_ratio": 1.7061611374407584, "no_speech_prob": 2.0082217815797776e-05}, {"id": 196, "seek": 53528, "start": 545.8, "end": 547.48, "text": " not have time to investigate it,", "tokens": [406, 362, 565, 281, 15013, 309, 11], "temperature": 0.0, "avg_logprob": -0.29337123555874606, "compression_ratio": 1.7061611374407584, "no_speech_prob": 2.0082217815797776e-05}, {"id": 197, "seek": 53528, "start": 547.48, "end": 550.68, "text": " or we just didn't get any test result with new one.", "tokens": [420, 321, 445, 994, 380, 483, 604, 1500, 1874, 365, 777, 472, 13], "temperature": 0.0, "avg_logprob": -0.29337123555874606, "compression_ratio": 1.7061611374407584, "no_speech_prob": 2.0082217815797776e-05}, {"id": 198, "seek": 53528, "start": 550.68, "end": 556.76, "text": " So what we're trying to do is we got to fix this, right?", "tokens": [407, 437, 321, 434, 1382, 281, 360, 307, 321, 658, 281, 3191, 341, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.29337123555874606, "compression_ratio": 1.7061611374407584, "no_speech_prob": 2.0082217815797776e-05}, {"id": 199, "seek": 53528, "start": 556.76, "end": 560.72, "text": " So we got to fix the test results.", "tokens": [407, 321, 658, 281, 3191, 264, 1500, 3542, 13], "temperature": 0.0, "avg_logprob": -0.29337123555874606, "compression_ratio": 1.7061611374407584, "no_speech_prob": 2.0082217815797776e-05}, {"id": 200, "seek": 56072, "start": 560.72, "end": 565.44, "text": " So we fix the test result.", "tokens": [407, 321, 3191, 264, 1500, 1874, 13], "temperature": 0.0, "avg_logprob": -0.17838751885198778, "compression_ratio": 1.6932773109243697, "no_speech_prob": 0.00017567866598255932}, {"id": 201, "seek": 56072, "start": 565.44, "end": 567.76, "text": " We look at the test output conditions,", "tokens": [492, 574, 412, 264, 1500, 5598, 4487, 11], "temperature": 0.0, "avg_logprob": -0.17838751885198778, "compression_ratio": 1.6932773109243697, "no_speech_prob": 0.00017567866598255932}, {"id": 202, "seek": 56072, "start": 567.76, "end": 570.28, "text": " et cetera, and we add a rule to the database saying like,", "tokens": [1030, 11458, 11, 293, 321, 909, 257, 4978, 281, 264, 8149, 1566, 411, 11], "temperature": 0.0, "avg_logprob": -0.17838751885198778, "compression_ratio": 1.6932773109243697, "no_speech_prob": 0.00017567866598255932}, {"id": 203, "seek": 56072, "start": 570.28, "end": 572.4, "text": " okay, well, this failed,", "tokens": [1392, 11, 731, 11, 341, 7612, 11], "temperature": 0.0, "avg_logprob": -0.17838751885198778, "compression_ratio": 1.6932773109243697, "no_speech_prob": 0.00017567866598255932}, {"id": 204, "seek": 56072, "start": 572.4, "end": 573.64, "text": " but we know about this,", "tokens": [457, 321, 458, 466, 341, 11], "temperature": 0.0, "avg_logprob": -0.17838751885198778, "compression_ratio": 1.6932773109243697, "no_speech_prob": 0.00017567866598255932}, {"id": 205, "seek": 56072, "start": 573.64, "end": 574.84, "text": " here's the bug that was open,", "tokens": [510, 311, 264, 7426, 300, 390, 1269, 11], "temperature": 0.0, "avg_logprob": -0.17838751885198778, "compression_ratio": 1.6932773109243697, "no_speech_prob": 0.00017567866598255932}, {"id": 206, "seek": 56072, "start": 574.84, "end": 577.28, "text": " so don't complain to developers,", "tokens": [370, 500, 380, 11024, 281, 8849, 11], "temperature": 0.0, "avg_logprob": -0.17838751885198778, "compression_ratio": 1.6932773109243697, "no_speech_prob": 0.00017567866598255932}, {"id": 207, "seek": 56072, "start": 577.28, "end": 579.88, "text": " don't waste their attention,", "tokens": [500, 380, 5964, 641, 3202, 11], "temperature": 0.0, "avg_logprob": -0.17838751885198778, "compression_ratio": 1.6932773109243697, "no_speech_prob": 0.00017567866598255932}, {"id": 208, "seek": 56072, "start": 579.88, "end": 582.96, "text": " and it looks like this,", "tokens": [293, 309, 1542, 411, 341, 11], "temperature": 0.0, "avg_logprob": -0.17838751885198778, "compression_ratio": 1.6932773109243697, "no_speech_prob": 0.00017567866598255932}, {"id": 209, "seek": 56072, "start": 582.96, "end": 584.24, "text": " shiny and sparkly,", "tokens": [16997, 293, 9908, 356, 11], "temperature": 0.0, "avg_logprob": -0.17838751885198778, "compression_ratio": 1.6932773109243697, "no_speech_prob": 0.00017567866598255932}, {"id": 210, "seek": 56072, "start": 584.24, "end": 585.5600000000001, "text": " but after a while,", "tokens": [457, 934, 257, 1339, 11], "temperature": 0.0, "avg_logprob": -0.17838751885198778, "compression_ratio": 1.6932773109243697, "no_speech_prob": 0.00017567866598255932}, {"id": 211, "seek": 56072, "start": 585.5600000000001, "end": 587.08, "text": " we get this fix into the test,", "tokens": [321, 483, 341, 3191, 666, 264, 1500, 11], "temperature": 0.0, "avg_logprob": -0.17838751885198778, "compression_ratio": 1.6932773109243697, "no_speech_prob": 0.00017567866598255932}, {"id": 212, "seek": 56072, "start": 587.08, "end": 589.6800000000001, "text": " and we repeat the process with another issue.", "tokens": [293, 321, 7149, 264, 1399, 365, 1071, 2734, 13], "temperature": 0.0, "avg_logprob": -0.17838751885198778, "compression_ratio": 1.6932773109243697, "no_speech_prob": 0.00017567866598255932}, {"id": 213, "seek": 58968, "start": 589.68, "end": 592.4399999999999, "text": " So these things are already working in", "tokens": [407, 613, 721, 366, 1217, 1364, 294], "temperature": 0.0, "avg_logprob": -0.3020542689732143, "compression_ratio": 1.7016129032258065, "no_speech_prob": 8.811900625005364e-05}, {"id": 214, "seek": 58968, "start": 592.4399999999999, "end": 594.4799999999999, "text": " separate CI systems like the CKI.", "tokens": [4994, 37777, 3652, 411, 264, 383, 27731, 13], "temperature": 0.0, "avg_logprob": -0.3020542689732143, "compression_ratio": 1.7016129032258065, "no_speech_prob": 8.811900625005364e-05}, {"id": 215, "seek": 58968, "start": 594.4799999999999, "end": 597.8399999999999, "text": " There's a UI screen for an issue in the kernel,", "tokens": [821, 311, 257, 15682, 2568, 337, 364, 2734, 294, 264, 28256, 11], "temperature": 0.0, "avg_logprob": -0.3020542689732143, "compression_ratio": 1.7016129032258065, "no_speech_prob": 8.811900625005364e-05}, {"id": 216, "seek": 58968, "start": 597.8399999999999, "end": 600.2399999999999, "text": " it says like, okay, look for this output in the test,", "tokens": [309, 1619, 411, 11, 1392, 11, 574, 337, 341, 5598, 294, 264, 1500, 11], "temperature": 0.0, "avg_logprob": -0.3020542689732143, "compression_ratio": 1.7016129032258065, "no_speech_prob": 8.811900625005364e-05}, {"id": 217, "seek": 58968, "start": 600.2399999999999, "end": 601.8399999999999, "text": " for this string in the test output,", "tokens": [337, 341, 6798, 294, 264, 1500, 5598, 11], "temperature": 0.0, "avg_logprob": -0.3020542689732143, "compression_ratio": 1.7016129032258065, "no_speech_prob": 8.811900625005364e-05}, {"id": 218, "seek": 58968, "start": 601.8399999999999, "end": 604.0, "text": " if you see it for this test,", "tokens": [498, 291, 536, 309, 337, 341, 1500, 11], "temperature": 0.0, "avg_logprob": -0.3020542689732143, "compression_ratio": 1.7016129032258065, "no_speech_prob": 8.811900625005364e-05}, {"id": 219, "seek": 58968, "start": 604.0, "end": 608.7199999999999, "text": " then we consider it a kernel bug and don't raise the problem.", "tokens": [550, 321, 1949, 309, 257, 28256, 7426, 293, 500, 380, 5300, 264, 1154, 13], "temperature": 0.0, "avg_logprob": -0.3020542689732143, "compression_ratio": 1.7016129032258065, "no_speech_prob": 8.811900625005364e-05}, {"id": 220, "seek": 58968, "start": 608.7199999999999, "end": 612.52, "text": " Okay, so or bug log CI,", "tokens": [1033, 11, 370, 420, 7426, 3565, 37777, 11], "temperature": 0.0, "avg_logprob": -0.3020542689732143, "compression_ratio": 1.7016129032258065, "no_speech_prob": 8.811900625005364e-05}, {"id": 221, "seek": 58968, "start": 612.52, "end": 614.7199999999999, "text": " Intel's CI system,", "tokens": [19762, 311, 37777, 1185, 11], "temperature": 0.0, "avg_logprob": -0.3020542689732143, "compression_ratio": 1.7016129032258065, "no_speech_prob": 8.811900625005364e-05}, {"id": 222, "seek": 58968, "start": 614.7199999999999, "end": 616.64, "text": " they have like a huge form.", "tokens": [436, 362, 411, 257, 2603, 1254, 13], "temperature": 0.0, "avg_logprob": -0.3020542689732143, "compression_ratio": 1.7016129032258065, "no_speech_prob": 8.811900625005364e-05}, {"id": 223, "seek": 58968, "start": 616.64, "end": 618.5999999999999, "text": " For file in this, you can see another string that", "tokens": [1171, 3991, 294, 341, 11, 291, 393, 536, 1071, 6798, 300], "temperature": 0.0, "avg_logprob": -0.3020542689732143, "compression_ratio": 1.7016129032258065, "no_speech_prob": 8.811900625005364e-05}, {"id": 224, "seek": 61860, "start": 618.6, "end": 620.0400000000001, "text": " is you're supposed to look in", "tokens": [307, 291, 434, 3442, 281, 574, 294], "temperature": 0.0, "avg_logprob": -0.3252681366940762, "compression_ratio": 1.5961538461538463, "no_speech_prob": 8.64922913024202e-05}, {"id": 225, "seek": 61860, "start": 620.0400000000001, "end": 622.2, "text": " the error output and the conditions and", "tokens": [264, 6713, 5598, 293, 264, 4487, 293], "temperature": 0.0, "avg_logprob": -0.3252681366940762, "compression_ratio": 1.5961538461538463, "no_speech_prob": 8.64922913024202e-05}, {"id": 226, "seek": 61860, "start": 622.2, "end": 625.24, "text": " what kind of status you want to assign to the test, et cetera.", "tokens": [437, 733, 295, 6558, 291, 528, 281, 6269, 281, 264, 1500, 11, 1030, 11458, 13], "temperature": 0.0, "avg_logprob": -0.3252681366940762, "compression_ratio": 1.5961538461538463, "no_speech_prob": 8.64922913024202e-05}, {"id": 227, "seek": 61860, "start": 625.24, "end": 629.36, "text": " So here's a dog tags for you to take a breath,", "tokens": [407, 510, 311, 257, 3000, 18632, 337, 291, 281, 747, 257, 6045, 11], "temperature": 0.0, "avg_logprob": -0.3252681366940762, "compression_ratio": 1.5961538461538463, "no_speech_prob": 8.64922913024202e-05}, {"id": 228, "seek": 61860, "start": 629.36, "end": 631.8000000000001, "text": " and for me to take a drink.", "tokens": [293, 337, 385, 281, 747, 257, 2822, 13], "temperature": 0.0, "avg_logprob": -0.3252681366940762, "compression_ratio": 1.5961538461538463, "no_speech_prob": 8.64922913024202e-05}, {"id": 229, "seek": 61860, "start": 636.8000000000001, "end": 639.96, "text": " So I'll dive into the model.", "tokens": [407, 286, 603, 9192, 666, 264, 2316, 13], "temperature": 0.0, "avg_logprob": -0.3252681366940762, "compression_ratio": 1.5961538461538463, "no_speech_prob": 8.64922913024202e-05}, {"id": 230, "seek": 61860, "start": 640.4, "end": 644.48, "text": " We start with checkouts which basically just specify", "tokens": [492, 722, 365, 1520, 7711, 597, 1936, 445, 16500], "temperature": 0.0, "avg_logprob": -0.3252681366940762, "compression_ratio": 1.5961538461538463, "no_speech_prob": 8.64922913024202e-05}, {"id": 231, "seek": 61860, "start": 644.48, "end": 647.28, "text": " what kind of revision you're checking out,", "tokens": [437, 733, 295, 34218, 291, 434, 8568, 484, 11], "temperature": 0.0, "avg_logprob": -0.3252681366940762, "compression_ratio": 1.5961538461538463, "no_speech_prob": 8.64922913024202e-05}, {"id": 232, "seek": 64728, "start": 647.28, "end": 651.12, "text": " we have taken it from repository branch and which commit,", "tokens": [321, 362, 2726, 309, 490, 25841, 9819, 293, 597, 5599, 11], "temperature": 0.0, "avg_logprob": -0.3040220700777494, "compression_ratio": 1.9253731343283582, "no_speech_prob": 0.00015415540838148445}, {"id": 233, "seek": 64728, "start": 651.12, "end": 652.72, "text": " and if you have patches applied on top,", "tokens": [293, 498, 291, 362, 26531, 6456, 322, 1192, 11], "temperature": 0.0, "avg_logprob": -0.3040220700777494, "compression_ratio": 1.9253731343283582, "no_speech_prob": 0.00015415540838148445}, {"id": 234, "seek": 64728, "start": 652.72, "end": 655.3199999999999, "text": " and the patch log and everything like that,", "tokens": [293, 264, 9972, 3565, 293, 1203, 411, 300, 11], "temperature": 0.0, "avg_logprob": -0.3040220700777494, "compression_ratio": 1.9253731343283582, "no_speech_prob": 0.00015415540838148445}, {"id": 235, "seek": 64728, "start": 655.3199999999999, "end": 657.8, "text": " then we aggregate that to get the revision data,", "tokens": [550, 321, 26118, 300, 281, 483, 264, 34218, 1412, 11], "temperature": 0.0, "avg_logprob": -0.3040220700777494, "compression_ratio": 1.9253731343283582, "no_speech_prob": 0.00015415540838148445}, {"id": 236, "seek": 64728, "start": 657.8, "end": 659.6, "text": " like from multiple checkouts of the same revision,", "tokens": [411, 490, 3866, 1520, 7711, 295, 264, 912, 34218, 11], "temperature": 0.0, "avg_logprob": -0.3040220700777494, "compression_ratio": 1.9253731343283582, "no_speech_prob": 0.00015415540838148445}, {"id": 237, "seek": 64728, "start": 659.6, "end": 661.52, "text": " they get the same single revision,", "tokens": [436, 483, 264, 912, 2167, 34218, 11], "temperature": 0.0, "avg_logprob": -0.3040220700777494, "compression_ratio": 1.9253731343283582, "no_speech_prob": 0.00015415540838148445}, {"id": 238, "seek": 64728, "start": 661.52, "end": 664.68, "text": " and they have builds which link to the checkouts,", "tokens": [293, 436, 362, 15182, 597, 2113, 281, 264, 1520, 7711, 11], "temperature": 0.0, "avg_logprob": -0.3040220700777494, "compression_ratio": 1.9253731343283582, "no_speech_prob": 0.00015415540838148445}, {"id": 239, "seek": 64728, "start": 664.68, "end": 667.4, "text": " to say like, oh, we just tested this check out,", "tokens": [281, 584, 411, 11, 1954, 11, 321, 445, 8246, 341, 1520, 484, 11], "temperature": 0.0, "avg_logprob": -0.3040220700777494, "compression_ratio": 1.9253731343283582, "no_speech_prob": 0.00015415540838148445}, {"id": 240, "seek": 64728, "start": 667.4, "end": 669.68, "text": " and therefore link to the revision.", "tokens": [293, 4412, 2113, 281, 264, 34218, 13], "temperature": 0.0, "avg_logprob": -0.3040220700777494, "compression_ratio": 1.9253731343283582, "no_speech_prob": 0.00015415540838148445}, {"id": 241, "seek": 64728, "start": 669.68, "end": 671.9599999999999, "text": " The builds describe which architecture,", "tokens": [440, 15182, 6786, 597, 9482, 11], "temperature": 0.0, "avg_logprob": -0.3040220700777494, "compression_ratio": 1.9253731343283582, "no_speech_prob": 0.00015415540838148445}, {"id": 242, "seek": 64728, "start": 671.9599999999999, "end": 673.76, "text": " compiler and configuration,", "tokens": [31958, 293, 11694, 11], "temperature": 0.0, "avg_logprob": -0.3040220700777494, "compression_ratio": 1.9253731343283582, "no_speech_prob": 0.00015415540838148445}, {"id": 243, "seek": 64728, "start": 673.76, "end": 675.8399999999999, "text": " output files and logs and everything,", "tokens": [5598, 7098, 293, 20820, 293, 1203, 11], "temperature": 0.0, "avg_logprob": -0.3040220700777494, "compression_ratio": 1.9253731343283582, "no_speech_prob": 0.00015415540838148445}, {"id": 244, "seek": 67584, "start": 675.84, "end": 678.24, "text": " and we get the test results finally,", "tokens": [293, 321, 483, 264, 1500, 3542, 2721, 11], "temperature": 0.0, "avg_logprob": -0.3107288300044953, "compression_ratio": 1.7857142857142858, "no_speech_prob": 9.705300180939957e-05}, {"id": 245, "seek": 67584, "start": 678.24, "end": 680.0, "text": " and yeah, builds can fail,", "tokens": [293, 1338, 11, 15182, 393, 3061, 11], "temperature": 0.0, "avg_logprob": -0.3107288300044953, "compression_ratio": 1.7857142857142858, "no_speech_prob": 9.705300180939957e-05}, {"id": 246, "seek": 67584, "start": 680.0, "end": 683.12, "text": " they have failed builds all the time and it stops nobody.", "tokens": [436, 362, 7612, 15182, 439, 264, 565, 293, 309, 10094, 5079, 13], "temperature": 0.0, "avg_logprob": -0.3107288300044953, "compression_ratio": 1.7857142857142858, "no_speech_prob": 9.705300180939957e-05}, {"id": 247, "seek": 67584, "start": 683.12, "end": 687.36, "text": " So we have kind of test which we are running", "tokens": [407, 321, 362, 733, 295, 1500, 597, 321, 366, 2614], "temperature": 0.0, "avg_logprob": -0.3107288300044953, "compression_ratio": 1.7857142857142858, "no_speech_prob": 9.705300180939957e-05}, {"id": 248, "seek": 67584, "start": 687.36, "end": 689.52, "text": " the environment to train on,", "tokens": [264, 2823, 281, 3847, 322, 11], "temperature": 0.0, "avg_logprob": -0.3107288300044953, "compression_ratio": 1.7857142857142858, "no_speech_prob": 9.705300180939957e-05}, {"id": 249, "seek": 67584, "start": 689.52, "end": 691.76, "text": " what kind of result it was,", "tokens": [437, 733, 295, 1874, 309, 390, 11], "temperature": 0.0, "avg_logprob": -0.3107288300044953, "compression_ratio": 1.7857142857142858, "no_speech_prob": 9.705300180939957e-05}, {"id": 250, "seek": 67584, "start": 691.76, "end": 693.8000000000001, "text": " the status result, pass, fail, et cetera,", "tokens": [264, 6558, 1874, 11, 1320, 11, 3061, 11, 1030, 11458, 11], "temperature": 0.0, "avg_logprob": -0.3107288300044953, "compression_ratio": 1.7857142857142858, "no_speech_prob": 9.705300180939957e-05}, {"id": 251, "seek": 67584, "start": 693.8000000000001, "end": 697.12, "text": " and the output files logs and stuff like that, very typical.", "tokens": [293, 264, 5598, 7098, 20820, 293, 1507, 411, 300, 11, 588, 7476, 13], "temperature": 0.0, "avg_logprob": -0.3107288300044953, "compression_ratio": 1.7857142857142858, "no_speech_prob": 9.705300180939957e-05}, {"id": 252, "seek": 67584, "start": 697.12, "end": 701.24, "text": " Then we get the issues which describe like which bug it is,", "tokens": [1396, 321, 483, 264, 2663, 597, 6786, 411, 597, 7426, 309, 307, 11], "temperature": 0.0, "avg_logprob": -0.3107288300044953, "compression_ratio": 1.7857142857142858, "no_speech_prob": 9.705300180939957e-05}, {"id": 253, "seek": 67584, "start": 701.24, "end": 703.5600000000001, "text": " and who is to blame like the kernel,", "tokens": [293, 567, 307, 281, 10127, 411, 264, 28256, 11], "temperature": 0.0, "avg_logprob": -0.3107288300044953, "compression_ratio": 1.7857142857142858, "no_speech_prob": 9.705300180939957e-05}, {"id": 254, "seek": 67584, "start": 703.5600000000001, "end": 705.08, "text": " the test or the framework,", "tokens": [264, 1500, 420, 264, 8388, 11], "temperature": 0.0, "avg_logprob": -0.3107288300044953, "compression_ratio": 1.7857142857142858, "no_speech_prob": 9.705300180939957e-05}, {"id": 255, "seek": 70508, "start": 705.08, "end": 707.96, "text": " and we will have the pattern there matching the test results,", "tokens": [293, 321, 486, 362, 264, 5102, 456, 14324, 264, 1500, 3542, 11], "temperature": 0.0, "avg_logprob": -0.2210754156112671, "compression_ratio": 1.788104089219331, "no_speech_prob": 6.765530997654423e-05}, {"id": 256, "seek": 70508, "start": 707.96, "end": 709.36, "text": " okay, this test, this output,", "tokens": [1392, 11, 341, 1500, 11, 341, 5598, 11], "temperature": 0.0, "avg_logprob": -0.2210754156112671, "compression_ratio": 1.788104089219331, "no_speech_prob": 6.765530997654423e-05}, {"id": 257, "seek": 70508, "start": 709.36, "end": 711.6, "text": " what you saw on that screen.", "tokens": [437, 291, 1866, 322, 300, 2568, 13], "temperature": 0.0, "avg_logprob": -0.2210754156112671, "compression_ratio": 1.788104089219331, "no_speech_prob": 6.765530997654423e-05}, {"id": 258, "seek": 70508, "start": 711.6, "end": 715.2800000000001, "text": " The status that it should have and the issue version,", "tokens": [440, 6558, 300, 309, 820, 362, 293, 264, 2734, 3037, 11], "temperature": 0.0, "avg_logprob": -0.2210754156112671, "compression_ratio": 1.788104089219331, "no_speech_prob": 6.765530997654423e-05}, {"id": 259, "seek": 70508, "start": 715.2800000000001, "end": 718.32, "text": " because we want to change those issues over time,", "tokens": [570, 321, 528, 281, 1319, 729, 2663, 670, 565, 11], "temperature": 0.0, "avg_logprob": -0.2210754156112671, "compression_ratio": 1.788104089219331, "no_speech_prob": 6.765530997654423e-05}, {"id": 260, "seek": 70508, "start": 718.32, "end": 720.2800000000001, "text": " and finally have the incidents which are linked in", "tokens": [293, 2721, 362, 264, 21139, 597, 366, 9408, 294], "temperature": 0.0, "avg_logprob": -0.2210754156112671, "compression_ratio": 1.788104089219331, "no_speech_prob": 6.765530997654423e-05}, {"id": 261, "seek": 70508, "start": 720.2800000000001, "end": 723.24, "text": " those builds and issues together,", "tokens": [729, 15182, 293, 2663, 1214, 11], "temperature": 0.0, "avg_logprob": -0.2210754156112671, "compression_ratio": 1.788104089219331, "no_speech_prob": 6.765530997654423e-05}, {"id": 262, "seek": 70508, "start": 723.24, "end": 725.8000000000001, "text": " so saying like, oh, this is the issue with this build,", "tokens": [370, 1566, 411, 11, 1954, 11, 341, 307, 264, 2734, 365, 341, 1322, 11], "temperature": 0.0, "avg_logprob": -0.2210754156112671, "compression_ratio": 1.788104089219331, "no_speech_prob": 6.765530997654423e-05}, {"id": 263, "seek": 70508, "start": 725.8000000000001, "end": 727.8000000000001, "text": " and things like that.", "tokens": [293, 721, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.2210754156112671, "compression_ratio": 1.788104089219331, "no_speech_prob": 6.765530997654423e-05}, {"id": 264, "seek": 70508, "start": 727.8000000000001, "end": 731.84, "text": " So that's all we keep in the relational database,", "tokens": [407, 300, 311, 439, 321, 1066, 294, 264, 38444, 8149, 11], "temperature": 0.0, "avg_logprob": -0.2210754156112671, "compression_ratio": 1.788104089219331, "no_speech_prob": 6.765530997654423e-05}, {"id": 265, "seek": 70508, "start": 731.84, "end": 734.76, "text": " but then we got to talk about the revisions.", "tokens": [457, 550, 321, 658, 281, 751, 466, 264, 3698, 4252, 13], "temperature": 0.0, "avg_logprob": -0.2210754156112671, "compression_ratio": 1.788104089219331, "no_speech_prob": 6.765530997654423e-05}, {"id": 266, "seek": 73476, "start": 734.76, "end": 740.16, "text": " So revisions could be just a commit to get history,", "tokens": [407, 3698, 4252, 727, 312, 445, 257, 5599, 281, 483, 2503, 11], "temperature": 0.0, "avg_logprob": -0.25036841305819424, "compression_ratio": 1.695852534562212, "no_speech_prob": 8.748683467274532e-05}, {"id": 267, "seek": 73476, "start": 740.16, "end": 741.84, "text": " and here's your graph.", "tokens": [293, 510, 311, 428, 4295, 13], "temperature": 0.0, "avg_logprob": -0.25036841305819424, "compression_ratio": 1.695852534562212, "no_speech_prob": 8.748683467274532e-05}, {"id": 268, "seek": 73476, "start": 741.84, "end": 746.92, "text": " So that's the basic thing that we've tried to do,", "tokens": [407, 300, 311, 264, 3875, 551, 300, 321, 600, 3031, 281, 360, 11], "temperature": 0.0, "avg_logprob": -0.25036841305819424, "compression_ratio": 1.695852534562212, "no_speech_prob": 8.748683467274532e-05}, {"id": 269, "seek": 73476, "start": 746.92, "end": 750.04, "text": " but we also need to have revisions of", "tokens": [457, 321, 611, 643, 281, 362, 3698, 4252, 295], "temperature": 0.0, "avg_logprob": -0.25036841305819424, "compression_ratio": 1.695852534562212, "no_speech_prob": 8.748683467274532e-05}, {"id": 270, "seek": 73476, "start": 750.04, "end": 751.72, "text": " patches applied on top and somebody", "tokens": [26531, 6456, 322, 1192, 293, 2618], "temperature": 0.0, "avg_logprob": -0.25036841305819424, "compression_ratio": 1.695852534562212, "no_speech_prob": 8.748683467274532e-05}, {"id": 271, "seek": 73476, "start": 751.72, "end": 753.2, "text": " posts the patch on the main list.", "tokens": [12300, 264, 9972, 322, 264, 2135, 1329, 13], "temperature": 0.0, "avg_logprob": -0.25036841305819424, "compression_ratio": 1.695852534562212, "no_speech_prob": 8.748683467274532e-05}, {"id": 272, "seek": 73476, "start": 753.2, "end": 755.04, "text": " We take it, apply it to some commit,", "tokens": [492, 747, 309, 11, 3079, 309, 281, 512, 5599, 11], "temperature": 0.0, "avg_logprob": -0.25036841305819424, "compression_ratio": 1.695852534562212, "no_speech_prob": 8.748683467274532e-05}, {"id": 273, "seek": 73476, "start": 755.04, "end": 757.52, "text": " which is pointed to and we test it,", "tokens": [597, 307, 10932, 281, 293, 321, 1500, 309, 11], "temperature": 0.0, "avg_logprob": -0.25036841305819424, "compression_ratio": 1.695852534562212, "no_speech_prob": 8.748683467274532e-05}, {"id": 274, "seek": 73476, "start": 757.52, "end": 759.08, "text": " we get the results,", "tokens": [321, 483, 264, 3542, 11], "temperature": 0.0, "avg_logprob": -0.25036841305819424, "compression_ratio": 1.695852534562212, "no_speech_prob": 8.748683467274532e-05}, {"id": 275, "seek": 73476, "start": 759.08, "end": 762.12, "text": " and we know it was applied to this commit.", "tokens": [293, 321, 458, 309, 390, 6456, 281, 341, 5599, 13], "temperature": 0.0, "avg_logprob": -0.25036841305819424, "compression_ratio": 1.695852534562212, "no_speech_prob": 8.748683467274532e-05}, {"id": 276, "seek": 76212, "start": 762.12, "end": 766.12, "text": " Then somebody reworks that patch and posts a new version,", "tokens": [1396, 2618, 319, 18357, 300, 9972, 293, 12300, 257, 777, 3037, 11], "temperature": 0.0, "avg_logprob": -0.19015425689949478, "compression_ratio": 1.803088803088803, "no_speech_prob": 8.418718789471313e-05}, {"id": 277, "seek": 76212, "start": 766.12, "end": 768.92, "text": " they got a link, both the commit we tested", "tokens": [436, 658, 257, 2113, 11, 1293, 264, 5599, 321, 8246], "temperature": 0.0, "avg_logprob": -0.19015425689949478, "compression_ratio": 1.803088803088803, "no_speech_prob": 8.418718789471313e-05}, {"id": 278, "seek": 76212, "start": 768.92, "end": 772.36, "text": " upon and to the previous revision of the patch set.", "tokens": [3564, 293, 281, 264, 3894, 34218, 295, 264, 9972, 992, 13], "temperature": 0.0, "avg_logprob": -0.19015425689949478, "compression_ratio": 1.803088803088803, "no_speech_prob": 8.418718789471313e-05}, {"id": 279, "seek": 76212, "start": 772.36, "end": 775.32, "text": " Then there is this weird thing when", "tokens": [1396, 456, 307, 341, 3657, 551, 562], "temperature": 0.0, "avg_logprob": -0.19015425689949478, "compression_ratio": 1.803088803088803, "no_speech_prob": 8.418718789471313e-05}, {"id": 280, "seek": 76212, "start": 775.32, "end": 777.52, "text": " maintainers keep a special branch for", "tokens": [6909, 433, 1066, 257, 2121, 9819, 337], "temperature": 0.0, "avg_logprob": -0.19015425689949478, "compression_ratio": 1.803088803088803, "no_speech_prob": 8.418718789471313e-05}, {"id": 281, "seek": 76212, "start": 777.52, "end": 780.36, "text": " CI for the testing systems to pick up", "tokens": [37777, 337, 264, 4997, 3652, 281, 1888, 493], "temperature": 0.0, "avg_logprob": -0.19015425689949478, "compression_ratio": 1.803088803088803, "no_speech_prob": 8.418718789471313e-05}, {"id": 282, "seek": 76212, "start": 780.36, "end": 783.04, "text": " their work and test and send them results,", "tokens": [641, 589, 293, 1500, 293, 2845, 552, 3542, 11], "temperature": 0.0, "avg_logprob": -0.19015425689949478, "compression_ratio": 1.803088803088803, "no_speech_prob": 8.418718789471313e-05}, {"id": 283, "seek": 76212, "start": 783.04, "end": 784.48, "text": " and they just keep pushing there like they're", "tokens": [293, 436, 445, 1066, 7380, 456, 411, 436, 434], "temperature": 0.0, "avg_logprob": -0.19015425689949478, "compression_ratio": 1.803088803088803, "no_speech_prob": 8.418718789471313e-05}, {"id": 284, "seek": 76212, "start": 784.48, "end": 786.12, "text": " working on something, they push there,", "tokens": [1364, 322, 746, 11, 436, 2944, 456, 11], "temperature": 0.0, "avg_logprob": -0.19015425689949478, "compression_ratio": 1.803088803088803, "no_speech_prob": 8.418718789471313e-05}, {"id": 285, "seek": 76212, "start": 786.12, "end": 788.64, "text": " they get results after a while from testing,", "tokens": [436, 483, 3542, 934, 257, 1339, 490, 4997, 11], "temperature": 0.0, "avg_logprob": -0.19015425689949478, "compression_ratio": 1.803088803088803, "no_speech_prob": 8.418718789471313e-05}, {"id": 286, "seek": 76212, "start": 788.64, "end": 790.32, "text": " then they push a new version,", "tokens": [550, 436, 2944, 257, 777, 3037, 11], "temperature": 0.0, "avg_logprob": -0.19015425689949478, "compression_ratio": 1.803088803088803, "no_speech_prob": 8.418718789471313e-05}, {"id": 287, "seek": 79032, "start": 790.32, "end": 793.0400000000001, "text": " and then they get new results and they got to say like,", "tokens": [293, 550, 436, 483, 777, 3542, 293, 436, 658, 281, 584, 411, 11], "temperature": 0.0, "avg_logprob": -0.27663269409766567, "compression_ratio": 1.6839622641509433, "no_speech_prob": 4.796194480150007e-05}, {"id": 288, "seek": 79032, "start": 793.0400000000001, "end": 795.2, "text": " okay, this is the Git commit history,", "tokens": [1392, 11, 341, 307, 264, 16939, 5599, 2503, 11], "temperature": 0.0, "avg_logprob": -0.27663269409766567, "compression_ratio": 1.6839622641509433, "no_speech_prob": 4.796194480150007e-05}, {"id": 289, "seek": 79032, "start": 795.2, "end": 797.1600000000001, "text": " but we also know that we checked", "tokens": [457, 321, 611, 458, 300, 321, 10033], "temperature": 0.0, "avg_logprob": -0.27663269409766567, "compression_ratio": 1.6839622641509433, "no_speech_prob": 4.796194480150007e-05}, {"id": 290, "seek": 79032, "start": 797.1600000000001, "end": 798.7600000000001, "text": " this branch out previously,", "tokens": [341, 9819, 484, 8046, 11], "temperature": 0.0, "avg_logprob": -0.27663269409766567, "compression_ratio": 1.6839622641509433, "no_speech_prob": 4.796194480150007e-05}, {"id": 291, "seek": 79032, "start": 798.7600000000001, "end": 802.0, "text": " so this is the child of that branch,", "tokens": [370, 341, 307, 264, 1440, 295, 300, 9819, 11], "temperature": 0.0, "avg_logprob": -0.27663269409766567, "compression_ratio": 1.6839622641509433, "no_speech_prob": 4.796194480150007e-05}, {"id": 292, "seek": 79032, "start": 802.0, "end": 804.32, "text": " of that previous revision.", "tokens": [295, 300, 3894, 34218, 13], "temperature": 0.0, "avg_logprob": -0.27663269409766567, "compression_ratio": 1.6839622641509433, "no_speech_prob": 4.796194480150007e-05}, {"id": 293, "seek": 79032, "start": 806.32, "end": 809.08, "text": " This basically it.", "tokens": [639, 1936, 309, 13], "temperature": 0.0, "avg_logprob": -0.27663269409766567, "compression_ratio": 1.6839622641509433, "no_speech_prob": 4.796194480150007e-05}, {"id": 294, "seek": 79032, "start": 809.08, "end": 811.32, "text": " Well, as you probably all know,", "tokens": [1042, 11, 382, 291, 1391, 439, 458, 11], "temperature": 0.0, "avg_logprob": -0.27663269409766567, "compression_ratio": 1.6839622641509433, "no_speech_prob": 4.796194480150007e-05}, {"id": 295, "seek": 79032, "start": 811.32, "end": 812.8000000000001, "text": " this is a directed acyclic graph,", "tokens": [341, 307, 257, 12898, 696, 88, 66, 1050, 4295, 11], "temperature": 0.0, "avg_logprob": -0.27663269409766567, "compression_ratio": 1.6839622641509433, "no_speech_prob": 4.796194480150007e-05}, {"id": 296, "seek": 79032, "start": 812.8000000000001, "end": 817.0, "text": " so test directed edges and it doesn't loop on itself.", "tokens": [370, 1500, 12898, 8819, 293, 309, 1177, 380, 6367, 322, 2564, 13], "temperature": 0.0, "avg_logprob": -0.27663269409766567, "compression_ratio": 1.6839622641509433, "no_speech_prob": 4.796194480150007e-05}, {"id": 297, "seek": 81700, "start": 817.0, "end": 821.48, "text": " So that's about what I know about graphs.", "tokens": [407, 300, 311, 466, 437, 286, 458, 466, 24877, 13], "temperature": 0.0, "avg_logprob": -0.18631091686563755, "compression_ratio": 1.6622222222222223, "no_speech_prob": 1.7720760297379456e-05}, {"id": 298, "seek": 81700, "start": 821.48, "end": 825.36, "text": " So bear with me.", "tokens": [407, 6155, 365, 385, 13], "temperature": 0.0, "avg_logprob": -0.18631091686563755, "compression_ratio": 1.6622222222222223, "no_speech_prob": 1.7720760297379456e-05}, {"id": 299, "seek": 81700, "start": 825.36, "end": 828.64, "text": " Finally, I think that there's", "tokens": [6288, 11, 286, 519, 300, 456, 311], "temperature": 0.0, "avg_logprob": -0.18631091686563755, "compression_ratio": 1.6622222222222223, "no_speech_prob": 1.7720760297379456e-05}, {"id": 300, "seek": 81700, "start": 828.64, "end": 830.44, "text": " just too many build and test results to", "tokens": [445, 886, 867, 1322, 293, 1500, 3542, 281], "temperature": 0.0, "avg_logprob": -0.18631091686563755, "compression_ratio": 1.6622222222222223, "no_speech_prob": 1.7720760297379456e-05}, {"id": 301, "seek": 81700, "start": 830.44, "end": 833.56, "text": " put them all into a graph database at least so far.", "tokens": [829, 552, 439, 666, 257, 4295, 8149, 412, 1935, 370, 1400, 13], "temperature": 0.0, "avg_logprob": -0.18631091686563755, "compression_ratio": 1.6622222222222223, "no_speech_prob": 1.7720760297379456e-05}, {"id": 302, "seek": 81700, "start": 833.56, "end": 835.76, "text": " I might be wrong, but that's my idea.", "tokens": [286, 1062, 312, 2085, 11, 457, 300, 311, 452, 1558, 13], "temperature": 0.0, "avg_logprob": -0.18631091686563755, "compression_ratio": 1.6622222222222223, "no_speech_prob": 1.7720760297379456e-05}, {"id": 303, "seek": 81700, "start": 835.76, "end": 838.44, "text": " We obviously need to keep the graph of", "tokens": [492, 2745, 643, 281, 1066, 264, 4295, 295], "temperature": 0.0, "avg_logprob": -0.18631091686563755, "compression_ratio": 1.6622222222222223, "no_speech_prob": 1.7720760297379456e-05}, {"id": 304, "seek": 81700, "start": 838.44, "end": 840.8, "text": " the revisions to be able to reason about them,", "tokens": [264, 3698, 4252, 281, 312, 1075, 281, 1778, 466, 552, 11], "temperature": 0.0, "avg_logprob": -0.18631091686563755, "compression_ratio": 1.6622222222222223, "no_speech_prob": 1.7720760297379456e-05}, {"id": 305, "seek": 81700, "start": 840.8, "end": 843.24, "text": " but we might be able to put", "tokens": [457, 321, 1062, 312, 1075, 281, 829], "temperature": 0.0, "avg_logprob": -0.18631091686563755, "compression_ratio": 1.6622222222222223, "no_speech_prob": 1.7720760297379456e-05}, {"id": 306, "seek": 81700, "start": 843.24, "end": 845.28, "text": " issues there as well in the same database", "tokens": [2663, 456, 382, 731, 294, 264, 912, 8149], "temperature": 0.0, "avg_logprob": -0.18631091686563755, "compression_ratio": 1.6622222222222223, "no_speech_prob": 1.7720760297379456e-05}, {"id": 307, "seek": 84528, "start": 845.28, "end": 847.56, "text": " if it saves us something.", "tokens": [498, 309, 19155, 505, 746, 13], "temperature": 0.0, "avg_logprob": -0.30144822792928727, "compression_ratio": 1.7792207792207793, "no_speech_prob": 4.118397191632539e-05}, {"id": 308, "seek": 84528, "start": 847.56, "end": 851.4399999999999, "text": " So this is just a short list.", "tokens": [407, 341, 307, 445, 257, 2099, 1329, 13], "temperature": 0.0, "avg_logprob": -0.30144822792928727, "compression_ratio": 1.7792207792207793, "no_speech_prob": 4.118397191632539e-05}, {"id": 309, "seek": 84528, "start": 851.64, "end": 854.52, "text": " Basically, what we want to know,", "tokens": [8537, 11, 437, 321, 528, 281, 458, 11], "temperature": 0.0, "avg_logprob": -0.30144822792928727, "compression_ratio": 1.7792207792207793, "no_speech_prob": 4.118397191632539e-05}, {"id": 310, "seek": 84528, "start": 854.52, "end": 857.0, "text": " okay, as the data commit comes in,", "tokens": [1392, 11, 382, 264, 1412, 5599, 1487, 294, 11], "temperature": 0.0, "avg_logprob": -0.30144822792928727, "compression_ratio": 1.7792207792207793, "no_speech_prob": 4.118397191632539e-05}, {"id": 311, "seek": 84528, "start": 857.0, "end": 857.88, "text": " the test results you got to", "tokens": [264, 1500, 3542, 291, 658, 281], "temperature": 0.0, "avg_logprob": -0.30144822792928727, "compression_ratio": 1.7792207792207793, "no_speech_prob": 4.118397191632539e-05}, {"id": 312, "seek": 84528, "start": 857.88, "end": 859.8, "text": " try them and match them against the issue.", "tokens": [853, 552, 293, 2995, 552, 1970, 264, 2734, 13], "temperature": 0.0, "avg_logprob": -0.30144822792928727, "compression_ratio": 1.7792207792207793, "no_speech_prob": 4.118397191632539e-05}, {"id": 313, "seek": 84528, "start": 859.8, "end": 861.4, "text": " So we can say, okay, we found an issue here,", "tokens": [407, 321, 393, 584, 11, 1392, 11, 321, 1352, 364, 2734, 510, 11], "temperature": 0.0, "avg_logprob": -0.30144822792928727, "compression_ratio": 1.7792207792207793, "no_speech_prob": 4.118397191632539e-05}, {"id": 314, "seek": 84528, "start": 861.4, "end": 865.0, "text": " so don't raise the flag or something like that,", "tokens": [370, 500, 380, 5300, 264, 7166, 420, 746, 411, 300, 11], "temperature": 0.0, "avg_logprob": -0.30144822792928727, "compression_ratio": 1.7792207792207793, "no_speech_prob": 4.118397191632539e-05}, {"id": 315, "seek": 84528, "start": 865.0, "end": 867.04, "text": " like similar, okay.", "tokens": [411, 2531, 11, 1392, 13], "temperature": 0.0, "avg_logprob": -0.30144822792928727, "compression_ratio": 1.7792207792207793, "no_speech_prob": 4.118397191632539e-05}, {"id": 316, "seek": 84528, "start": 867.04, "end": 870.72, "text": " There is no issue here on test result,", "tokens": [821, 307, 572, 2734, 510, 322, 1500, 1874, 11], "temperature": 0.0, "avg_logprob": -0.30144822792928727, "compression_ratio": 1.7792207792207793, "no_speech_prob": 4.118397191632539e-05}, {"id": 317, "seek": 84528, "start": 870.72, "end": 873.8, "text": " but we want to raise the flag because there's actually an issue.", "tokens": [457, 321, 528, 281, 5300, 264, 7166, 570, 456, 311, 767, 364, 2734, 13], "temperature": 0.0, "avg_logprob": -0.30144822792928727, "compression_ratio": 1.7792207792207793, "no_speech_prob": 4.118397191632539e-05}, {"id": 318, "seek": 87380, "start": 873.8, "end": 878.92, "text": " We cannot possibly try all the issues", "tokens": [492, 2644, 6264, 853, 439, 264, 2663], "temperature": 0.0, "avg_logprob": -0.18033533096313475, "compression_ratio": 1.786610878661088, "no_speech_prob": 8.031073230085894e-05}, {"id": 319, "seek": 87380, "start": 878.92, "end": 882.52, "text": " against all test results because there's going to be a lot.", "tokens": [1970, 439, 1500, 3542, 570, 456, 311, 516, 281, 312, 257, 688, 13], "temperature": 0.0, "avg_logprob": -0.18033533096313475, "compression_ratio": 1.786610878661088, "no_speech_prob": 8.031073230085894e-05}, {"id": 320, "seek": 87380, "start": 882.52, "end": 885.9599999999999, "text": " So we have to build a priority for those issues,", "tokens": [407, 321, 362, 281, 1322, 257, 9365, 337, 729, 2663, 11], "temperature": 0.0, "avg_logprob": -0.18033533096313475, "compression_ratio": 1.786610878661088, "no_speech_prob": 8.031073230085894e-05}, {"id": 321, "seek": 87380, "start": 885.9599999999999, "end": 888.7199999999999, "text": " and then we have to cut off that priority somehow,", "tokens": [293, 550, 321, 362, 281, 1723, 766, 300, 9365, 6063, 11], "temperature": 0.0, "avg_logprob": -0.18033533096313475, "compression_ratio": 1.786610878661088, "no_speech_prob": 8.031073230085894e-05}, {"id": 322, "seek": 87380, "start": 888.7199999999999, "end": 890.28, "text": " and say like, okay, at this moment,", "tokens": [293, 584, 411, 11, 1392, 11, 412, 341, 1623, 11], "temperature": 0.0, "avg_logprob": -0.18033533096313475, "compression_ratio": 1.786610878661088, "no_speech_prob": 8.031073230085894e-05}, {"id": 323, "seek": 87380, "start": 890.28, "end": 891.68, "text": " we can tell the developer that we've", "tokens": [321, 393, 980, 264, 10754, 300, 321, 600], "temperature": 0.0, "avg_logprob": -0.18033533096313475, "compression_ratio": 1.786610878661088, "no_speech_prob": 8.031073230085894e-05}, {"id": 324, "seek": 87380, "start": 891.68, "end": 893.0799999999999, "text": " basically tried these results,", "tokens": [1936, 3031, 613, 3542, 11], "temperature": 0.0, "avg_logprob": -0.18033533096313475, "compression_ratio": 1.786610878661088, "no_speech_prob": 8.031073230085894e-05}, {"id": 325, "seek": 87380, "start": 893.0799999999999, "end": 894.24, "text": " you can go take a look,", "tokens": [291, 393, 352, 747, 257, 574, 11], "temperature": 0.0, "avg_logprob": -0.18033533096313475, "compression_ratio": 1.786610878661088, "no_speech_prob": 8.031073230085894e-05}, {"id": 326, "seek": 87380, "start": 894.24, "end": 895.64, "text": " but we can still continue and", "tokens": [457, 321, 393, 920, 2354, 293], "temperature": 0.0, "avg_logprob": -0.18033533096313475, "compression_ratio": 1.786610878661088, "no_speech_prob": 8.031073230085894e-05}, {"id": 327, "seek": 87380, "start": 895.64, "end": 897.64, "text": " try those issues as the time goes on.", "tokens": [853, 729, 2663, 382, 264, 565, 1709, 322, 13], "temperature": 0.0, "avg_logprob": -0.18033533096313475, "compression_ratio": 1.786610878661088, "no_speech_prob": 8.031073230085894e-05}, {"id": 328, "seek": 87380, "start": 897.64, "end": 902.64, "text": " So we have to base that on one of", "tokens": [407, 321, 362, 281, 3096, 300, 322, 472, 295], "temperature": 0.0, "avg_logprob": -0.18033533096313475, "compression_ratio": 1.786610878661088, "no_speech_prob": 8.031073230085894e-05}, {"id": 329, "seek": 90264, "start": 902.64, "end": 905.4, "text": " the criteria that we might need is how far,", "tokens": [264, 11101, 300, 321, 1062, 643, 307, 577, 1400, 11], "temperature": 0.0, "avg_logprob": -0.23019452859427184, "compression_ratio": 1.7222222222222223, "no_speech_prob": 3.213748277630657e-05}, {"id": 330, "seek": 90264, "start": 905.4, "end": 908.68, "text": " for example, that revision is from the current situation,", "tokens": [337, 1365, 11, 300, 34218, 307, 490, 264, 2190, 2590, 11], "temperature": 0.0, "avg_logprob": -0.23019452859427184, "compression_ratio": 1.7222222222222223, "no_speech_prob": 3.213748277630657e-05}, {"id": 331, "seek": 90264, "start": 908.68, "end": 912.3199999999999, "text": " like if this issue only appeared somewhere,", "tokens": [411, 498, 341, 2734, 787, 8516, 4079, 11], "temperature": 0.0, "avg_logprob": -0.23019452859427184, "compression_ratio": 1.7222222222222223, "no_speech_prob": 3.213748277630657e-05}, {"id": 332, "seek": 90264, "start": 912.3199999999999, "end": 914.48, "text": " I don't know, like 1,000 commits ago,", "tokens": [286, 500, 380, 458, 11, 411, 502, 11, 1360, 48311, 2057, 11], "temperature": 0.0, "avg_logprob": -0.23019452859427184, "compression_ratio": 1.7222222222222223, "no_speech_prob": 3.213748277630657e-05}, {"id": 333, "seek": 90264, "start": 914.48, "end": 917.16, "text": " or 1,000 is not that much for the Linux kernel,", "tokens": [420, 502, 11, 1360, 307, 406, 300, 709, 337, 264, 18734, 28256, 11], "temperature": 0.0, "avg_logprob": -0.23019452859427184, "compression_ratio": 1.7222222222222223, "no_speech_prob": 3.213748277630657e-05}, {"id": 334, "seek": 90264, "start": 917.16, "end": 919.92, "text": " okay, 10,000 commits ago,", "tokens": [1392, 11, 1266, 11, 1360, 48311, 2057, 11], "temperature": 0.0, "avg_logprob": -0.23019452859427184, "compression_ratio": 1.7222222222222223, "no_speech_prob": 3.213748277630657e-05}, {"id": 335, "seek": 90264, "start": 919.92, "end": 922.4, "text": " then we don't need to try it right now.", "tokens": [550, 321, 500, 380, 643, 281, 853, 309, 558, 586, 13], "temperature": 0.0, "avg_logprob": -0.23019452859427184, "compression_ratio": 1.7222222222222223, "no_speech_prob": 3.213748277630657e-05}, {"id": 336, "seek": 90264, "start": 922.4, "end": 923.8, "text": " We can tell the developer, okay, it's fine,", "tokens": [492, 393, 980, 264, 10754, 11, 1392, 11, 309, 311, 2489, 11], "temperature": 0.0, "avg_logprob": -0.23019452859427184, "compression_ratio": 1.7222222222222223, "no_speech_prob": 3.213748277630657e-05}, {"id": 337, "seek": 90264, "start": 923.8, "end": 925.16, "text": " and then we'll go and continue", "tokens": [293, 550, 321, 603, 352, 293, 2354], "temperature": 0.0, "avg_logprob": -0.23019452859427184, "compression_ratio": 1.7222222222222223, "no_speech_prob": 3.213748277630657e-05}, {"id": 338, "seek": 90264, "start": 925.16, "end": 927.72, "text": " try it and if we find something,", "tokens": [853, 309, 293, 498, 321, 915, 746, 11], "temperature": 0.0, "avg_logprob": -0.23019452859427184, "compression_ratio": 1.7222222222222223, "no_speech_prob": 3.213748277630657e-05}, {"id": 339, "seek": 90264, "start": 927.72, "end": 929.96, "text": " then we can raise the alarm.", "tokens": [550, 321, 393, 5300, 264, 14183, 13], "temperature": 0.0, "avg_logprob": -0.23019452859427184, "compression_ratio": 1.7222222222222223, "no_speech_prob": 3.213748277630657e-05}, {"id": 340, "seek": 92996, "start": 929.96, "end": 933.6, "text": " Okay, then we can ask,", "tokens": [1033, 11, 550, 321, 393, 1029, 11], "temperature": 0.0, "avg_logprob": -0.17263752117491604, "compression_ratio": 1.8428571428571427, "no_speech_prob": 0.00013224132999312133}, {"id": 341, "seek": 92996, "start": 933.6, "end": 935.96, "text": " like what were the last X-test results,", "tokens": [411, 437, 645, 264, 1036, 1783, 12, 31636, 3542, 11], "temperature": 0.0, "avg_logprob": -0.17263752117491604, "compression_ratio": 1.8428571428571427, "no_speech_prob": 0.00013224132999312133}, {"id": 342, "seek": 92996, "start": 935.96, "end": 937.72, "text": " like for this particular test,", "tokens": [411, 337, 341, 1729, 1500, 11], "temperature": 0.0, "avg_logprob": -0.17263752117491604, "compression_ratio": 1.8428571428571427, "no_speech_prob": 0.00013224132999312133}, {"id": 343, "seek": 92996, "start": 937.72, "end": 942.76, "text": " for this number of commits to be able to say,", "tokens": [337, 341, 1230, 295, 48311, 281, 312, 1075, 281, 584, 11], "temperature": 0.0, "avg_logprob": -0.17263752117491604, "compression_ratio": 1.8428571428571427, "no_speech_prob": 0.00013224132999312133}, {"id": 344, "seek": 92996, "start": 942.76, "end": 947.0, "text": " okay, this test wasn't often failing,", "tokens": [1392, 11, 341, 1500, 2067, 380, 2049, 18223, 11], "temperature": 0.0, "avg_logprob": -0.17263752117491604, "compression_ratio": 1.8428571428571427, "no_speech_prob": 0.00013224132999312133}, {"id": 345, "seek": 92996, "start": 947.0, "end": 949.32, "text": " okay, it was failing sometimes, but that's okay,", "tokens": [1392, 11, 309, 390, 18223, 2171, 11, 457, 300, 311, 1392, 11], "temperature": 0.0, "avg_logprob": -0.17263752117491604, "compression_ratio": 1.8428571428571427, "no_speech_prob": 0.00013224132999312133}, {"id": 346, "seek": 92996, "start": 949.32, "end": 951.32, "text": " but if it suddenly starts failing more often,", "tokens": [457, 498, 309, 5800, 3719, 18223, 544, 2049, 11], "temperature": 0.0, "avg_logprob": -0.17263752117491604, "compression_ratio": 1.8428571428571427, "no_speech_prob": 0.00013224132999312133}, {"id": 347, "seek": 92996, "start": 951.32, "end": 952.6800000000001, "text": " we got to raise the alarm,", "tokens": [321, 658, 281, 5300, 264, 14183, 11], "temperature": 0.0, "avg_logprob": -0.17263752117491604, "compression_ratio": 1.8428571428571427, "no_speech_prob": 0.00013224132999312133}, {"id": 348, "seek": 92996, "start": 952.6800000000001, "end": 954.88, "text": " or if it stops failing so often,", "tokens": [420, 498, 309, 10094, 18223, 370, 2049, 11], "temperature": 0.0, "avg_logprob": -0.17263752117491604, "compression_ratio": 1.8428571428571427, "no_speech_prob": 0.00013224132999312133}, {"id": 349, "seek": 92996, "start": 954.88, "end": 958.84, "text": " we got to also raise the alarm and see what's changed.", "tokens": [321, 658, 281, 611, 5300, 264, 14183, 293, 536, 437, 311, 3105, 13], "temperature": 0.0, "avg_logprob": -0.17263752117491604, "compression_ratio": 1.8428571428571427, "no_speech_prob": 0.00013224132999312133}, {"id": 350, "seek": 95884, "start": 958.84, "end": 961.52, "text": " Then we need to track the performance trends,", "tokens": [1396, 321, 643, 281, 2837, 264, 3389, 13892, 11], "temperature": 0.0, "avg_logprob": -0.26162902644423186, "compression_ratio": 1.75, "no_speech_prob": 0.00018083894974552095}, {"id": 351, "seek": 95884, "start": 961.52, "end": 966.1600000000001, "text": " of course, over the history of the development,", "tokens": [295, 1164, 11, 670, 264, 2503, 295, 264, 3250, 11], "temperature": 0.0, "avg_logprob": -0.26162902644423186, "compression_ratio": 1.75, "no_speech_prob": 0.00018083894974552095}, {"id": 352, "seek": 95884, "start": 966.1600000000001, "end": 969.08, "text": " and once again, we cannot do this just based on time,", "tokens": [293, 1564, 797, 11, 321, 2644, 360, 341, 445, 2361, 322, 565, 11], "temperature": 0.0, "avg_logprob": -0.26162902644423186, "compression_ratio": 1.75, "no_speech_prob": 0.00018083894974552095}, {"id": 353, "seek": 95884, "start": 969.08, "end": 971.44, "text": " because some systems move at", "tokens": [570, 512, 3652, 1286, 412], "temperature": 0.0, "avg_logprob": -0.26162902644423186, "compression_ratio": 1.75, "no_speech_prob": 0.00018083894974552095}, {"id": 354, "seek": 95884, "start": 971.44, "end": 974.5600000000001, "text": " a different speed and some systems might start to decide to,", "tokens": [257, 819, 3073, 293, 512, 3652, 1062, 722, 281, 4536, 281, 11], "temperature": 0.0, "avg_logprob": -0.26162902644423186, "compression_ratio": 1.75, "no_speech_prob": 0.00018083894974552095}, {"id": 355, "seek": 95884, "start": 974.5600000000001, "end": 976.64, "text": " okay, we're going to test this old branch because", "tokens": [1392, 11, 321, 434, 516, 281, 1500, 341, 1331, 9819, 570], "temperature": 0.0, "avg_logprob": -0.26162902644423186, "compression_ratio": 1.75, "no_speech_prob": 0.00018083894974552095}, {"id": 356, "seek": 95884, "start": 976.64, "end": 981.08, "text": " somebody if some of our clients wants to base their BSP on it,", "tokens": [2618, 498, 512, 295, 527, 6982, 2738, 281, 3096, 641, 27253, 47, 322, 309, 11], "temperature": 0.0, "avg_logprob": -0.26162902644423186, "compression_ratio": 1.75, "no_speech_prob": 0.00018083894974552095}, {"id": 357, "seek": 95884, "start": 981.08, "end": 984.52, "text": " wants to base the release some software with that kernel,", "tokens": [2738, 281, 3096, 264, 4374, 512, 4722, 365, 300, 28256, 11], "temperature": 0.0, "avg_logprob": -0.26162902644423186, "compression_ratio": 1.75, "no_speech_prob": 0.00018083894974552095}, {"id": 358, "seek": 95884, "start": 984.52, "end": 985.6800000000001, "text": " and we got to start testing it,", "tokens": [293, 321, 658, 281, 722, 4997, 309, 11], "temperature": 0.0, "avg_logprob": -0.26162902644423186, "compression_ratio": 1.75, "no_speech_prob": 0.00018083894974552095}, {"id": 359, "seek": 95884, "start": 985.6800000000001, "end": 986.76, "text": " and it starts coming in like", "tokens": [293, 309, 3719, 1348, 294, 411], "temperature": 0.0, "avg_logprob": -0.26162902644423186, "compression_ratio": 1.75, "no_speech_prob": 0.00018083894974552095}, {"id": 360, "seek": 98676, "start": 986.76, "end": 988.8, "text": " the last year's release or something,", "tokens": [264, 1036, 1064, 311, 4374, 420, 746, 11], "temperature": 0.0, "avg_logprob": -0.24121728897094727, "compression_ratio": 1.6343612334801763, "no_speech_prob": 4.397711745696142e-05}, {"id": 361, "seek": 98676, "start": 988.8, "end": 991.4, "text": " and we cannot just take that data into account", "tokens": [293, 321, 2644, 445, 747, 300, 1412, 666, 2696], "temperature": 0.0, "avg_logprob": -0.24121728897094727, "compression_ratio": 1.6343612334801763, "no_speech_prob": 4.397711745696142e-05}, {"id": 362, "seek": 98676, "start": 991.4, "end": 994.48, "text": " for testing the current releases or vice versa.", "tokens": [337, 4997, 264, 2190, 16952, 420, 11964, 25650, 13], "temperature": 0.0, "avg_logprob": -0.24121728897094727, "compression_ratio": 1.6343612334801763, "no_speech_prob": 4.397711745696142e-05}, {"id": 363, "seek": 98676, "start": 994.48, "end": 999.16, "text": " So, or for stable kernel maintainer,", "tokens": [407, 11, 420, 337, 8351, 28256, 6909, 260, 11], "temperature": 0.0, "avg_logprob": -0.24121728897094727, "compression_ratio": 1.6343612334801763, "no_speech_prob": 4.397711745696142e-05}, {"id": 364, "seek": 98676, "start": 999.16, "end": 1002.4399999999999, "text": " if Greg wants to release a branch,", "tokens": [498, 11490, 2738, 281, 4374, 257, 9819, 11], "temperature": 0.0, "avg_logprob": -0.24121728897094727, "compression_ratio": 1.6343612334801763, "no_speech_prob": 4.397711745696142e-05}, {"id": 365, "seek": 98676, "start": 1002.4399999999999, "end": 1004.04, "text": " he might want to see like,", "tokens": [415, 1062, 528, 281, 536, 411, 11], "temperature": 0.0, "avg_logprob": -0.24121728897094727, "compression_ratio": 1.6343612334801763, "no_speech_prob": 4.397711745696142e-05}, {"id": 366, "seek": 98676, "start": 1004.04, "end": 1005.68, "text": " okay, which issues were discovered starting", "tokens": [1392, 11, 597, 2663, 645, 6941, 2891], "temperature": 0.0, "avg_logprob": -0.24121728897094727, "compression_ratio": 1.6343612334801763, "no_speech_prob": 4.397711745696142e-05}, {"id": 367, "seek": 98676, "start": 1005.68, "end": 1009.88, "text": " from the previous release in this branch,", "tokens": [490, 264, 3894, 4374, 294, 341, 9819, 11], "temperature": 0.0, "avg_logprob": -0.24121728897094727, "compression_ratio": 1.6343612334801763, "no_speech_prob": 4.397711745696142e-05}, {"id": 368, "seek": 98676, "start": 1009.88, "end": 1013.4, "text": " and finally, yeah,", "tokens": [293, 2721, 11, 1338, 11], "temperature": 0.0, "avg_logprob": -0.24121728897094727, "compression_ratio": 1.6343612334801763, "no_speech_prob": 4.397711745696142e-05}, {"id": 369, "seek": 98676, "start": 1013.4, "end": 1014.76, "text": " like just for the dashboard, like,", "tokens": [411, 445, 337, 264, 18342, 11, 411, 11], "temperature": 0.0, "avg_logprob": -0.24121728897094727, "compression_ratio": 1.6343612334801763, "no_speech_prob": 4.397711745696142e-05}, {"id": 370, "seek": 101476, "start": 1014.76, "end": 1016.76, "text": " okay, I want to see issues in this branch,", "tokens": [1392, 11, 286, 528, 281, 536, 2663, 294, 341, 9819, 11], "temperature": 0.0, "avg_logprob": -0.22278341880211464, "compression_ratio": 1.6682027649769586, "no_speech_prob": 0.000179209717316553}, {"id": 371, "seek": 101476, "start": 1016.76, "end": 1019.76, "text": " or which branches contain this issue.", "tokens": [420, 597, 14770, 5304, 341, 2734, 13], "temperature": 0.0, "avg_logprob": -0.22278341880211464, "compression_ratio": 1.6682027649769586, "no_speech_prob": 0.000179209717316553}, {"id": 372, "seek": 101476, "start": 1019.76, "end": 1025.44, "text": " So, that's what we tried to do with Neo4j.", "tokens": [407, 11, 300, 311, 437, 321, 3031, 281, 360, 365, 24458, 19, 73, 13], "temperature": 0.0, "avg_logprob": -0.22278341880211464, "compression_ratio": 1.6682027649769586, "no_speech_prob": 0.000179209717316553}, {"id": 373, "seek": 101476, "start": 1025.44, "end": 1026.52, "text": " I did basic things,", "tokens": [286, 630, 3875, 721, 11], "temperature": 0.0, "avg_logprob": -0.22278341880211464, "compression_ratio": 1.6682027649769586, "no_speech_prob": 0.000179209717316553}, {"id": 374, "seek": 101476, "start": 1026.52, "end": 1027.92, "text": " so I wrote a little script to get", "tokens": [370, 286, 4114, 257, 707, 5755, 281, 483], "temperature": 0.0, "avg_logprob": -0.22278341880211464, "compression_ratio": 1.6682027649769586, "no_speech_prob": 0.000179209717316553}, {"id": 375, "seek": 101476, "start": 1027.92, "end": 1031.16, "text": " the Git log in a particular format,", "tokens": [264, 16939, 3565, 294, 257, 1729, 7877, 11], "temperature": 0.0, "avg_logprob": -0.22278341880211464, "compression_ratio": 1.6682027649769586, "no_speech_prob": 0.000179209717316553}, {"id": 376, "seek": 101476, "start": 1031.16, "end": 1035.96, "text": " and then generate the data for commits and for relations.", "tokens": [293, 550, 8460, 264, 1412, 337, 48311, 293, 337, 2299, 13], "temperature": 0.0, "avg_logprob": -0.22278341880211464, "compression_ratio": 1.6682027649769586, "no_speech_prob": 0.000179209717316553}, {"id": 377, "seek": 101476, "start": 1035.96, "end": 1041.6, "text": " It was a little over a million commits look like this,", "tokens": [467, 390, 257, 707, 670, 257, 2459, 48311, 574, 411, 341, 11], "temperature": 0.0, "avg_logprob": -0.22278341880211464, "compression_ratio": 1.6682027649769586, "no_speech_prob": 0.000179209717316553}, {"id": 378, "seek": 101476, "start": 1041.6, "end": 1044.36, "text": " and it was a little more relations,", "tokens": [293, 309, 390, 257, 707, 544, 2299, 11], "temperature": 0.0, "avg_logprob": -0.22278341880211464, "compression_ratio": 1.6682027649769586, "no_speech_prob": 0.000179209717316553}, {"id": 379, "seek": 104436, "start": 1044.36, "end": 1046.8799999999999, "text": " because as you probably know,", "tokens": [570, 382, 291, 1391, 458, 11], "temperature": 0.0, "avg_logprob": -0.22221280910350658, "compression_ratio": 1.6017316017316017, "no_speech_prob": 8.789273852016777e-05}, {"id": 380, "seek": 104436, "start": 1046.8799999999999, "end": 1050.24, "text": " a commit can have more than one parent in Git,", "tokens": [257, 5599, 393, 362, 544, 813, 472, 2596, 294, 16939, 11], "temperature": 0.0, "avg_logprob": -0.22221280910350658, "compression_ratio": 1.6017316017316017, "no_speech_prob": 8.789273852016777e-05}, {"id": 381, "seek": 104436, "start": 1050.24, "end": 1052.9199999999998, "text": " and it looks like this, very simple.", "tokens": [293, 309, 1542, 411, 341, 11, 588, 2199, 13], "temperature": 0.0, "avg_logprob": -0.22221280910350658, "compression_ratio": 1.6017316017316017, "no_speech_prob": 8.789273852016777e-05}, {"id": 382, "seek": 104436, "start": 1052.9199999999998, "end": 1057.52, "text": " So, I loaded this into Neo4j with something like this.", "tokens": [407, 11, 286, 13210, 341, 666, 24458, 19, 73, 365, 746, 411, 341, 13], "temperature": 0.0, "avg_logprob": -0.22221280910350658, "compression_ratio": 1.6017316017316017, "no_speech_prob": 8.789273852016777e-05}, {"id": 383, "seek": 104436, "start": 1057.52, "end": 1059.84, "text": " This is updated to the latest release.", "tokens": [639, 307, 10588, 281, 264, 6792, 4374, 13], "temperature": 0.0, "avg_logprob": -0.22221280910350658, "compression_ratio": 1.6017316017316017, "no_speech_prob": 8.789273852016777e-05}, {"id": 384, "seek": 104436, "start": 1059.84, "end": 1062.84, "text": " It was different than created an index for", "tokens": [467, 390, 819, 813, 2942, 364, 8186, 337], "temperature": 0.0, "avg_logprob": -0.22221280910350658, "compression_ratio": 1.6017316017316017, "no_speech_prob": 8.789273852016777e-05}, {"id": 385, "seek": 104436, "start": 1062.84, "end": 1066.7199999999998, "text": " hashes and then loaded the relations,", "tokens": [575, 8076, 293, 550, 13210, 264, 2299, 11], "temperature": 0.0, "avg_logprob": -0.22221280910350658, "compression_ratio": 1.6017316017316017, "no_speech_prob": 8.789273852016777e-05}, {"id": 386, "seek": 104436, "start": 1066.7199999999998, "end": 1068.3999999999999, "text": " and it worked fine,", "tokens": [293, 309, 2732, 2489, 11], "temperature": 0.0, "avg_logprob": -0.22221280910350658, "compression_ratio": 1.6017316017316017, "no_speech_prob": 8.789273852016777e-05}, {"id": 387, "seek": 104436, "start": 1068.3999999999999, "end": 1070.1599999999999, "text": " but not a few days ago when I", "tokens": [457, 406, 257, 1326, 1708, 2057, 562, 286], "temperature": 0.0, "avg_logprob": -0.22221280910350658, "compression_ratio": 1.6017316017316017, "no_speech_prob": 8.789273852016777e-05}, {"id": 388, "seek": 104436, "start": 1070.1599999999999, "end": 1072.36, "text": " tried the Thresh Neo4j release,", "tokens": [3031, 264, 334, 3644, 24458, 19, 73, 4374, 11], "temperature": 0.0, "avg_logprob": -0.22221280910350658, "compression_ratio": 1.6017316017316017, "no_speech_prob": 8.789273852016777e-05}, {"id": 389, "seek": 107236, "start": 1072.36, "end": 1075.6799999999998, "text": " it just hung like this forever.", "tokens": [309, 445, 5753, 411, 341, 5680, 13], "temperature": 0.0, "avg_logprob": -0.20488889129073531, "compression_ratio": 1.5467289719626167, "no_speech_prob": 5.870650056749582e-05}, {"id": 390, "seek": 107236, "start": 1075.6799999999998, "end": 1077.4799999999998, "text": " So, I don't know, I could not give you", "tokens": [407, 11, 286, 500, 380, 458, 11, 286, 727, 406, 976, 291], "temperature": 0.0, "avg_logprob": -0.20488889129073531, "compression_ratio": 1.5467289719626167, "no_speech_prob": 5.870650056749582e-05}, {"id": 391, "seek": 107236, "start": 1077.4799999999998, "end": 1079.04, "text": " a fresh data how it works right now,", "tokens": [257, 4451, 1412, 577, 309, 1985, 558, 586, 11], "temperature": 0.0, "avg_logprob": -0.20488889129073531, "compression_ratio": 1.5467289719626167, "no_speech_prob": 5.870650056749582e-05}, {"id": 392, "seek": 107236, "start": 1079.04, "end": 1082.1599999999999, "text": " but I tried it last year,", "tokens": [457, 286, 3031, 309, 1036, 1064, 11], "temperature": 0.0, "avg_logprob": -0.20488889129073531, "compression_ratio": 1.5467289719626167, "no_speech_prob": 5.870650056749582e-05}, {"id": 393, "seek": 107236, "start": 1082.1599999999999, "end": 1085.9199999999998, "text": " and I couldn't get answer a simple question", "tokens": [293, 286, 2809, 380, 483, 1867, 257, 2199, 1168], "temperature": 0.0, "avg_logprob": -0.20488889129073531, "compression_ratio": 1.5467289719626167, "no_speech_prob": 5.870650056749582e-05}, {"id": 394, "seek": 107236, "start": 1085.9199999999998, "end": 1088.24, "text": " if these two commits are connected.", "tokens": [498, 613, 732, 48311, 366, 4582, 13], "temperature": 0.0, "avg_logprob": -0.20488889129073531, "compression_ratio": 1.5467289719626167, "no_speech_prob": 5.870650056749582e-05}, {"id": 395, "seek": 107236, "start": 1088.24, "end": 1090.8799999999999, "text": " It was just go on forever,", "tokens": [467, 390, 445, 352, 322, 5680, 11], "temperature": 0.0, "avg_logprob": -0.20488889129073531, "compression_ratio": 1.5467289719626167, "no_speech_prob": 5.870650056749582e-05}, {"id": 396, "seek": 107236, "start": 1090.8799999999999, "end": 1092.9599999999998, "text": " then run out of RAM.", "tokens": [550, 1190, 484, 295, 14561, 13], "temperature": 0.0, "avg_logprob": -0.20488889129073531, "compression_ratio": 1.5467289719626167, "no_speech_prob": 5.870650056749582e-05}, {"id": 397, "seek": 107236, "start": 1093.8799999999999, "end": 1097.84, "text": " But with Epoch, I could do that.", "tokens": [583, 365, 462, 2259, 339, 11, 286, 727, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.20488889129073531, "compression_ratio": 1.5467289719626167, "no_speech_prob": 5.870650056749582e-05}, {"id": 398, "seek": 107236, "start": 1097.84, "end": 1099.56, "text": " I could get the answer.", "tokens": [286, 727, 483, 264, 1867, 13], "temperature": 0.0, "avg_logprob": -0.20488889129073531, "compression_ratio": 1.5467289719626167, "no_speech_prob": 5.870650056749582e-05}, {"id": 399, "seek": 109956, "start": 1099.56, "end": 1104.2, "text": " It was okay, but if I wanted to get", "tokens": [467, 390, 1392, 11, 457, 498, 286, 1415, 281, 483], "temperature": 0.0, "avg_logprob": -0.22374741574551196, "compression_ratio": 1.5213270142180095, "no_speech_prob": 4.79931513837073e-05}, {"id": 400, "seek": 109956, "start": 1104.2, "end": 1106.2, "text": " the nodes between those two commits,", "tokens": [264, 13891, 1296, 729, 732, 48311, 11], "temperature": 0.0, "avg_logprob": -0.22374741574551196, "compression_ratio": 1.5213270142180095, "no_speech_prob": 4.79931513837073e-05}, {"id": 401, "seek": 109956, "start": 1106.2, "end": 1108.24, "text": " it would do the same thing.", "tokens": [309, 576, 360, 264, 912, 551, 13], "temperature": 0.0, "avg_logprob": -0.22374741574551196, "compression_ratio": 1.5213270142180095, "no_speech_prob": 4.79931513837073e-05}, {"id": 402, "seek": 109956, "start": 1108.24, "end": 1112.96, "text": " But with Git, I complete that in milliseconds.", "tokens": [583, 365, 16939, 11, 286, 3566, 300, 294, 34184, 13], "temperature": 0.0, "avg_logprob": -0.22374741574551196, "compression_ratio": 1.5213270142180095, "no_speech_prob": 4.79931513837073e-05}, {"id": 403, "seek": 109956, "start": 1112.96, "end": 1114.96, "text": " So, here you go.", "tokens": [407, 11, 510, 291, 352, 13], "temperature": 0.0, "avg_logprob": -0.22374741574551196, "compression_ratio": 1.5213270142180095, "no_speech_prob": 4.79931513837073e-05}, {"id": 404, "seek": 109956, "start": 1114.96, "end": 1117.48, "text": " I think the problem, well, in my opinion,", "tokens": [286, 519, 264, 1154, 11, 731, 11, 294, 452, 4800, 11], "temperature": 0.0, "avg_logprob": -0.22374741574551196, "compression_ratio": 1.5213270142180095, "no_speech_prob": 4.79931513837073e-05}, {"id": 405, "seek": 109956, "start": 1117.48, "end": 1120.32, "text": " is that the graph management databases and", "tokens": [307, 300, 264, 4295, 4592, 22380, 293], "temperature": 0.0, "avg_logprob": -0.22374741574551196, "compression_ratio": 1.5213270142180095, "no_speech_prob": 4.79931513837073e-05}, {"id": 406, "seek": 109956, "start": 1120.32, "end": 1124.08, "text": " software there aimed at a general graph problem,", "tokens": [4722, 456, 20540, 412, 257, 2674, 4295, 1154, 11], "temperature": 0.0, "avg_logprob": -0.22374741574551196, "compression_ratio": 1.5213270142180095, "no_speech_prob": 4.79931513837073e-05}, {"id": 407, "seek": 109956, "start": 1124.08, "end": 1126.24, "text": " and not tuned to DAGs.", "tokens": [293, 406, 10870, 281, 9578, 33715, 13], "temperature": 0.0, "avg_logprob": -0.22374741574551196, "compression_ratio": 1.5213270142180095, "no_speech_prob": 4.79931513837073e-05}, {"id": 408, "seek": 112624, "start": 1126.24, "end": 1129.64, "text": " How Git does that, Git is tuned to DAG,", "tokens": [1012, 16939, 775, 300, 11, 16939, 307, 10870, 281, 9578, 38, 11], "temperature": 0.0, "avg_logprob": -0.21851055549852777, "compression_ratio": 1.6433566433566433, "no_speech_prob": 2.9731951144640334e-05}, {"id": 409, "seek": 112624, "start": 1129.64, "end": 1131.44, "text": " they have a lot of optimizations for that,", "tokens": [436, 362, 257, 688, 295, 5028, 14455, 337, 300, 11], "temperature": 0.0, "avg_logprob": -0.21851055549852777, "compression_ratio": 1.6433566433566433, "no_speech_prob": 2.9731951144640334e-05}, {"id": 410, "seek": 112624, "start": 1131.44, "end": 1133.0, "text": " and there are streaks to make", "tokens": [293, 456, 366, 2242, 5461, 281, 652], "temperature": 0.0, "avg_logprob": -0.21851055549852777, "compression_ratio": 1.6433566433566433, "no_speech_prob": 2.9731951144640334e-05}, {"id": 411, "seek": 112624, "start": 1133.0, "end": 1135.48, "text": " like repositories like the Linux kernel work.", "tokens": [411, 22283, 2083, 411, 264, 18734, 28256, 589, 13], "temperature": 0.0, "avg_logprob": -0.21851055549852777, "compression_ratio": 1.6433566433566433, "no_speech_prob": 2.9731951144640334e-05}, {"id": 412, "seek": 112624, "start": 1135.48, "end": 1139.88, "text": " So, I don't know nothing how you do this.", "tokens": [407, 11, 286, 500, 380, 458, 1825, 577, 291, 360, 341, 13], "temperature": 0.0, "avg_logprob": -0.21851055549852777, "compression_ratio": 1.6433566433566433, "no_speech_prob": 2.9731951144640334e-05}, {"id": 413, "seek": 112624, "start": 1139.88, "end": 1141.08, "text": " This is magic to me,", "tokens": [639, 307, 5585, 281, 385, 11], "temperature": 0.0, "avg_logprob": -0.21851055549852777, "compression_ratio": 1.6433566433566433, "no_speech_prob": 2.9731951144640334e-05}, {"id": 414, "seek": 112624, "start": 1141.08, "end": 1143.56, "text": " and this would be new to me in this book.", "tokens": [293, 341, 576, 312, 777, 281, 385, 294, 341, 1446, 13], "temperature": 0.0, "avg_logprob": -0.21851055549852777, "compression_ratio": 1.6433566433566433, "no_speech_prob": 2.9731951144640334e-05}, {"id": 415, "seek": 112624, "start": 1143.56, "end": 1145.88, "text": " But from a purely engineering perspective,", "tokens": [583, 490, 257, 17491, 7043, 4585, 11], "temperature": 0.0, "avg_logprob": -0.21851055549852777, "compression_ratio": 1.6433566433566433, "no_speech_prob": 2.9731951144640334e-05}, {"id": 416, "seek": 112624, "start": 1145.88, "end": 1147.88, "text": " I would have liked to see something like", "tokens": [286, 576, 362, 4501, 281, 536, 746, 411], "temperature": 0.0, "avg_logprob": -0.21851055549852777, "compression_ratio": 1.6433566433566433, "no_speech_prob": 2.9731951144640334e-05}, {"id": 417, "seek": 112624, "start": 1147.88, "end": 1151.04, "text": " a support for databases that are restricted for DAGs only,", "tokens": [257, 1406, 337, 22380, 300, 366, 20608, 337, 9578, 33715, 787, 11], "temperature": 0.0, "avg_logprob": -0.21851055549852777, "compression_ratio": 1.6433566433566433, "no_speech_prob": 2.9731951144640334e-05}, {"id": 418, "seek": 112624, "start": 1151.04, "end": 1153.48, "text": " and that apparently could be done", "tokens": [293, 300, 7970, 727, 312, 1096], "temperature": 0.0, "avg_logprob": -0.21851055549852777, "compression_ratio": 1.6433566433566433, "no_speech_prob": 2.9731951144640334e-05}, {"id": 419, "seek": 112624, "start": 1153.48, "end": 1156.2, "text": " with not so much computation.", "tokens": [365, 406, 370, 709, 24903, 13], "temperature": 0.0, "avg_logprob": -0.21851055549852777, "compression_ratio": 1.6433566433566433, "no_speech_prob": 2.9731951144640334e-05}, {"id": 420, "seek": 115620, "start": 1156.2, "end": 1158.4, "text": " Then, once you have that,", "tokens": [1396, 11, 1564, 291, 362, 300, 11], "temperature": 0.0, "avg_logprob": -0.18610766294191208, "compression_ratio": 1.691449814126394, "no_speech_prob": 4.804169657290913e-05}, {"id": 421, "seek": 115620, "start": 1158.4, "end": 1160.64, "text": " then you can do some branching and say like,", "tokens": [550, 291, 393, 360, 512, 9819, 278, 293, 584, 411, 11], "temperature": 0.0, "avg_logprob": -0.18610766294191208, "compression_ratio": 1.691449814126394, "no_speech_prob": 4.804169657290913e-05}, {"id": 422, "seek": 115620, "start": 1160.64, "end": 1161.8, "text": " okay, if we are DAG database,", "tokens": [1392, 11, 498, 321, 366, 9578, 38, 8149, 11], "temperature": 0.0, "avg_logprob": -0.18610766294191208, "compression_ratio": 1.691449814126394, "no_speech_prob": 4.804169657290913e-05}, {"id": 423, "seek": 115620, "start": 1161.8, "end": 1164.0800000000002, "text": " then we can do the optimizations", "tokens": [550, 321, 393, 360, 264, 5028, 14455], "temperature": 0.0, "avg_logprob": -0.18610766294191208, "compression_ratio": 1.691449814126394, "no_speech_prob": 4.804169657290913e-05}, {"id": 424, "seek": 115620, "start": 1164.0800000000002, "end": 1167.1200000000001, "text": " and do the fast thing with them.", "tokens": [293, 360, 264, 2370, 551, 365, 552, 13], "temperature": 0.0, "avg_logprob": -0.18610766294191208, "compression_ratio": 1.691449814126394, "no_speech_prob": 4.804169657290913e-05}, {"id": 425, "seek": 115620, "start": 1167.1200000000001, "end": 1169.76, "text": " So, the full back plan is obviously just", "tokens": [407, 11, 264, 1577, 646, 1393, 307, 2745, 445], "temperature": 0.0, "avg_logprob": -0.18610766294191208, "compression_ratio": 1.691449814126394, "no_speech_prob": 4.804169657290913e-05}, {"id": 426, "seek": 115620, "start": 1169.76, "end": 1172.8, "text": " put everything in Git, put the commits,", "tokens": [829, 1203, 294, 16939, 11, 829, 264, 48311, 11], "temperature": 0.0, "avg_logprob": -0.18610766294191208, "compression_ratio": 1.691449814126394, "no_speech_prob": 4.804169657290913e-05}, {"id": 427, "seek": 115620, "start": 1172.8, "end": 1174.96, "text": " and the patches, and all the branches,", "tokens": [293, 264, 26531, 11, 293, 439, 264, 14770, 11], "temperature": 0.0, "avg_logprob": -0.18610766294191208, "compression_ratio": 1.691449814126394, "no_speech_prob": 4.804169657290913e-05}, {"id": 428, "seek": 115620, "start": 1174.96, "end": 1177.96, "text": " and all the subsystems, it's going to be giant repo.", "tokens": [293, 439, 264, 2090, 9321, 82, 11, 309, 311, 516, 281, 312, 7410, 49040, 13], "temperature": 0.0, "avg_logprob": -0.18610766294191208, "compression_ratio": 1.691449814126394, "no_speech_prob": 4.804169657290913e-05}, {"id": 429, "seek": 115620, "start": 1177.96, "end": 1179.4, "text": " Maybe we can manage that,", "tokens": [2704, 321, 393, 3067, 300, 11], "temperature": 0.0, "avg_logprob": -0.18610766294191208, "compression_ratio": 1.691449814126394, "no_speech_prob": 4.804169657290913e-05}, {"id": 430, "seek": 115620, "start": 1179.4, "end": 1181.04, "text": " and then query it with libGit2,", "tokens": [293, 550, 14581, 309, 365, 22854, 38, 270, 17, 11], "temperature": 0.0, "avg_logprob": -0.18610766294191208, "compression_ratio": 1.691449814126394, "no_speech_prob": 4.804169657290913e-05}, {"id": 431, "seek": 115620, "start": 1181.04, "end": 1185.2, "text": " which is the library that Git uses to work with the data.", "tokens": [597, 307, 264, 6405, 300, 16939, 4960, 281, 589, 365, 264, 1412, 13], "temperature": 0.0, "avg_logprob": -0.18610766294191208, "compression_ratio": 1.691449814126394, "no_speech_prob": 4.804169657290913e-05}, {"id": 432, "seek": 118520, "start": 1185.2, "end": 1188.68, "text": " Then, well, shuttle the commits with the relational database.", "tokens": [1396, 11, 731, 11, 26728, 264, 48311, 365, 264, 38444, 8149, 13], "temperature": 0.0, "avg_logprob": -0.28665670801381593, "compression_ratio": 1.5, "no_speech_prob": 0.0001368972152704373}, {"id": 433, "seek": 118520, "start": 1188.68, "end": 1191.16, "text": " Okay, we want to see if between those releases,", "tokens": [1033, 11, 321, 528, 281, 536, 498, 1296, 729, 16952, 11], "temperature": 0.0, "avg_logprob": -0.28665670801381593, "compression_ratio": 1.5, "no_speech_prob": 0.0001368972152704373}, {"id": 434, "seek": 118520, "start": 1191.16, "end": 1192.76, "text": " we have issues and we take", "tokens": [321, 362, 2663, 293, 321, 747], "temperature": 0.0, "avg_logprob": -0.28665670801381593, "compression_ratio": 1.5, "no_speech_prob": 0.0001368972152704373}, {"id": 435, "seek": 118520, "start": 1192.76, "end": 1197.16, "text": " the commit hashes from Git and then query the database with that.", "tokens": [264, 5599, 575, 8076, 490, 16939, 293, 550, 14581, 264, 8149, 365, 300, 13], "temperature": 0.0, "avg_logprob": -0.28665670801381593, "compression_ratio": 1.5, "no_speech_prob": 0.0001368972152704373}, {"id": 436, "seek": 118520, "start": 1197.16, "end": 1199.92, "text": " That's all. Thanks.", "tokens": [663, 311, 439, 13, 2561, 13], "temperature": 0.0, "avg_logprob": -0.28665670801381593, "compression_ratio": 1.5, "no_speech_prob": 0.0001368972152704373}, {"id": 437, "seek": 119992, "start": 1199.92, "end": 1215.96, "text": " So, we can help you with the Neo4j things.", "tokens": [407, 11, 321, 393, 854, 291, 365, 264, 24458, 19, 73, 721, 13], "temperature": 0.0, "avg_logprob": -0.4796094236702755, "compression_ratio": 1.3432835820895523, "no_speech_prob": 6.298977677943185e-05}, {"id": 438, "seek": 119992, "start": 1215.96, "end": 1223.52, "text": " It's just like literally this string, this length.", "tokens": [467, 311, 445, 411, 3736, 341, 6798, 11, 341, 4641, 13], "temperature": 0.0, "avg_logprob": -0.4796094236702755, "compression_ratio": 1.3432835820895523, "no_speech_prob": 6.298977677943185e-05}, {"id": 439, "seek": 119992, "start": 1223.52, "end": 1226.68, "text": " No, it's text index is for full text back for.", "tokens": [883, 11, 309, 311, 2487, 8186, 307, 337, 1577, 2487, 646, 337, 13], "temperature": 0.0, "avg_logprob": -0.4796094236702755, "compression_ratio": 1.3432835820895523, "no_speech_prob": 6.298977677943185e-05}, {"id": 440, "seek": 119992, "start": 1226.68, "end": 1229.8000000000002, "text": " Okay. Well, it was just this one thing.", "tokens": [1033, 13, 1042, 11, 309, 390, 445, 341, 472, 551, 13], "temperature": 0.0, "avg_logprob": -0.4796094236702755, "compression_ratio": 1.3432835820895523, "no_speech_prob": 6.298977677943185e-05}, {"id": 441, "seek": 122980, "start": 1229.8, "end": 1235.52, "text": " So, do you have the data somewhere to try it out?", "tokens": [407, 11, 360, 291, 362, 264, 1412, 4079, 281, 853, 309, 484, 30], "temperature": 0.0, "avg_logprob": -0.34360485810499924, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.00010871688573388383}, {"id": 442, "seek": 122980, "start": 1235.52, "end": 1236.6399999999999, "text": " Of course. Of course.", "tokens": [2720, 1164, 13, 2720, 1164, 13], "temperature": 0.0, "avg_logprob": -0.34360485810499924, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.00010871688573388383}, {"id": 443, "seek": 122980, "start": 1236.6399999999999, "end": 1238.24, "text": " There's a link from the slides to", "tokens": [821, 311, 257, 2113, 490, 264, 9788, 281], "temperature": 0.0, "avg_logprob": -0.34360485810499924, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.00010871688573388383}, {"id": 444, "seek": 122980, "start": 1238.24, "end": 1241.04, "text": " the script that you can use yourself on any Git repo.", "tokens": [264, 5755, 300, 291, 393, 764, 1803, 322, 604, 16939, 49040, 13], "temperature": 0.0, "avg_logprob": -0.34360485810499924, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.00010871688573388383}, {"id": 445, "seek": 122980, "start": 1241.04, "end": 1247.0, "text": " Yeah. Any more questions?", "tokens": [865, 13, 2639, 544, 1651, 30], "temperature": 0.0, "avg_logprob": -0.34360485810499924, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.00010871688573388383}, {"id": 446, "seek": 122980, "start": 1247.0, "end": 1248.12, "text": " Yes?", "tokens": [1079, 30], "temperature": 0.0, "avg_logprob": -0.34360485810499924, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.00010871688573388383}, {"id": 447, "seek": 122980, "start": 1248.12, "end": 1250.24, "text": " Did you try any other graph databases?", "tokens": [2589, 291, 853, 604, 661, 4295, 22380, 30], "temperature": 0.0, "avg_logprob": -0.34360485810499924, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.00010871688573388383}, {"id": 448, "seek": 122980, "start": 1250.24, "end": 1254.3999999999999, "text": " Well, I looked at the question is,", "tokens": [1042, 11, 286, 2956, 412, 264, 1168, 307, 11], "temperature": 0.0, "avg_logprob": -0.34360485810499924, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.00010871688573388383}, {"id": 449, "seek": 122980, "start": 1254.3999999999999, "end": 1257.48, "text": " did I try any other graph databases?", "tokens": [630, 286, 853, 604, 661, 4295, 22380, 30], "temperature": 0.0, "avg_logprob": -0.34360485810499924, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.00010871688573388383}, {"id": 450, "seek": 122980, "start": 1257.48, "end": 1259.28, "text": " Yeah, I looked at a bunch of them.", "tokens": [865, 11, 286, 2956, 412, 257, 3840, 295, 552, 13], "temperature": 0.0, "avg_logprob": -0.34360485810499924, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.00010871688573388383}, {"id": 451, "seek": 125928, "start": 1259.28, "end": 1263.44, "text": " Some of them require so much setup that I was just floored,", "tokens": [2188, 295, 552, 3651, 370, 709, 8657, 300, 286, 390, 445, 2591, 2769, 11], "temperature": 0.0, "avg_logprob": -0.2042144203186035, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0002635146083775908}, {"id": 452, "seek": 125928, "start": 1263.44, "end": 1265.12, "text": " but I read the documentation.", "tokens": [457, 286, 1401, 264, 14333, 13], "temperature": 0.0, "avg_logprob": -0.2042144203186035, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0002635146083775908}, {"id": 453, "seek": 125928, "start": 1265.12, "end": 1268.72, "text": " I couldn't see any indication that it would be any different", "tokens": [286, 2809, 380, 536, 604, 18877, 300, 309, 576, 312, 604, 819], "temperature": 0.0, "avg_logprob": -0.2042144203186035, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0002635146083775908}, {"id": 454, "seek": 125928, "start": 1268.72, "end": 1271.04, "text": " because nobody says anything about DAGs,", "tokens": [570, 5079, 1619, 1340, 466, 9578, 33715, 11], "temperature": 0.0, "avg_logprob": -0.2042144203186035, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0002635146083775908}, {"id": 455, "seek": 125928, "start": 1271.04, "end": 1272.8, "text": " any optimizations or anything.", "tokens": [604, 5028, 14455, 420, 1340, 13], "temperature": 0.0, "avg_logprob": -0.2042144203186035, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0002635146083775908}, {"id": 456, "seek": 125928, "start": 1272.8, "end": 1277.24, "text": " I tried memgraph before this talk,", "tokens": [286, 3031, 1334, 34091, 949, 341, 751, 11], "temperature": 0.0, "avg_logprob": -0.2042144203186035, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0002635146083775908}, {"id": 457, "seek": 125928, "start": 1277.24, "end": 1283.04, "text": " but I had the same problem with loading revisions,", "tokens": [457, 286, 632, 264, 912, 1154, 365, 15114, 3698, 4252, 11], "temperature": 0.0, "avg_logprob": -0.2042144203186035, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0002635146083775908}, {"id": 458, "seek": 125928, "start": 1283.04, "end": 1284.44, "text": " I think for some reason.", "tokens": [286, 519, 337, 512, 1778, 13], "temperature": 0.0, "avg_logprob": -0.2042144203186035, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0002635146083775908}, {"id": 459, "seek": 125928, "start": 1284.44, "end": 1286.6, "text": " Because previously, I could load revisions.", "tokens": [1436, 8046, 11, 286, 727, 3677, 3698, 4252, 13], "temperature": 0.0, "avg_logprob": -0.2042144203186035, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0002635146083775908}, {"id": 460, "seek": 128660, "start": 1286.6, "end": 1291.24, "text": " I guess in Neo4j, the syntax for indexes has changed since then.", "tokens": [286, 2041, 294, 24458, 19, 73, 11, 264, 28431, 337, 8186, 279, 575, 3105, 1670, 550, 13], "temperature": 0.0, "avg_logprob": -0.27509125796231354, "compression_ratio": 1.57421875, "no_speech_prob": 0.0001453520089853555}, {"id": 461, "seek": 128660, "start": 1291.24, "end": 1295.28, "text": " Maybe I did create indexing correctly as I was just hinted at.", "tokens": [2704, 286, 630, 1884, 8186, 278, 8944, 382, 286, 390, 445, 12075, 292, 412, 13], "temperature": 0.0, "avg_logprob": -0.27509125796231354, "compression_ratio": 1.57421875, "no_speech_prob": 0.0001453520089853555}, {"id": 462, "seek": 128660, "start": 1295.28, "end": 1298.6399999999999, "text": " But I could load them in reasonable time before in Neo4j and", "tokens": [583, 286, 727, 3677, 552, 294, 10585, 565, 949, 294, 24458, 19, 73, 293], "temperature": 0.0, "avg_logprob": -0.27509125796231354, "compression_ratio": 1.57421875, "no_speech_prob": 0.0001453520089853555}, {"id": 463, "seek": 128660, "start": 1298.6399999999999, "end": 1302.0, "text": " everything fine and like in query and except that thing.", "tokens": [1203, 2489, 293, 411, 294, 14581, 293, 3993, 300, 551, 13], "temperature": 0.0, "avg_logprob": -0.27509125796231354, "compression_ratio": 1.57421875, "no_speech_prob": 0.0001453520089853555}, {"id": 464, "seek": 128660, "start": 1302.0, "end": 1304.9199999999998, "text": " In memgraph, I just hit the wall because it's", "tokens": [682, 1334, 34091, 11, 286, 445, 2045, 264, 2929, 570, 309, 311], "temperature": 0.0, "avg_logprob": -0.27509125796231354, "compression_ratio": 1.57421875, "no_speech_prob": 0.0001453520089853555}, {"id": 465, "seek": 128660, "start": 1304.9199999999998, "end": 1306.9599999999998, "text": " a different syntax slightly, it was slow.", "tokens": [257, 819, 28431, 4748, 11, 309, 390, 2964, 13], "temperature": 0.0, "avg_logprob": -0.27509125796231354, "compression_ratio": 1.57421875, "no_speech_prob": 0.0001453520089853555}, {"id": 466, "seek": 128660, "start": 1306.9599999999998, "end": 1311.7199999999998, "text": " But yeah, no such luck and it took like four gigabytes of disk space.", "tokens": [583, 1338, 11, 572, 1270, 3668, 293, 309, 1890, 411, 1451, 42741, 295, 12355, 1901, 13], "temperature": 0.0, "avg_logprob": -0.27509125796231354, "compression_ratio": 1.57421875, "no_speech_prob": 0.0001453520089853555}, {"id": 467, "seek": 131172, "start": 1311.72, "end": 1316.72, "text": " So, not too bad, okay.", "tokens": [407, 11, 406, 886, 1578, 11, 1392, 13], "temperature": 0.0, "avg_logprob": -0.3356793212890625, "compression_ratio": 1.5103092783505154, "no_speech_prob": 0.0006080657476559281}, {"id": 468, "seek": 131172, "start": 1316.72, "end": 1319.72, "text": " What version of Neo4j was successful?", "tokens": [708, 3037, 295, 24458, 19, 73, 390, 4406, 30], "temperature": 0.0, "avg_logprob": -0.3356793212890625, "compression_ratio": 1.5103092783505154, "no_speech_prob": 0.0006080657476559281}, {"id": 469, "seek": 131172, "start": 1319.72, "end": 1321.32, "text": " I don't remember now.", "tokens": [286, 500, 380, 1604, 586, 13], "temperature": 0.0, "avg_logprob": -0.3356793212890625, "compression_ratio": 1.5103092783505154, "no_speech_prob": 0.0006080657476559281}, {"id": 470, "seek": 131172, "start": 1321.32, "end": 1324.1200000000001, "text": " I think it was, if I take a look now,", "tokens": [286, 519, 309, 390, 11, 498, 286, 747, 257, 574, 586, 11], "temperature": 0.0, "avg_logprob": -0.3356793212890625, "compression_ratio": 1.5103092783505154, "no_speech_prob": 0.0006080657476559281}, {"id": 471, "seek": 131172, "start": 1324.1200000000001, "end": 1324.72, "text": " I think I-", "tokens": [286, 519, 286, 12], "temperature": 0.0, "avg_logprob": -0.3356793212890625, "compression_ratio": 1.5103092783505154, "no_speech_prob": 0.0006080657476559281}, {"id": 472, "seek": 131172, "start": 1324.72, "end": 1327.64, "text": " The version will also be successful, it's just research.", "tokens": [440, 3037, 486, 611, 312, 4406, 11, 309, 311, 445, 2132, 13], "temperature": 0.0, "avg_logprob": -0.3356793212890625, "compression_ratio": 1.5103092783505154, "no_speech_prob": 0.0006080657476559281}, {"id": 473, "seek": 131172, "start": 1327.64, "end": 1334.24, "text": " I tried one Neo4j desktop 1.4 before,", "tokens": [286, 3031, 472, 24458, 19, 73, 14502, 502, 13, 19, 949, 11], "temperature": 0.0, "avg_logprob": -0.3356793212890625, "compression_ratio": 1.5103092783505154, "no_speech_prob": 0.0006080657476559281}, {"id": 474, "seek": 131172, "start": 1334.24, "end": 1336.4, "text": " 1.415 and that worked.", "tokens": [502, 13, 19, 5211, 293, 300, 2732, 13], "temperature": 0.0, "avg_logprob": -0.3356793212890625, "compression_ratio": 1.5103092783505154, "no_speech_prob": 0.0006080657476559281}, {"id": 475, "seek": 133640, "start": 1336.4, "end": 1342.4, "text": " I don't know which one, which version it was included.", "tokens": [286, 500, 380, 458, 597, 472, 11, 597, 3037, 309, 390, 5556, 13], "temperature": 0.0, "avg_logprob": -0.47090475294325085, "compression_ratio": 1.527363184079602, "no_speech_prob": 0.0010706327157095075}, {"id": 476, "seek": 133640, "start": 1342.4, "end": 1346.4, "text": " Any other questions?", "tokens": [2639, 661, 1651, 30], "temperature": 0.0, "avg_logprob": -0.47090475294325085, "compression_ratio": 1.527363184079602, "no_speech_prob": 0.0010706327157095075}, {"id": 477, "seek": 133640, "start": 1346.4, "end": 1347.4, "text": " Thank you so much, Nikolaj.", "tokens": [1044, 291, 370, 709, 11, 13969, 401, 1805, 13], "temperature": 0.0, "avg_logprob": -0.47090475294325085, "compression_ratio": 1.527363184079602, "no_speech_prob": 0.0010706327157095075}, {"id": 478, "seek": 133640, "start": 1347.4, "end": 1348.4, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.47090475294325085, "compression_ratio": 1.527363184079602, "no_speech_prob": 0.0010706327157095075}, {"id": 479, "seek": 133640, "start": 1348.4, "end": 1353.4, "text": " Thank you, everyone.", "tokens": [1044, 291, 11, 1518, 13], "temperature": 0.0, "avg_logprob": -0.47090475294325085, "compression_ratio": 1.527363184079602, "no_speech_prob": 0.0010706327157095075}, {"id": 480, "seek": 133640, "start": 1353.4, "end": 1356.4, "text": " I'm still looking forward to work with data in the graph database.", "tokens": [286, 478, 920, 1237, 2128, 281, 589, 365, 1412, 294, 264, 4295, 8149, 13], "temperature": 0.0, "avg_logprob": -0.47090475294325085, "compression_ratio": 1.527363184079602, "no_speech_prob": 0.0010706327157095075}, {"id": 481, "seek": 133640, "start": 1356.4, "end": 1361.4, "text": " Because I think that's actually good for the graph database.", "tokens": [1436, 286, 519, 300, 311, 767, 665, 337, 264, 4295, 8149, 13], "temperature": 0.0, "avg_logprob": -0.47090475294325085, "compression_ratio": 1.527363184079602, "no_speech_prob": 0.0010706327157095075}, {"id": 482, "seek": 133640, "start": 1361.4, "end": 1364.4, "text": " And so we can make it work and then Dexter,", "tokens": [400, 370, 321, 393, 652, 309, 589, 293, 550, 1346, 36671, 11], "temperature": 0.0, "avg_logprob": -0.47090475294325085, "compression_ratio": 1.527363184079602, "no_speech_prob": 0.0010706327157095075}, {"id": 483, "seek": 136440, "start": 1364.4, "end": 1368.4, "text": " you can come back and do some large scale analysis on the data.", "tokens": [291, 393, 808, 646, 293, 360, 512, 2416, 4373, 5215, 322, 264, 1412, 13], "temperature": 0.0, "avg_logprob": -0.2812784268305852, "compression_ratio": 1.3818181818181818, "no_speech_prob": 0.006268616300076246}, {"id": 484, "seek": 136440, "start": 1368.4, "end": 1370.4, "text": " Okay, that would be great.", "tokens": [1033, 11, 300, 576, 312, 869, 13], "temperature": 0.0, "avg_logprob": -0.2812784268305852, "compression_ratio": 1.3818181818181818, "no_speech_prob": 0.006268616300076246}, {"id": 485, "seek": 136440, "start": 1370.4, "end": 1372.4, "text": " That's what you can do.", "tokens": [663, 311, 437, 291, 393, 360, 13], "temperature": 0.0, "avg_logprob": -0.2812784268305852, "compression_ratio": 1.3818181818181818, "no_speech_prob": 0.006268616300076246}, {"id": 486, "seek": 136440, "start": 1372.4, "end": 1374.4, "text": " Yes, thank you.", "tokens": [1079, 11, 1309, 291, 13], "temperature": 0.0, "avg_logprob": -0.2812784268305852, "compression_ratio": 1.3818181818181818, "no_speech_prob": 0.006268616300076246}, {"id": 487, "seek": 136440, "start": 1374.4, "end": 1376.4, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.2812784268305852, "compression_ratio": 1.3818181818181818, "no_speech_prob": 0.006268616300076246}, {"id": 488, "seek": 137640, "start": 1376.4, "end": 1395.4, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 51314], "temperature": 0.0, "avg_logprob": -0.4613010088602702, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.005166747607290745}], "language": "en"}