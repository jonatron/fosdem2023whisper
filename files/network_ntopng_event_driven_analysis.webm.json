{"text": " Okay, good morning. This time it's a turn to talk about something different. And top ng. What is in top ng? It's an open source application, of course. We are here. And you can download the code on GitHub. We'll see the link at the end of the talk. What is in top ng doing? It is, first of all, a real-time network and traffic monitoring application. So it means that it displays you on a web interface what is happening in your network live. Okay, no delay. This is unless, of course, we are receiving flows coming from a router that are somehow a little bit delayed because by nature they are on average. So they have a certain lifetime. And it is designed for network monitoring and cybersecurity. It means that there are some behavioral checks. So we are not bound to rules. You have seen Suricata representation before. You see there are some rules in case this happens then. So this is not our case. So we work based on behavior. So it means that if you have a host that is misbehaving, more or less similar to what you have seen before, that suddenly start to send too much traffic with respect to the past, or starting to, you know, fire up a new application. So accept connection on a certain port for TLS that was not open before. This is a typical example. So therefore it means that the application simply starts up and learns what is happening on the network. There are some levels of learning. So sometimes it is an immediate learning because, you know, you specify some sort of configuration. But usually this is not the case. The case is that the application learns what is happening and in case something goes wrong, goes different, fires up and alert. This is the idea. And the architecture is actually divided in two parts. Okay. First of all, the pocket processing part that is based on more or less PF ring or lead pickup. So this means that you can run on Windows, Linux, Mac OS, FreeBSD, whatever. Instead, PF ring is something that we have co-developed that is a Linux technology for accelerating pocket capture, but not only for that, but also for merging traffic for multiple adapters, for distributing traffic. So it's much more than simply RX acceleration. And top of this, there is an open source library that we still maintain at N-top called NDPI. So this is the only open source library that is doing the pocket inspection. But for us, it means that we try to understand from the traffic what is the application protocol. So if it's TLS, if it's a generic protocol, if it's Google mail, but it's a very specific protocol. And out of the traffic, we extract the metadata. So for instance, we extract certificate information and we generate something we call RISC. So looking at the traffic, we see if there is something wrong, okay, such as for instance, an expired certificate just to give you an idea. And we trigger an alert. On top of this, there is a TopNG because this is the first part that is basically provided by the operating system. And TopNG has a C++ engine that is processing packets, that is in essence doing traffic analysis, creates internally, okay, the representation of the data based on the concept of network interfaces because we can have a multiple network interfaces from which the traffic is received. It can be a virtual interface such as, you know, a NetFlow collection or a physical interface, ETH0. And then we have something we call behavioral checks, where we check flows and hosts. Flows means that each independent communication, such as a TCP connection, is checked. Instead, a host, we take the host as a whole. So in essence, if a host is doing a port scan, each individual communication is okay, or more or less okay. But the fact that this host is doing this, you know, in a sequence, in a network or in a host, it's a problem. So this is called behavioral checks. And on top of this, we trigger alerts that can be consumed locally or sent elsewhere. This is the fast part. On top of this, we have the Lua interface. Why Lua? Because we like C++. But C++ is something not for everybody, okay? So we need to simplify, for instance, the development of the web interface. So for instance, the REST API is written in Lua, sitting on top of C++. So we have created an API that allows us to avoid typical problems of C++ at the same time we simplify the way the application is working. So therefore, we use Lua for operations that are not critical, such as the web GUI, or for checking interfaces that are not necessarily real-time, so for the SNMP. For SNMP, we fetch the data every five minutes and do the checks. So traffic ingestion, as I said, is done in multiple ways. Sometime is serial traffic, so packets. Sometime it is not. It's a flow. And this is handled by the C++ engine. So the C++ engine is doing it efficiently. And then we have other type of ingestions based on events. So something that we don't really control completely, but that are relevant for us. So we have seen Surikata, the presentation before, some minutes ago. This is a typical example of input. Why this? Because, as I said at the beginning, we don't have rules. We don't want to have rules. So we don't want to say if the payload contains this and this and this and this then, because we don't believe that this is what we should do. Instead, there are wonderful tools such as Surikata that are doing that very well. So therefore, the idea is to combine network monitoring and behavior analysis with these type of tools. So therefore, indirectly, through tools such as Surikata that is optional, of course, you don't have to run it with N-top-ng monitoring, you can have this type of information that can be combined directly by N-top-ng. Of course, we have firewall logs and syslog. Why this is important? Because we can have a look at information that is not visible from the traffic. So we always play with packets, me and Alfredo. But we understand that packets have limitations, okay, especially for encryption. So we have seen before rules saying if you are downloading a buyer application, that is fine if it's plain text. But if TLS, you will never see that happen, okay. So you have to use things like rules on top of this, on top of this, but they are just guesses. So instead, if through syslog or other means, we know that. So for example, we see an attack or a wordpress saying that this host is trying to guess the password of administrator user. This is much relevant information. And from the network standpoint, it looks simply nice. Everything is okay. The problem is from the application. That's why we believe in network. By the same time, we need to have some other information that is injected into the application. And of course, we have historical data. We use a database called Clickhouse. So we can put a billion of records. Everything is working very fast. This is also an open source database. And for time series, we use round robin database or influxdp. And as I said before, we have checks that are divided in two parts. C++ for efficiency. So the fast part, in essence, where you have to process traffic in line, such as when you have a pocket, an incoming pocket, you have to check if this pocket belonging to a flow is relevant. And then we have other types of checks that are not so real time. So for a check on an SNMP interface, that need to be easy to be developed. But at the same time, that don't need to be fast. Because as I said, if we pull SNMP out in five minutes, we have plenty of time for doing that. And of course, we have notifications that we send out. So for instance, we trigger a shell script, a webhook, syslog, you know, telegram, you know, usual thing. Nothing new here. Okay, let's now start the talk after this introduction of NTOC and GIM. The problem is the following. So we have added over 150 checks, behavioral checks on the traffic. But there is always somebody that comes and says, I want to do something different. How can we support these people? How can we enable new programmers or let's say people that used to use Python, shell script, you know, this type of programming language or that don't want to learn the internals of our application? How can we do that? And many times this happens when you are in a harsh. So that is an attack. That is something happening on your network that you want to check. And we have, you know, two levels of the problem. First of all, we have to extend the behavioral checks in order to have some behavioral detection in a different way. And in the second part that Alfredo will describe later. So how can we use NTOC and G as a data lake from languages such as Python, for instance, that is very popular. So that you can use NTOC and G as a source of data for your own application. Of course, you have time series. As I said, we save data in influxDB if you want. So therefore, you can use Grafana for creating your own dashboard. But these are simple dashboards. So if we want to do something more complicated, if we want to go beyond that, in addition to that, how can we do that? So this is the idea today. So we like C++. C++ is super efficient. We like it. Okay. We are used to play with it since many years. But we understand that it's not what everybody wants. Okay. We need something easier. And we would like to understand also how it was possible to develop checks in minutes for people who are saying, okay, if I see this specific certificate or if I see this specific behavior, then there is a problem. Something very peculiar to an organization. So not general for everybody, but for specific people. So for instance, how do I trigger an alert if there is traffic, TLS traffic within host A and B? So for instance, a printer should not make any TLS traffic just to make an example. So if this happens, and how can you trigger an alert? Another problem is the following. If I have a certificate signed by a certain organization, or for instance, if I have a BitTorrent connection that is going above one gigabit, or notifying me if there is a Zoom call with bad quality, things like this. Things like very, very peculiar, very specific checks that people want to do. Maybe on an operating, sorry, on an autonomous system, and not on another, or on an actor, and not on another. So things that are not general that we can implement for everybody. How can we do that? So let me talk how it works in top NG internally. Let's have a look at the flow, also communication. So in top NG creates a data structure inside itself as soon as we see the first packet of the flow. So we see episodes of the destination, source parts of destination, protocol, VLAN, whatever. And then this is the first event that is relevant for us. And then, as I said, everything sits on top of NDPI, so the yellow part. So we have another event when the application protocol is detected. Actually, this one is divided in two parts. First of all, as soon as the main protocol is detected, such as TLS, okay, and then we can refine this information with metadata saying, okay, this is TLS that is going to Google mail, and not Google search or Google something else, okay. So second event and NDPI. And then we have, for long-standing flows, some periodic activities. So in essence, every minute, we do something different, something like, you know, I want to trigger, you know, an action. And then at the end, the flow end notification, so as soon as the flow is over. So what we wanted to do, we wanted to create a low API that allows people to create the simple checks that are efficient. Efficient enough for most people, because not everybody needs one and a gigabit, but many people have one gigabit networks or, you know, two, five gigabit networks. So they need some sort of efficiency, but they are not super extreme. So let's say use Lua for prototype on a check for some people who need speed, or use Lua for people who have, let's say, an industrial network or a network that is, you know, running at one gigabit or two. So in essence, we have created an API that allows from Lua to see internally, in N-top and G, properties of the flow. For instance, the number of bytes, multicast, layers, seven information, these type of things. And the API calls are very small. So in essence, we don't want, you know, the application to be inefficient simply because we download to Lua the representation of the host, the representation of the flow. Well, simply the method that we are interested in. So in the left side, you will see the C++ code, how it implements the stuff. On the right side, you will see an example of the Lua code. So in this case, just to give you an idea of how it works. So whenever there is one of the events, so for instance, we have to check the flow because, you know, NDPI is over, so the protocol has been detected. So if you want to block, let's say, Google Mail, okay? So what you need to do is to execute a Lua check after this happened. So in essence, the C++ code, we have put the code to the Lua VM that executes a script, okay? A script that can be, you know, applied to many flows, not just for one. So this is where, you know, this happens. And this is an example of a check. So we have a simple example. If you have a flow that is either TLS or quick from, started from host or anything in 192.68, 178.2, 1.1. And if it's TLS, and if the protocol issue is, so a very simple check that, for instance, a friend of mine has asked because it's monitoring IoT networks and they have found a vulnerability on a specific type of rule and the client was a specific device. So something that is not general. Okay. So this is the way it works. Very simple to write. The problem is the following. That the overhead introduced, this is a very slow Intel I3. So just to give you an idea of the super worst case, is 30 microseconds for everything, okay, in average. Whereas with C++, we can do it in one microsecond. Now, you say, this is bad. In a way, it is bad. I agree because we are 30 times lower. But you have to think, first of all, on one gigabit networks, that this is not the problem. Also, you have to think that most of these checks are asynchronous. This is one of the few ones that are synchronous. So in essence, as soon as the protocol has been detected, we call this method. But it is not why the packets are coming. So in essence, we have another threat that is calling this while the traffic is coming. But we don't stop the execution tree. So in essence, just to make it short. So if you take this overhead that you have introduced and you sum to everything and you stay below certain boundaries, so if you want for every minute to execute the flow checks on all the flows, you are good, okay. And of course, we trigger an alert. And the result of the alert is a notification on the GUI that can be sent, for instance, through Microsoft Teams, just to give you an idea. Or we can trigger a shell script for something or can send an alert to my friend on Telegram. So this is the way it works. Okay, now I have this. Okay, so we have seen how to extend the N-top-ng engine with Lua scripts to access traffic information and use those information to check the traffic and trigger alerts, for instance. Now, recently released also a Python package that you can install with pip install N-top-ng that allows you to, you can use it as a library to create a Python script which is able to access traffic information in N-top-ng. And this happens through the REST API. This means that you can run your script even on a remote location. For example, you can access live data in N-top-ng. In this case, we are importing the N-top-ng class. We are connecting to N-top-ng using the N-top-ng class. We get an instance of the, of an interface in N-top-ng, for instance, eth0. We use this method to get all the hosts which are active in my network with all the metadata. And there are plenty of methods in this class or another class in this library that allows you to get traffic information. So you can get alerts, flows, hosts, whatever. And you can also get historical data. So the same way, so you connect to N-top-ng, you get an interface. From this interface, you get the, an instance of the historical class. And you can run queries in the database. For instance, you can get alerts statistics from this time to this time, for instance, for the last 24 hours. And just print the, of the alerts that you have. Now, those are two examples of querying the, the engine to get the data. Of course, we have seen that N-top-ng is able to, when a check or an external event detects something, an event, we can trigger an alert. And we have seen that N-top-ng supports several endpoints. So we can send this alert using mail, a messaging system, like telegrams, LAC. We can run a shell script. We can call a web book. So we can run a shell script. For instance, in this script, it can be a Python script. So let's try to put all the pieces together. So we receive an event from, which is generated by an internal check or an external check. This event can call a Python script. This Python script can get information from the alert itself or can query the engine through this API that we created to get more data, to fetch more data and argument the alert information. And this can have some logic and trigger some action. So you can write your actions here to react to this event. In order to implement this, what you have to do in N-top-ng is, first of all, you have to enable the check that you want to use to analyze the traffic. For instance, in this case, we are using a custom check that the user creates in Lua as Luca showed you before. Then if you want to write your Python script that reacts to this event, you have to write an alert tender, which is a script that you place under N-top-ng script shell. And this case is a simple script, which is just getting, as in the standard input, the traffic information, the metadata. And, for instance, if the alert type is our user script, I want to do something. In this case, I'm just logging the IP address related to the host that triggered the alert and a message from our custom script. Then you have to go inside N-top-ng. You go under notifications. You set that you want to send alerts to the shell script. Here you have all the options, like email, whatever. And you select your handler. And then you specify for your handler that you want to receive just critical alerts. So you specify the severity. You specify the category that you want to, of alerts that you want to handle, from this case, cybersecurity, and the entity. In this case, I want to handle alerts about hosts. And then we can extend our handler. We have seen how to print just the alert information, but we can, again, we can use our Python library and N-top-ng to access more information about the host. So we receive this alert, which has been triggered on a specific host in our network. For instance, this host has been infected by malware. It's generating unexpected traffic, whatever. We want to get more information about this host to build a report, for instance. In fact, in our library, we also have the ability to generate a report, or you can generate your own report using the API that we have. So we build this report and send an email. So this is a simple script that you can use. It's a few lines of code to handle alerts and generate reports and get, for instance, an email or your mobile phone with the alert. So this is the big picture of the example that we're seeing right now. So we have defined a user script that triggers an alert, or we receive, again, events from any other source or internal checks. We are calling our script, which is getting more information from the engine to build a report and send this report by email. So the result is this. So the system is checking your traffic, is building a report when something happens, and we'll send you an email with the report of the traffic for the host with the top alerts sorted by severity or by count, the top contacts for the host, the chart of the traffic generated by the host, where you can add more, like the top applications used by the host, et cetera. Do you want to wrap up? Okay. So we have seen that within top ng, you can collect traffic information from traffic, flows, events, events from Suricada, for instance, et cetera. And we started with the top, actually Luca started with the top, then we moved to the top ng. It was mainly a traffic monitoring tool. Today is also a cybersecurity tool able to do behavioral checks, not just for providing visibility, but also providing cybersecurity monitoring. You are now able to extend this engine, both with new scripts integrated in top ng or even with C++ plugins, let's say checks, if you need to scale with performance, or you can use our Python library to write Python tools that can run externally, even remote boxes, to access traffic information in the top ng engine, and be, for instance, a PDF as we have seen with reporting what's going on in your network. Of course, all the code is available on GitHub, so if you want to contribute, you are welcome. Especially now, you don't have excuses. We have a lot of libraries, scripting languages for interacting with the engines, or something else to add. No. The only thing I want to say is that this is an efficient way from our point of view to do network monitoring and cybersecurity, and at the same time to extract information in a way that does not interfere with the main engine, so that allows, I believe, most of the people sitting in this room to do whatever they like to create a monitoring tool that is tailored for their own needs, and that's the first set that is open source. That's all. Thank you very much. Any questions? Any questions? Wait, wait, wait. It's just a simple question. How does it compare with CN tools? It looks like it does everything CN could do. CN tools. Yeah. I don't know the tools. No problem. I am not familiar with them. Any other questions? The scripts can be compiled to be more performance, or do you not have this task in your developer timeline? To compile script, to have more performance. Loa script, or like CCC, we saw that CCC script takes one millisecond, but the Loa script takes 30 milliseconds. Yes, of course, you can compile them, but you have to code it in C++ at the moment. So we used Loa just in time to compile the one seen before by a stamp switch, but it is not available everywhere for its own arm, and we want to support it as various. So yes, it is possible, but again, these are microseconds, not milliseconds. So one million of them per second. Any questions? Anybody else? Hi, thank you. Do you have some figures about performance you are able to achieve on typical server, about flow per second? Some figures to share on Loa scripting, and also some example on Python, which should be less efficient? Okay. We are, when you process packets with Ntop.ng itself, you are able to process like a few gigabits per second, depending on the drivers you use, how you tune Ntop.ng, let's say, to scale with the performance, you can get 10 gigabits, for instance, but more or less, we range from a few gigabits to 10 gigabits in Ntop.ng itself. You can use it in combination with our probes, which is Nprobe, or we have other probes like Cento. In that case, you can scale with the performance up to 100 gigabits per second, but the architecture changes a bit. It's one 100 gigabit in plus. As of the checks, it depends on the checks that you enable, of course. Okay. I think we are running out of time. Many thanks for being here now. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 14.36, "text": " Okay, good morning. This time it's a turn to talk about something different. And top", "tokens": [1033, 11, 665, 2446, 13, 639, 565, 309, 311, 257, 1261, 281, 751, 466, 746, 819, 13, 400, 1192], "temperature": 0.0, "avg_logprob": -0.26961566977304957, "compression_ratio": 1.4715909090909092, "no_speech_prob": 0.22853036224842072}, {"id": 1, "seek": 0, "start": 14.36, "end": 22.44, "text": " ng. What is in top ng? It's an open source application, of course. We are here. And you", "tokens": [6415, 13, 708, 307, 294, 1192, 6415, 30, 467, 311, 364, 1269, 4009, 3861, 11, 295, 1164, 13, 492, 366, 510, 13, 400, 291], "temperature": 0.0, "avg_logprob": -0.26961566977304957, "compression_ratio": 1.4715909090909092, "no_speech_prob": 0.22853036224842072}, {"id": 2, "seek": 0, "start": 22.44, "end": 29.34, "text": " can download the code on GitHub. We'll see the link at the end of the talk. What is in", "tokens": [393, 5484, 264, 3089, 322, 23331, 13, 492, 603, 536, 264, 2113, 412, 264, 917, 295, 264, 751, 13, 708, 307, 294], "temperature": 0.0, "avg_logprob": -0.26961566977304957, "compression_ratio": 1.4715909090909092, "no_speech_prob": 0.22853036224842072}, {"id": 3, "seek": 2934, "start": 29.34, "end": 33.92, "text": " top ng doing? It is, first of all, a real-time network and traffic monitoring application.", "tokens": [1192, 6415, 884, 30, 467, 307, 11, 700, 295, 439, 11, 257, 957, 12, 3766, 3209, 293, 6419, 11028, 3861, 13], "temperature": 0.0, "avg_logprob": -0.2266329639362839, "compression_ratio": 1.6268115942028984, "no_speech_prob": 0.0003466224006842822}, {"id": 4, "seek": 2934, "start": 33.92, "end": 37.96, "text": " So it means that it displays you on a web interface what is happening in your network", "tokens": [407, 309, 1355, 300, 309, 20119, 291, 322, 257, 3670, 9226, 437, 307, 2737, 294, 428, 3209], "temperature": 0.0, "avg_logprob": -0.2266329639362839, "compression_ratio": 1.6268115942028984, "no_speech_prob": 0.0003466224006842822}, {"id": 5, "seek": 2934, "start": 37.96, "end": 44.36, "text": " live. Okay, no delay. This is unless, of course, we are receiving flows coming from a router", "tokens": [1621, 13, 1033, 11, 572, 8577, 13, 639, 307, 5969, 11, 295, 1164, 11, 321, 366, 10040, 12867, 1348, 490, 257, 22492], "temperature": 0.0, "avg_logprob": -0.2266329639362839, "compression_ratio": 1.6268115942028984, "no_speech_prob": 0.0003466224006842822}, {"id": 6, "seek": 2934, "start": 44.36, "end": 49.480000000000004, "text": " that are somehow a little bit delayed because by nature they are on average. So they have", "tokens": [300, 366, 6063, 257, 707, 857, 20268, 570, 538, 3687, 436, 366, 322, 4274, 13, 407, 436, 362], "temperature": 0.0, "avg_logprob": -0.2266329639362839, "compression_ratio": 1.6268115942028984, "no_speech_prob": 0.0003466224006842822}, {"id": 7, "seek": 2934, "start": 49.480000000000004, "end": 55.64, "text": " a certain lifetime. And it is designed for network monitoring and cybersecurity. It means", "tokens": [257, 1629, 11364, 13, 400, 309, 307, 4761, 337, 3209, 11028, 293, 38765, 13, 467, 1355], "temperature": 0.0, "avg_logprob": -0.2266329639362839, "compression_ratio": 1.6268115942028984, "no_speech_prob": 0.0003466224006842822}, {"id": 8, "seek": 5564, "start": 55.64, "end": 61.28, "text": " that there are some behavioral checks. So we are not bound to rules. You have seen Suricata", "tokens": [300, 456, 366, 512, 19124, 13834, 13, 407, 321, 366, 406, 5472, 281, 4474, 13, 509, 362, 1612, 6732, 299, 3274], "temperature": 0.0, "avg_logprob": -0.16261390277317592, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.0008894001366570592}, {"id": 9, "seek": 5564, "start": 61.28, "end": 66.28, "text": " representation before. You see there are some rules in case this happens then. So this is", "tokens": [10290, 949, 13, 509, 536, 456, 366, 512, 4474, 294, 1389, 341, 2314, 550, 13, 407, 341, 307], "temperature": 0.0, "avg_logprob": -0.16261390277317592, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.0008894001366570592}, {"id": 10, "seek": 5564, "start": 66.28, "end": 72.24000000000001, "text": " not our case. So we work based on behavior. So it means that if you have a host that is", "tokens": [406, 527, 1389, 13, 407, 321, 589, 2361, 322, 5223, 13, 407, 309, 1355, 300, 498, 291, 362, 257, 3975, 300, 307], "temperature": 0.0, "avg_logprob": -0.16261390277317592, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.0008894001366570592}, {"id": 11, "seek": 5564, "start": 72.24000000000001, "end": 76.24000000000001, "text": " misbehaving, more or less similar to what you have seen before, that suddenly start", "tokens": [3346, 29437, 6152, 11, 544, 420, 1570, 2531, 281, 437, 291, 362, 1612, 949, 11, 300, 5800, 722], "temperature": 0.0, "avg_logprob": -0.16261390277317592, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.0008894001366570592}, {"id": 12, "seek": 5564, "start": 76.24000000000001, "end": 82.36, "text": " to send too much traffic with respect to the past, or starting to, you know, fire up a", "tokens": [281, 2845, 886, 709, 6419, 365, 3104, 281, 264, 1791, 11, 420, 2891, 281, 11, 291, 458, 11, 2610, 493, 257], "temperature": 0.0, "avg_logprob": -0.16261390277317592, "compression_ratio": 1.8181818181818181, "no_speech_prob": 0.0008894001366570592}, {"id": 13, "seek": 8236, "start": 82.36, "end": 90.36, "text": " new application. So accept connection on a certain port for TLS that was not open before.", "tokens": [777, 3861, 13, 407, 3241, 4984, 322, 257, 1629, 2436, 337, 314, 19198, 300, 390, 406, 1269, 949, 13], "temperature": 0.0, "avg_logprob": -0.13432223320007325, "compression_ratio": 1.8211382113821137, "no_speech_prob": 0.000617573969066143}, {"id": 14, "seek": 8236, "start": 90.36, "end": 96.56, "text": " This is a typical example. So therefore it means that the application simply starts up", "tokens": [639, 307, 257, 7476, 1365, 13, 407, 4412, 309, 1355, 300, 264, 3861, 2935, 3719, 493], "temperature": 0.0, "avg_logprob": -0.13432223320007325, "compression_ratio": 1.8211382113821137, "no_speech_prob": 0.000617573969066143}, {"id": 15, "seek": 8236, "start": 96.56, "end": 101.88, "text": " and learns what is happening on the network. There are some levels of learning. So sometimes", "tokens": [293, 27152, 437, 307, 2737, 322, 264, 3209, 13, 821, 366, 512, 4358, 295, 2539, 13, 407, 2171], "temperature": 0.0, "avg_logprob": -0.13432223320007325, "compression_ratio": 1.8211382113821137, "no_speech_prob": 0.000617573969066143}, {"id": 16, "seek": 8236, "start": 101.88, "end": 107.03999999999999, "text": " it is an immediate learning because, you know, you specify some sort of configuration. But", "tokens": [309, 307, 364, 11629, 2539, 570, 11, 291, 458, 11, 291, 16500, 512, 1333, 295, 11694, 13, 583], "temperature": 0.0, "avg_logprob": -0.13432223320007325, "compression_ratio": 1.8211382113821137, "no_speech_prob": 0.000617573969066143}, {"id": 17, "seek": 8236, "start": 107.03999999999999, "end": 110.96000000000001, "text": " usually this is not the case. The case is that the application learns what is happening", "tokens": [2673, 341, 307, 406, 264, 1389, 13, 440, 1389, 307, 300, 264, 3861, 27152, 437, 307, 2737], "temperature": 0.0, "avg_logprob": -0.13432223320007325, "compression_ratio": 1.8211382113821137, "no_speech_prob": 0.000617573969066143}, {"id": 18, "seek": 11096, "start": 110.96, "end": 118.6, "text": " and in case something goes wrong, goes different, fires up and alert. This is the idea. And", "tokens": [293, 294, 1389, 746, 1709, 2085, 11, 1709, 819, 11, 15044, 493, 293, 9615, 13, 639, 307, 264, 1558, 13, 400], "temperature": 0.0, "avg_logprob": -0.2592558409038343, "compression_ratio": 1.5125, "no_speech_prob": 0.0005071645136922598}, {"id": 19, "seek": 11096, "start": 118.6, "end": 124.47999999999999, "text": " the architecture is actually divided in two parts. Okay. First of all, the pocket processing", "tokens": [264, 9482, 307, 767, 6666, 294, 732, 3166, 13, 1033, 13, 2386, 295, 439, 11, 264, 8963, 9007], "temperature": 0.0, "avg_logprob": -0.2592558409038343, "compression_ratio": 1.5125, "no_speech_prob": 0.0005071645136922598}, {"id": 20, "seek": 11096, "start": 124.47999999999999, "end": 131.4, "text": " part that is based on more or less PF ring or lead pickup. So this means that you can", "tokens": [644, 300, 307, 2361, 322, 544, 420, 1570, 430, 37, 4875, 420, 1477, 25328, 13, 407, 341, 1355, 300, 291, 393], "temperature": 0.0, "avg_logprob": -0.2592558409038343, "compression_ratio": 1.5125, "no_speech_prob": 0.0005071645136922598}, {"id": 21, "seek": 11096, "start": 131.4, "end": 137.84, "text": " run on Windows, Linux, Mac OS, FreeBSD, whatever. Instead, PF ring is something that we have", "tokens": [1190, 322, 8591, 11, 18734, 11, 5707, 12731, 11, 11551, 8176, 35, 11, 2035, 13, 7156, 11, 430, 37, 4875, 307, 746, 300, 321, 362], "temperature": 0.0, "avg_logprob": -0.2592558409038343, "compression_ratio": 1.5125, "no_speech_prob": 0.0005071645136922598}, {"id": 22, "seek": 13784, "start": 137.84, "end": 142.28, "text": " co-developed that is a Linux technology for accelerating pocket capture, but not only", "tokens": [598, 12, 35464, 292, 300, 307, 257, 18734, 2899, 337, 34391, 8963, 7983, 11, 457, 406, 787], "temperature": 0.0, "avg_logprob": -0.22025098145463085, "compression_ratio": 1.7826086956521738, "no_speech_prob": 0.0001302079326706007}, {"id": 23, "seek": 13784, "start": 142.28, "end": 147.72, "text": " for that, but also for merging traffic for multiple adapters, for distributing traffic.", "tokens": [337, 300, 11, 457, 611, 337, 44559, 6419, 337, 3866, 23169, 1559, 11, 337, 41406, 6419, 13], "temperature": 0.0, "avg_logprob": -0.22025098145463085, "compression_ratio": 1.7826086956521738, "no_speech_prob": 0.0001302079326706007}, {"id": 24, "seek": 13784, "start": 147.72, "end": 153.24, "text": " So it's much more than simply RX acceleration. And top of this, there is an open source", "tokens": [407, 309, 311, 709, 544, 813, 2935, 46197, 17162, 13, 400, 1192, 295, 341, 11, 456, 307, 364, 1269, 4009], "temperature": 0.0, "avg_logprob": -0.22025098145463085, "compression_ratio": 1.7826086956521738, "no_speech_prob": 0.0001302079326706007}, {"id": 25, "seek": 13784, "start": 153.24, "end": 157.76, "text": " library that we still maintain at N-top called NDPI. So this is the only open source library", "tokens": [6405, 300, 321, 920, 6909, 412, 426, 12, 19337, 1219, 426, 11373, 40, 13, 407, 341, 307, 264, 787, 1269, 4009, 6405], "temperature": 0.0, "avg_logprob": -0.22025098145463085, "compression_ratio": 1.7826086956521738, "no_speech_prob": 0.0001302079326706007}, {"id": 26, "seek": 13784, "start": 157.76, "end": 162.64000000000001, "text": " that is doing the pocket inspection. But for us, it means that we try to understand from", "tokens": [300, 307, 884, 264, 8963, 22085, 13, 583, 337, 505, 11, 309, 1355, 300, 321, 853, 281, 1223, 490], "temperature": 0.0, "avg_logprob": -0.22025098145463085, "compression_ratio": 1.7826086956521738, "no_speech_prob": 0.0001302079326706007}, {"id": 27, "seek": 13784, "start": 162.64000000000001, "end": 167.68, "text": " the traffic what is the application protocol. So if it's TLS, if it's a generic protocol,", "tokens": [264, 6419, 437, 307, 264, 3861, 10336, 13, 407, 498, 309, 311, 314, 19198, 11, 498, 309, 311, 257, 19577, 10336, 11], "temperature": 0.0, "avg_logprob": -0.22025098145463085, "compression_ratio": 1.7826086956521738, "no_speech_prob": 0.0001302079326706007}, {"id": 28, "seek": 16768, "start": 167.68, "end": 174.20000000000002, "text": " if it's Google mail, but it's a very specific protocol. And out of the traffic, we extract", "tokens": [498, 309, 311, 3329, 10071, 11, 457, 309, 311, 257, 588, 2685, 10336, 13, 400, 484, 295, 264, 6419, 11, 321, 8947], "temperature": 0.0, "avg_logprob": -0.21161140714372909, "compression_ratio": 1.7318007662835249, "no_speech_prob": 0.0001492167211836204}, {"id": 29, "seek": 16768, "start": 174.20000000000002, "end": 179.72, "text": " the metadata. So for instance, we extract certificate information and we generate something", "tokens": [264, 26603, 13, 407, 337, 5197, 11, 321, 8947, 15953, 1589, 293, 321, 8460, 746], "temperature": 0.0, "avg_logprob": -0.21161140714372909, "compression_ratio": 1.7318007662835249, "no_speech_prob": 0.0001492167211836204}, {"id": 30, "seek": 16768, "start": 179.72, "end": 184.88, "text": " we call RISC. So looking at the traffic, we see if there is something wrong, okay, such", "tokens": [321, 818, 497, 2343, 34, 13, 407, 1237, 412, 264, 6419, 11, 321, 536, 498, 456, 307, 746, 2085, 11, 1392, 11, 1270], "temperature": 0.0, "avg_logprob": -0.21161140714372909, "compression_ratio": 1.7318007662835249, "no_speech_prob": 0.0001492167211836204}, {"id": 31, "seek": 16768, "start": 184.88, "end": 190.0, "text": " as for instance, an expired certificate just to give you an idea. And we trigger an alert.", "tokens": [382, 337, 5197, 11, 364, 36587, 15953, 445, 281, 976, 291, 364, 1558, 13, 400, 321, 7875, 364, 9615, 13], "temperature": 0.0, "avg_logprob": -0.21161140714372909, "compression_ratio": 1.7318007662835249, "no_speech_prob": 0.0001492167211836204}, {"id": 32, "seek": 16768, "start": 190.0, "end": 195.08, "text": " On top of this, there is a TopNG because this is the first part that is basically provided", "tokens": [1282, 1192, 295, 341, 11, 456, 307, 257, 8840, 30237, 570, 341, 307, 264, 700, 644, 300, 307, 1936, 5649], "temperature": 0.0, "avg_logprob": -0.21161140714372909, "compression_ratio": 1.7318007662835249, "no_speech_prob": 0.0001492167211836204}, {"id": 33, "seek": 19508, "start": 195.08, "end": 200.88000000000002, "text": " by the operating system. And TopNG has a C++ engine that is processing packets, that is", "tokens": [538, 264, 7447, 1185, 13, 400, 8840, 30237, 575, 257, 383, 25472, 2848, 300, 307, 9007, 30364, 11, 300, 307], "temperature": 0.0, "avg_logprob": -0.21578016468122893, "compression_ratio": 1.6629213483146068, "no_speech_prob": 0.0001613449421711266}, {"id": 34, "seek": 19508, "start": 200.88000000000002, "end": 205.92000000000002, "text": " in essence doing traffic analysis, creates internally, okay, the representation of the", "tokens": [294, 12801, 884, 6419, 5215, 11, 7829, 19501, 11, 1392, 11, 264, 10290, 295, 264], "temperature": 0.0, "avg_logprob": -0.21578016468122893, "compression_ratio": 1.6629213483146068, "no_speech_prob": 0.0001613449421711266}, {"id": 35, "seek": 19508, "start": 205.92000000000002, "end": 210.60000000000002, "text": " data based on the concept of network interfaces because we can have a multiple network interfaces", "tokens": [1412, 2361, 322, 264, 3410, 295, 3209, 28416, 570, 321, 393, 362, 257, 3866, 3209, 28416], "temperature": 0.0, "avg_logprob": -0.21578016468122893, "compression_ratio": 1.6629213483146068, "no_speech_prob": 0.0001613449421711266}, {"id": 36, "seek": 19508, "start": 210.60000000000002, "end": 214.4, "text": " from which the traffic is received. It can be a virtual interface such as, you know,", "tokens": [490, 597, 264, 6419, 307, 4613, 13, 467, 393, 312, 257, 6374, 9226, 1270, 382, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.21578016468122893, "compression_ratio": 1.6629213483146068, "no_speech_prob": 0.0001613449421711266}, {"id": 37, "seek": 19508, "start": 214.4, "end": 219.96, "text": " a NetFlow collection or a physical interface, ETH0. And then we have something we call", "tokens": [257, 6188, 31091, 5765, 420, 257, 4001, 9226, 11, 462, 9620, 15, 13, 400, 550, 321, 362, 746, 321, 818], "temperature": 0.0, "avg_logprob": -0.21578016468122893, "compression_ratio": 1.6629213483146068, "no_speech_prob": 0.0001613449421711266}, {"id": 38, "seek": 21996, "start": 219.96, "end": 225.76000000000002, "text": " behavioral checks, where we check flows and hosts. Flows means that each independent communication,", "tokens": [19124, 13834, 11, 689, 321, 1520, 12867, 293, 21573, 13, 3235, 1509, 1355, 300, 1184, 6695, 6101, 11], "temperature": 0.0, "avg_logprob": -0.24788082155406985, "compression_ratio": 1.7374517374517375, "no_speech_prob": 0.000316443300107494}, {"id": 39, "seek": 21996, "start": 225.76000000000002, "end": 232.60000000000002, "text": " such as a TCP connection, is checked. Instead, a host, we take the host as a whole. So in", "tokens": [1270, 382, 257, 48965, 4984, 11, 307, 10033, 13, 7156, 11, 257, 3975, 11, 321, 747, 264, 3975, 382, 257, 1379, 13, 407, 294], "temperature": 0.0, "avg_logprob": -0.24788082155406985, "compression_ratio": 1.7374517374517375, "no_speech_prob": 0.000316443300107494}, {"id": 40, "seek": 21996, "start": 232.60000000000002, "end": 236.60000000000002, "text": " essence, if a host is doing a port scan, each individual communication is okay, or more", "tokens": [12801, 11, 498, 257, 3975, 307, 884, 257, 2436, 11049, 11, 1184, 2609, 6101, 307, 1392, 11, 420, 544], "temperature": 0.0, "avg_logprob": -0.24788082155406985, "compression_ratio": 1.7374517374517375, "no_speech_prob": 0.000316443300107494}, {"id": 41, "seek": 21996, "start": 236.60000000000002, "end": 242.48000000000002, "text": " or less okay. But the fact that this host is doing this, you know, in a sequence, in", "tokens": [420, 1570, 1392, 13, 583, 264, 1186, 300, 341, 3975, 307, 884, 341, 11, 291, 458, 11, 294, 257, 8310, 11, 294], "temperature": 0.0, "avg_logprob": -0.24788082155406985, "compression_ratio": 1.7374517374517375, "no_speech_prob": 0.000316443300107494}, {"id": 42, "seek": 21996, "start": 242.48000000000002, "end": 247.12, "text": " a network or in a host, it's a problem. So this is called behavioral checks. And on top", "tokens": [257, 3209, 420, 294, 257, 3975, 11, 309, 311, 257, 1154, 13, 407, 341, 307, 1219, 19124, 13834, 13, 400, 322, 1192], "temperature": 0.0, "avg_logprob": -0.24788082155406985, "compression_ratio": 1.7374517374517375, "no_speech_prob": 0.000316443300107494}, {"id": 43, "seek": 24712, "start": 247.12, "end": 254.08, "text": " of this, we trigger alerts that can be consumed locally or sent elsewhere. This is the fast", "tokens": [295, 341, 11, 321, 7875, 28061, 300, 393, 312, 21226, 16143, 420, 2279, 14517, 13, 639, 307, 264, 2370], "temperature": 0.0, "avg_logprob": -0.15451833236316018, "compression_ratio": 1.6360294117647058, "no_speech_prob": 0.0001859313779277727}, {"id": 44, "seek": 24712, "start": 254.08, "end": 259.76, "text": " part. On top of this, we have the Lua interface. Why Lua? Because we like C++. But C++ is", "tokens": [644, 13, 1282, 1192, 295, 341, 11, 321, 362, 264, 441, 4398, 9226, 13, 1545, 441, 4398, 30, 1436, 321, 411, 383, 25472, 13, 583, 383, 25472, 307], "temperature": 0.0, "avg_logprob": -0.15451833236316018, "compression_ratio": 1.6360294117647058, "no_speech_prob": 0.0001859313779277727}, {"id": 45, "seek": 24712, "start": 259.76, "end": 266.16, "text": " something not for everybody, okay? So we need to simplify, for instance, the development", "tokens": [746, 406, 337, 2201, 11, 1392, 30, 407, 321, 643, 281, 20460, 11, 337, 5197, 11, 264, 3250], "temperature": 0.0, "avg_logprob": -0.15451833236316018, "compression_ratio": 1.6360294117647058, "no_speech_prob": 0.0001859313779277727}, {"id": 46, "seek": 24712, "start": 266.16, "end": 270.84000000000003, "text": " of the web interface. So for instance, the REST API is written in Lua, sitting on top", "tokens": [295, 264, 3670, 9226, 13, 407, 337, 5197, 11, 264, 497, 14497, 9362, 307, 3720, 294, 441, 4398, 11, 3798, 322, 1192], "temperature": 0.0, "avg_logprob": -0.15451833236316018, "compression_ratio": 1.6360294117647058, "no_speech_prob": 0.0001859313779277727}, {"id": 47, "seek": 24712, "start": 270.84000000000003, "end": 277.04, "text": " of C++. So we have created an API that allows us to avoid typical problems of C++ at the", "tokens": [295, 383, 25472, 13, 407, 321, 362, 2942, 364, 9362, 300, 4045, 505, 281, 5042, 7476, 2740, 295, 383, 25472, 412, 264], "temperature": 0.0, "avg_logprob": -0.15451833236316018, "compression_ratio": 1.6360294117647058, "no_speech_prob": 0.0001859313779277727}, {"id": 48, "seek": 27704, "start": 277.04, "end": 283.40000000000003, "text": " same time we simplify the way the application is working. So therefore, we use Lua for operations", "tokens": [912, 565, 321, 20460, 264, 636, 264, 3861, 307, 1364, 13, 407, 4412, 11, 321, 764, 441, 4398, 337, 7705], "temperature": 0.0, "avg_logprob": -0.15401957207119343, "compression_ratio": 1.626086956521739, "no_speech_prob": 0.0002872279437724501}, {"id": 49, "seek": 27704, "start": 283.40000000000003, "end": 289.52000000000004, "text": " that are not critical, such as the web GUI, or for checking interfaces that are not necessarily", "tokens": [300, 366, 406, 4924, 11, 1270, 382, 264, 3670, 17917, 40, 11, 420, 337, 8568, 28416, 300, 366, 406, 4725], "temperature": 0.0, "avg_logprob": -0.15401957207119343, "compression_ratio": 1.626086956521739, "no_speech_prob": 0.0002872279437724501}, {"id": 50, "seek": 27704, "start": 289.52000000000004, "end": 297.6, "text": " real-time, so for the SNMP. For SNMP, we fetch the data every five minutes and do the checks.", "tokens": [957, 12, 3766, 11, 370, 337, 264, 13955, 12224, 13, 1171, 13955, 12224, 11, 321, 23673, 264, 1412, 633, 1732, 2077, 293, 360, 264, 13834, 13], "temperature": 0.0, "avg_logprob": -0.15401957207119343, "compression_ratio": 1.626086956521739, "no_speech_prob": 0.0002872279437724501}, {"id": 51, "seek": 27704, "start": 297.6, "end": 303.72, "text": " So traffic ingestion, as I said, is done in multiple ways. Sometime is serial traffic,", "tokens": [407, 6419, 3957, 31342, 11, 382, 286, 848, 11, 307, 1096, 294, 3866, 2098, 13, 3379, 1312, 307, 17436, 6419, 11], "temperature": 0.0, "avg_logprob": -0.15401957207119343, "compression_ratio": 1.626086956521739, "no_speech_prob": 0.0002872279437724501}, {"id": 52, "seek": 30372, "start": 303.72, "end": 310.20000000000005, "text": " so packets. Sometime it is not. It's a flow. And this is handled by the C++ engine. So", "tokens": [370, 30364, 13, 3379, 1312, 309, 307, 406, 13, 467, 311, 257, 3095, 13, 400, 341, 307, 18033, 538, 264, 383, 25472, 2848, 13, 407], "temperature": 0.0, "avg_logprob": -0.15565983621697677, "compression_ratio": 1.575221238938053, "no_speech_prob": 0.0002582221059128642}, {"id": 53, "seek": 30372, "start": 310.20000000000005, "end": 316.40000000000003, "text": " the C++ engine is doing it efficiently. And then we have other type of ingestions based", "tokens": [264, 383, 25472, 2848, 307, 884, 309, 19621, 13, 400, 550, 321, 362, 661, 2010, 295, 3957, 377, 626, 2361], "temperature": 0.0, "avg_logprob": -0.15565983621697677, "compression_ratio": 1.575221238938053, "no_speech_prob": 0.0002582221059128642}, {"id": 54, "seek": 30372, "start": 316.40000000000003, "end": 321.84000000000003, "text": " on events. So something that we don't really control completely, but that are relevant", "tokens": [322, 3931, 13, 407, 746, 300, 321, 500, 380, 534, 1969, 2584, 11, 457, 300, 366, 7340], "temperature": 0.0, "avg_logprob": -0.15565983621697677, "compression_ratio": 1.575221238938053, "no_speech_prob": 0.0002582221059128642}, {"id": 55, "seek": 30372, "start": 321.84000000000003, "end": 328.12, "text": " for us. So we have seen Surikata, the presentation before, some minutes ago. This is a typical", "tokens": [337, 505, 13, 407, 321, 362, 1612, 6732, 1035, 3274, 11, 264, 5860, 949, 11, 512, 2077, 2057, 13, 639, 307, 257, 7476], "temperature": 0.0, "avg_logprob": -0.15565983621697677, "compression_ratio": 1.575221238938053, "no_speech_prob": 0.0002582221059128642}, {"id": 56, "seek": 32812, "start": 328.12, "end": 334.64, "text": " example of input. Why this? Because, as I said at the beginning, we don't have rules.", "tokens": [1365, 295, 4846, 13, 1545, 341, 30, 1436, 11, 382, 286, 848, 412, 264, 2863, 11, 321, 500, 380, 362, 4474, 13], "temperature": 0.0, "avg_logprob": -0.16875803470611572, "compression_ratio": 1.734375, "no_speech_prob": 0.0005849520093761384}, {"id": 57, "seek": 32812, "start": 334.64, "end": 338.84000000000003, "text": " We don't want to have rules. So we don't want to say if the payload contains this and this", "tokens": [492, 500, 380, 528, 281, 362, 4474, 13, 407, 321, 500, 380, 528, 281, 584, 498, 264, 30918, 8306, 341, 293, 341], "temperature": 0.0, "avg_logprob": -0.16875803470611572, "compression_ratio": 1.734375, "no_speech_prob": 0.0005849520093761384}, {"id": 58, "seek": 32812, "start": 338.84000000000003, "end": 345.4, "text": " and this and this then, because we don't believe that this is what we should do. Instead, there", "tokens": [293, 341, 293, 341, 550, 11, 570, 321, 500, 380, 1697, 300, 341, 307, 437, 321, 820, 360, 13, 7156, 11, 456], "temperature": 0.0, "avg_logprob": -0.16875803470611572, "compression_ratio": 1.734375, "no_speech_prob": 0.0005849520093761384}, {"id": 59, "seek": 32812, "start": 345.4, "end": 349.2, "text": " are wonderful tools such as Surikata that are doing that very well. So therefore, the", "tokens": [366, 3715, 3873, 1270, 382, 6732, 1035, 3274, 300, 366, 884, 300, 588, 731, 13, 407, 4412, 11, 264], "temperature": 0.0, "avg_logprob": -0.16875803470611572, "compression_ratio": 1.734375, "no_speech_prob": 0.0005849520093761384}, {"id": 60, "seek": 32812, "start": 349.2, "end": 354.24, "text": " idea is to combine network monitoring and behavior analysis with these type of tools.", "tokens": [1558, 307, 281, 10432, 3209, 11028, 293, 5223, 5215, 365, 613, 2010, 295, 3873, 13], "temperature": 0.0, "avg_logprob": -0.16875803470611572, "compression_ratio": 1.734375, "no_speech_prob": 0.0005849520093761384}, {"id": 61, "seek": 35424, "start": 354.24, "end": 357.92, "text": " So therefore, indirectly, through tools such as Surikata that is optional, of course, you", "tokens": [407, 4412, 11, 37779, 11, 807, 3873, 1270, 382, 6732, 1035, 3274, 300, 307, 17312, 11, 295, 1164, 11, 291], "temperature": 0.0, "avg_logprob": -0.24815840640310513, "compression_ratio": 1.673913043478261, "no_speech_prob": 0.0002545276074670255}, {"id": 62, "seek": 35424, "start": 357.92, "end": 363.28000000000003, "text": " don't have to run it with N-top-ng monitoring, you can have this type of information that", "tokens": [500, 380, 362, 281, 1190, 309, 365, 426, 12, 19337, 12, 872, 11028, 11, 291, 393, 362, 341, 2010, 295, 1589, 300], "temperature": 0.0, "avg_logprob": -0.24815840640310513, "compression_ratio": 1.673913043478261, "no_speech_prob": 0.0002545276074670255}, {"id": 63, "seek": 35424, "start": 363.28000000000003, "end": 370.16, "text": " can be combined directly by N-top-ng. Of course, we have firewall logs and syslog. Why this", "tokens": [393, 312, 9354, 3838, 538, 426, 12, 19337, 12, 872, 13, 2720, 1164, 11, 321, 362, 36109, 20820, 293, 262, 749, 4987, 13, 1545, 341], "temperature": 0.0, "avg_logprob": -0.24815840640310513, "compression_ratio": 1.673913043478261, "no_speech_prob": 0.0002545276074670255}, {"id": 64, "seek": 35424, "start": 370.16, "end": 375.96000000000004, "text": " is important? Because we can have a look at information that is not visible from the traffic.", "tokens": [307, 1021, 30, 1436, 321, 393, 362, 257, 574, 412, 1589, 300, 307, 406, 8974, 490, 264, 6419, 13], "temperature": 0.0, "avg_logprob": -0.24815840640310513, "compression_ratio": 1.673913043478261, "no_speech_prob": 0.0002545276074670255}, {"id": 65, "seek": 35424, "start": 375.96000000000004, "end": 381.44, "text": " So we always play with packets, me and Alfredo. But we understand that packets have limitations,", "tokens": [407, 321, 1009, 862, 365, 30364, 11, 385, 293, 28327, 78, 13, 583, 321, 1223, 300, 30364, 362, 15705, 11], "temperature": 0.0, "avg_logprob": -0.24815840640310513, "compression_ratio": 1.673913043478261, "no_speech_prob": 0.0002545276074670255}, {"id": 66, "seek": 38144, "start": 381.44, "end": 386.68, "text": " okay, especially for encryption. So we have seen before rules saying if you are downloading", "tokens": [1392, 11, 2318, 337, 29575, 13, 407, 321, 362, 1612, 949, 4474, 1566, 498, 291, 366, 32529], "temperature": 0.0, "avg_logprob": -0.21679658404851365, "compression_ratio": 1.709433962264151, "no_speech_prob": 0.0005645071505568922}, {"id": 67, "seek": 38144, "start": 386.68, "end": 391.4, "text": " a buyer application, that is fine if it's plain text. But if TLS, you will never see", "tokens": [257, 24645, 3861, 11, 300, 307, 2489, 498, 309, 311, 11121, 2487, 13, 583, 498, 314, 19198, 11, 291, 486, 1128, 536], "temperature": 0.0, "avg_logprob": -0.21679658404851365, "compression_ratio": 1.709433962264151, "no_speech_prob": 0.0005645071505568922}, {"id": 68, "seek": 38144, "start": 391.4, "end": 397.16, "text": " that happen, okay. So you have to use things like rules on top of this, on top of this,", "tokens": [300, 1051, 11, 1392, 13, 407, 291, 362, 281, 764, 721, 411, 4474, 322, 1192, 295, 341, 11, 322, 1192, 295, 341, 11], "temperature": 0.0, "avg_logprob": -0.21679658404851365, "compression_ratio": 1.709433962264151, "no_speech_prob": 0.0005645071505568922}, {"id": 69, "seek": 38144, "start": 397.16, "end": 404.2, "text": " but they are just guesses. So instead, if through syslog or other means, we know that. So for", "tokens": [457, 436, 366, 445, 42703, 13, 407, 2602, 11, 498, 807, 262, 749, 4987, 420, 661, 1355, 11, 321, 458, 300, 13, 407, 337], "temperature": 0.0, "avg_logprob": -0.21679658404851365, "compression_ratio": 1.709433962264151, "no_speech_prob": 0.0005645071505568922}, {"id": 70, "seek": 38144, "start": 404.2, "end": 408.24, "text": " example, we see an attack or a wordpress saying that this host is trying to guess the password", "tokens": [1365, 11, 321, 536, 364, 2690, 420, 257, 1349, 11637, 1566, 300, 341, 3975, 307, 1382, 281, 2041, 264, 11524], "temperature": 0.0, "avg_logprob": -0.21679658404851365, "compression_ratio": 1.709433962264151, "no_speech_prob": 0.0005645071505568922}, {"id": 71, "seek": 40824, "start": 408.24, "end": 412.52, "text": " of administrator user. This is much relevant information. And from the network standpoint,", "tokens": [295, 25529, 4195, 13, 639, 307, 709, 7340, 1589, 13, 400, 490, 264, 3209, 15827, 11], "temperature": 0.0, "avg_logprob": -0.20804279290356684, "compression_ratio": 1.6856060606060606, "no_speech_prob": 0.0005992759834043682}, {"id": 72, "seek": 40824, "start": 412.52, "end": 416.92, "text": " it looks simply nice. Everything is okay. The problem is from the application. That's", "tokens": [309, 1542, 2935, 1481, 13, 5471, 307, 1392, 13, 440, 1154, 307, 490, 264, 3861, 13, 663, 311], "temperature": 0.0, "avg_logprob": -0.20804279290356684, "compression_ratio": 1.6856060606060606, "no_speech_prob": 0.0005992759834043682}, {"id": 73, "seek": 40824, "start": 416.92, "end": 421.84000000000003, "text": " why we believe in network. By the same time, we need to have some other information that", "tokens": [983, 321, 1697, 294, 3209, 13, 3146, 264, 912, 565, 11, 321, 643, 281, 362, 512, 661, 1589, 300], "temperature": 0.0, "avg_logprob": -0.20804279290356684, "compression_ratio": 1.6856060606060606, "no_speech_prob": 0.0005992759834043682}, {"id": 74, "seek": 40824, "start": 421.84000000000003, "end": 427.72, "text": " is injected into the application. And of course, we have historical data. We use a database", "tokens": [307, 36967, 666, 264, 3861, 13, 400, 295, 1164, 11, 321, 362, 8584, 1412, 13, 492, 764, 257, 8149], "temperature": 0.0, "avg_logprob": -0.20804279290356684, "compression_ratio": 1.6856060606060606, "no_speech_prob": 0.0005992759834043682}, {"id": 75, "seek": 40824, "start": 427.72, "end": 433.16, "text": " called Clickhouse. So we can put a billion of records. Everything is working very fast.", "tokens": [1219, 8230, 6410, 13, 407, 321, 393, 829, 257, 5218, 295, 7724, 13, 5471, 307, 1364, 588, 2370, 13], "temperature": 0.0, "avg_logprob": -0.20804279290356684, "compression_ratio": 1.6856060606060606, "no_speech_prob": 0.0005992759834043682}, {"id": 76, "seek": 43316, "start": 433.16, "end": 438.8, "text": " This is also an open source database. And for time series, we use round robin database", "tokens": [639, 307, 611, 364, 1269, 4009, 8149, 13, 400, 337, 565, 2638, 11, 321, 764, 3098, 3870, 259, 8149], "temperature": 0.0, "avg_logprob": -0.22745474948677966, "compression_ratio": 1.6359447004608294, "no_speech_prob": 0.0003744743298739195}, {"id": 77, "seek": 43316, "start": 438.8, "end": 448.20000000000005, "text": " or influxdp. And as I said before, we have checks that are divided in two parts. C++", "tokens": [420, 9922, 2449, 67, 79, 13, 400, 382, 286, 848, 949, 11, 321, 362, 13834, 300, 366, 6666, 294, 732, 3166, 13, 383, 25472], "temperature": 0.0, "avg_logprob": -0.22745474948677966, "compression_ratio": 1.6359447004608294, "no_speech_prob": 0.0003744743298739195}, {"id": 78, "seek": 43316, "start": 448.20000000000005, "end": 453.76000000000005, "text": " for efficiency. So the fast part, in essence, where you have to process traffic in line,", "tokens": [337, 10493, 13, 407, 264, 2370, 644, 11, 294, 12801, 11, 689, 291, 362, 281, 1399, 6419, 294, 1622, 11], "temperature": 0.0, "avg_logprob": -0.22745474948677966, "compression_ratio": 1.6359447004608294, "no_speech_prob": 0.0003744743298739195}, {"id": 79, "seek": 43316, "start": 453.76000000000005, "end": 458.92, "text": " such as when you have a pocket, an incoming pocket, you have to check if this pocket belonging", "tokens": [1270, 382, 562, 291, 362, 257, 8963, 11, 364, 22341, 8963, 11, 291, 362, 281, 1520, 498, 341, 8963, 22957], "temperature": 0.0, "avg_logprob": -0.22745474948677966, "compression_ratio": 1.6359447004608294, "no_speech_prob": 0.0003744743298739195}, {"id": 80, "seek": 45892, "start": 458.92, "end": 466.68, "text": " to a flow is relevant. And then we have other types of checks that are not so real time.", "tokens": [281, 257, 3095, 307, 7340, 13, 400, 550, 321, 362, 661, 3467, 295, 13834, 300, 366, 406, 370, 957, 565, 13], "temperature": 0.0, "avg_logprob": -0.21693829127720424, "compression_ratio": 1.634703196347032, "no_speech_prob": 0.0007530191796831787}, {"id": 81, "seek": 45892, "start": 466.68, "end": 473.52000000000004, "text": " So for a check on an SNMP interface, that need to be easy to be developed. But at the same", "tokens": [407, 337, 257, 1520, 322, 364, 13955, 12224, 9226, 11, 300, 643, 281, 312, 1858, 281, 312, 4743, 13, 583, 412, 264, 912], "temperature": 0.0, "avg_logprob": -0.21693829127720424, "compression_ratio": 1.634703196347032, "no_speech_prob": 0.0007530191796831787}, {"id": 82, "seek": 45892, "start": 473.52000000000004, "end": 477.48, "text": " time, that don't need to be fast. Because as I said, if we pull SNMP out in five minutes,", "tokens": [565, 11, 300, 500, 380, 643, 281, 312, 2370, 13, 1436, 382, 286, 848, 11, 498, 321, 2235, 13955, 12224, 484, 294, 1732, 2077, 11], "temperature": 0.0, "avg_logprob": -0.21693829127720424, "compression_ratio": 1.634703196347032, "no_speech_prob": 0.0007530191796831787}, {"id": 83, "seek": 45892, "start": 477.48, "end": 483.48, "text": " we have plenty of time for doing that. And of course, we have notifications that we send", "tokens": [321, 362, 7140, 295, 565, 337, 884, 300, 13, 400, 295, 1164, 11, 321, 362, 13426, 300, 321, 2845], "temperature": 0.0, "avg_logprob": -0.21693829127720424, "compression_ratio": 1.634703196347032, "no_speech_prob": 0.0007530191796831787}, {"id": 84, "seek": 48348, "start": 483.48, "end": 489.16, "text": " out. So for instance, we trigger a shell script, a webhook, syslog, you know, telegram, you", "tokens": [484, 13, 407, 337, 5197, 11, 321, 7875, 257, 8720, 5755, 11, 257, 3670, 71, 1212, 11, 262, 749, 4987, 11, 291, 458, 11, 4304, 1342, 11, 291], "temperature": 0.0, "avg_logprob": -0.2990276112275965, "compression_ratio": 1.5586206896551724, "no_speech_prob": 0.0005385526455938816}, {"id": 85, "seek": 48348, "start": 489.16, "end": 494.20000000000005, "text": " know, usual thing. Nothing new here. Okay, let's now start the talk after this introduction", "tokens": [458, 11, 7713, 551, 13, 6693, 777, 510, 13, 1033, 11, 718, 311, 586, 722, 264, 751, 934, 341, 9339], "temperature": 0.0, "avg_logprob": -0.2990276112275965, "compression_ratio": 1.5586206896551724, "no_speech_prob": 0.0005385526455938816}, {"id": 86, "seek": 48348, "start": 494.20000000000005, "end": 501.20000000000005, "text": " of NTOC and GIM. The problem is the following. So we have added over 150 checks, behavioral", "tokens": [295, 426, 15427, 34, 293, 460, 6324, 13, 440, 1154, 307, 264, 3480, 13, 407, 321, 362, 3869, 670, 8451, 13834, 11, 19124], "temperature": 0.0, "avg_logprob": -0.2990276112275965, "compression_ratio": 1.5586206896551724, "no_speech_prob": 0.0005385526455938816}, {"id": 87, "seek": 48348, "start": 501.20000000000005, "end": 505.96000000000004, "text": " checks on the traffic. But there is always somebody that comes and says, I want to do", "tokens": [13834, 322, 264, 6419, 13, 583, 456, 307, 1009, 2618, 300, 1487, 293, 1619, 11, 286, 528, 281, 360], "temperature": 0.0, "avg_logprob": -0.2990276112275965, "compression_ratio": 1.5586206896551724, "no_speech_prob": 0.0005385526455938816}, {"id": 88, "seek": 48348, "start": 505.96000000000004, "end": 512.48, "text": " something different. How can we support these people? How can we enable new programmers or", "tokens": [746, 819, 13, 1012, 393, 321, 1406, 613, 561, 30, 1012, 393, 321, 9528, 777, 41504, 420], "temperature": 0.0, "avg_logprob": -0.2990276112275965, "compression_ratio": 1.5586206896551724, "no_speech_prob": 0.0005385526455938816}, {"id": 89, "seek": 51248, "start": 512.48, "end": 516.88, "text": " let's say people that used to use Python, shell script, you know, this type of programming", "tokens": [718, 311, 584, 561, 300, 1143, 281, 764, 15329, 11, 8720, 5755, 11, 291, 458, 11, 341, 2010, 295, 9410], "temperature": 0.0, "avg_logprob": -0.1659418460542122, "compression_ratio": 1.6853932584269662, "no_speech_prob": 9.764668357092887e-05}, {"id": 90, "seek": 51248, "start": 516.88, "end": 522.8000000000001, "text": " language or that don't want to learn the internals of our application? How can we do that? And", "tokens": [2856, 420, 300, 500, 380, 528, 281, 1466, 264, 2154, 1124, 295, 527, 3861, 30, 1012, 393, 321, 360, 300, 30, 400], "temperature": 0.0, "avg_logprob": -0.1659418460542122, "compression_ratio": 1.6853932584269662, "no_speech_prob": 9.764668357092887e-05}, {"id": 91, "seek": 51248, "start": 522.8000000000001, "end": 527.4, "text": " many times this happens when you are in a harsh. So that is an attack. That is something", "tokens": [867, 1413, 341, 2314, 562, 291, 366, 294, 257, 14897, 13, 407, 300, 307, 364, 2690, 13, 663, 307, 746], "temperature": 0.0, "avg_logprob": -0.1659418460542122, "compression_ratio": 1.6853932584269662, "no_speech_prob": 9.764668357092887e-05}, {"id": 92, "seek": 51248, "start": 527.4, "end": 534.0, "text": " happening on your network that you want to check. And we have, you know, two levels of", "tokens": [2737, 322, 428, 3209, 300, 291, 528, 281, 1520, 13, 400, 321, 362, 11, 291, 458, 11, 732, 4358, 295], "temperature": 0.0, "avg_logprob": -0.1659418460542122, "compression_ratio": 1.6853932584269662, "no_speech_prob": 9.764668357092887e-05}, {"id": 93, "seek": 51248, "start": 534.0, "end": 538.76, "text": " the problem. First of all, we have to extend the behavioral checks in order to have some", "tokens": [264, 1154, 13, 2386, 295, 439, 11, 321, 362, 281, 10101, 264, 19124, 13834, 294, 1668, 281, 362, 512], "temperature": 0.0, "avg_logprob": -0.1659418460542122, "compression_ratio": 1.6853932584269662, "no_speech_prob": 9.764668357092887e-05}, {"id": 94, "seek": 53876, "start": 538.76, "end": 544.4399999999999, "text": " behavioral detection in a different way. And in the second part that Alfredo will describe", "tokens": [19124, 17784, 294, 257, 819, 636, 13, 400, 294, 264, 1150, 644, 300, 28327, 78, 486, 6786], "temperature": 0.0, "avg_logprob": -0.21609371503194172, "compression_ratio": 1.6470588235294117, "no_speech_prob": 8.614867692813277e-05}, {"id": 95, "seek": 53876, "start": 544.4399999999999, "end": 550.2, "text": " later. So how can we use NTOC and G as a data lake from languages such as Python, for instance,", "tokens": [1780, 13, 407, 577, 393, 321, 764, 426, 15427, 34, 293, 460, 382, 257, 1412, 11001, 490, 8650, 1270, 382, 15329, 11, 337, 5197, 11], "temperature": 0.0, "avg_logprob": -0.21609371503194172, "compression_ratio": 1.6470588235294117, "no_speech_prob": 8.614867692813277e-05}, {"id": 96, "seek": 53876, "start": 550.2, "end": 555.36, "text": " that is very popular. So that you can use NTOC and G as a source of data for your own", "tokens": [300, 307, 588, 3743, 13, 407, 300, 291, 393, 764, 426, 15427, 34, 293, 460, 382, 257, 4009, 295, 1412, 337, 428, 1065], "temperature": 0.0, "avg_logprob": -0.21609371503194172, "compression_ratio": 1.6470588235294117, "no_speech_prob": 8.614867692813277e-05}, {"id": 97, "seek": 53876, "start": 555.36, "end": 561.04, "text": " application. Of course, you have time series. As I said, we save data in influxDB if you", "tokens": [3861, 13, 2720, 1164, 11, 291, 362, 565, 2638, 13, 1018, 286, 848, 11, 321, 3155, 1412, 294, 9922, 2449, 27735, 498, 291], "temperature": 0.0, "avg_logprob": -0.21609371503194172, "compression_ratio": 1.6470588235294117, "no_speech_prob": 8.614867692813277e-05}, {"id": 98, "seek": 53876, "start": 561.04, "end": 564.68, "text": " want. So therefore, you can use Grafana for creating your own dashboard. But these are", "tokens": [528, 13, 407, 4412, 11, 291, 393, 764, 8985, 69, 2095, 337, 4084, 428, 1065, 18342, 13, 583, 613, 366], "temperature": 0.0, "avg_logprob": -0.21609371503194172, "compression_ratio": 1.6470588235294117, "no_speech_prob": 8.614867692813277e-05}, {"id": 99, "seek": 56468, "start": 564.68, "end": 569.1999999999999, "text": " simple dashboards. So if we want to do something more complicated, if we want to go beyond", "tokens": [2199, 8240, 17228, 13, 407, 498, 321, 528, 281, 360, 746, 544, 6179, 11, 498, 321, 528, 281, 352, 4399], "temperature": 0.0, "avg_logprob": -0.1651028271379142, "compression_ratio": 1.6754716981132076, "no_speech_prob": 0.0004250205820426345}, {"id": 100, "seek": 56468, "start": 569.1999999999999, "end": 576.8, "text": " that, in addition to that, how can we do that? So this is the idea today. So we like C++.", "tokens": [300, 11, 294, 4500, 281, 300, 11, 577, 393, 321, 360, 300, 30, 407, 341, 307, 264, 1558, 965, 13, 407, 321, 411, 383, 25472, 13], "temperature": 0.0, "avg_logprob": -0.1651028271379142, "compression_ratio": 1.6754716981132076, "no_speech_prob": 0.0004250205820426345}, {"id": 101, "seek": 56468, "start": 576.8, "end": 583.4399999999999, "text": " C++ is super efficient. We like it. Okay. We are used to play with it since many years.", "tokens": [383, 25472, 307, 1687, 7148, 13, 492, 411, 309, 13, 1033, 13, 492, 366, 1143, 281, 862, 365, 309, 1670, 867, 924, 13], "temperature": 0.0, "avg_logprob": -0.1651028271379142, "compression_ratio": 1.6754716981132076, "no_speech_prob": 0.0004250205820426345}, {"id": 102, "seek": 56468, "start": 583.4399999999999, "end": 588.4, "text": " But we understand that it's not what everybody wants. Okay. We need something easier. And", "tokens": [583, 321, 1223, 300, 309, 311, 406, 437, 2201, 2738, 13, 1033, 13, 492, 643, 746, 3571, 13, 400], "temperature": 0.0, "avg_logprob": -0.1651028271379142, "compression_ratio": 1.6754716981132076, "no_speech_prob": 0.0004250205820426345}, {"id": 103, "seek": 56468, "start": 588.4, "end": 593.8, "text": " we would like to understand also how it was possible to develop checks in minutes for", "tokens": [321, 576, 411, 281, 1223, 611, 577, 309, 390, 1944, 281, 1499, 13834, 294, 2077, 337], "temperature": 0.0, "avg_logprob": -0.1651028271379142, "compression_ratio": 1.6754716981132076, "no_speech_prob": 0.0004250205820426345}, {"id": 104, "seek": 59380, "start": 593.8, "end": 599.4399999999999, "text": " people who are saying, okay, if I see this specific certificate or if I see this specific", "tokens": [561, 567, 366, 1566, 11, 1392, 11, 498, 286, 536, 341, 2685, 15953, 420, 498, 286, 536, 341, 2685], "temperature": 0.0, "avg_logprob": -0.1689226670698686, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.00025470784748904407}, {"id": 105, "seek": 59380, "start": 599.4399999999999, "end": 604.4, "text": " behavior, then there is a problem. Something very peculiar to an organization. So not general", "tokens": [5223, 11, 550, 456, 307, 257, 1154, 13, 6595, 588, 27149, 281, 364, 4475, 13, 407, 406, 2674], "temperature": 0.0, "avg_logprob": -0.1689226670698686, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.00025470784748904407}, {"id": 106, "seek": 59380, "start": 604.4, "end": 608.8, "text": " for everybody, but for specific people. So for instance, how do I trigger an alert if", "tokens": [337, 2201, 11, 457, 337, 2685, 561, 13, 407, 337, 5197, 11, 577, 360, 286, 7875, 364, 9615, 498], "temperature": 0.0, "avg_logprob": -0.1689226670698686, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.00025470784748904407}, {"id": 107, "seek": 59380, "start": 608.8, "end": 613.04, "text": " there is traffic, TLS traffic within host A and B? So for instance, a printer should", "tokens": [456, 307, 6419, 11, 314, 19198, 6419, 1951, 3975, 316, 293, 363, 30, 407, 337, 5197, 11, 257, 16671, 820], "temperature": 0.0, "avg_logprob": -0.1689226670698686, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.00025470784748904407}, {"id": 108, "seek": 59380, "start": 613.04, "end": 618.56, "text": " not make any TLS traffic just to make an example. So if this happens, and how can you trigger", "tokens": [406, 652, 604, 314, 19198, 6419, 445, 281, 652, 364, 1365, 13, 407, 498, 341, 2314, 11, 293, 577, 393, 291, 7875], "temperature": 0.0, "avg_logprob": -0.1689226670698686, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.00025470784748904407}, {"id": 109, "seek": 61856, "start": 618.56, "end": 624.3599999999999, "text": " an alert? Another problem is the following. If I have a certificate signed by a certain", "tokens": [364, 9615, 30, 3996, 1154, 307, 264, 3480, 13, 759, 286, 362, 257, 15953, 8175, 538, 257, 1629], "temperature": 0.0, "avg_logprob": -0.21727227628900764, "compression_ratio": 1.5669642857142858, "no_speech_prob": 0.00044523735414259136}, {"id": 110, "seek": 61856, "start": 624.3599999999999, "end": 628.7199999999999, "text": " organization, or for instance, if I have a BitTorrent connection that is going above", "tokens": [4475, 11, 420, 337, 5197, 11, 498, 286, 362, 257, 9101, 51, 284, 1753, 4984, 300, 307, 516, 3673], "temperature": 0.0, "avg_logprob": -0.21727227628900764, "compression_ratio": 1.5669642857142858, "no_speech_prob": 0.00044523735414259136}, {"id": 111, "seek": 61856, "start": 628.7199999999999, "end": 635.04, "text": " one gigabit, or notifying me if there is a Zoom call with bad quality, things like this.", "tokens": [472, 8741, 455, 270, 11, 420, 406, 5489, 385, 498, 456, 307, 257, 13453, 818, 365, 1578, 3125, 11, 721, 411, 341, 13], "temperature": 0.0, "avg_logprob": -0.21727227628900764, "compression_ratio": 1.5669642857142858, "no_speech_prob": 0.00044523735414259136}, {"id": 112, "seek": 61856, "start": 635.04, "end": 642.76, "text": " Things like very, very peculiar, very specific checks that people want to do. Maybe on an", "tokens": [9514, 411, 588, 11, 588, 27149, 11, 588, 2685, 13834, 300, 561, 528, 281, 360, 13, 2704, 322, 364], "temperature": 0.0, "avg_logprob": -0.21727227628900764, "compression_ratio": 1.5669642857142858, "no_speech_prob": 0.00044523735414259136}, {"id": 113, "seek": 64276, "start": 642.76, "end": 648.8, "text": " operating, sorry, on an autonomous system, and not on another, or on an actor, and not", "tokens": [7447, 11, 2597, 11, 322, 364, 23797, 1185, 11, 293, 406, 322, 1071, 11, 420, 322, 364, 8747, 11, 293, 406], "temperature": 0.0, "avg_logprob": -0.26451443359915133, "compression_ratio": 1.6884615384615385, "no_speech_prob": 0.0003658693749457598}, {"id": 114, "seek": 64276, "start": 648.8, "end": 651.52, "text": " on another. So things that are not general that we can implement for everybody. How can", "tokens": [322, 1071, 13, 407, 721, 300, 366, 406, 2674, 300, 321, 393, 4445, 337, 2201, 13, 1012, 393], "temperature": 0.0, "avg_logprob": -0.26451443359915133, "compression_ratio": 1.6884615384615385, "no_speech_prob": 0.0003658693749457598}, {"id": 115, "seek": 64276, "start": 651.52, "end": 658.36, "text": " we do that? So let me talk how it works in top NG internally. Let's have a look at the", "tokens": [321, 360, 300, 30, 407, 718, 385, 751, 577, 309, 1985, 294, 1192, 426, 38, 19501, 13, 961, 311, 362, 257, 574, 412, 264], "temperature": 0.0, "avg_logprob": -0.26451443359915133, "compression_ratio": 1.6884615384615385, "no_speech_prob": 0.0003658693749457598}, {"id": 116, "seek": 64276, "start": 658.36, "end": 664.04, "text": " flow, also communication. So in top NG creates a data structure inside itself as soon as", "tokens": [3095, 11, 611, 6101, 13, 407, 294, 1192, 426, 38, 7829, 257, 1412, 3877, 1854, 2564, 382, 2321, 382], "temperature": 0.0, "avg_logprob": -0.26451443359915133, "compression_ratio": 1.6884615384615385, "no_speech_prob": 0.0003658693749457598}, {"id": 117, "seek": 64276, "start": 664.04, "end": 668.92, "text": " we see the first packet of the flow. So we see episodes of the destination, source parts", "tokens": [321, 536, 264, 700, 20300, 295, 264, 3095, 13, 407, 321, 536, 9313, 295, 264, 12236, 11, 4009, 3166], "temperature": 0.0, "avg_logprob": -0.26451443359915133, "compression_ratio": 1.6884615384615385, "no_speech_prob": 0.0003658693749457598}, {"id": 118, "seek": 66892, "start": 668.92, "end": 674.4399999999999, "text": " of destination, protocol, VLAN, whatever. And then this is the first event that is relevant", "tokens": [295, 12236, 11, 10336, 11, 691, 36527, 11, 2035, 13, 400, 550, 341, 307, 264, 700, 2280, 300, 307, 7340], "temperature": 0.0, "avg_logprob": -0.13943298861511752, "compression_ratio": 1.7325581395348837, "no_speech_prob": 8.980862912721932e-05}, {"id": 119, "seek": 66892, "start": 674.4399999999999, "end": 680.8399999999999, "text": " for us. And then, as I said, everything sits on top of NDPI, so the yellow part. So we", "tokens": [337, 505, 13, 400, 550, 11, 382, 286, 848, 11, 1203, 12696, 322, 1192, 295, 426, 11373, 40, 11, 370, 264, 5566, 644, 13, 407, 321], "temperature": 0.0, "avg_logprob": -0.13943298861511752, "compression_ratio": 1.7325581395348837, "no_speech_prob": 8.980862912721932e-05}, {"id": 120, "seek": 66892, "start": 680.8399999999999, "end": 685.88, "text": " have another event when the application protocol is detected. Actually, this one is divided", "tokens": [362, 1071, 2280, 562, 264, 3861, 10336, 307, 21896, 13, 5135, 11, 341, 472, 307, 6666], "temperature": 0.0, "avg_logprob": -0.13943298861511752, "compression_ratio": 1.7325581395348837, "no_speech_prob": 8.980862912721932e-05}, {"id": 121, "seek": 66892, "start": 685.88, "end": 692.12, "text": " in two parts. First of all, as soon as the main protocol is detected, such as TLS, okay,", "tokens": [294, 732, 3166, 13, 2386, 295, 439, 11, 382, 2321, 382, 264, 2135, 10336, 307, 21896, 11, 1270, 382, 314, 19198, 11, 1392, 11], "temperature": 0.0, "avg_logprob": -0.13943298861511752, "compression_ratio": 1.7325581395348837, "no_speech_prob": 8.980862912721932e-05}, {"id": 122, "seek": 66892, "start": 692.12, "end": 696.88, "text": " and then we can refine this information with metadata saying, okay, this is TLS that is", "tokens": [293, 550, 321, 393, 33906, 341, 1589, 365, 26603, 1566, 11, 1392, 11, 341, 307, 314, 19198, 300, 307], "temperature": 0.0, "avg_logprob": -0.13943298861511752, "compression_ratio": 1.7325581395348837, "no_speech_prob": 8.980862912721932e-05}, {"id": 123, "seek": 69688, "start": 696.88, "end": 701.72, "text": " going to Google mail, and not Google search or Google something else, okay. So second", "tokens": [516, 281, 3329, 10071, 11, 293, 406, 3329, 3164, 420, 3329, 746, 1646, 11, 1392, 13, 407, 1150], "temperature": 0.0, "avg_logprob": -0.18872554485614484, "compression_ratio": 1.7490196078431373, "no_speech_prob": 0.00013032497372478247}, {"id": 124, "seek": 69688, "start": 701.72, "end": 707.76, "text": " event and NDPI. And then we have, for long-standing flows, some periodic activities. So in essence,", "tokens": [2280, 293, 426, 11373, 40, 13, 400, 550, 321, 362, 11, 337, 938, 12, 8618, 12867, 11, 512, 27790, 5354, 13, 407, 294, 12801, 11], "temperature": 0.0, "avg_logprob": -0.18872554485614484, "compression_ratio": 1.7490196078431373, "no_speech_prob": 0.00013032497372478247}, {"id": 125, "seek": 69688, "start": 707.76, "end": 713.2, "text": " every minute, we do something different, something like, you know, I want to trigger,", "tokens": [633, 3456, 11, 321, 360, 746, 819, 11, 746, 411, 11, 291, 458, 11, 286, 528, 281, 7875, 11], "temperature": 0.0, "avg_logprob": -0.18872554485614484, "compression_ratio": 1.7490196078431373, "no_speech_prob": 0.00013032497372478247}, {"id": 126, "seek": 69688, "start": 713.2, "end": 718.72, "text": " you know, an action. And then at the end, the flow end notification, so as soon as the", "tokens": [291, 458, 11, 364, 3069, 13, 400, 550, 412, 264, 917, 11, 264, 3095, 917, 11554, 11, 370, 382, 2321, 382, 264], "temperature": 0.0, "avg_logprob": -0.18872554485614484, "compression_ratio": 1.7490196078431373, "no_speech_prob": 0.00013032497372478247}, {"id": 127, "seek": 69688, "start": 718.72, "end": 725.68, "text": " flow is over. So what we wanted to do, we wanted to create a low API that allows people", "tokens": [3095, 307, 670, 13, 407, 437, 321, 1415, 281, 360, 11, 321, 1415, 281, 1884, 257, 2295, 9362, 300, 4045, 561], "temperature": 0.0, "avg_logprob": -0.18872554485614484, "compression_ratio": 1.7490196078431373, "no_speech_prob": 0.00013032497372478247}, {"id": 128, "seek": 72568, "start": 725.68, "end": 730.8399999999999, "text": " to create the simple checks that are efficient. Efficient enough for most people, because", "tokens": [281, 1884, 264, 2199, 13834, 300, 366, 7148, 13, 462, 7816, 1547, 337, 881, 561, 11, 570], "temperature": 0.0, "avg_logprob": -0.2383708788001019, "compression_ratio": 1.823045267489712, "no_speech_prob": 0.0003840721328742802}, {"id": 129, "seek": 72568, "start": 730.8399999999999, "end": 734.9599999999999, "text": " not everybody needs one and a gigabit, but many people have one gigabit networks or,", "tokens": [406, 2201, 2203, 472, 293, 257, 8741, 455, 270, 11, 457, 867, 561, 362, 472, 8741, 455, 270, 9590, 420, 11], "temperature": 0.0, "avg_logprob": -0.2383708788001019, "compression_ratio": 1.823045267489712, "no_speech_prob": 0.0003840721328742802}, {"id": 130, "seek": 72568, "start": 734.9599999999999, "end": 739.9599999999999, "text": " you know, two, five gigabit networks. So they need some sort of efficiency, but they are", "tokens": [291, 458, 11, 732, 11, 1732, 8741, 455, 270, 9590, 13, 407, 436, 643, 512, 1333, 295, 10493, 11, 457, 436, 366], "temperature": 0.0, "avg_logprob": -0.2383708788001019, "compression_ratio": 1.823045267489712, "no_speech_prob": 0.0003840721328742802}, {"id": 131, "seek": 72568, "start": 739.9599999999999, "end": 744.8399999999999, "text": " not super extreme. So let's say use Lua for prototype on a check for some people who need", "tokens": [406, 1687, 8084, 13, 407, 718, 311, 584, 764, 441, 4398, 337, 19475, 322, 257, 1520, 337, 512, 561, 567, 643], "temperature": 0.0, "avg_logprob": -0.2383708788001019, "compression_ratio": 1.823045267489712, "no_speech_prob": 0.0003840721328742802}, {"id": 132, "seek": 72568, "start": 744.8399999999999, "end": 750.0799999999999, "text": " speed, or use Lua for people who have, let's say, an industrial network or a network that", "tokens": [3073, 11, 420, 764, 441, 4398, 337, 561, 567, 362, 11, 718, 311, 584, 11, 364, 9987, 3209, 420, 257, 3209, 300], "temperature": 0.0, "avg_logprob": -0.2383708788001019, "compression_ratio": 1.823045267489712, "no_speech_prob": 0.0003840721328742802}, {"id": 133, "seek": 75008, "start": 750.08, "end": 756.2800000000001, "text": " is, you know, running at one gigabit or two. So in essence, we have created an API that", "tokens": [307, 11, 291, 458, 11, 2614, 412, 472, 8741, 455, 270, 420, 732, 13, 407, 294, 12801, 11, 321, 362, 2942, 364, 9362, 300], "temperature": 0.0, "avg_logprob": -0.20149601015270266, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0005828436696901917}, {"id": 134, "seek": 75008, "start": 756.2800000000001, "end": 762.9200000000001, "text": " allows from Lua to see internally, in N-top and G, properties of the flow. For instance,", "tokens": [4045, 490, 441, 4398, 281, 536, 19501, 11, 294, 426, 12, 19337, 293, 460, 11, 7221, 295, 264, 3095, 13, 1171, 5197, 11], "temperature": 0.0, "avg_logprob": -0.20149601015270266, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0005828436696901917}, {"id": 135, "seek": 75008, "start": 762.9200000000001, "end": 767.48, "text": " the number of bytes, multicast, layers, seven information, these type of things. And the", "tokens": [264, 1230, 295, 36088, 11, 30608, 525, 11, 7914, 11, 3407, 1589, 11, 613, 2010, 295, 721, 13, 400, 264], "temperature": 0.0, "avg_logprob": -0.20149601015270266, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0005828436696901917}, {"id": 136, "seek": 75008, "start": 767.48, "end": 773.1600000000001, "text": " API calls are very small. So in essence, we don't want, you know, the application to", "tokens": [9362, 5498, 366, 588, 1359, 13, 407, 294, 12801, 11, 321, 500, 380, 528, 11, 291, 458, 11, 264, 3861, 281], "temperature": 0.0, "avg_logprob": -0.20149601015270266, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0005828436696901917}, {"id": 137, "seek": 75008, "start": 773.1600000000001, "end": 778.2, "text": " be inefficient simply because we download to Lua the representation of the host, the representation", "tokens": [312, 43495, 2935, 570, 321, 5484, 281, 441, 4398, 264, 10290, 295, 264, 3975, 11, 264, 10290], "temperature": 0.0, "avg_logprob": -0.20149601015270266, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0005828436696901917}, {"id": 138, "seek": 77820, "start": 778.2, "end": 782.9200000000001, "text": " of the flow. Well, simply the method that we are interested in. So in the left side,", "tokens": [295, 264, 3095, 13, 1042, 11, 2935, 264, 3170, 300, 321, 366, 3102, 294, 13, 407, 294, 264, 1411, 1252, 11], "temperature": 0.0, "avg_logprob": -0.14492310418023002, "compression_ratio": 1.7093023255813953, "no_speech_prob": 3.411494617466815e-05}, {"id": 139, "seek": 77820, "start": 782.9200000000001, "end": 786.5200000000001, "text": " you will see the C++ code, how it implements the stuff. On the right side, you will see", "tokens": [291, 486, 536, 264, 383, 25472, 3089, 11, 577, 309, 704, 17988, 264, 1507, 13, 1282, 264, 558, 1252, 11, 291, 486, 536], "temperature": 0.0, "avg_logprob": -0.14492310418023002, "compression_ratio": 1.7093023255813953, "no_speech_prob": 3.411494617466815e-05}, {"id": 140, "seek": 77820, "start": 786.5200000000001, "end": 793.5200000000001, "text": " an example of the Lua code. So in this case, just to give you an idea of how it works.", "tokens": [364, 1365, 295, 264, 441, 4398, 3089, 13, 407, 294, 341, 1389, 11, 445, 281, 976, 291, 364, 1558, 295, 577, 309, 1985, 13], "temperature": 0.0, "avg_logprob": -0.14492310418023002, "compression_ratio": 1.7093023255813953, "no_speech_prob": 3.411494617466815e-05}, {"id": 141, "seek": 77820, "start": 793.5200000000001, "end": 797.2800000000001, "text": " So whenever there is one of the events, so for instance, we have to check the flow because,", "tokens": [407, 5699, 456, 307, 472, 295, 264, 3931, 11, 370, 337, 5197, 11, 321, 362, 281, 1520, 264, 3095, 570, 11], "temperature": 0.0, "avg_logprob": -0.14492310418023002, "compression_ratio": 1.7093023255813953, "no_speech_prob": 3.411494617466815e-05}, {"id": 142, "seek": 77820, "start": 797.2800000000001, "end": 801.5200000000001, "text": " you know, NDPI is over, so the protocol has been detected. So if you want to block, let's", "tokens": [291, 458, 11, 426, 11373, 40, 307, 670, 11, 370, 264, 10336, 575, 668, 21896, 13, 407, 498, 291, 528, 281, 3461, 11, 718, 311], "temperature": 0.0, "avg_logprob": -0.14492310418023002, "compression_ratio": 1.7093023255813953, "no_speech_prob": 3.411494617466815e-05}, {"id": 143, "seek": 80152, "start": 801.52, "end": 809.16, "text": " say, Google Mail, okay? So what you need to do is to execute a Lua check after this happened.", "tokens": [584, 11, 3329, 29164, 11, 1392, 30, 407, 437, 291, 643, 281, 360, 307, 281, 14483, 257, 441, 4398, 1520, 934, 341, 2011, 13], "temperature": 0.0, "avg_logprob": -0.23216187953948975, "compression_ratio": 1.7007575757575757, "no_speech_prob": 0.00023593410151079297}, {"id": 144, "seek": 80152, "start": 809.16, "end": 815.04, "text": " So in essence, the C++ code, we have put the code to the Lua VM that executes a script,", "tokens": [407, 294, 12801, 11, 264, 383, 25472, 3089, 11, 321, 362, 829, 264, 3089, 281, 264, 441, 4398, 18038, 300, 4454, 1819, 257, 5755, 11], "temperature": 0.0, "avg_logprob": -0.23216187953948975, "compression_ratio": 1.7007575757575757, "no_speech_prob": 0.00023593410151079297}, {"id": 145, "seek": 80152, "start": 815.04, "end": 819.76, "text": " okay? A script that can be, you know, applied to many flows, not just for one. So this is", "tokens": [1392, 30, 316, 5755, 300, 393, 312, 11, 291, 458, 11, 6456, 281, 867, 12867, 11, 406, 445, 337, 472, 13, 407, 341, 307], "temperature": 0.0, "avg_logprob": -0.23216187953948975, "compression_ratio": 1.7007575757575757, "no_speech_prob": 0.00023593410151079297}, {"id": 146, "seek": 80152, "start": 819.76, "end": 824.6, "text": " where, you know, this happens. And this is an example of a check. So we have a simple", "tokens": [689, 11, 291, 458, 11, 341, 2314, 13, 400, 341, 307, 364, 1365, 295, 257, 1520, 13, 407, 321, 362, 257, 2199], "temperature": 0.0, "avg_logprob": -0.23216187953948975, "compression_ratio": 1.7007575757575757, "no_speech_prob": 0.00023593410151079297}, {"id": 147, "seek": 80152, "start": 824.6, "end": 831.0, "text": " example. If you have a flow that is either TLS or quick from, started from host or anything", "tokens": [1365, 13, 759, 291, 362, 257, 3095, 300, 307, 2139, 314, 19198, 420, 1702, 490, 11, 1409, 490, 3975, 420, 1340], "temperature": 0.0, "avg_logprob": -0.23216187953948975, "compression_ratio": 1.7007575757575757, "no_speech_prob": 0.00023593410151079297}, {"id": 148, "seek": 83100, "start": 831.0, "end": 842.04, "text": " in 192.68, 178.2, 1.1. And if it's TLS, and if the protocol issue is, so a very simple", "tokens": [294, 1294, 17, 13, 27102, 11, 3282, 23, 13, 17, 11, 502, 13, 16, 13, 400, 498, 309, 311, 314, 19198, 11, 293, 498, 264, 10336, 2734, 307, 11, 370, 257, 588, 2199], "temperature": 0.0, "avg_logprob": -0.3054497954133269, "compression_ratio": 1.3865979381443299, "no_speech_prob": 0.000255239981925115}, {"id": 149, "seek": 83100, "start": 842.04, "end": 847.92, "text": " check that, for instance, a friend of mine has asked because it's monitoring IoT networks", "tokens": [1520, 300, 11, 337, 5197, 11, 257, 1277, 295, 3892, 575, 2351, 570, 309, 311, 11028, 30112, 9590], "temperature": 0.0, "avg_logprob": -0.3054497954133269, "compression_ratio": 1.3865979381443299, "no_speech_prob": 0.000255239981925115}, {"id": 150, "seek": 83100, "start": 847.92, "end": 855.6, "text": " and they have found a vulnerability on a specific type of rule and the client was a specific", "tokens": [293, 436, 362, 1352, 257, 24210, 322, 257, 2685, 2010, 295, 4978, 293, 264, 6423, 390, 257, 2685], "temperature": 0.0, "avg_logprob": -0.3054497954133269, "compression_ratio": 1.3865979381443299, "no_speech_prob": 0.000255239981925115}, {"id": 151, "seek": 85560, "start": 855.6, "end": 860.88, "text": " device. So something that is not general. Okay. So this is the way it works. Very simple", "tokens": [4302, 13, 407, 746, 300, 307, 406, 2674, 13, 1033, 13, 407, 341, 307, 264, 636, 309, 1985, 13, 4372, 2199], "temperature": 0.0, "avg_logprob": -0.2044235495633857, "compression_ratio": 1.6366906474820144, "no_speech_prob": 0.0005038059898652136}, {"id": 152, "seek": 85560, "start": 860.88, "end": 865.64, "text": " to write. The problem is the following. That the overhead introduced, this is a very slow", "tokens": [281, 2464, 13, 440, 1154, 307, 264, 3480, 13, 663, 264, 19922, 7268, 11, 341, 307, 257, 588, 2964], "temperature": 0.0, "avg_logprob": -0.2044235495633857, "compression_ratio": 1.6366906474820144, "no_speech_prob": 0.0005038059898652136}, {"id": 153, "seek": 85560, "start": 865.64, "end": 870.84, "text": " Intel I3. So just to give you an idea of the super worst case, is 30 microseconds for everything,", "tokens": [19762, 286, 18, 13, 407, 445, 281, 976, 291, 364, 1558, 295, 264, 1687, 5855, 1389, 11, 307, 2217, 3123, 37841, 28750, 337, 1203, 11], "temperature": 0.0, "avg_logprob": -0.2044235495633857, "compression_ratio": 1.6366906474820144, "no_speech_prob": 0.0005038059898652136}, {"id": 154, "seek": 85560, "start": 870.84, "end": 876.6, "text": " okay, in average. Whereas with C++, we can do it in one microsecond. Now, you say, this", "tokens": [1392, 11, 294, 4274, 13, 13813, 365, 383, 25472, 11, 321, 393, 360, 309, 294, 472, 3123, 37841, 18882, 13, 823, 11, 291, 584, 11, 341], "temperature": 0.0, "avg_logprob": -0.2044235495633857, "compression_ratio": 1.6366906474820144, "no_speech_prob": 0.0005038059898652136}, {"id": 155, "seek": 85560, "start": 876.6, "end": 882.2, "text": " is bad. In a way, it is bad. I agree because we are 30 times lower. But you have to think,", "tokens": [307, 1578, 13, 682, 257, 636, 11, 309, 307, 1578, 13, 286, 3986, 570, 321, 366, 2217, 1413, 3126, 13, 583, 291, 362, 281, 519, 11], "temperature": 0.0, "avg_logprob": -0.2044235495633857, "compression_ratio": 1.6366906474820144, "no_speech_prob": 0.0005038059898652136}, {"id": 156, "seek": 88220, "start": 882.2, "end": 885.6800000000001, "text": " first of all, on one gigabit networks, that this is not the problem. Also, you have to", "tokens": [700, 295, 439, 11, 322, 472, 8741, 455, 270, 9590, 11, 300, 341, 307, 406, 264, 1154, 13, 2743, 11, 291, 362, 281], "temperature": 0.0, "avg_logprob": -0.13575885243659472, "compression_ratio": 1.8677966101694916, "no_speech_prob": 0.000676720985211432}, {"id": 157, "seek": 88220, "start": 885.6800000000001, "end": 890.9200000000001, "text": " think that most of these checks are asynchronous. This is one of the few ones that are synchronous.", "tokens": [519, 300, 881, 295, 613, 13834, 366, 49174, 13, 639, 307, 472, 295, 264, 1326, 2306, 300, 366, 44743, 13], "temperature": 0.0, "avg_logprob": -0.13575885243659472, "compression_ratio": 1.8677966101694916, "no_speech_prob": 0.000676720985211432}, {"id": 158, "seek": 88220, "start": 890.9200000000001, "end": 895.32, "text": " So in essence, as soon as the protocol has been detected, we call this method. But it", "tokens": [407, 294, 12801, 11, 382, 2321, 382, 264, 10336, 575, 668, 21896, 11, 321, 818, 341, 3170, 13, 583, 309], "temperature": 0.0, "avg_logprob": -0.13575885243659472, "compression_ratio": 1.8677966101694916, "no_speech_prob": 0.000676720985211432}, {"id": 159, "seek": 88220, "start": 895.32, "end": 900.2, "text": " is not why the packets are coming. So in essence, we have another threat that is calling this", "tokens": [307, 406, 983, 264, 30364, 366, 1348, 13, 407, 294, 12801, 11, 321, 362, 1071, 4734, 300, 307, 5141, 341], "temperature": 0.0, "avg_logprob": -0.13575885243659472, "compression_ratio": 1.8677966101694916, "no_speech_prob": 0.000676720985211432}, {"id": 160, "seek": 88220, "start": 900.2, "end": 905.6400000000001, "text": " while the traffic is coming. But we don't stop the execution tree. So in essence, just", "tokens": [1339, 264, 6419, 307, 1348, 13, 583, 321, 500, 380, 1590, 264, 15058, 4230, 13, 407, 294, 12801, 11, 445], "temperature": 0.0, "avg_logprob": -0.13575885243659472, "compression_ratio": 1.8677966101694916, "no_speech_prob": 0.000676720985211432}, {"id": 161, "seek": 88220, "start": 905.6400000000001, "end": 911.1600000000001, "text": " to make it short. So if you take this overhead that you have introduced and you sum to everything", "tokens": [281, 652, 309, 2099, 13, 407, 498, 291, 747, 341, 19922, 300, 291, 362, 7268, 293, 291, 2408, 281, 1203], "temperature": 0.0, "avg_logprob": -0.13575885243659472, "compression_ratio": 1.8677966101694916, "no_speech_prob": 0.000676720985211432}, {"id": 162, "seek": 91116, "start": 911.16, "end": 915.28, "text": " and you stay below certain boundaries, so if you want for every minute to execute the", "tokens": [293, 291, 1754, 2507, 1629, 13180, 11, 370, 498, 291, 528, 337, 633, 3456, 281, 14483, 264], "temperature": 0.0, "avg_logprob": -0.20589050224849156, "compression_ratio": 1.6194029850746268, "no_speech_prob": 0.0003911496314685792}, {"id": 163, "seek": 91116, "start": 915.28, "end": 920.6, "text": " flow checks on all the flows, you are good, okay. And of course, we trigger an alert.", "tokens": [3095, 13834, 322, 439, 264, 12867, 11, 291, 366, 665, 11, 1392, 13, 400, 295, 1164, 11, 321, 7875, 364, 9615, 13], "temperature": 0.0, "avg_logprob": -0.20589050224849156, "compression_ratio": 1.6194029850746268, "no_speech_prob": 0.0003911496314685792}, {"id": 164, "seek": 91116, "start": 920.6, "end": 925.8, "text": " And the result of the alert is a notification on the GUI that can be sent, for instance,", "tokens": [400, 264, 1874, 295, 264, 9615, 307, 257, 11554, 322, 264, 17917, 40, 300, 393, 312, 2279, 11, 337, 5197, 11], "temperature": 0.0, "avg_logprob": -0.20589050224849156, "compression_ratio": 1.6194029850746268, "no_speech_prob": 0.0003911496314685792}, {"id": 165, "seek": 91116, "start": 925.8, "end": 929.4, "text": " through Microsoft Teams, just to give you an idea. Or we can trigger a shell script", "tokens": [807, 8116, 24702, 11, 445, 281, 976, 291, 364, 1558, 13, 1610, 321, 393, 7875, 257, 8720, 5755], "temperature": 0.0, "avg_logprob": -0.20589050224849156, "compression_ratio": 1.6194029850746268, "no_speech_prob": 0.0003911496314685792}, {"id": 166, "seek": 91116, "start": 929.4, "end": 935.9599999999999, "text": " for something or can send an alert to my friend on Telegram. So this is the way it works.", "tokens": [337, 746, 420, 393, 2845, 364, 9615, 281, 452, 1277, 322, 14889, 1342, 13, 407, 341, 307, 264, 636, 309, 1985, 13], "temperature": 0.0, "avg_logprob": -0.20589050224849156, "compression_ratio": 1.6194029850746268, "no_speech_prob": 0.0003911496314685792}, {"id": 167, "seek": 93596, "start": 935.96, "end": 943.12, "text": " Okay, now I have this. Okay, so we have seen how to extend the N-top-ng engine with Lua", "tokens": [1033, 11, 586, 286, 362, 341, 13, 1033, 11, 370, 321, 362, 1612, 577, 281, 10101, 264, 426, 12, 19337, 12, 872, 2848, 365, 441, 4398], "temperature": 0.0, "avg_logprob": -0.2140259000990126, "compression_ratio": 1.6635514018691588, "no_speech_prob": 4.277571861166507e-05}, {"id": 168, "seek": 93596, "start": 943.12, "end": 949.0400000000001, "text": " scripts to access traffic information and use those information to check the traffic", "tokens": [23294, 281, 2105, 6419, 1589, 293, 764, 729, 1589, 281, 1520, 264, 6419], "temperature": 0.0, "avg_logprob": -0.2140259000990126, "compression_ratio": 1.6635514018691588, "no_speech_prob": 4.277571861166507e-05}, {"id": 169, "seek": 93596, "start": 949.0400000000001, "end": 955.52, "text": " and trigger alerts, for instance. Now, recently released also a Python package that you can", "tokens": [293, 7875, 28061, 11, 337, 5197, 13, 823, 11, 3938, 4736, 611, 257, 15329, 7372, 300, 291, 393], "temperature": 0.0, "avg_logprob": -0.2140259000990126, "compression_ratio": 1.6635514018691588, "no_speech_prob": 4.277571861166507e-05}, {"id": 170, "seek": 93596, "start": 955.52, "end": 963.4000000000001, "text": " install with pip install N-top-ng that allows you to, you can use it as a library to create", "tokens": [3625, 365, 8489, 3625, 426, 12, 19337, 12, 872, 300, 4045, 291, 281, 11, 291, 393, 764, 309, 382, 257, 6405, 281, 1884], "temperature": 0.0, "avg_logprob": -0.2140259000990126, "compression_ratio": 1.6635514018691588, "no_speech_prob": 4.277571861166507e-05}, {"id": 171, "seek": 96340, "start": 963.4, "end": 970.24, "text": " a Python script which is able to access traffic information in N-top-ng. And this happens", "tokens": [257, 15329, 5755, 597, 307, 1075, 281, 2105, 6419, 1589, 294, 426, 12, 19337, 12, 872, 13, 400, 341, 2314], "temperature": 0.0, "avg_logprob": -0.14313755220579868, "compression_ratio": 1.6886792452830188, "no_speech_prob": 2.0292312910896726e-05}, {"id": 172, "seek": 96340, "start": 970.24, "end": 979.04, "text": " through the REST API. This means that you can run your script even on a remote location.", "tokens": [807, 264, 497, 14497, 9362, 13, 639, 1355, 300, 291, 393, 1190, 428, 5755, 754, 322, 257, 8607, 4914, 13], "temperature": 0.0, "avg_logprob": -0.14313755220579868, "compression_ratio": 1.6886792452830188, "no_speech_prob": 2.0292312910896726e-05}, {"id": 173, "seek": 96340, "start": 979.04, "end": 984.4399999999999, "text": " For example, you can access live data in N-top-ng. In this case, we are importing the N-top-ng", "tokens": [1171, 1365, 11, 291, 393, 2105, 1621, 1412, 294, 426, 12, 19337, 12, 872, 13, 682, 341, 1389, 11, 321, 366, 43866, 264, 426, 12, 19337, 12, 872], "temperature": 0.0, "avg_logprob": -0.14313755220579868, "compression_ratio": 1.6886792452830188, "no_speech_prob": 2.0292312910896726e-05}, {"id": 174, "seek": 96340, "start": 984.4399999999999, "end": 991.1999999999999, "text": " class. We are connecting to N-top-ng using the N-top-ng class. We get an instance of", "tokens": [1508, 13, 492, 366, 11015, 281, 426, 12, 19337, 12, 872, 1228, 264, 426, 12, 19337, 12, 872, 1508, 13, 492, 483, 364, 5197, 295], "temperature": 0.0, "avg_logprob": -0.14313755220579868, "compression_ratio": 1.6886792452830188, "no_speech_prob": 2.0292312910896726e-05}, {"id": 175, "seek": 99120, "start": 991.2, "end": 999.0400000000001, "text": " the, of an interface in N-top-ng, for instance, eth0. We use this method to get all the hosts", "tokens": [264, 11, 295, 364, 9226, 294, 426, 12, 19337, 12, 872, 11, 337, 5197, 11, 1030, 71, 15, 13, 492, 764, 341, 3170, 281, 483, 439, 264, 21573], "temperature": 0.0, "avg_logprob": -0.17238687961659532, "compression_ratio": 1.6529680365296804, "no_speech_prob": 6.926615697011584e-06}, {"id": 176, "seek": 99120, "start": 999.0400000000001, "end": 1005.1600000000001, "text": " which are active in my network with all the metadata. And there are plenty of methods", "tokens": [597, 366, 4967, 294, 452, 3209, 365, 439, 264, 26603, 13, 400, 456, 366, 7140, 295, 7150], "temperature": 0.0, "avg_logprob": -0.17238687961659532, "compression_ratio": 1.6529680365296804, "no_speech_prob": 6.926615697011584e-06}, {"id": 177, "seek": 99120, "start": 1005.1600000000001, "end": 1009.5600000000001, "text": " in this class or another class in this library that allows you to get traffic information.", "tokens": [294, 341, 1508, 420, 1071, 1508, 294, 341, 6405, 300, 4045, 291, 281, 483, 6419, 1589, 13], "temperature": 0.0, "avg_logprob": -0.17238687961659532, "compression_ratio": 1.6529680365296804, "no_speech_prob": 6.926615697011584e-06}, {"id": 178, "seek": 99120, "start": 1009.5600000000001, "end": 1018.2, "text": " So you can get alerts, flows, hosts, whatever. And you can also get historical data. So the", "tokens": [407, 291, 393, 483, 28061, 11, 12867, 11, 21573, 11, 2035, 13, 400, 291, 393, 611, 483, 8584, 1412, 13, 407, 264], "temperature": 0.0, "avg_logprob": -0.17238687961659532, "compression_ratio": 1.6529680365296804, "no_speech_prob": 6.926615697011584e-06}, {"id": 179, "seek": 101820, "start": 1018.2, "end": 1022.8000000000001, "text": " same way, so you connect to N-top-ng, you get an interface. From this interface, you", "tokens": [912, 636, 11, 370, 291, 1745, 281, 426, 12, 19337, 12, 872, 11, 291, 483, 364, 9226, 13, 3358, 341, 9226, 11, 291], "temperature": 0.0, "avg_logprob": -0.2177471247586337, "compression_ratio": 1.7553191489361701, "no_speech_prob": 4.5194803533377126e-05}, {"id": 180, "seek": 101820, "start": 1022.8000000000001, "end": 1027.72, "text": " get the, an instance of the historical class. And you can run queries in the database. For", "tokens": [483, 264, 11, 364, 5197, 295, 264, 8584, 1508, 13, 400, 291, 393, 1190, 24109, 294, 264, 8149, 13, 1171], "temperature": 0.0, "avg_logprob": -0.2177471247586337, "compression_ratio": 1.7553191489361701, "no_speech_prob": 4.5194803533377126e-05}, {"id": 181, "seek": 101820, "start": 1027.72, "end": 1033.32, "text": " instance, you can get alerts statistics from this time to this time, for instance, for", "tokens": [5197, 11, 291, 393, 483, 28061, 12523, 490, 341, 565, 281, 341, 565, 11, 337, 5197, 11, 337], "temperature": 0.0, "avg_logprob": -0.2177471247586337, "compression_ratio": 1.7553191489361701, "no_speech_prob": 4.5194803533377126e-05}, {"id": 182, "seek": 101820, "start": 1033.32, "end": 1041.6000000000001, "text": " the last 24 hours. And just print the, of the alerts that you have.", "tokens": [264, 1036, 4022, 2496, 13, 400, 445, 4482, 264, 11, 295, 264, 28061, 300, 291, 362, 13], "temperature": 0.0, "avg_logprob": -0.2177471247586337, "compression_ratio": 1.7553191489361701, "no_speech_prob": 4.5194803533377126e-05}, {"id": 183, "seek": 104160, "start": 1041.6, "end": 1049.9599999999998, "text": " Now, those are two examples of querying the, the engine to get the data. Of course, we", "tokens": [823, 11, 729, 366, 732, 5110, 295, 7083, 1840, 264, 11, 264, 2848, 281, 483, 264, 1412, 13, 2720, 1164, 11, 321], "temperature": 0.0, "avg_logprob": -0.17748610789959246, "compression_ratio": 1.6116071428571428, "no_speech_prob": 1.0409482456452679e-05}, {"id": 184, "seek": 104160, "start": 1049.9599999999998, "end": 1057.48, "text": " have seen that N-top-ng is able to, when a check or an external event detects something,", "tokens": [362, 1612, 300, 426, 12, 19337, 12, 872, 307, 1075, 281, 11, 562, 257, 1520, 420, 364, 8320, 2280, 5531, 82, 746, 11], "temperature": 0.0, "avg_logprob": -0.17748610789959246, "compression_ratio": 1.6116071428571428, "no_speech_prob": 1.0409482456452679e-05}, {"id": 185, "seek": 104160, "start": 1057.48, "end": 1062.9199999999998, "text": " an event, we can trigger an alert. And we have seen that N-top-ng supports several endpoints.", "tokens": [364, 2280, 11, 321, 393, 7875, 364, 9615, 13, 400, 321, 362, 1612, 300, 426, 12, 19337, 12, 872, 9346, 2940, 917, 20552, 13], "temperature": 0.0, "avg_logprob": -0.17748610789959246, "compression_ratio": 1.6116071428571428, "no_speech_prob": 1.0409482456452679e-05}, {"id": 186, "seek": 104160, "start": 1062.9199999999998, "end": 1071.48, "text": " So we can send this alert using mail, a messaging system, like telegrams, LAC. We can run a", "tokens": [407, 321, 393, 2845, 341, 9615, 1228, 10071, 11, 257, 21812, 1185, 11, 411, 4304, 1342, 82, 11, 441, 4378, 13, 492, 393, 1190, 257], "temperature": 0.0, "avg_logprob": -0.17748610789959246, "compression_ratio": 1.6116071428571428, "no_speech_prob": 1.0409482456452679e-05}, {"id": 187, "seek": 107148, "start": 1071.48, "end": 1077.6, "text": " shell script. We can call a web book. So we can run a shell script. For instance, in", "tokens": [8720, 5755, 13, 492, 393, 818, 257, 3670, 1446, 13, 407, 321, 393, 1190, 257, 8720, 5755, 13, 1171, 5197, 11, 294], "temperature": 0.0, "avg_logprob": -0.14211439002643933, "compression_ratio": 1.7692307692307692, "no_speech_prob": 1.4865086995996535e-05}, {"id": 188, "seek": 107148, "start": 1077.6, "end": 1085.84, "text": " this script, it can be a Python script. So let's try to put all the pieces together.", "tokens": [341, 5755, 11, 309, 393, 312, 257, 15329, 5755, 13, 407, 718, 311, 853, 281, 829, 439, 264, 3755, 1214, 13], "temperature": 0.0, "avg_logprob": -0.14211439002643933, "compression_ratio": 1.7692307692307692, "no_speech_prob": 1.4865086995996535e-05}, {"id": 189, "seek": 107148, "start": 1085.84, "end": 1092.88, "text": " So we receive an event from, which is generated by an internal check or an external check.", "tokens": [407, 321, 4774, 364, 2280, 490, 11, 597, 307, 10833, 538, 364, 6920, 1520, 420, 364, 8320, 1520, 13], "temperature": 0.0, "avg_logprob": -0.14211439002643933, "compression_ratio": 1.7692307692307692, "no_speech_prob": 1.4865086995996535e-05}, {"id": 190, "seek": 107148, "start": 1092.88, "end": 1098.44, "text": " This event can call a Python script. This Python script can get information from the", "tokens": [639, 2280, 393, 818, 257, 15329, 5755, 13, 639, 15329, 5755, 393, 483, 1589, 490, 264], "temperature": 0.0, "avg_logprob": -0.14211439002643933, "compression_ratio": 1.7692307692307692, "no_speech_prob": 1.4865086995996535e-05}, {"id": 191, "seek": 109844, "start": 1098.44, "end": 1105.0800000000002, "text": " alert itself or can query the engine through this API that we created to get more data,", "tokens": [9615, 2564, 420, 393, 14581, 264, 2848, 807, 341, 9362, 300, 321, 2942, 281, 483, 544, 1412, 11], "temperature": 0.0, "avg_logprob": -0.15534817487343974, "compression_ratio": 1.6132075471698113, "no_speech_prob": 1.312922358920332e-05}, {"id": 192, "seek": 109844, "start": 1105.0800000000002, "end": 1110.3200000000002, "text": " to fetch more data and argument the alert information. And this can have some logic", "tokens": [281, 23673, 544, 1412, 293, 6770, 264, 9615, 1589, 13, 400, 341, 393, 362, 512, 9952], "temperature": 0.0, "avg_logprob": -0.15534817487343974, "compression_ratio": 1.6132075471698113, "no_speech_prob": 1.312922358920332e-05}, {"id": 193, "seek": 109844, "start": 1110.3200000000002, "end": 1118.8400000000001, "text": " and trigger some action. So you can write your actions here to react to this event.", "tokens": [293, 7875, 512, 3069, 13, 407, 291, 393, 2464, 428, 5909, 510, 281, 4515, 281, 341, 2280, 13], "temperature": 0.0, "avg_logprob": -0.15534817487343974, "compression_ratio": 1.6132075471698113, "no_speech_prob": 1.312922358920332e-05}, {"id": 194, "seek": 109844, "start": 1118.8400000000001, "end": 1122.48, "text": " In order to implement this, what you have to do in N-top-ng is, first of all, you have", "tokens": [682, 1668, 281, 4445, 341, 11, 437, 291, 362, 281, 360, 294, 426, 12, 19337, 12, 872, 307, 11, 700, 295, 439, 11, 291, 362], "temperature": 0.0, "avg_logprob": -0.15534817487343974, "compression_ratio": 1.6132075471698113, "no_speech_prob": 1.312922358920332e-05}, {"id": 195, "seek": 112248, "start": 1122.48, "end": 1128.6, "text": " to enable the check that you want to use to analyze the traffic. For instance, in this", "tokens": [281, 9528, 264, 1520, 300, 291, 528, 281, 764, 281, 12477, 264, 6419, 13, 1171, 5197, 11, 294, 341], "temperature": 0.0, "avg_logprob": -0.17250974885709994, "compression_ratio": 1.6619718309859155, "no_speech_prob": 3.436761471675709e-05}, {"id": 196, "seek": 112248, "start": 1128.6, "end": 1138.8, "text": " case, we are using a custom check that the user creates in Lua as Luca showed you before.", "tokens": [1389, 11, 321, 366, 1228, 257, 2375, 1520, 300, 264, 4195, 7829, 294, 441, 4398, 382, 42076, 4712, 291, 949, 13], "temperature": 0.0, "avg_logprob": -0.17250974885709994, "compression_ratio": 1.6619718309859155, "no_speech_prob": 3.436761471675709e-05}, {"id": 197, "seek": 112248, "start": 1138.8, "end": 1143.8, "text": " Then if you want to write your Python script that reacts to this event, you have to write", "tokens": [1396, 498, 291, 528, 281, 2464, 428, 15329, 5755, 300, 33305, 281, 341, 2280, 11, 291, 362, 281, 2464], "temperature": 0.0, "avg_logprob": -0.17250974885709994, "compression_ratio": 1.6619718309859155, "no_speech_prob": 3.436761471675709e-05}, {"id": 198, "seek": 112248, "start": 1143.8, "end": 1150.72, "text": " an alert tender, which is a script that you place under N-top-ng script shell. And this", "tokens": [364, 9615, 15036, 11, 597, 307, 257, 5755, 300, 291, 1081, 833, 426, 12, 19337, 12, 872, 5755, 8720, 13, 400, 341], "temperature": 0.0, "avg_logprob": -0.17250974885709994, "compression_ratio": 1.6619718309859155, "no_speech_prob": 3.436761471675709e-05}, {"id": 199, "seek": 115072, "start": 1150.72, "end": 1156.28, "text": " case is a simple script, which is just getting, as in the standard input, the traffic information,", "tokens": [1389, 307, 257, 2199, 5755, 11, 597, 307, 445, 1242, 11, 382, 294, 264, 3832, 4846, 11, 264, 6419, 1589, 11], "temperature": 0.0, "avg_logprob": -0.20272149642308554, "compression_ratio": 1.5829787234042554, "no_speech_prob": 2.583868808869738e-05}, {"id": 200, "seek": 115072, "start": 1156.28, "end": 1163.0, "text": " the metadata. And, for instance, if the alert type is our user script, I want to do something.", "tokens": [264, 26603, 13, 400, 11, 337, 5197, 11, 498, 264, 9615, 2010, 307, 527, 4195, 5755, 11, 286, 528, 281, 360, 746, 13], "temperature": 0.0, "avg_logprob": -0.20272149642308554, "compression_ratio": 1.5829787234042554, "no_speech_prob": 2.583868808869738e-05}, {"id": 201, "seek": 115072, "start": 1163.0, "end": 1168.88, "text": " In this case, I'm just logging the IP address related to the host that triggered the alert", "tokens": [682, 341, 1389, 11, 286, 478, 445, 27991, 264, 8671, 2985, 4077, 281, 264, 3975, 300, 21710, 264, 9615], "temperature": 0.0, "avg_logprob": -0.20272149642308554, "compression_ratio": 1.5829787234042554, "no_speech_prob": 2.583868808869738e-05}, {"id": 202, "seek": 115072, "start": 1168.88, "end": 1177.32, "text": " and a message from our custom script. Then you have to go inside N-top-ng. You go under", "tokens": [293, 257, 3636, 490, 527, 2375, 5755, 13, 1396, 291, 362, 281, 352, 1854, 426, 12, 19337, 12, 872, 13, 509, 352, 833], "temperature": 0.0, "avg_logprob": -0.20272149642308554, "compression_ratio": 1.5829787234042554, "no_speech_prob": 2.583868808869738e-05}, {"id": 203, "seek": 117732, "start": 1177.32, "end": 1183.36, "text": " notifications. You set that you want to send alerts to the shell script. Here you have", "tokens": [13426, 13, 509, 992, 300, 291, 528, 281, 2845, 28061, 281, 264, 8720, 5755, 13, 1692, 291, 362], "temperature": 0.0, "avg_logprob": -0.2055988765898205, "compression_ratio": 1.8835978835978835, "no_speech_prob": 2.9170709240133874e-05}, {"id": 204, "seek": 117732, "start": 1183.36, "end": 1189.12, "text": " all the options, like email, whatever. And you select your handler. And then you specify", "tokens": [439, 264, 3956, 11, 411, 3796, 11, 2035, 13, 400, 291, 3048, 428, 41967, 13, 400, 550, 291, 16500], "temperature": 0.0, "avg_logprob": -0.2055988765898205, "compression_ratio": 1.8835978835978835, "no_speech_prob": 2.9170709240133874e-05}, {"id": 205, "seek": 117732, "start": 1189.12, "end": 1193.8799999999999, "text": " for your handler that you want to receive just critical alerts. So you specify the severity.", "tokens": [337, 428, 41967, 300, 291, 528, 281, 4774, 445, 4924, 28061, 13, 407, 291, 16500, 264, 35179, 13], "temperature": 0.0, "avg_logprob": -0.2055988765898205, "compression_ratio": 1.8835978835978835, "no_speech_prob": 2.9170709240133874e-05}, {"id": 206, "seek": 117732, "start": 1193.8799999999999, "end": 1197.96, "text": " You specify the category that you want to, of alerts that you want to handle, from this", "tokens": [509, 16500, 264, 7719, 300, 291, 528, 281, 11, 295, 28061, 300, 291, 528, 281, 4813, 11, 490, 341], "temperature": 0.0, "avg_logprob": -0.2055988765898205, "compression_ratio": 1.8835978835978835, "no_speech_prob": 2.9170709240133874e-05}, {"id": 207, "seek": 119796, "start": 1197.96, "end": 1208.04, "text": " case, cybersecurity, and the entity. In this case, I want to handle alerts about hosts.", "tokens": [1389, 11, 38765, 11, 293, 264, 13977, 13, 682, 341, 1389, 11, 286, 528, 281, 4813, 28061, 466, 21573, 13], "temperature": 0.0, "avg_logprob": -0.1536485336639069, "compression_ratio": 1.609865470852018, "no_speech_prob": 2.4907207262003794e-05}, {"id": 208, "seek": 119796, "start": 1208.04, "end": 1213.6000000000001, "text": " And then we can extend our handler. We have seen how to print just the alert information,", "tokens": [400, 550, 321, 393, 10101, 527, 41967, 13, 492, 362, 1612, 577, 281, 4482, 445, 264, 9615, 1589, 11], "temperature": 0.0, "avg_logprob": -0.1536485336639069, "compression_ratio": 1.609865470852018, "no_speech_prob": 2.4907207262003794e-05}, {"id": 209, "seek": 119796, "start": 1213.6000000000001, "end": 1221.08, "text": " but we can, again, we can use our Python library and N-top-ng to access more information about", "tokens": [457, 321, 393, 11, 797, 11, 321, 393, 764, 527, 15329, 6405, 293, 426, 12, 19337, 12, 872, 281, 2105, 544, 1589, 466], "temperature": 0.0, "avg_logprob": -0.1536485336639069, "compression_ratio": 1.609865470852018, "no_speech_prob": 2.4907207262003794e-05}, {"id": 210, "seek": 119796, "start": 1221.08, "end": 1226.8400000000001, "text": " the host. So we receive this alert, which has been triggered on a specific host in our", "tokens": [264, 3975, 13, 407, 321, 4774, 341, 9615, 11, 597, 575, 668, 21710, 322, 257, 2685, 3975, 294, 527], "temperature": 0.0, "avg_logprob": -0.1536485336639069, "compression_ratio": 1.609865470852018, "no_speech_prob": 2.4907207262003794e-05}, {"id": 211, "seek": 122684, "start": 1226.84, "end": 1232.6399999999999, "text": " network. For instance, this host has been infected by malware. It's generating unexpected", "tokens": [3209, 13, 1171, 5197, 11, 341, 3975, 575, 668, 15414, 538, 40747, 13, 467, 311, 17746, 13106], "temperature": 0.0, "avg_logprob": -0.15201697188816712, "compression_ratio": 1.6355555555555557, "no_speech_prob": 2.2158017600304447e-05}, {"id": 212, "seek": 122684, "start": 1232.6399999999999, "end": 1239.9199999999998, "text": " traffic, whatever. We want to get more information about this host to build a report, for instance.", "tokens": [6419, 11, 2035, 13, 492, 528, 281, 483, 544, 1589, 466, 341, 3975, 281, 1322, 257, 2275, 11, 337, 5197, 13], "temperature": 0.0, "avg_logprob": -0.15201697188816712, "compression_ratio": 1.6355555555555557, "no_speech_prob": 2.2158017600304447e-05}, {"id": 213, "seek": 122684, "start": 1239.9199999999998, "end": 1243.84, "text": " In fact, in our library, we also have the ability to generate a report, or you can generate", "tokens": [682, 1186, 11, 294, 527, 6405, 11, 321, 611, 362, 264, 3485, 281, 8460, 257, 2275, 11, 420, 291, 393, 8460], "temperature": 0.0, "avg_logprob": -0.15201697188816712, "compression_ratio": 1.6355555555555557, "no_speech_prob": 2.2158017600304447e-05}, {"id": 214, "seek": 122684, "start": 1243.84, "end": 1252.4399999999998, "text": " your own report using the API that we have. So we build this report and send an email.", "tokens": [428, 1065, 2275, 1228, 264, 9362, 300, 321, 362, 13, 407, 321, 1322, 341, 2275, 293, 2845, 364, 3796, 13], "temperature": 0.0, "avg_logprob": -0.15201697188816712, "compression_ratio": 1.6355555555555557, "no_speech_prob": 2.2158017600304447e-05}, {"id": 215, "seek": 125244, "start": 1252.44, "end": 1257.52, "text": " So this is a simple script that you can use. It's a few lines of code to handle alerts", "tokens": [407, 341, 307, 257, 2199, 5755, 300, 291, 393, 764, 13, 467, 311, 257, 1326, 3876, 295, 3089, 281, 4813, 28061], "temperature": 0.0, "avg_logprob": -0.169267182939508, "compression_ratio": 1.6359447004608294, "no_speech_prob": 2.545743336668238e-05}, {"id": 216, "seek": 125244, "start": 1257.52, "end": 1265.48, "text": " and generate reports and get, for instance, an email or your mobile phone with the alert.", "tokens": [293, 8460, 7122, 293, 483, 11, 337, 5197, 11, 364, 3796, 420, 428, 6013, 2593, 365, 264, 9615, 13], "temperature": 0.0, "avg_logprob": -0.169267182939508, "compression_ratio": 1.6359447004608294, "no_speech_prob": 2.545743336668238e-05}, {"id": 217, "seek": 125244, "start": 1265.48, "end": 1271.56, "text": " So this is the big picture of the example that we're seeing right now. So we have defined", "tokens": [407, 341, 307, 264, 955, 3036, 295, 264, 1365, 300, 321, 434, 2577, 558, 586, 13, 407, 321, 362, 7642], "temperature": 0.0, "avg_logprob": -0.169267182939508, "compression_ratio": 1.6359447004608294, "no_speech_prob": 2.545743336668238e-05}, {"id": 218, "seek": 125244, "start": 1271.56, "end": 1278.8400000000001, "text": " a user script that triggers an alert, or we receive, again, events from any other source", "tokens": [257, 4195, 5755, 300, 22827, 364, 9615, 11, 420, 321, 4774, 11, 797, 11, 3931, 490, 604, 661, 4009], "temperature": 0.0, "avg_logprob": -0.169267182939508, "compression_ratio": 1.6359447004608294, "no_speech_prob": 2.545743336668238e-05}, {"id": 219, "seek": 127884, "start": 1278.84, "end": 1284.6399999999999, "text": " or internal checks. We are calling our script, which is getting more information from the", "tokens": [420, 6920, 13834, 13, 492, 366, 5141, 527, 5755, 11, 597, 307, 1242, 544, 1589, 490, 264], "temperature": 0.0, "avg_logprob": -0.1699381328764416, "compression_ratio": 1.7009345794392523, "no_speech_prob": 2.9004491807427257e-05}, {"id": 220, "seek": 127884, "start": 1284.6399999999999, "end": 1290.9199999999998, "text": " engine to build a report and send this report by email. So the result is this. So the system", "tokens": [2848, 281, 1322, 257, 2275, 293, 2845, 341, 2275, 538, 3796, 13, 407, 264, 1874, 307, 341, 13, 407, 264, 1185], "temperature": 0.0, "avg_logprob": -0.1699381328764416, "compression_ratio": 1.7009345794392523, "no_speech_prob": 2.9004491807427257e-05}, {"id": 221, "seek": 127884, "start": 1290.9199999999998, "end": 1296.48, "text": " is checking your traffic, is building a report when something happens, and we'll send you", "tokens": [307, 8568, 428, 6419, 11, 307, 2390, 257, 2275, 562, 746, 2314, 11, 293, 321, 603, 2845, 291], "temperature": 0.0, "avg_logprob": -0.1699381328764416, "compression_ratio": 1.7009345794392523, "no_speech_prob": 2.9004491807427257e-05}, {"id": 222, "seek": 127884, "start": 1296.48, "end": 1302.6399999999999, "text": " an email with the report of the traffic for the host with the top alerts sorted by severity", "tokens": [364, 3796, 365, 264, 2275, 295, 264, 6419, 337, 264, 3975, 365, 264, 1192, 28061, 25462, 538, 35179], "temperature": 0.0, "avg_logprob": -0.1699381328764416, "compression_ratio": 1.7009345794392523, "no_speech_prob": 2.9004491807427257e-05}, {"id": 223, "seek": 130264, "start": 1302.64, "end": 1309.0, "text": " or by count, the top contacts for the host, the chart of the traffic generated by the", "tokens": [420, 538, 1207, 11, 264, 1192, 15836, 337, 264, 3975, 11, 264, 6927, 295, 264, 6419, 10833, 538, 264], "temperature": 0.0, "avg_logprob": -0.20910833192908246, "compression_ratio": 1.7254901960784315, "no_speech_prob": 2.6773630452225916e-05}, {"id": 224, "seek": 130264, "start": 1309.0, "end": 1315.72, "text": " host, where you can add more, like the top applications used by the host, et cetera.", "tokens": [3975, 11, 689, 291, 393, 909, 544, 11, 411, 264, 1192, 5821, 1143, 538, 264, 3975, 11, 1030, 11458, 13], "temperature": 0.0, "avg_logprob": -0.20910833192908246, "compression_ratio": 1.7254901960784315, "no_speech_prob": 2.6773630452225916e-05}, {"id": 225, "seek": 130264, "start": 1315.72, "end": 1321.2, "text": " Do you want to wrap up? Okay. So we have seen that within top ng, you can collect traffic", "tokens": [1144, 291, 528, 281, 7019, 493, 30, 1033, 13, 407, 321, 362, 1612, 300, 1951, 1192, 6415, 11, 291, 393, 2500, 6419], "temperature": 0.0, "avg_logprob": -0.20910833192908246, "compression_ratio": 1.7254901960784315, "no_speech_prob": 2.6773630452225916e-05}, {"id": 226, "seek": 130264, "start": 1321.2, "end": 1331.24, "text": " information from traffic, flows, events, events from Suricada, for instance, et cetera. And", "tokens": [1589, 490, 6419, 11, 12867, 11, 3931, 11, 3931, 490, 6732, 299, 1538, 11, 337, 5197, 11, 1030, 11458, 13, 400], "temperature": 0.0, "avg_logprob": -0.20910833192908246, "compression_ratio": 1.7254901960784315, "no_speech_prob": 2.6773630452225916e-05}, {"id": 227, "seek": 133124, "start": 1331.24, "end": 1336.4, "text": " we started with the top, actually Luca started with the top, then we moved to the top ng.", "tokens": [321, 1409, 365, 264, 1192, 11, 767, 42076, 1409, 365, 264, 1192, 11, 550, 321, 4259, 281, 264, 1192, 6415, 13], "temperature": 0.0, "avg_logprob": -0.2759667140681569, "compression_ratio": 1.6866359447004609, "no_speech_prob": 9.956295252777636e-05}, {"id": 228, "seek": 133124, "start": 1336.4, "end": 1344.44, "text": " It was mainly a traffic monitoring tool. Today is also a cybersecurity tool able to do behavioral", "tokens": [467, 390, 8704, 257, 6419, 11028, 2290, 13, 2692, 307, 611, 257, 38765, 2290, 1075, 281, 360, 19124], "temperature": 0.0, "avg_logprob": -0.2759667140681569, "compression_ratio": 1.6866359447004609, "no_speech_prob": 9.956295252777636e-05}, {"id": 229, "seek": 133124, "start": 1344.44, "end": 1352.8, "text": " checks, not just for providing visibility, but also providing cybersecurity monitoring.", "tokens": [13834, 11, 406, 445, 337, 6530, 19883, 11, 457, 611, 6530, 38765, 11028, 13], "temperature": 0.0, "avg_logprob": -0.2759667140681569, "compression_ratio": 1.6866359447004609, "no_speech_prob": 9.956295252777636e-05}, {"id": 230, "seek": 133124, "start": 1352.8, "end": 1359.84, "text": " You are now able to extend this engine, both with new scripts integrated in top ng or even", "tokens": [509, 366, 586, 1075, 281, 10101, 341, 2848, 11, 1293, 365, 777, 23294, 10919, 294, 1192, 6415, 420, 754], "temperature": 0.0, "avg_logprob": -0.2759667140681569, "compression_ratio": 1.6866359447004609, "no_speech_prob": 9.956295252777636e-05}, {"id": 231, "seek": 135984, "start": 1359.84, "end": 1368.04, "text": " with C++ plugins, let's say checks, if you need to scale with performance, or you can", "tokens": [365, 383, 25472, 33759, 11, 718, 311, 584, 13834, 11, 498, 291, 643, 281, 4373, 365, 3389, 11, 420, 291, 393], "temperature": 0.0, "avg_logprob": -0.20961128581653943, "compression_ratio": 1.5434782608695652, "no_speech_prob": 5.2416791731957346e-05}, {"id": 232, "seek": 135984, "start": 1368.04, "end": 1376.12, "text": " use our Python library to write Python tools that can run externally, even remote boxes,", "tokens": [764, 527, 15329, 6405, 281, 2464, 15329, 3873, 300, 393, 1190, 40899, 11, 754, 8607, 9002, 11], "temperature": 0.0, "avg_logprob": -0.20961128581653943, "compression_ratio": 1.5434782608695652, "no_speech_prob": 5.2416791731957346e-05}, {"id": 233, "seek": 135984, "start": 1376.12, "end": 1384.24, "text": " to access traffic information in the top ng engine, and be, for instance, a PDF as we", "tokens": [281, 2105, 6419, 1589, 294, 264, 1192, 6415, 2848, 11, 293, 312, 11, 337, 5197, 11, 257, 17752, 382, 321], "temperature": 0.0, "avg_logprob": -0.20961128581653943, "compression_ratio": 1.5434782608695652, "no_speech_prob": 5.2416791731957346e-05}, {"id": 234, "seek": 135984, "start": 1384.24, "end": 1388.84, "text": " have seen with reporting what's going on in your network. Of course, all the code is available", "tokens": [362, 1612, 365, 10031, 437, 311, 516, 322, 294, 428, 3209, 13, 2720, 1164, 11, 439, 264, 3089, 307, 2435], "temperature": 0.0, "avg_logprob": -0.20961128581653943, "compression_ratio": 1.5434782608695652, "no_speech_prob": 5.2416791731957346e-05}, {"id": 235, "seek": 138884, "start": 1388.84, "end": 1394.72, "text": " on GitHub, so if you want to contribute, you are welcome. Especially now, you don't have", "tokens": [322, 23331, 11, 370, 498, 291, 528, 281, 10586, 11, 291, 366, 2928, 13, 8545, 586, 11, 291, 500, 380, 362], "temperature": 0.0, "avg_logprob": -0.23814762339872472, "compression_ratio": 1.6121673003802282, "no_speech_prob": 0.0006867257761768997}, {"id": 236, "seek": 138884, "start": 1394.72, "end": 1402.9199999999998, "text": " excuses. We have a lot of libraries, scripting languages for interacting with the engines,", "tokens": [24666, 13, 492, 362, 257, 688, 295, 15148, 11, 5755, 278, 8650, 337, 18017, 365, 264, 12982, 11], "temperature": 0.0, "avg_logprob": -0.23814762339872472, "compression_ratio": 1.6121673003802282, "no_speech_prob": 0.0006867257761768997}, {"id": 237, "seek": 138884, "start": 1402.9199999999998, "end": 1409.52, "text": " or something else to add. No. The only thing I want to say is that this", "tokens": [420, 746, 1646, 281, 909, 13, 883, 13, 440, 787, 551, 286, 528, 281, 584, 307, 300, 341], "temperature": 0.0, "avg_logprob": -0.23814762339872472, "compression_ratio": 1.6121673003802282, "no_speech_prob": 0.0006867257761768997}, {"id": 238, "seek": 138884, "start": 1409.52, "end": 1413.8799999999999, "text": " is an efficient way from our point of view to do network monitoring and cybersecurity,", "tokens": [307, 364, 7148, 636, 490, 527, 935, 295, 1910, 281, 360, 3209, 11028, 293, 38765, 11], "temperature": 0.0, "avg_logprob": -0.23814762339872472, "compression_ratio": 1.6121673003802282, "no_speech_prob": 0.0006867257761768997}, {"id": 239, "seek": 138884, "start": 1413.8799999999999, "end": 1418.0, "text": " and at the same time to extract information in a way that does not interfere with the", "tokens": [293, 412, 264, 912, 565, 281, 8947, 1589, 294, 257, 636, 300, 775, 406, 23946, 365, 264], "temperature": 0.0, "avg_logprob": -0.23814762339872472, "compression_ratio": 1.6121673003802282, "no_speech_prob": 0.0006867257761768997}, {"id": 240, "seek": 141800, "start": 1418.0, "end": 1423.8, "text": " main engine, so that allows, I believe, most of the people sitting in this room to do whatever", "tokens": [2135, 2848, 11, 370, 300, 4045, 11, 286, 1697, 11, 881, 295, 264, 561, 3798, 294, 341, 1808, 281, 360, 2035], "temperature": 0.0, "avg_logprob": -0.3479660087161594, "compression_ratio": 1.5414364640883977, "no_speech_prob": 0.0011424716794863343}, {"id": 241, "seek": 141800, "start": 1423.8, "end": 1427.72, "text": " they like to create a monitoring tool that is tailored for their own needs, and that's", "tokens": [436, 411, 281, 1884, 257, 11028, 2290, 300, 307, 34858, 337, 641, 1065, 2203, 11, 293, 300, 311], "temperature": 0.0, "avg_logprob": -0.3479660087161594, "compression_ratio": 1.5414364640883977, "no_speech_prob": 0.0011424716794863343}, {"id": 242, "seek": 141800, "start": 1427.72, "end": 1434.72, "text": " the first set that is open source. That's all. Thank you very much.", "tokens": [264, 700, 992, 300, 307, 1269, 4009, 13, 663, 311, 439, 13, 1044, 291, 588, 709, 13], "temperature": 0.0, "avg_logprob": -0.3479660087161594, "compression_ratio": 1.5414364640883977, "no_speech_prob": 0.0011424716794863343}, {"id": 243, "seek": 141800, "start": 1434.72, "end": 1440.68, "text": " Any questions? Any questions?", "tokens": [2639, 1651, 30, 2639, 1651, 30], "temperature": 0.0, "avg_logprob": -0.3479660087161594, "compression_ratio": 1.5414364640883977, "no_speech_prob": 0.0011424716794863343}, {"id": 244, "seek": 144068, "start": 1440.68, "end": 1448.8, "text": " Wait, wait, wait. It's just a simple question. How does it compare with CN tools? It looks", "tokens": [3802, 11, 1699, 11, 1699, 13, 467, 311, 445, 257, 2199, 1168, 13, 1012, 775, 309, 6794, 365, 14589, 3873, 30, 467, 1542], "temperature": 0.0, "avg_logprob": -0.2957990990310419, "compression_ratio": 1.3866666666666667, "no_speech_prob": 0.010030253790318966}, {"id": 245, "seek": 144068, "start": 1448.8, "end": 1454.6000000000001, "text": " like it does everything CN could do. CN tools. Yeah.", "tokens": [411, 309, 775, 1203, 14589, 727, 360, 13, 14589, 3873, 13, 865, 13], "temperature": 0.0, "avg_logprob": -0.2957990990310419, "compression_ratio": 1.3866666666666667, "no_speech_prob": 0.010030253790318966}, {"id": 246, "seek": 144068, "start": 1454.6000000000001, "end": 1461.92, "text": " I don't know the tools. No problem. I am not familiar with them.", "tokens": [286, 500, 380, 458, 264, 3873, 13, 883, 1154, 13, 286, 669, 406, 4963, 365, 552, 13], "temperature": 0.0, "avg_logprob": -0.2957990990310419, "compression_ratio": 1.3866666666666667, "no_speech_prob": 0.010030253790318966}, {"id": 247, "seek": 146192, "start": 1461.92, "end": 1479.16, "text": " Any other questions? The scripts can be compiled to be more", "tokens": [2639, 661, 1651, 30, 440, 23294, 393, 312, 36548, 281, 312, 544], "temperature": 0.0, "avg_logprob": -0.32430678606033325, "compression_ratio": 0.921875, "no_speech_prob": 0.006813343148678541}, {"id": 248, "seek": 147916, "start": 1479.16, "end": 1491.4, "text": " performance, or do you not have this task in your developer timeline? To compile script,", "tokens": [3389, 11, 420, 360, 291, 406, 362, 341, 5633, 294, 428, 10754, 12933, 30, 1407, 31413, 5755, 11], "temperature": 0.0, "avg_logprob": -0.385322397405451, "compression_ratio": 1.35, "no_speech_prob": 0.008767714723944664}, {"id": 249, "seek": 147916, "start": 1491.4, "end": 1499.92, "text": " to have more performance. Loa script, or like CCC, we saw that CCC script", "tokens": [281, 362, 544, 3389, 13, 6130, 64, 5755, 11, 420, 411, 383, 11717, 11, 321, 1866, 300, 383, 11717, 5755], "temperature": 0.0, "avg_logprob": -0.385322397405451, "compression_ratio": 1.35, "no_speech_prob": 0.008767714723944664}, {"id": 250, "seek": 149992, "start": 1499.92, "end": 1512.3200000000002, "text": " takes one millisecond, but the Loa script takes 30 milliseconds. Yes, of course, you", "tokens": [2516, 472, 27940, 18882, 11, 457, 264, 6130, 64, 5755, 2516, 2217, 34184, 13, 1079, 11, 295, 1164, 11, 291], "temperature": 0.0, "avg_logprob": -0.2818557024002075, "compression_ratio": 1.610091743119266, "no_speech_prob": 0.0016796921845525503}, {"id": 251, "seek": 149992, "start": 1512.3200000000002, "end": 1517.48, "text": " can compile them, but you have to code it in C++ at the moment. So we used Loa just", "tokens": [393, 31413, 552, 11, 457, 291, 362, 281, 3089, 309, 294, 383, 25472, 412, 264, 1623, 13, 407, 321, 1143, 6130, 64, 445], "temperature": 0.0, "avg_logprob": -0.2818557024002075, "compression_ratio": 1.610091743119266, "no_speech_prob": 0.0016796921845525503}, {"id": 252, "seek": 149992, "start": 1517.48, "end": 1522.3600000000001, "text": " in time to compile the one seen before by a stamp switch, but it is not available everywhere", "tokens": [294, 565, 281, 31413, 264, 472, 1612, 949, 538, 257, 9921, 3679, 11, 457, 309, 307, 406, 2435, 5315], "temperature": 0.0, "avg_logprob": -0.2818557024002075, "compression_ratio": 1.610091743119266, "no_speech_prob": 0.0016796921845525503}, {"id": 253, "seek": 149992, "start": 1522.3600000000001, "end": 1527.0800000000002, "text": " for its own arm, and we want to support it as various. So yes, it is possible, but again,", "tokens": [337, 1080, 1065, 3726, 11, 293, 321, 528, 281, 1406, 309, 382, 3683, 13, 407, 2086, 11, 309, 307, 1944, 11, 457, 797, 11], "temperature": 0.0, "avg_logprob": -0.2818557024002075, "compression_ratio": 1.610091743119266, "no_speech_prob": 0.0016796921845525503}, {"id": 254, "seek": 152708, "start": 1527.08, "end": 1534.08, "text": " these are microseconds, not milliseconds. So one million of them per second.", "tokens": [613, 366, 3123, 37841, 28750, 11, 406, 34184, 13, 407, 472, 2459, 295, 552, 680, 1150, 13], "temperature": 0.0, "avg_logprob": -0.29483043670654296, "compression_ratio": 1.3655172413793104, "no_speech_prob": 0.004132586531341076}, {"id": 255, "seek": 152708, "start": 1534.08, "end": 1543.96, "text": " Any questions? Anybody else?", "tokens": [2639, 1651, 30, 19082, 1646, 30], "temperature": 0.0, "avg_logprob": -0.29483043670654296, "compression_ratio": 1.3655172413793104, "no_speech_prob": 0.004132586531341076}, {"id": 256, "seek": 152708, "start": 1543.96, "end": 1550.1999999999998, "text": " Hi, thank you. Do you have some figures about performance you are able to achieve on typical", "tokens": [2421, 11, 1309, 291, 13, 1144, 291, 362, 512, 9624, 466, 3389, 291, 366, 1075, 281, 4584, 322, 7476], "temperature": 0.0, "avg_logprob": -0.29483043670654296, "compression_ratio": 1.3655172413793104, "no_speech_prob": 0.004132586531341076}, {"id": 257, "seek": 155020, "start": 1550.2, "end": 1560.52, "text": " server, about flow per second? Some figures to share on Loa scripting, and also some example", "tokens": [7154, 11, 466, 3095, 680, 1150, 30, 2188, 9624, 281, 2073, 322, 6130, 64, 5755, 278, 11, 293, 611, 512, 1365], "temperature": 0.0, "avg_logprob": -0.3601855966779921, "compression_ratio": 1.4331550802139037, "no_speech_prob": 0.002856909530237317}, {"id": 258, "seek": 155020, "start": 1560.52, "end": 1569.48, "text": " on Python, which should be less efficient? Okay. We are, when you process packets with", "tokens": [322, 15329, 11, 597, 820, 312, 1570, 7148, 30, 1033, 13, 492, 366, 11, 562, 291, 1399, 30364, 365], "temperature": 0.0, "avg_logprob": -0.3601855966779921, "compression_ratio": 1.4331550802139037, "no_speech_prob": 0.002856909530237317}, {"id": 259, "seek": 155020, "start": 1569.48, "end": 1576.0, "text": " Ntop.ng itself, you are able to process like a few gigabits per second, depending on the", "tokens": [426, 83, 404, 13, 872, 2564, 11, 291, 366, 1075, 281, 1399, 411, 257, 1326, 8741, 455, 1208, 680, 1150, 11, 5413, 322, 264], "temperature": 0.0, "avg_logprob": -0.3601855966779921, "compression_ratio": 1.4331550802139037, "no_speech_prob": 0.002856909530237317}, {"id": 260, "seek": 157600, "start": 1576.0, "end": 1582.2, "text": " drivers you use, how you tune Ntop.ng, let's say, to scale with the performance, you can", "tokens": [11590, 291, 764, 11, 577, 291, 10864, 426, 83, 404, 13, 872, 11, 718, 311, 584, 11, 281, 4373, 365, 264, 3389, 11, 291, 393], "temperature": 0.0, "avg_logprob": -0.18394738593987658, "compression_ratio": 1.727699530516432, "no_speech_prob": 8.828767749946564e-05}, {"id": 261, "seek": 157600, "start": 1582.2, "end": 1588.76, "text": " get 10 gigabits, for instance, but more or less, we range from a few gigabits to 10 gigabits", "tokens": [483, 1266, 8741, 455, 1208, 11, 337, 5197, 11, 457, 544, 420, 1570, 11, 321, 3613, 490, 257, 1326, 8741, 455, 1208, 281, 1266, 8741, 455, 1208], "temperature": 0.0, "avg_logprob": -0.18394738593987658, "compression_ratio": 1.727699530516432, "no_speech_prob": 8.828767749946564e-05}, {"id": 262, "seek": 157600, "start": 1588.76, "end": 1594.24, "text": " in Ntop.ng itself. You can use it in combination with our probes, which is Nprobe, or we have", "tokens": [294, 426, 83, 404, 13, 872, 2564, 13, 509, 393, 764, 309, 294, 6562, 365, 527, 1239, 279, 11, 597, 307, 426, 4318, 650, 11, 420, 321, 362], "temperature": 0.0, "avg_logprob": -0.18394738593987658, "compression_ratio": 1.727699530516432, "no_speech_prob": 8.828767749946564e-05}, {"id": 263, "seek": 157600, "start": 1594.24, "end": 1599.84, "text": " other probes like Cento. In that case, you can scale with the performance up to 100 gigabits", "tokens": [661, 1239, 279, 411, 3408, 78, 13, 682, 300, 1389, 11, 291, 393, 4373, 365, 264, 3389, 493, 281, 2319, 8741, 455, 1208], "temperature": 0.0, "avg_logprob": -0.18394738593987658, "compression_ratio": 1.727699530516432, "no_speech_prob": 8.828767749946564e-05}, {"id": 264, "seek": 159984, "start": 1599.84, "end": 1609.72, "text": " per second, but the architecture changes a bit. It's one 100 gigabit in plus. As of", "tokens": [680, 1150, 11, 457, 264, 9482, 2962, 257, 857, 13, 467, 311, 472, 2319, 8741, 455, 270, 294, 1804, 13, 1018, 295], "temperature": 0.0, "avg_logprob": -0.2656973581465464, "compression_ratio": 1.3962264150943395, "no_speech_prob": 5.476083970279433e-05}, {"id": 265, "seek": 159984, "start": 1609.72, "end": 1616.12, "text": " the checks, it depends on the checks that you enable, of course. Okay. I think we are", "tokens": [264, 13834, 11, 309, 5946, 322, 264, 13834, 300, 291, 9528, 11, 295, 1164, 13, 1033, 13, 286, 519, 321, 366], "temperature": 0.0, "avg_logprob": -0.2656973581465464, "compression_ratio": 1.3962264150943395, "no_speech_prob": 5.476083970279433e-05}, {"id": 266, "seek": 159984, "start": 1616.12, "end": 1619.12, "text": " running out of time. Many thanks for being here now.", "tokens": [2614, 484, 295, 565, 13, 5126, 3231, 337, 885, 510, 586, 13], "temperature": 0.0, "avg_logprob": -0.2656973581465464, "compression_ratio": 1.3962264150943395, "no_speech_prob": 5.476083970279433e-05}, {"id": 267, "seek": 161912, "start": 1619.12, "end": 1630.32, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 50924], "temperature": 0.0, "avg_logprob": -0.8032554785410563, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.0020339018665254116}], "language": "en"}