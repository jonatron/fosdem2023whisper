[00:00.000 --> 00:16.040]  Can we hear me okay? Awesome. So Hugo is just here. He has just warned me if I step here
[00:16.040 --> 00:19.400]  that it will no longer pick me up on the camera, but I like to walk, so I'm going to do a little
[00:19.400 --> 00:24.280]  bit just to get out of my system if that's okay. So I want to talk to you today about
[00:24.280 --> 00:29.600]  malware on the Python package index, but more importantly than that, I'm actually going
[00:29.600 --> 00:35.080]  to run some malware on my own machine to show you what happens. So I think if I do this,
[00:35.080 --> 00:38.120]  you don't have to, and you'll know what the dangers are, right? So you don't have to worry.
[00:38.120 --> 00:41.160]  So I'm going to go here just so the people, if there's a live stream, and if I'm popular
[00:41.160 --> 00:44.720]  enough for anyone to look at it, then they'll see me. Hello, everybody. I think we might
[00:44.720 --> 00:48.960]  be getting a double microphone here. How do I make it off? I don't know. I'm just going
[00:48.960 --> 00:54.640]  to hide it. I'll put it there. It's all good. Right. So my name's Max, and I'm a developer
[00:54.680 --> 01:00.680]  advocate at Vonage, this company here, up there on left, hearing something. Okay. So
[01:00.680 --> 01:03.320]  what I want to do, first of all, is just explain, because these guys have paid for me to come
[01:03.320 --> 01:05.840]  here. They've paid for my flight. I've come from the UK, so I'm going to do the bit where
[01:05.840 --> 01:11.040]  I tell you what they do, right? So what we do is we make communications APIs. So things
[01:11.040 --> 01:15.880]  like SMS, like voice calls, like video chats, two-factor authentication as a service on
[01:15.880 --> 01:20.120]  demand. That's what we do, basically. So what I actually do is I manage the Python tooling
[01:20.160 --> 01:24.400]  before that. So in my role, I've done quite a lot of work to actually understand how I
[01:24.400 --> 01:27.680]  can not get myself screwed over with malware, right? Which is where this kind of talk comes
[01:27.680 --> 01:33.040]  from. Unfortunately, my research on malware has started to annoy some people. So this
[01:33.040 --> 01:37.280]  is a colleague I actually work with who no longer trusts anything I send him, because
[01:37.280 --> 01:40.240]  he knows I'm researching malware and he gets annoyed now. He's like, hey, don't send me
[01:40.240 --> 01:45.640]  that weird stuff. So, unfortunately, he's like, come on, man, don't do this to me. But he
[01:45.640 --> 01:49.360]  said this is not going to be a slide in your talk, and I was like, yes, it is. This is
[01:49.400 --> 01:54.000]  going to be a slide in my talk. That's what's going to happen. Okay. So he didn't like it
[01:54.000 --> 01:58.480]  because I'm going into the Vonage Python SDK, right? But I made a version called not the
[01:58.480 --> 02:02.040]  Vonage Python SDK that I uploaded to PyPy. I'm going to show you what happens if you
[02:02.040 --> 02:05.280]  install it. Please do not install it unless you want to have a bad time, okay? But it
[02:05.280 --> 02:09.480]  is live and you could literally do it right now. Please don't, again, but you could. Maybe
[02:09.480 --> 02:14.240]  you should. It's up to you, right? So that's where we are with this, right? But before we
[02:14.240 --> 02:17.440]  get there, that's the foreshadowing bit where I say, look, this is Chekhov's malware. You
[02:17.520 --> 02:20.880]  know, we set it up at the start. We hit it at the end. That's what we do. I've just also
[02:20.880 --> 02:26.440]  hit that. That's a literal punch. Okay. So first question for you. Does anybody remember
[02:26.440 --> 02:32.040]  this website, this old font? Remember that? Quick question, yes? Anyone remember that?
[02:32.040 --> 02:38.280]  Who thought that said Google.com? It didn't. It didn't say Google.com. You're wrong. You're
[02:38.280 --> 02:45.400]  crazy. It says Google.com. And actually, this was a real website that in the mid-2000s,
[02:45.400 --> 02:49.440]  you might accidentally visit when you were typing in Google.com into your browser. And
[02:49.440 --> 02:52.560]  if you did, I can see some nodding here. I can see some people might know about this
[02:52.560 --> 02:56.720]  website. But what would happen is it would do a drive-by download of malware onto your
[02:56.720 --> 03:01.280]  machine and it would basically screw over your machine. So this was like one of the
[03:01.280 --> 03:05.520]  really prominent examples in the early 2000s of typosquatting, where just making one typo
[03:05.520 --> 03:09.000]  would absolutely destroy you. So actually, what's really nice is I managed to get some
[03:09.000 --> 03:14.160]  archive footage of a machine being infected with the Google.com malware. And I'll show
[03:14.200 --> 03:18.840]  it to you now. So here's the machine, and here it is after malware has actually infected
[03:18.840 --> 03:28.240]  it. I'm just going to drink some water because I'm a millennial. So what are we going to
[03:28.240 --> 03:31.680]  talk about today? Well, hopefully we're not going to run on because I see panic looks
[03:31.680 --> 03:35.200]  over there from Hugo. Thank you very much. So in this talk, we're going to talk about
[03:35.200 --> 03:39.360]  malware, as you might expect at this point, given the very obvious foreshadowing. We're
[03:39.360 --> 03:43.080]  also going to talk about how it gets onto your machine from Pi Pi. We're going to talk
[03:43.120 --> 03:47.680]  about how it gets made to look legitimate. We're going to talk about how it works, and
[03:47.680 --> 03:53.080]  we're going to talk about how we can protect ourselves from malware. As you can see now,
[03:53.080 --> 03:56.280]  because I'm reading my presenter view, not the actual view, and that's the issue there.
[03:56.280 --> 04:01.280]  So does that sound good to everybody who's here? Open question. I'm seeing, hey, more
[04:01.280 --> 04:07.920]  of that, more energy. I love it. So I feel like there's been some really very smart people
[04:07.920 --> 04:11.400]  giving talks, and I'm not that. So I'm just hyping you up. That's my job. I'm like that
[04:11.480 --> 04:14.480]  guy in the back. He's like, come on, guys, let's get going. Right. That's me. Okay. So
[04:14.480 --> 04:19.280]  right. Quick disclaimer. First of all, I'm a freaking idiot, as you've now learned. More
[04:19.280 --> 04:23.600]  importantly, malware evolves and it changes. A lot of stuff happens here. A lot of stuff
[04:23.600 --> 04:27.080]  goes on. And what I'm going to show you today is kind of currently what I'm seeing. I'm
[04:27.080 --> 04:30.600]  reading a lot of research kind of blogs and stuff, you know, from really smart people.
[04:30.600 --> 04:35.960]  But this is the kind of way that I'm the malware I'll show you works in the way that it's kind
[04:35.960 --> 04:39.080]  of currently working, but that will not be the same in a year's time or two years time.
[04:39.280 --> 04:43.240]  This stuff is going to evolve and it's going to change as bad actors get better at dealing
[04:43.240 --> 04:48.000]  with malware or hiding the malware. Also, I am not a security professional. I'm just
[04:48.000 --> 04:51.280]  a guy. I just walk up here. They just let me. I haven't even registered for this thing.
[04:51.280 --> 04:56.200]  I just showed up and it was like, yeah, sure, we got a slot. Right. So essentially, you
[04:56.200 --> 04:59.960]  know, I, what I'm saying is the stuff that I found through my own research, but please
[04:59.960 --> 05:05.720]  don't, you know, please don't yourself try and necessarily like take what I say as gospel
[05:05.800 --> 05:08.960]  because I'm learning and sharing what I know. Is that cool? Is that cool with you?
[05:10.640 --> 05:16.040]  I love it. Okay. If we're cool with that, then I'd like to show you an image I generated
[05:16.040 --> 05:19.760]  with Dali because it's cute as heck. That's the only reason I included it. It's just really
[05:19.760 --> 05:23.920]  cute. Look at that little face. Look at those eyes. You got 50% hit rate on eyes, which
[05:23.920 --> 05:28.880]  is why he's only showed one on there. But let's see. So the cost of malware, this is
[05:28.880 --> 05:34.160]  important because this is big business, right? Malware is big business. So the question,
[05:34.200 --> 05:37.760]  first of all, so these things came from these stats I'm about to show you. They came from
[05:37.760 --> 05:41.960]  a research study that was done by the Poneman Research Institute last year. They studied
[05:41.960 --> 05:46.720]  550 organizations. I've got to walk. I'm gonna walk. I studied 550 organizations that have
[05:46.720 --> 05:51.120]  been infected with malware and how they dealt with that. And they basically shared their
[05:51.120 --> 05:54.840]  findings. Right. So the question here, first of all, this is a genuine question. Shout
[05:54.840 --> 05:58.400]  out. What do you think the average cost of it was a data, of a data breach was for those
[05:58.400 --> 06:05.400]  organizations? Anybody? Shout at me. 100,000. Keep going. 300,000. Keep going. 500,000.
[06:06.240 --> 06:13.360]  Keep going. Say that again. A million. Keep going. I had 5 million sold to the gentleman
[06:13.360 --> 06:20.160]  in the red shirt. So 4.35 million was the average cost of a data breach on PyPy. So
[06:20.160 --> 06:23.200]  that was not true. It's just a free breach in those organizations. I just did a spin
[06:23.200 --> 06:26.680]  and distracted myself. It's the blood flow. So another question here. This is slightly
[06:26.720 --> 06:31.360]  more relevant to our talk today is what percentage of breaches were caused by compromised credentials?
[06:31.360 --> 06:35.480]  And I don't mean phishing scams. I mean some malware scraping your credentials and actually
[06:35.480 --> 06:42.600]  then using those credentials to infect a network. What percentage? 70. A little lower.
[06:42.600 --> 06:49.440]  95. A little lower. 3. Slightly high. Okay. You know what? We can play this all day. I'll
[06:49.440 --> 06:53.960]  show you. It's 19%. So about one in five breaches were caused by this exact thing. I love your
[06:54.000 --> 06:58.480]  enthusiasm as well. Dig it. Right. And back here so the people, if anybody is watching
[06:58.480 --> 07:03.480]  this, can see me. But the question really I'd like us to think about is what does this mean?
[07:03.480 --> 07:10.880]  Thanks. That was my water break. And I'll tell you what I think it means is that developers
[07:10.880 --> 07:14.960]  are now a target for this type of malware, right? Developers are a real target. And actually
[07:14.960 --> 07:19.680]  there's two reasons that a malware actor might want to target a developer. Hello, new people.
[07:19.800 --> 07:24.680]  Welcome. There's two reasons. The first one is obviously because developers are installing
[07:24.680 --> 07:27.760]  something they've got, you know, they're going to have stuff on their machine to exploit,
[07:27.760 --> 07:31.160]  but also because those developers might make software for end users and we might be able
[07:31.160 --> 07:36.560]  to screw them as well, right? That's awesome. For the malware. It's not good for us. I'm
[07:36.560 --> 07:41.920]  just enthusiastic. I don't love crime. There's the first of all, let's talk about remote
[07:41.920 --> 07:45.840]  code execution. So this is kind of the gold standard. If a bad actor gets onto your machine,
[07:45.840 --> 07:49.080]  they execute some code on there, what can they do? Well, we've talked about prudential
[07:49.080 --> 07:53.600]  stealing, but also ransomware, also things like crypto mining and actually also crypto
[07:53.600 --> 07:57.720]  diversion. I saw a piece of malware recently that would actually siphon off payments that
[07:57.720 --> 08:01.400]  are supposed to go to your Bitcoin or Ethereum wallet and would actually just put it to a
[08:01.400 --> 08:05.560]  different wallet address and put it to the attacker's wallet. So there's some quite interesting
[08:05.560 --> 08:09.680]  use cases for this, unfortunately. Again, I don't love crime. But what's important there
[08:09.680 --> 08:13.440]  is that you can be a target as a developer, but also your end users can be targeted. So
[08:13.440 --> 08:18.640]  if you make software that's important that someone's using, you might download a dependency
[08:18.640 --> 08:22.840]  that behaves as expected, except for the fact that it includes some vulnerabilities. And
[08:22.840 --> 08:27.240]  that means that your users could be vulnerable, but alternatively, it could use outdated versions
[08:27.240 --> 08:32.840]  of dependencies itself or an outdated version of the package. That means that essentially
[08:32.840 --> 08:36.480]  your users will be vulnerable as well because it hasn't, for example, received updates or
[08:36.480 --> 08:40.320]  if there's a CVE that's come out, say, look, here's a threat advisory, we need to patch
[08:40.400 --> 08:44.000]  this, you won't get that patch. So these kinds of things can be done to actually get your
[08:44.000 --> 08:48.880]  end users as well. Does that make sense? Good, because this is the most dramatic slide I
[08:48.880 --> 08:52.800]  put in, or one of them, which is this, Python developers beware. I'd like to set the scene
[08:52.800 --> 08:56.920]  for you here. It's a stormy night, it's a castle in Romania, a man in ragged clothes
[08:56.920 --> 09:00.720]  is running, he's running away from the castle, bats chasing after him, he hears the howling
[09:00.720 --> 09:04.320]  of wolves in the distance, and then lightning flashes, and he says, stay away, he screams
[09:04.400 --> 09:11.200]  with wild eyes, stay away from the Python package index. I didn't rehearse that, I'm
[09:11.200 --> 09:20.200]  kind of proud, actually. That went pretty well. Okay, so right, PyPy is what we're talking
[09:20.200 --> 09:24.440]  about today, because whilst it's awesome, and I don't really think you should stay away,
[09:24.440 --> 09:28.000]  it's an awesome way to get our dependencies right. I couldn't live without this thing,
[09:28.000 --> 09:32.240]  well, I could literally live, but I couldn't do my work without this thing. So I want to
[09:32.280 --> 09:37.600]  talk to you about why maybe it's not the safest place in the world in certain contexts. So
[09:37.600 --> 09:42.640]  the first thing is that if we talk about typosquatting, that's if you mistype something, you misremember
[09:42.640 --> 09:46.800]  something, you put it in wrong, this is the case, for example, with goggle.com, where a
[09:46.800 --> 09:51.640]  user would type it in wrong and get screwed over, they'd get that malware on their machine.
[09:51.640 --> 09:56.040]  But the same exists with PyPy, because if you type in pip install and then a package,
[09:56.040 --> 09:59.080]  if you type that wrong, it doesn't check, it doesn't say, oh, did you mean request?
[09:59.080 --> 10:03.520]  It says, okay, yeah, I'll install ASDFJ. You know, that's fine too. So as long as that
[10:03.520 --> 10:08.480]  package exists, you will get it. And that can be concerning. So quick question here, what
[10:08.480 --> 10:12.280]  percentage of PyPy packages are estimated to actually potentially be using a typosquatting
[10:12.280 --> 10:21.440]  technique? Five, that's a good number. Any other guesses? 40, 20. 42, very specific, I
[10:21.440 --> 10:33.440]  love it. 41.9. About 3%. So a lot closer this time. You redeemed yourself, I respect it.
[10:33.440 --> 10:38.040]  So yeah, basically, a little smaller. But still, there's millions of packages on there.
[10:38.040 --> 10:44.160]  So this is a big ass number. This is a big old number. Right. So the next question, this
[10:44.160 --> 10:49.240]  is maybe relevant to us now, is what percentage of PyPy downloads are estimated to be of typosquatting
[10:49.240 --> 10:53.600]  packages? So in percent, how many times does someone download something? They maybe didn't
[10:53.600 --> 11:07.080]  mean to. 10%. Okay. 2%. 4%. Sold. So 0.5 is about the right answer. So again, we're getting
[11:07.080 --> 11:10.960]  some people who, I just thought, yes, and I respect that as well. I love the enthusiasm
[11:10.960 --> 11:18.600]  that we're generating here. That's really the content. You guys are the product, right?
[11:18.600 --> 11:23.400]  So yeah, but 0.5 is not much, but it's 1 in 200. And if you think about how many millions
[11:23.400 --> 11:28.040]  of things are downloaded from PyPy every day, that's a big deal. That's a really big number.
[11:28.040 --> 11:37.280]  Easy photo, good. Let's talk about types of squats. In fact, this is a typosquat of typosquat,
[11:37.280 --> 11:41.720]  which is a pun, and I'm so proud of it, I didn't sleep all night. Types of squats that
[11:41.720 --> 11:45.680]  you can get. So misspelling, pretty obvious. You mean to type something, you hit the wrong
[11:45.680 --> 11:49.520]  button, something goes wrong. For example, these are all real typosquats from the request
[11:49.520 --> 11:55.200]  module. We all know the request module, I hope, I assume. You send HTTP requests, awesome.
[11:55.200 --> 12:02.720]  Well, you might send requests, or requests, or equests, any of those, and those are real
[12:02.720 --> 12:08.160]  actual pieces of malware that were found on PyPy. So if you had mistyped, they would
[12:08.160 --> 12:15.240]  be on your machine, which isn't ideal for you. There's another type, which is confusion
[12:15.240 --> 12:19.640]  typosquats, where the user misremembers the name of the package, and there may be some
[12:19.640 --> 12:23.640]  separate confusion or order in confusion, for example, easy install, maybe there's an underscore,
[12:23.640 --> 12:27.440]  maybe there's a hyphen, maybe there's nothing, maybe it's install easy, who knows. So in
[12:27.440 --> 12:33.120]  this case, you might end up with some malware, but there's also version in confusion, where
[12:33.120 --> 12:38.920]  basically you think, oh, this is a certain version, or maybe beautiful Super 4, BS4, that's
[12:38.920 --> 12:44.280]  the kind of thing where BS4, I never scraped before, sure. So there are some examples where
[12:44.320 --> 12:48.320]  you wouldn't actually want, you know, you'd want to basically consider these different
[12:48.320 --> 12:52.560]  versions. So for example, this is a real piece of malware that I saw on PyPy, request three,
[12:52.560 --> 12:56.160]  you might think, oh, a beta version of version three of requests, yeah, yeah, okay, I'll
[12:56.160 --> 13:00.760]  get that, I'll get that, that's good stuff. Do not do that, do not do that, get the request
[13:00.760 --> 13:07.480]  module. Right, let's play a little game, because apparently all we do now is audience participation.
[13:07.480 --> 13:13.400]  So which of these is the malware? Choose now, top one or bottom one, hands up for top one,
[13:13.440 --> 13:20.080]  hands up for the bottom one, heck yeah, damn right. Okay, another one here, libkill or PyKill,
[13:20.080 --> 13:26.080]  which is the malware, this is a Python package, which is the Python package? Top one? Bottom
[13:26.080 --> 13:32.320]  one? Top one, a really split on that one. So I think the confusion there is because libkill
[13:32.320 --> 13:36.640]  is the actual package that PyKill calls, that's the system package, but actually the actual
[13:36.640 --> 13:40.280]  Python package is called PyKill, and that's why if you would guess wrong, it's really
[13:40.320 --> 13:44.840]  sensible that you might guess libkill, but it's actually malware. So once you've got some
[13:44.840 --> 13:51.520]  malware, how does it look legit? So one way is that you can have dependencies where basically
[13:51.520 --> 13:55.480]  you have a package itself that is innocent, doesn't do anything bad, but it includes a
[13:55.480 --> 14:00.280]  package as a dependency that is malicious, and in this situation you might have the original
[14:00.280 --> 14:05.040]  package behaving as normal, but actually that's just to avoid suspicion, but the actual second
[14:05.040 --> 14:09.400]  package is the malware, and we'll see an example of that very soon, and we'll see a live example
[14:09.440 --> 14:15.000]  depending on how good the Wi-Fi isn't here. So it's also malicious commits over time, and
[14:15.000 --> 14:20.960]  this is another real attack vector. This is not so based on typoscotting, this is based
[14:20.960 --> 14:26.120]  on other elements of trust and abuse. So first of all, the project might be safe, nothing
[14:26.120 --> 14:30.200]  wrong with it, but then builds up a user base, it's a useful package, people start to use
[14:30.200 --> 14:34.920]  it, and eventually maybe malware gets at it, and this was the case with a package called
[14:34.920 --> 14:39.240]  FastAPI Toolkit, so if we've heard of FastAPI, there was a Toolkit package which was adding
[14:39.280 --> 14:45.240]  some useful stuff, and the Toolkit package eventually, in version 0.27, actually added
[14:45.240 --> 14:48.760]  some malware, which has now been rolled back, but as I'll show you later, that doesn't mean
[14:48.760 --> 14:55.560]  you don't get that malware. I heard it, oh, yeah. It got me, it shot me to my core, it
[14:55.560 --> 15:01.280]  shot me to the very depths of my soul. I've gone very Manchester all of a sudden. Right,
[15:01.280 --> 15:05.880]  the other way this thing can work, come in, come in, join us, join us, move that way,
[15:05.960 --> 15:11.000]  the shift left principle. Okay, so the other way this can work is that a repo might get
[15:11.000 --> 15:16.640]  a new maintainer, so somebody who starts to contribute to the repo in a useful way, and
[15:16.640 --> 15:19.560]  they say, hey, can I just get some admin access, I want to maintain this repo, I want to take
[15:19.560 --> 15:24.600]  something over. Okay, awesome, sure. Oh, no, this person added malware, what a surprise,
[15:24.600 --> 15:28.960]  what a coincidence. And this is a genuine and real thing that does happen. Now, I want
[15:28.960 --> 15:31.640]  to drink some more water, so I'm going to show you a pretty slide with a cute snake
[15:31.640 --> 15:35.120]  on it. It's nudge hacking, look at the cute snake, he hypnotized by it while I drink
[15:35.160 --> 15:42.600]  this water. Sick, thank you. Right, have we heard of starjacking, is that something
[15:42.600 --> 15:47.160]  that we're familiar with as a term? Shaking heads, okay, perfect, 10 minutes left, really?
[15:47.160 --> 15:51.600]  Oh, no, okay, we're going to be hauling, okay, right. Starjacking, what is it? I'll tell
[15:51.600 --> 15:56.880]  you what it is. On Pipi, they don't verify the URL that you give as the project URL,
[15:56.880 --> 16:01.480]  and that means you can exploit that. So, quick one here, I'll tell you the answer, we don't
[16:01.520 --> 16:06.760]  have time. Request tool belt or tool belt request, one of these is an actual tooling
[16:06.760 --> 16:10.200]  package for request, it's the top one, the bottom one is malware, how do I know? Because
[16:10.200 --> 16:14.160]  I made it, and it's on Pipi, that's how I know. But we can see here if we look at the
[16:14.160 --> 16:19.240]  page on Pipi, look at these stars, look at them, I've got 900 stars, I only did it yesterday,
[16:19.240 --> 16:22.200]  I'm that popular, and you can see this is a real thing, so if you go and check out a
[16:22.200 --> 16:26.760]  package, you can get screwed this way. So think about it, when you look at this, right, it's
[16:26.840 --> 16:31.800]  a real problem. Okay, right, we are pushing for time, so I'll say a typical chain of events
[16:31.800 --> 16:35.520]  that happens, the user installs a dodgy package that's been typosquoted or another way is
[16:35.520 --> 16:41.640]  confused, it depends on a malicious one, that package runs, it decodes some basic c4 encoded
[16:41.640 --> 16:46.240]  code, which actually then downloads some true malware from a remote server, okay, the upshot
[16:46.240 --> 16:51.760]  of it is very sad snake, hello, the upshot of it is very sad snake. So, let's show an
[16:51.760 --> 16:55.040]  example, that's what we're here for, we want to see my machine get screwed, that's why
[16:55.120 --> 16:58.080]  we're here, that's why we're all in this talk, that's why I've got a full room, right, yeah,
[16:58.080 --> 17:04.800]  yeah, yeah, come on boys, yeah, everybody, so, right, I said I worked for this company,
[17:04.800 --> 17:08.400]  right, and I maintain this particular SDK, you can look at it if you want, I just put
[17:08.400 --> 17:11.720]  the QR code in again because they pay for my flight, right, that's why I did that, you
[17:11.720 --> 17:14.920]  can scan it if you want, but the reason my colleague didn't trust me earlier is because
[17:14.920 --> 17:19.160]  I made a version of this called not the Vonage Python SDK, I didn't want to make it too obviously
[17:19.160 --> 17:23.320]  typo-able because I'd actually don't want someone downloading this, but this is a real
[17:23.360 --> 17:27.400]  package, I uploaded, you can see it looks similar, it has the same number of stars as
[17:27.400 --> 17:32.400]  the actual package, so again, it looks pretty legit, but I want to show you what happens
[17:32.400 --> 17:37.480]  if you download that, so that's the plan, see, just to summarize, we got these two packages
[17:37.480 --> 17:41.400]  here that I've uploaded to PyPy, as of yesterday, I had to make a fake account because they
[17:41.400 --> 17:46.680]  deleted my first set, that's not a joke, I didn't get to go to this conference because
[17:46.680 --> 17:52.360]  I was redoing my malware, so anyway, the point is here, I've got these two packages and what
[17:52.400 --> 17:57.160]  I want to do, show you what happens when you run them, can you, nope, I've got a, oh dear,
[17:57.160 --> 18:00.880]  we're going to have a problem, I'm going to drag you over there, which I think, does it
[18:00.880 --> 18:06.040]  think I'm here, it does, great, there's a thing, all righty, so we can see here, this
[18:06.040 --> 18:11.720]  is going to be very difficult to manage, essentially this is my Python SDK, and we can see here
[18:11.720 --> 18:15.240]  with the setup py, it's normal, except for the fact here, it includes tool belt requests
[18:15.240 --> 18:18.840]  which is a new dependency that wasn't there before, and we can see in the client class
[18:18.880 --> 18:23.440]  here, I've got request util, this is a random function I've imported, it doesn't do anything,
[18:23.440 --> 18:26.840]  but what's important there is I've imported tool belt requests, can we all see that, is
[18:26.840 --> 18:32.360]  that big enough at the back? Great stuff, okay, awesome, so if I actually go and wear
[18:32.360 --> 18:36.880]  my mouse, I'll show you, this one on here, this is going to be quite a lot of dragging
[18:36.880 --> 18:42.440]  and clicking, this is my malware package, this is tool belt requests, and we can see
[18:42.440 --> 18:47.640]  here that this setup py looks normal, request util looks fine, nothing happens in here,
[18:47.760 --> 18:51.960]  but if we go to init py, again, looks normal, where's the malware, well, let's scroll over
[18:51.960 --> 18:59.120]  a little bit, shall we? And I say this, this is a legitimate technique that is used by
[18:59.120 --> 19:09.880]  bad actors, this is real. So, if we scroll over, what do we, oh look, a base 64 encoded,
[19:09.880 --> 19:16.960]  payload, what could this be, who knows? Right, so this is what we end up with, right, and
[19:17.040 --> 19:22.040]  what happens is this command will decode that, and then it will run it, and so because of
[19:22.040 --> 19:27.000]  the first package what we had was this import statement here, it will run as soon as we
[19:27.000 --> 19:30.360]  import the first package, and the reason for that is that actually in the init py file
[19:30.360 --> 19:34.440]  we've got this import of everything for clients, so basically when we import a package we believe
[19:34.440 --> 19:38.800]  is called Vonage, which inherently the module, the package itself is called Vonage still,
[19:38.800 --> 19:42.040]  so a user may not know that they've downloaded the wrong package at this point, you will
[19:42.080 --> 19:47.760]  download and install and then use and activate that malware. So, what's left to do, check
[19:47.760 --> 19:55.400]  off the malware, let's get some malware going, right, so I've got this up here, so I've used
[19:55.400 --> 20:01.160]  a blank one because I'm hoping we can download it live, so let's do that, can I track this
[20:01.160 --> 20:11.200]  while not looking, not the Vonage Python SDK, okay, Wi-Fi is working nice, okay, so this
[20:11.240 --> 20:18.600]  is a blank VN that I've got here, we can now see if I do a PIP list, we can see that I've
[20:18.600 --> 20:23.120]  got tool belt requests in here, which is my malware, and we can see here that I've got
[20:23.120 --> 20:28.800]  not the Vonage Python SDK, okay, so now if I open up a Python shell, cool, and if I actually
[20:28.800 --> 20:39.120]  import that what's going to happen? Import Vonage, what are we going to do? Oh wait a
[20:39.140 --> 20:42.600]  minute, it's done it on my off, this demo would have been so cool if I just mirrored
[20:42.600 --> 20:46.960]  my screens, where's my mouse? I'll show you what it did, I'll show you what it did, can
[20:46.960 --> 21:05.000]  I do that? No, I can't, I need to do it this way, I'll show you right now, all righty,
[21:05.000 --> 21:08.440]  so that's what I want to show you for now with that, but because we don't have much time,
[21:08.480 --> 21:11.120]  I'm going to actually tell you, now I've spent most of my time telling you what screws you
[21:11.120 --> 21:14.960]  up, I'm now going to tell you how you can protect yourself a little bit, so thank you
[21:14.960 --> 21:19.920]  Mr. Astley for your once again, your dedicated service, it actually won't play because the
[21:19.920 --> 21:28.400]  Wi-Fi is not fast enough, but you can imagine it in your head if you want. So right, now
[21:28.400 --> 21:32.000]  we're back here, let's talk about protecting ourselves, right, again, adorable snake, that's
[21:32.000 --> 21:38.200]  my water break, snake for the break, okay, so as maintainers, if you maintain a package
[21:38.200 --> 21:41.960]  and you don't want your users to get the wrong thing like me, what can you do? Well, your
[21:41.960 --> 21:46.360]  dependencies might become compromised, right, so you need to think about how you can look
[21:46.360 --> 21:50.240]  for those compromises and deal with those, so this is the case where maybe, you know,
[21:50.240 --> 21:53.720]  a package like fast API toolkit becomes malicious over time or there's some vulnerability that's
[21:53.720 --> 21:57.720]  discovered, in that case, automated scanning tools can help you, right, five minutes left,
[21:57.720 --> 22:01.720]  okay, no worries, we got this, we're a team, I appreciate you giving me a little more,
[22:01.720 --> 22:06.880]  I like that, okay, so, right, so first of all, you know, there are things to use, we
[22:06.920 --> 22:11.240]  use this, we give these guys an awful lot of money, so if you want to do the same, please
[22:11.240 --> 22:15.880]  feel free, I guess, I'm not sponsored by them, there's also dependable, there's other services
[22:15.880 --> 22:20.600]  basically that will scan your repos and just check, see if there's any malware or any CVs
[22:20.600 --> 22:25.840]  that might, you know, provide vulnerabilities, also as maintainers, another cute snake, you
[22:25.840 --> 22:30.120]  might want to consider defensively typosquatting, which is where you preemptively, you typosquat
[22:30.120 --> 22:33.920]  your own stuff, like I did there with not the Vonage Python SDK, you might do that yourself
[22:33.960 --> 22:38.320]  with your own package, you might give something like similar typos or confusions, you might
[22:38.320 --> 22:50.320]  want to make those yourself, and, oh, now it plays, huh, okay, by the way, I actually turned
[22:50.320 --> 23:08.120]  off, I actually don't know what that's up, wow, okay, wow, I did not think it would go
[23:08.120 --> 23:13.160]  like this, this is my second proper talk, right, so when we are preemptively typosquatting,
[23:13.160 --> 23:17.400]  that means you can save the packages that you're dealing with, right, so there was a
[23:17.480 --> 23:21.080]  person, William Bengston, who actually decided to take some of this into his own hands, and
[23:21.080 --> 23:26.360]  he typosquatted a thousand packages, and he actually, in two years, they got over 500,000
[23:26.360 --> 23:30.080]  downloads, which just shows how useful that technique was to stop those 500,000 dollars
[23:30.080 --> 23:35.600]  potentially going to malware, right, as package users, we've got other things we can do, the
[23:35.600 --> 23:39.920]  obvious one here, you know, if you type something in, you know, you're at risk, so you might
[23:39.920 --> 23:44.560]  want to look at how you do that, so what is obviously maybe a good practice is we're
[23:44.680 --> 23:47.200]  going to install from a file, so you can check what you've written, vet your dependences
[23:47.200 --> 23:52.760]  if you can, and again, you might want to use those automated scanning tools. Now, if you're
[23:52.760 --> 23:56.720]  using a mirror, you might want to check the latest safe version, and this is really important,
[23:56.720 --> 24:00.760]  because if you're using a mirror, what can actually happen? I'll give you the fast API
[24:00.760 --> 24:04.440]  example again, but basically, mirror sites, so for example, if you're in an enterprise
[24:04.440 --> 24:08.520]  and you download all your stuff, it's cached at a mirror site, you can end up in a situation
[24:08.520 --> 24:13.800]  where, for example, 0.27 is malware, 0.26 is not, when that was discovered, the whole
[24:13.880 --> 24:17.920]  thing, on PyPy, it went back to 0.26, but in the mirrors, they often configured so that
[24:17.920 --> 24:21.720]  they only take the latest version, and so in that case, you'd actually not get that
[24:21.720 --> 24:25.440]  safe version, it would keep the malware on your mirror, so just consider that as well
[24:25.440 --> 24:30.360]  if that is how you install stuff, so because I've got like two minutes left, I'm just going
[24:30.360 --> 24:36.280]  to sum up really quickly, so first of all, typosquatting on PyPy is a real attack vector,
[24:36.280 --> 24:41.800]  so benign packages that become malicious, as we've just said, so what you should do is
[24:41.840 --> 24:46.000]  vet your dependencies really carefully, and if you can, use automated vulnerability scanning
[24:46.000 --> 24:51.320]  tools, and if you really have to, you might want to consider defensive typosquatting, because
[24:51.320 --> 24:56.240]  that's a way to protect your users, but also, be careful when you're using mirrors, okay?
[24:56.240 --> 24:59.200]  So the final thing I just want to say, first of all, is never get security up, it will
[24:59.200 --> 25:05.200]  never let you down, run around, or even, and I quote, desert you. Thank you very much.
[25:11.800 --> 25:18.800]  Thank you, so just quickly, my, if you want to see the slides or any resources, they are
[25:24.720 --> 25:27.280]  there, and this is just the summary, because the other one wasn't super useful, if you
[25:27.280 --> 25:31.160]  want to tweet me and ask me questions, feel free, I'm an idiot, tweet me, it's fine, okay?
[25:31.160 --> 25:34.440]  That's me, if there is anything else, any questions, shout them out me, and I'll attempt
[25:34.440 --> 25:38.640]  to answer them.
[25:38.640 --> 25:45.640]  Thank you, Max. I really want to install your SDK. I haven't seen that video enough.
