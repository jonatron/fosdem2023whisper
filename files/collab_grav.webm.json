{"text": " Hello, everyone. My name is Andrea. I am a product specialist for documentation at Agen, and I'm happy to be here today to share about how we use graph for our documentation both internally and externally. I used to be a technical writer for more than five years, and before that I used to be a research scientist. But enough about me. Let's look a little bit into Agen, the company that I work for, so we can better understand the needs for documentation internally and externally. Agen is a financial technology platform, which has seen a lot of growth since its inception back in 2007. These days we are over 2,000 employees of more than 100 nationalities across the world in 26 offices. In development, we use write and maintain open-source software. And to keep all of this together, we have internal hubs for knowledge sharing and externally to build that confidence in the businesses that we work with and to help them integrate. We also have documentation for them. The team, doing documentation at Agen, the Docs at Agen team, now has around 30 people. This picture is a bit outdated, so a bit less than 30 people in there. It was taken back in November when we had an off-site to work on objectives for 2023. But getting back to the point, so about half of the Docs team is technical writers who work closely with the development teams to produce integration information that our clients use. And the other half is more product-focused. They look after our graph implementation and try and make it as user-focused as possible, where the users are both the people reading the documentation as well as the people writing the documentation. So we've got front-enders, back-enders, we've got automation engineers, we call them DocOps engineers. We've got product managers and designers working for us. And it would be a bit incomplete if we were to not mention all the contributors. So the external documentation are not open source, but they are inner-sourced, which means that our colleagues at Agen can contribute suggestions if they find something that they think is not quite right, or they have an idea of how to improve things. And the internal knowledge base is open for everyone to edit. And in the last four years, there have been over 3,000 people who have contributed to the internal knowledge base. Now, some of you might have been wondering what exactly is graph. It's an open-source flat file content management system. It's got a really big community around it, and it has consistently won some awards as a product. And for support with your graph implementation, there is also Trilby Media, a company of the people who have written graph. Graph itself is written in PHP. The content is in Markdown. You can also do templating using Twig. And its features are greatly extensible through its powerful API and package management. So some of you might have seen this talk from back in 2018 from Alexei. who was then talking about the migration to graph from Confluence. He was emphasizing how we chose graph because of the possibilities it offers in terms of collaboration, contribution, and extensibility. Other benefits were obviously it being open-source, which meant no fee per user, which used to be the model at the time with Confluence. It also allowed us to unify how we do documentation internally. So before migrating to graph, there were several CMSs serving various needs. The knowledge was quite fragmented. And switching to graph enabled us to create a go-to place for internal knowledge sharing. Also moving away from Confluence allowed us to have full control over the look and feel of the website, believe it or not. And I could hardly believe it when people were telling me that in order to customize the look and feel of the Confluence website, they had to modify the DOM using JavaScript. There was a very roundabout way of doing it. And also being able to fully customize both the end user experience and the writer experience, according to their needs, is a big plus that graph was bringing. Now, in terms of this talk, we're going to look at the graph implementation from a tech perspective, looking at how the code base is organized and what kind of quality assurance and customizability we do with it. We're also going to look at the implementation from a people perspective, all the different ways that people collaborate and create content using graph. We're going to talk about the collaboration with the open source project maintainers themselves. And then we're going to end looking into the crystal ball into what we expect or what we're looking forward to in terms of the future. Now, for the tech part, the really neat thing about graph is that it's possible to have a single code base that then enables several websites to be deployed. This is because we have the graph code base in a separate repo from the various content repositories. And then for each content repository, you can even have them deployed to several domains, according to their own specific domain base configuration file, which can even turn on and off various features depending on domain. For example, this happens, we use this for the external documentation, where we have two domains, we have an internal domain for staging environment and a public domain for the documentation that our clients use. Graph also supports both static and dynamic versions of a website. For public documentation, we always use static HTML websites for security reasons, but internally, so that users can immediately see the changes that they've saved, we do use the dynamic version of the website. So talking directly to the server. Graph also allows quite finely grained control of access to people, so you can restrict read write access based on user profile, or you can even do this outside of graph by putting a particular server instance behind a firewall. So to look at this visually, we have the one graph code base that then together with a content repository and domain config files will produce one website. And then from the same code base together with a different content repo and say a domain config file for dynamic websites will produce the dynamic website. And then to get a static website, for example, all you need to get a static website for the same content repo, all you need is a domain config file for the static version. And then you already take the single graph code base together with the content and produce the static website. In terms of quality assurance, our DocOps engineers are working hard to write tests. For example, we never publish broken links. That's because we have the broken link checker, which produces a report like what you see here, telling writers where the broken link is, so that it can go fix it. We also have security checks, so we have to be very careful for compliance reasons, what kind of card numbers we use, for example, in code samples. So this kind of check will always prevent people from publishing if the test fail. But there are, say, you know, less crucial things like maybe like small style checks or like small typos that we will not stop publishing for. People, writers still get the reports for this, and they will fix it, but it won't stop publishing. And one of the great strengths of Graph customization, this can be done at various levels. So first of all, the look and feel can be customized using various themes. As you can see here, two fairly different looking websites. We can establish various page templates where we see that there is recurring content of a certain shape. We also build custom components for the UI. So if we identify, for example, a component we built last year was for decision trees. So for example, for people doing tech support internally or for people trying to choose their particular online payments integration with Adien, they would need to either read a few pages or they could take this, like answer a few questions, and they'll get a recommended integration. So that kind of decision tree component is something that we built for Graph. And because we have a single code base that can work with several repos, that component can be enabled on various websites, so whichever ones need it. And then also another neat thing is the extensibility using plugins, which means that we can add new functionality in a modular way. We particularly use this for the internal knowledge base for Hub to create integrations with other tools we use internally. So for example, to allow colleagues to easily embed content from, say, the issue tracker or from the internal stack overflow, because like I said, we want Hub to be the go-to place for knowledge sharing internally, and therefore it needs to provide good connections to all the other tools that are used within the company. Now, all of this, of course, does not come without these challenges. The team has grown probably about five times because there was one developer when Alexey gave his talk in 2018. And we now have five developers working on the various projects. Part of getting here was defining and enforcing workflows so that everyone works consistently and predictably, which also helps, makes for easier troubleshooting. Another challenge that came with us having offices across the world meant that if the internal documentation was hosted in the Netherlands, our colleagues over in Australia or Singapore were having to wait quite a long time to see the content that they needed. And this came back as a pain point from the users. So we started deploying the internal documentation to service in APAC as well. So then we also had to deal with thinking changes across services worldwide. So we've done that one too. Right. Moving on to people and how they work together. And Graf does enable various ways of collaborating and managing content. And for this part, I'm going to look at the internal docs and the external docs in parallel so we can better see the various characteristics depending on how people collaborate and how they create content. So for the internal documentation, it's run wiki style, which means that anyone can make changes. People mostly make changes using the browser editor. We also accept poor requests, but relatively small percentage of people will raise a poor request. The internal documentation also has page and section owners visible at the top of the page so that people can easily find out who to contact if they have questions or if they spotted something wrong on the page. And our colleagues from development have also set up certain integrations with code repositories and internal tools to again facilitate this communication and knowledge sharing in one place. Now in terms of the external documentation, like I said, there is the group of technical writers who write and maintain the content. Now unlike Hub, unlike the people writing content for Hub, people writing docs mostly use their ID. They commit their markdown changes and push them to the remote. They will check the state of the docs locally and all of that. So in other words, they use a doc's code approach to creating and maintaining content. I kind of mentioned this before that we have a way for people to suggest changes internally. So we have a technical writer on duty every week who reviews changes coming from colleagues. Because there is this small group focusing on curating this content and they are quite, so like text-heavy-day tree documentation is code, there is a lot of reuse and parameterization in the external documentation trying to find that sweet spot, that balance between writing content in a scalable way, so reducing the maintenance burden but also without increasing the cognitive load for maintenance too much. But also an interesting thing that has, well, interesting thing that has happened since 2018 is that Agen as a company went from being a payments company to a financial technology platform. So this means that on the one hand, the payments products stayed, became, so like the bread and butter of what the company does and the basis for a lot of other products. And those products had more and more releases, so there have been iterations, several versions to document. But on the other hand, extending into financial products meant that a series of other new products were built which also needed documentation. So there has been a lot of content growth along both of these axes. So let's have a look at how the company growth has, is reflected in documentation as well. So in terms of internal documentation, we all use it, right? So the fact that the company has grown about three times since 2018 means that the audience has also grown just as much. The content itself has grown two and a half times. Last I checked with the product specialist for Hub, we had more than 12,000 pages. That is a lot of content. And those 12,000 pages have been written by over 3,000 people in the last four years. Yeah, I was quite surprised when I first saw these numbers. Now for the external documentation, the audience has also increased even more than the internal one. So this is another aspect of how company growth can be seen in docs analytics. The amount of content we have in the docs has also increased undoubtedly with all the new versions, all the new products. But somehow in a more controlled, curated way. And maybe when we look at the challenges in the next slides, it might become more apparent why the growth for external documentation has been a bit more controlled. And of course, definitely worth mentioning that more than 350 colleagues have suggested changes in the last three and a bit years because the suggest changes flow is a bit more recent. So we get on average 100 people a year making suggestions and that is very, very valuable to us because with thousands of pages of documentation, the help that we get from people suggesting changes is invaluable. And now let's look at the challenges that come with the growth in number of people and growth in content. So again, looking at hub, the internal documentation, or the last four years I've taught us is that we need to have a good strategy for content ownership long term because time passes and people come, people go, but the content remains. And there needs to be a plan in place for what happens to that who becomes responsible for it. There's also the issue of broken links. So I was saying earlier that in the external documentation, we never publish a broken link. And that is true. But with internal documentation, we don't have that kind of flow in place because the editing flow is also different. And we are looking into possible ways that we can let people know when links that they have in sections that they own are broken. This normally happens when other parts of the internal documentation that they refer to have been restructured, pages have been removed or reorganized. So yeah, that's definitely something we're looking into. Also, empowering people to write good content is important and making them feel responsible for the content that they've written because writing the content is not enough. It's great that they have written it. But this mindset that once you've written something, you're responsible for it is something that we need to work on a bit more. Now, in terms of the external documentation, one of the pain points that we see from feedback is that it's easy to pull out of sync with other platforms that we have. So for example, documentation versus the marketing website or versus the internal documentation. And this is because the same information is maintained manually by different people. Needing to scale complex content means that we need to have some way of having the same information being shown everywhere, offering a consistent experience in terms of navigation and things like that. We already have ideas for how to tackle this. I'm going to defer this to the last section about the future. Something else that we get is I was saying with the passing of time, several software versions, we find that users do ask for older versions. So versioning is something that we're also working on. Versioning for documentation. And that can be a whole separate talk in itself. So maybe see you next year. And as you might have seen, I've been avoiding the last point for both because finding relevant content quickly is a continuing challenge, especially in a climate of growth. And that is where search and information architecture have to be on point. And continuously iterating on that and seeing what works, what doesn't work for people is a core part. But then also looking at how to show people only the information that is relevant to them is something we're also exploring. Now, in terms of collaboration with the open source community, we have a direct relationship with the graph project maintainers. We've sponsored building certain plugins, which we have then open sourced. So some plugins are for our own internal use because they are very business case specific. But we've also collaborated on plugins that we've then open sourced. And we also contribute bug fixes to the code repository. Moving on to look at the future, I'm only going to look at the biggest challenge that I am very excited about tackling, which is scaling consistently across all the platforms that we have. And now that I'm looking at this diagram, it kind of looks a bit like a present, doesn't it? With a hat. So this inconsistency that I was saying, we're starting to see between the different platforms, not all of which are running on graph. We want to create a single source of truth. And the interface for inputting the information for the single source of truth is probably also going to be an instance of graph using the same one code base that I was mentioning at the beginning. So this is for the kind of information that cannot be generated automatically from code. So this is not for things like API reference. This is for things like emerging properties of various features. So something that is not just a flag in the code. This is something that the product teams will be responsible for. And having using graph for this means that they'll be able to have the same familiar user experience when inputting information about their product as well. So then in the future, other systems, whether they're running graph or not, will be able to use the same information that will be accurately rendered in all these different portals. So maybe see you in another four years to tell you how this one went. So let's move on to the Q&A session. Thank you for your attention and see you in a bit. Okay, so thank you. I think that we have so we just have a couple of minutes for questions. And then in three minutes, we'll get into the next talk. So if you have any questions, don't hesitate to put it in the chat. In three minutes, we'll get into the next talk. Yeah, I did put a question. Me, Andrea, the speaker, have put a question in my own talk. Because I was wondering, I was curious how many people would already be familiar and with graph because me, like myself, I only found out about it when I started my current job. So, yeah, I was just curious within the community if there are people who use it, but it seems that it's, well, at least amongst the people here is not that well-known. Indeed, on Mayan, at least I didn't know about it. Since we started talking about it at first I think it was one or two years ago, but it's nice to see that it's also evolving. Yeah, there has been one. Yeah, sorry, there is a bit of a quarrel, I think. Yeah, I'm not sure which stream to mute. Should one of us maybe read the question that was asked in the chat? So, the question from Mungal, is there any integration with ECM CSP products to include documents and preview on the website? I can see that NextCloud is provided, but only for backup purposes. Yeah, so, like I said, we do use NextCloud, but we don't embed it in the internal knowledge base per se. So, for any need to access that, we link out. I'm pretty sure part of the reason for that is because some NextCloud files have restricted access and having this double layer of access restriction was seemed a bit unnecessary, but I don't think we've had requests for it either. Cool, so, I think that no, if anyone wants to ask some questions, we have the room that we are discussing in, which is now open. So, I guess that you can take questions here. On my end, I will switch to the next talk for the dev room. So, thanks a lot, Andrea, for coming and thanks for your presentation. It should be online on the website very soon, if I'm not mistaken. Yeah, thanks for having me. I'll see you around. Thank you. Bye. Bye. you", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 13.56, "text": " Hello, everyone. My name is Andrea. I am a product specialist for documentation at Agen,", "tokens": [50364, 2425, 11, 1518, 13, 1222, 1315, 307, 24215, 13, 286, 669, 257, 1674, 17008, 337, 14333, 412, 316, 1766, 11, 51042], "temperature": 0.0, "avg_logprob": -0.21160520613193512, "compression_ratio": 1.4943181818181819, "no_speech_prob": 0.02558339573442936}, {"id": 1, "seek": 0, "start": 13.56, "end": 21.48, "text": " and I'm happy to be here today to share about how we use graph for our documentation both", "tokens": [51042, 293, 286, 478, 2055, 281, 312, 510, 965, 281, 2073, 466, 577, 321, 764, 4295, 337, 527, 14333, 1293, 51438], "temperature": 0.0, "avg_logprob": -0.21160520613193512, "compression_ratio": 1.4943181818181819, "no_speech_prob": 0.02558339573442936}, {"id": 2, "seek": 0, "start": 21.48, "end": 27.84, "text": " internally and externally. I used to be a technical writer for more than five years,", "tokens": [51438, 19501, 293, 40899, 13, 286, 1143, 281, 312, 257, 6191, 9936, 337, 544, 813, 1732, 924, 11, 51756], "temperature": 0.0, "avg_logprob": -0.21160520613193512, "compression_ratio": 1.4943181818181819, "no_speech_prob": 0.02558339573442936}, {"id": 3, "seek": 2784, "start": 27.84, "end": 34.44, "text": " and before that I used to be a research scientist. But enough about me. Let's look a little bit", "tokens": [50364, 293, 949, 300, 286, 1143, 281, 312, 257, 2132, 12662, 13, 583, 1547, 466, 385, 13, 961, 311, 574, 257, 707, 857, 50694], "temperature": 0.0, "avg_logprob": -0.15438505736264316, "compression_ratio": 1.5061728395061729, "no_speech_prob": 0.001732510980218649}, {"id": 4, "seek": 2784, "start": 34.44, "end": 42.56, "text": " into Agen, the company that I work for, so we can better understand the needs for documentation", "tokens": [50694, 666, 316, 1766, 11, 264, 2237, 300, 286, 589, 337, 11, 370, 321, 393, 1101, 1223, 264, 2203, 337, 14333, 51100], "temperature": 0.0, "avg_logprob": -0.15438505736264316, "compression_ratio": 1.5061728395061729, "no_speech_prob": 0.001732510980218649}, {"id": 5, "seek": 2784, "start": 42.56, "end": 50.519999999999996, "text": " internally and externally. Agen is a financial technology platform, which has seen a lot", "tokens": [51100, 19501, 293, 40899, 13, 316, 1766, 307, 257, 4669, 2899, 3663, 11, 597, 575, 1612, 257, 688, 51498], "temperature": 0.0, "avg_logprob": -0.15438505736264316, "compression_ratio": 1.5061728395061729, "no_speech_prob": 0.001732510980218649}, {"id": 6, "seek": 2784, "start": 50.519999999999996, "end": 57.0, "text": " of growth since its inception back in 2007. These days we are over 2,000 employees of", "tokens": [51498, 295, 4599, 1670, 1080, 49834, 646, 294, 12656, 13, 1981, 1708, 321, 366, 670, 568, 11, 1360, 6619, 295, 51822], "temperature": 0.0, "avg_logprob": -0.15438505736264316, "compression_ratio": 1.5061728395061729, "no_speech_prob": 0.001732510980218649}, {"id": 7, "seek": 5700, "start": 57.0, "end": 65.92, "text": " more than 100 nationalities across the world in 26 offices. In development, we use write", "tokens": [50364, 544, 813, 2319, 4048, 1088, 2108, 264, 1002, 294, 7551, 14434, 13, 682, 3250, 11, 321, 764, 2464, 50810], "temperature": 0.0, "avg_logprob": -0.19479294146521617, "compression_ratio": 1.435483870967742, "no_speech_prob": 0.0014867193531244993}, {"id": 8, "seek": 5700, "start": 65.92, "end": 77.32, "text": " and maintain open-source software. And to keep all of this together, we have internal hubs", "tokens": [50810, 293, 6909, 1269, 12, 41676, 4722, 13, 400, 281, 1066, 439, 295, 341, 1214, 11, 321, 362, 6920, 46870, 51380], "temperature": 0.0, "avg_logprob": -0.19479294146521617, "compression_ratio": 1.435483870967742, "no_speech_prob": 0.0014867193531244993}, {"id": 9, "seek": 5700, "start": 77.32, "end": 83.36, "text": " for knowledge sharing and externally to build that confidence in the businesses that we", "tokens": [51380, 337, 3601, 5414, 293, 40899, 281, 1322, 300, 6687, 294, 264, 6011, 300, 321, 51682], "temperature": 0.0, "avg_logprob": -0.19479294146521617, "compression_ratio": 1.435483870967742, "no_speech_prob": 0.0014867193531244993}, {"id": 10, "seek": 8336, "start": 83.36, "end": 90.44, "text": " work with and to help them integrate. We also have documentation for them. The team,", "tokens": [50364, 589, 365, 293, 281, 854, 552, 13365, 13, 492, 611, 362, 14333, 337, 552, 13, 440, 1469, 11, 50718], "temperature": 0.0, "avg_logprob": -0.1683046523838827, "compression_ratio": 1.4866310160427807, "no_speech_prob": 0.0037147135008126497}, {"id": 11, "seek": 8336, "start": 90.44, "end": 97.72, "text": " doing documentation at Agen, the Docs at Agen team, now has around 30 people. This picture is a bit", "tokens": [50718, 884, 14333, 412, 316, 1766, 11, 264, 16024, 82, 412, 316, 1766, 1469, 11, 586, 575, 926, 2217, 561, 13, 639, 3036, 307, 257, 857, 51082], "temperature": 0.0, "avg_logprob": -0.1683046523838827, "compression_ratio": 1.4866310160427807, "no_speech_prob": 0.0037147135008126497}, {"id": 12, "seek": 8336, "start": 97.72, "end": 105.68, "text": " outdated, so a bit less than 30 people in there. It was taken back in November when we had an", "tokens": [51082, 36313, 11, 370, 257, 857, 1570, 813, 2217, 561, 294, 456, 13, 467, 390, 2726, 646, 294, 7674, 562, 321, 632, 364, 51480], "temperature": 0.0, "avg_logprob": -0.1683046523838827, "compression_ratio": 1.4866310160427807, "no_speech_prob": 0.0037147135008126497}, {"id": 13, "seek": 10568, "start": 105.68, "end": 114.08000000000001, "text": " off-site to work on objectives for 2023. But getting back to the point, so about half of the", "tokens": [50364, 766, 12, 30417, 281, 589, 322, 15961, 337, 44377, 13, 583, 1242, 646, 281, 264, 935, 11, 370, 466, 1922, 295, 264, 50784], "temperature": 0.0, "avg_logprob": -0.20813626509446365, "compression_ratio": 1.4639175257731958, "no_speech_prob": 0.008369950577616692}, {"id": 14, "seek": 10568, "start": 114.08000000000001, "end": 122.76, "text": " Docs team is technical writers who work closely with the development teams to produce integration", "tokens": [50784, 16024, 82, 1469, 307, 6191, 13491, 567, 589, 8185, 365, 264, 3250, 5491, 281, 5258, 10980, 51218], "temperature": 0.0, "avg_logprob": -0.20813626509446365, "compression_ratio": 1.4639175257731958, "no_speech_prob": 0.008369950577616692}, {"id": 15, "seek": 10568, "start": 122.76, "end": 135.64000000000001, "text": " information that our clients use. And the other half is more product-focused. They look after", "tokens": [51218, 1589, 300, 527, 6982, 764, 13, 400, 264, 661, 1922, 307, 544, 1674, 12, 44062, 13, 814, 574, 934, 51862], "temperature": 0.0, "avg_logprob": -0.20813626509446365, "compression_ratio": 1.4639175257731958, "no_speech_prob": 0.008369950577616692}, {"id": 16, "seek": 13564, "start": 136.48, "end": 147.95999999999998, "text": " our graph implementation and try and make it as user-focused as possible, where the users are", "tokens": [50406, 527, 4295, 11420, 293, 853, 293, 652, 309, 382, 4195, 12, 44062, 382, 1944, 11, 689, 264, 5022, 366, 50980], "temperature": 0.0, "avg_logprob": -0.1711253045310437, "compression_ratio": 1.713450292397661, "no_speech_prob": 0.0009426003671251237}, {"id": 17, "seek": 13564, "start": 147.95999999999998, "end": 154.04, "text": " both the people reading the documentation as well as the people writing the documentation. So we've", "tokens": [50980, 1293, 264, 561, 3760, 264, 14333, 382, 731, 382, 264, 561, 3579, 264, 14333, 13, 407, 321, 600, 51284], "temperature": 0.0, "avg_logprob": -0.1711253045310437, "compression_ratio": 1.713450292397661, "no_speech_prob": 0.0009426003671251237}, {"id": 18, "seek": 13564, "start": 154.04, "end": 160.79999999999998, "text": " got front-enders, back-enders, we've got automation engineers, we call them DocOps engineers. We've", "tokens": [51284, 658, 1868, 12, 521, 433, 11, 646, 12, 521, 433, 11, 321, 600, 658, 17769, 11955, 11, 321, 818, 552, 16024, 36179, 11955, 13, 492, 600, 51622], "temperature": 0.0, "avg_logprob": -0.1711253045310437, "compression_ratio": 1.713450292397661, "no_speech_prob": 0.0009426003671251237}, {"id": 19, "seek": 16080, "start": 160.84, "end": 170.88000000000002, "text": " got product managers and designers working for us. And it would be a bit incomplete if we were to not", "tokens": [50366, 658, 1674, 14084, 293, 16196, 1364, 337, 505, 13, 400, 309, 576, 312, 257, 857, 31709, 498, 321, 645, 281, 406, 50868], "temperature": 0.0, "avg_logprob": -0.1150869456204501, "compression_ratio": 1.5343915343915344, "no_speech_prob": 0.0009771169861778617}, {"id": 20, "seek": 16080, "start": 170.88000000000002, "end": 178.08, "text": " mention all the contributors. So the external documentation are not open source, but they are", "tokens": [50868, 2152, 439, 264, 45627, 13, 407, 264, 8320, 14333, 366, 406, 1269, 4009, 11, 457, 436, 366, 51228], "temperature": 0.0, "avg_logprob": -0.1150869456204501, "compression_ratio": 1.5343915343915344, "no_speech_prob": 0.0009771169861778617}, {"id": 21, "seek": 16080, "start": 178.08, "end": 185.96, "text": " inner-sourced, which means that our colleagues at Agen can contribute suggestions if they find", "tokens": [51228, 7284, 12, 82, 396, 1232, 11, 597, 1355, 300, 527, 7734, 412, 316, 1766, 393, 10586, 13396, 498, 436, 915, 51622], "temperature": 0.0, "avg_logprob": -0.1150869456204501, "compression_ratio": 1.5343915343915344, "no_speech_prob": 0.0009771169861778617}, {"id": 22, "seek": 18596, "start": 185.96, "end": 191.6, "text": " something that they think is not quite right, or they have an idea of how to improve things. And the", "tokens": [50364, 746, 300, 436, 519, 307, 406, 1596, 558, 11, 420, 436, 362, 364, 1558, 295, 577, 281, 3470, 721, 13, 400, 264, 50646], "temperature": 0.0, "avg_logprob": -0.13598671365291515, "compression_ratio": 1.6680672268907564, "no_speech_prob": 0.0009758525411598384}, {"id": 23, "seek": 18596, "start": 191.6, "end": 198.8, "text": " internal knowledge base is open for everyone to edit. And in the last four years, there have been", "tokens": [50646, 6920, 3601, 3096, 307, 1269, 337, 1518, 281, 8129, 13, 400, 294, 264, 1036, 1451, 924, 11, 456, 362, 668, 51006], "temperature": 0.0, "avg_logprob": -0.13598671365291515, "compression_ratio": 1.6680672268907564, "no_speech_prob": 0.0009758525411598384}, {"id": 24, "seek": 18596, "start": 198.8, "end": 207.56, "text": " over 3,000 people who have contributed to the internal knowledge base. Now, some of you might have", "tokens": [51006, 670, 805, 11, 1360, 561, 567, 362, 18434, 281, 264, 6920, 3601, 3096, 13, 823, 11, 512, 295, 291, 1062, 362, 51444], "temperature": 0.0, "avg_logprob": -0.13598671365291515, "compression_ratio": 1.6680672268907564, "no_speech_prob": 0.0009758525411598384}, {"id": 25, "seek": 18596, "start": 207.56, "end": 213.64000000000001, "text": " been wondering what exactly is graph. It's an open-source flat file content management system. It's", "tokens": [51444, 668, 6359, 437, 2293, 307, 4295, 13, 467, 311, 364, 1269, 12, 41676, 4962, 3991, 2701, 4592, 1185, 13, 467, 311, 51748], "temperature": 0.0, "avg_logprob": -0.13598671365291515, "compression_ratio": 1.6680672268907564, "no_speech_prob": 0.0009758525411598384}, {"id": 26, "seek": 21364, "start": 213.67999999999998, "end": 227.11999999999998, "text": " got a really big community around it, and it has consistently won some awards as a product. And for", "tokens": [50366, 658, 257, 534, 955, 1768, 926, 309, 11, 293, 309, 575, 14961, 1582, 512, 15193, 382, 257, 1674, 13, 400, 337, 51038], "temperature": 0.0, "avg_logprob": -0.23713172750270112, "compression_ratio": 1.3448275862068966, "no_speech_prob": 0.002769492333754897}, {"id": 27, "seek": 21364, "start": 228.39999999999998, "end": 236.88, "text": " support with your graph implementation, there is also Trilby Media, a company of the people who", "tokens": [51102, 1406, 365, 428, 4295, 11420, 11, 456, 307, 611, 1765, 388, 2322, 14741, 11, 257, 2237, 295, 264, 561, 567, 51526], "temperature": 0.0, "avg_logprob": -0.23713172750270112, "compression_ratio": 1.3448275862068966, "no_speech_prob": 0.002769492333754897}, {"id": 28, "seek": 23688, "start": 236.92, "end": 246.2, "text": " have written graph. Graph itself is written in PHP. The content is in Markdown. You can also do", "tokens": [50366, 362, 3720, 4295, 13, 21884, 2564, 307, 3720, 294, 47298, 13, 440, 2701, 307, 294, 3934, 5093, 13, 509, 393, 611, 360, 50830], "temperature": 0.0, "avg_logprob": -0.17104346716581886, "compression_ratio": 1.381188118811881, "no_speech_prob": 0.0019479072652757168}, {"id": 29, "seek": 23688, "start": 246.2, "end": 253.51999999999998, "text": " templating using Twig. And its features are greatly extensible through its powerful API and", "tokens": [50830, 9100, 990, 1228, 2574, 328, 13, 400, 1080, 4122, 366, 14147, 1279, 30633, 807, 1080, 4005, 9362, 293, 51196], "temperature": 0.0, "avg_logprob": -0.17104346716581886, "compression_ratio": 1.381188118811881, "no_speech_prob": 0.0019479072652757168}, {"id": 30, "seek": 23688, "start": 253.51999999999998, "end": 266.36, "text": " package management. So some of you might have seen this talk from back in 2018 from Alexei.", "tokens": [51196, 7372, 4592, 13, 407, 512, 295, 291, 1062, 362, 1612, 341, 751, 490, 646, 294, 6096, 490, 5202, 17067, 13, 51838], "temperature": 0.0, "avg_logprob": -0.17104346716581886, "compression_ratio": 1.381188118811881, "no_speech_prob": 0.0019479072652757168}, {"id": 31, "seek": 26688, "start": 266.88, "end": 277.12, "text": " who was then talking about the migration to graph from Confluence. He was emphasizing how we chose", "tokens": [50364, 567, 390, 550, 1417, 466, 264, 17011, 281, 4295, 490, 11701, 40432, 13, 634, 390, 45550, 577, 321, 5111, 50876], "temperature": 0.0, "avg_logprob": -0.1694965816679455, "compression_ratio": 1.5106382978723405, "no_speech_prob": 0.0006990749388933182}, {"id": 32, "seek": 26688, "start": 277.12, "end": 282.28, "text": " graph because of the possibilities it offers in terms of collaboration, contribution, and", "tokens": [50876, 4295, 570, 295, 264, 12178, 309, 7736, 294, 2115, 295, 9363, 11, 13150, 11, 293, 51134], "temperature": 0.0, "avg_logprob": -0.1694965816679455, "compression_ratio": 1.5106382978723405, "no_speech_prob": 0.0006990749388933182}, {"id": 33, "seek": 26688, "start": 282.28, "end": 292.15999999999997, "text": " extensibility. Other benefits were obviously it being open-source, which meant no fee per user,", "tokens": [51134, 1279, 694, 2841, 13, 5358, 5311, 645, 2745, 309, 885, 1269, 12, 41676, 11, 597, 4140, 572, 12054, 680, 4195, 11, 51628], "temperature": 0.0, "avg_logprob": -0.1694965816679455, "compression_ratio": 1.5106382978723405, "no_speech_prob": 0.0006990749388933182}, {"id": 34, "seek": 29216, "start": 292.16, "end": 300.52000000000004, "text": " which used to be the model at the time with Confluence. It also allowed us to unify how we do", "tokens": [50364, 597, 1143, 281, 312, 264, 2316, 412, 264, 565, 365, 11701, 40432, 13, 467, 611, 4350, 505, 281, 517, 2505, 577, 321, 360, 50782], "temperature": 0.0, "avg_logprob": -0.1230883381583474, "compression_ratio": 1.6406926406926408, "no_speech_prob": 0.0015179244801402092}, {"id": 35, "seek": 29216, "start": 300.52000000000004, "end": 306.52000000000004, "text": " documentation internally. So before migrating to graph, there were several CMSs serving various", "tokens": [50782, 14333, 19501, 13, 407, 949, 6186, 8754, 281, 4295, 11, 456, 645, 2940, 33124, 82, 8148, 3683, 51082], "temperature": 0.0, "avg_logprob": -0.1230883381583474, "compression_ratio": 1.6406926406926408, "no_speech_prob": 0.0015179244801402092}, {"id": 36, "seek": 29216, "start": 306.52000000000004, "end": 313.08000000000004, "text": " needs. The knowledge was quite fragmented. And switching to graph enabled us to create a go-to", "tokens": [51082, 2203, 13, 440, 3601, 390, 1596, 9241, 14684, 13, 400, 16493, 281, 4295, 15172, 505, 281, 1884, 257, 352, 12, 1353, 51410], "temperature": 0.0, "avg_logprob": -0.1230883381583474, "compression_ratio": 1.6406926406926408, "no_speech_prob": 0.0015179244801402092}, {"id": 37, "seek": 29216, "start": 313.08000000000004, "end": 320.20000000000005, "text": " place for internal knowledge sharing. Also moving away from Confluence allowed us to have full", "tokens": [51410, 1081, 337, 6920, 3601, 5414, 13, 2743, 2684, 1314, 490, 11701, 40432, 4350, 505, 281, 362, 1577, 51766], "temperature": 0.0, "avg_logprob": -0.1230883381583474, "compression_ratio": 1.6406926406926408, "no_speech_prob": 0.0015179244801402092}, {"id": 38, "seek": 32020, "start": 320.24, "end": 324.03999999999996, "text": " control over the look and feel of the website, believe it or not. And I could hardly believe it", "tokens": [50366, 1969, 670, 264, 574, 293, 841, 295, 264, 3144, 11, 1697, 309, 420, 406, 13, 400, 286, 727, 13572, 1697, 309, 50556], "temperature": 0.0, "avg_logprob": -0.12176302976386491, "compression_ratio": 1.6502242152466369, "no_speech_prob": 0.0027880778070539236}, {"id": 39, "seek": 32020, "start": 324.03999999999996, "end": 329.52, "text": " when people were telling me that in order to customize the look and feel of the Confluence", "tokens": [50556, 562, 561, 645, 3585, 385, 300, 294, 1668, 281, 19734, 264, 574, 293, 841, 295, 264, 11701, 40432, 50830], "temperature": 0.0, "avg_logprob": -0.12176302976386491, "compression_ratio": 1.6502242152466369, "no_speech_prob": 0.0027880778070539236}, {"id": 40, "seek": 32020, "start": 329.52, "end": 334.24, "text": " website, they had to modify the DOM using JavaScript. There was a very roundabout way of", "tokens": [50830, 3144, 11, 436, 632, 281, 16927, 264, 35727, 1228, 15778, 13, 821, 390, 257, 588, 3098, 21970, 636, 295, 51066], "temperature": 0.0, "avg_logprob": -0.12176302976386491, "compression_ratio": 1.6502242152466369, "no_speech_prob": 0.0027880778070539236}, {"id": 41, "seek": 32020, "start": 334.24, "end": 347.56, "text": " doing it. And also being able to fully customize both the end user experience and the writer", "tokens": [51066, 884, 309, 13, 400, 611, 885, 1075, 281, 4498, 19734, 1293, 264, 917, 4195, 1752, 293, 264, 9936, 51732], "temperature": 0.0, "avg_logprob": -0.12176302976386491, "compression_ratio": 1.6502242152466369, "no_speech_prob": 0.0027880778070539236}, {"id": 42, "seek": 34756, "start": 347.56, "end": 357.32, "text": " experience, according to their needs, is a big plus that graph was bringing. Now, in terms of", "tokens": [50364, 1752, 11, 4650, 281, 641, 2203, 11, 307, 257, 955, 1804, 300, 4295, 390, 5062, 13, 823, 11, 294, 2115, 295, 50852], "temperature": 0.0, "avg_logprob": -0.1817784598379424, "compression_ratio": 1.4973262032085561, "no_speech_prob": 0.0010446005035191774}, {"id": 43, "seek": 34756, "start": 357.32, "end": 362.48, "text": " this talk, we're going to look at the graph implementation from a tech perspective, looking", "tokens": [50852, 341, 751, 11, 321, 434, 516, 281, 574, 412, 264, 4295, 11420, 490, 257, 7553, 4585, 11, 1237, 51110], "temperature": 0.0, "avg_logprob": -0.1817784598379424, "compression_ratio": 1.4973262032085561, "no_speech_prob": 0.0010446005035191774}, {"id": 44, "seek": 34756, "start": 362.48, "end": 371.28, "text": " at how the code base is organized and what kind of quality assurance and customizability we do", "tokens": [51110, 412, 577, 264, 3089, 3096, 307, 9983, 293, 437, 733, 295, 3125, 32189, 293, 2375, 590, 2310, 321, 360, 51550], "temperature": 0.0, "avg_logprob": -0.1817784598379424, "compression_ratio": 1.4973262032085561, "no_speech_prob": 0.0010446005035191774}, {"id": 45, "seek": 37128, "start": 371.84, "end": 377.52, "text": " with it. We're also going to look at the implementation from a people perspective, all the", "tokens": [50392, 365, 309, 13, 492, 434, 611, 516, 281, 574, 412, 264, 11420, 490, 257, 561, 4585, 11, 439, 264, 50676], "temperature": 0.0, "avg_logprob": -0.1490608396984282, "compression_ratio": 1.7264573991031391, "no_speech_prob": 0.014234306290745735}, {"id": 46, "seek": 37128, "start": 377.52, "end": 382.64, "text": " different ways that people collaborate and create content using graph. We're going to talk about", "tokens": [50676, 819, 2098, 300, 561, 18338, 293, 1884, 2701, 1228, 4295, 13, 492, 434, 516, 281, 751, 466, 50932], "temperature": 0.0, "avg_logprob": -0.1490608396984282, "compression_ratio": 1.7264573991031391, "no_speech_prob": 0.014234306290745735}, {"id": 47, "seek": 37128, "start": 383.44, "end": 388.79999999999995, "text": " the collaboration with the open source project maintainers themselves. And then we're going to end", "tokens": [50972, 264, 9363, 365, 264, 1269, 4009, 1716, 6909, 433, 2969, 13, 400, 550, 321, 434, 516, 281, 917, 51240], "temperature": 0.0, "avg_logprob": -0.1490608396984282, "compression_ratio": 1.7264573991031391, "no_speech_prob": 0.014234306290745735}, {"id": 48, "seek": 37128, "start": 389.84, "end": 396.64, "text": " looking into the crystal ball into what we expect or what we're looking forward to in terms of the", "tokens": [51292, 1237, 666, 264, 13662, 2594, 666, 437, 321, 2066, 420, 437, 321, 434, 1237, 2128, 281, 294, 2115, 295, 264, 51632], "temperature": 0.0, "avg_logprob": -0.1490608396984282, "compression_ratio": 1.7264573991031391, "no_speech_prob": 0.014234306290745735}, {"id": 49, "seek": 39664, "start": 396.64, "end": 409.12, "text": " future. Now, for the tech part, the really neat thing about graph is that it's possible to have a", "tokens": [50364, 2027, 13, 823, 11, 337, 264, 7553, 644, 11, 264, 534, 10654, 551, 466, 4295, 307, 300, 309, 311, 1944, 281, 362, 257, 50988], "temperature": 0.0, "avg_logprob": -0.12931434144365025, "compression_ratio": 1.3884892086330936, "no_speech_prob": 0.0010629245080053806}, {"id": 50, "seek": 39664, "start": 409.12, "end": 420.56, "text": " single code base that then enables several websites to be deployed. This is because we have the", "tokens": [50988, 2167, 3089, 3096, 300, 550, 17077, 2940, 12891, 281, 312, 17826, 13, 639, 307, 570, 321, 362, 264, 51560], "temperature": 0.0, "avg_logprob": -0.12931434144365025, "compression_ratio": 1.3884892086330936, "no_speech_prob": 0.0010629245080053806}, {"id": 51, "seek": 42056, "start": 420.96, "end": 426.96, "text": " graph code base in a separate repo from the various content repositories. And then for each content", "tokens": [50384, 4295, 3089, 3096, 294, 257, 4994, 49040, 490, 264, 3683, 2701, 22283, 2083, 13, 400, 550, 337, 1184, 2701, 50684], "temperature": 0.0, "avg_logprob": -0.18698504992893764, "compression_ratio": 1.7280701754385965, "no_speech_prob": 0.0010967443231493235}, {"id": 52, "seek": 42056, "start": 426.96, "end": 434.4, "text": " repository, you can even have them deployed to several domains, according to their own specific", "tokens": [50684, 25841, 11, 291, 393, 754, 362, 552, 17826, 281, 2940, 25514, 11, 4650, 281, 641, 1065, 2685, 51056], "temperature": 0.0, "avg_logprob": -0.18698504992893764, "compression_ratio": 1.7280701754385965, "no_speech_prob": 0.0010967443231493235}, {"id": 53, "seek": 42056, "start": 434.4, "end": 439.28, "text": " domain base configuration file, which can even turn on and off various features depending on domain.", "tokens": [51056, 9274, 3096, 11694, 3991, 11, 597, 393, 754, 1261, 322, 293, 766, 3683, 4122, 5413, 322, 9274, 13, 51300], "temperature": 0.0, "avg_logprob": -0.18698504992893764, "compression_ratio": 1.7280701754385965, "no_speech_prob": 0.0010967443231493235}, {"id": 54, "seek": 42056, "start": 440.96, "end": 449.28, "text": " For example, this happens, we use this for the external documentation, where we have two domains,", "tokens": [51384, 1171, 1365, 11, 341, 2314, 11, 321, 764, 341, 337, 264, 8320, 14333, 11, 689, 321, 362, 732, 25514, 11, 51800], "temperature": 0.0, "avg_logprob": -0.18698504992893764, "compression_ratio": 1.7280701754385965, "no_speech_prob": 0.0010967443231493235}, {"id": 55, "seek": 44928, "start": 449.28, "end": 455.35999999999996, "text": " we have an internal domain for staging environment and a public domain for the", "tokens": [50364, 321, 362, 364, 6920, 9274, 337, 41085, 2823, 293, 257, 1908, 9274, 337, 264, 50668], "temperature": 0.0, "avg_logprob": -0.10474791350188078, "compression_ratio": 1.543859649122807, "no_speech_prob": 0.0005927203455939889}, {"id": 56, "seek": 44928, "start": 455.35999999999996, "end": 464.88, "text": " documentation that our clients use. Graph also supports both static and dynamic versions of a", "tokens": [50668, 14333, 300, 527, 6982, 764, 13, 21884, 611, 9346, 1293, 13437, 293, 8546, 9606, 295, 257, 51144], "temperature": 0.0, "avg_logprob": -0.10474791350188078, "compression_ratio": 1.543859649122807, "no_speech_prob": 0.0005927203455939889}, {"id": 57, "seek": 44928, "start": 464.88, "end": 471.11999999999995, "text": " website. For public documentation, we always use static HTML websites for security reasons,", "tokens": [51144, 3144, 13, 1171, 1908, 14333, 11, 321, 1009, 764, 13437, 17995, 12891, 337, 3825, 4112, 11, 51456], "temperature": 0.0, "avg_logprob": -0.10474791350188078, "compression_ratio": 1.543859649122807, "no_speech_prob": 0.0005927203455939889}, {"id": 58, "seek": 47112, "start": 472.08, "end": 482.32, "text": " but internally, so that users can immediately see the changes that they've saved,", "tokens": [50412, 457, 19501, 11, 370, 300, 5022, 393, 4258, 536, 264, 2962, 300, 436, 600, 6624, 11, 50924], "temperature": 0.0, "avg_logprob": -0.16813301217967067, "compression_ratio": 1.4619883040935673, "no_speech_prob": 0.000645008753053844}, {"id": 59, "seek": 47112, "start": 482.32, "end": 488.72, "text": " we do use the dynamic version of the website. So talking directly to the server.", "tokens": [50924, 321, 360, 764, 264, 8546, 3037, 295, 264, 3144, 13, 407, 1417, 3838, 281, 264, 7154, 13, 51244], "temperature": 0.0, "avg_logprob": -0.16813301217967067, "compression_ratio": 1.4619883040935673, "no_speech_prob": 0.000645008753053844}, {"id": 60, "seek": 47112, "start": 490.16, "end": 497.36, "text": " Graph also allows quite finely grained control of access to people, so you can restrict", "tokens": [51316, 21884, 611, 4045, 1596, 31529, 1295, 2001, 1969, 295, 2105, 281, 561, 11, 370, 291, 393, 7694, 51676], "temperature": 0.0, "avg_logprob": -0.16813301217967067, "compression_ratio": 1.4619883040935673, "no_speech_prob": 0.000645008753053844}, {"id": 61, "seek": 49736, "start": 498.0, "end": 504.24, "text": " read write access based on user profile, or you can even do this outside of graph by putting a", "tokens": [50396, 1401, 2464, 2105, 2361, 322, 4195, 7964, 11, 420, 291, 393, 754, 360, 341, 2380, 295, 4295, 538, 3372, 257, 50708], "temperature": 0.0, "avg_logprob": -0.1144461711247762, "compression_ratio": 1.5, "no_speech_prob": 0.000560436979867518}, {"id": 62, "seek": 49736, "start": 504.24, "end": 514.16, "text": " particular server instance behind a firewall. So to look at this visually, we have the one", "tokens": [50708, 1729, 7154, 5197, 2261, 257, 36109, 13, 407, 281, 574, 412, 341, 19622, 11, 321, 362, 264, 472, 51204], "temperature": 0.0, "avg_logprob": -0.1144461711247762, "compression_ratio": 1.5, "no_speech_prob": 0.000560436979867518}, {"id": 63, "seek": 49736, "start": 514.16, "end": 520.24, "text": " graph code base that then together with a content repository and domain config files", "tokens": [51204, 4295, 3089, 3096, 300, 550, 1214, 365, 257, 2701, 25841, 293, 9274, 6662, 7098, 51508], "temperature": 0.0, "avg_logprob": -0.1144461711247762, "compression_ratio": 1.5, "no_speech_prob": 0.000560436979867518}, {"id": 64, "seek": 52024, "start": 521.04, "end": 529.28, "text": " will produce one website. And then from the same code base together with a different content repo", "tokens": [50404, 486, 5258, 472, 3144, 13, 400, 550, 490, 264, 912, 3089, 3096, 1214, 365, 257, 819, 2701, 49040, 50816], "temperature": 0.0, "avg_logprob": -0.14801958740734664, "compression_ratio": 1.769736842105263, "no_speech_prob": 0.0021208508405834436}, {"id": 65, "seek": 52024, "start": 529.28, "end": 534.96, "text": " and say a domain config file for dynamic websites will produce the dynamic website.", "tokens": [50816, 293, 584, 257, 9274, 6662, 3991, 337, 8546, 12891, 486, 5258, 264, 8546, 3144, 13, 51100], "temperature": 0.0, "avg_logprob": -0.14801958740734664, "compression_ratio": 1.769736842105263, "no_speech_prob": 0.0021208508405834436}, {"id": 66, "seek": 52024, "start": 536.96, "end": 543.28, "text": " And then to get a static website, for example, all you need to get a static website for", "tokens": [51200, 400, 550, 281, 483, 257, 13437, 3144, 11, 337, 1365, 11, 439, 291, 643, 281, 483, 257, 13437, 3144, 337, 51516], "temperature": 0.0, "avg_logprob": -0.14801958740734664, "compression_ratio": 1.769736842105263, "no_speech_prob": 0.0021208508405834436}, {"id": 67, "seek": 54328, "start": 544.24, "end": 550.16, "text": " the same content repo, all you need is a domain config file for the static version.", "tokens": [50412, 264, 912, 2701, 49040, 11, 439, 291, 643, 307, 257, 9274, 6662, 3991, 337, 264, 13437, 3037, 13, 50708], "temperature": 0.0, "avg_logprob": -0.12748548292344616, "compression_ratio": 1.4919786096256684, "no_speech_prob": 0.0002593243552837521}, {"id": 68, "seek": 54328, "start": 550.8, "end": 559.92, "text": " And then you already take the single graph code base together with the content and produce the", "tokens": [50740, 400, 550, 291, 1217, 747, 264, 2167, 4295, 3089, 3096, 1214, 365, 264, 2701, 293, 5258, 264, 51196], "temperature": 0.0, "avg_logprob": -0.12748548292344616, "compression_ratio": 1.4919786096256684, "no_speech_prob": 0.0002593243552837521}, {"id": 69, "seek": 54328, "start": 559.92, "end": 571.8399999999999, "text": " static website. In terms of quality assurance, our DocOps engineers are working hard to write tests.", "tokens": [51196, 13437, 3144, 13, 682, 2115, 295, 3125, 32189, 11, 527, 16024, 36179, 11955, 366, 1364, 1152, 281, 2464, 6921, 13, 51792], "temperature": 0.0, "avg_logprob": -0.12748548292344616, "compression_ratio": 1.4919786096256684, "no_speech_prob": 0.0002593243552837521}, {"id": 70, "seek": 57328, "start": 573.28, "end": 578.0, "text": " For example, we never publish broken links. That's because we have the broken link checker,", "tokens": [50364, 1171, 1365, 11, 321, 1128, 11374, 5463, 6123, 13, 663, 311, 570, 321, 362, 264, 5463, 2113, 1520, 260, 11, 50600], "temperature": 0.0, "avg_logprob": -0.11878094889900902, "compression_ratio": 1.6435185185185186, "no_speech_prob": 0.000532624195329845}, {"id": 71, "seek": 57328, "start": 578.0, "end": 583.8399999999999, "text": " which produces a report like what you see here, telling writers where the broken link is,", "tokens": [50600, 597, 14725, 257, 2275, 411, 437, 291, 536, 510, 11, 3585, 13491, 689, 264, 5463, 2113, 307, 11, 50892], "temperature": 0.0, "avg_logprob": -0.11878094889900902, "compression_ratio": 1.6435185185185186, "no_speech_prob": 0.000532624195329845}, {"id": 72, "seek": 57328, "start": 584.4, "end": 590.16, "text": " so that it can go fix it. We also have security checks, so we have to be very careful", "tokens": [50920, 370, 300, 309, 393, 352, 3191, 309, 13, 492, 611, 362, 3825, 13834, 11, 370, 321, 362, 281, 312, 588, 5026, 51208], "temperature": 0.0, "avg_logprob": -0.11878094889900902, "compression_ratio": 1.6435185185185186, "no_speech_prob": 0.000532624195329845}, {"id": 73, "seek": 57328, "start": 591.52, "end": 597.92, "text": " for compliance reasons, what kind of card numbers we use, for example, in code samples.", "tokens": [51276, 337, 15882, 4112, 11, 437, 733, 295, 2920, 3547, 321, 764, 11, 337, 1365, 11, 294, 3089, 10938, 13, 51596], "temperature": 0.0, "avg_logprob": -0.11878094889900902, "compression_ratio": 1.6435185185185186, "no_speech_prob": 0.000532624195329845}, {"id": 74, "seek": 59792, "start": 598.64, "end": 607.1999999999999, "text": " So this kind of check will always prevent people from publishing if the test fail.", "tokens": [50400, 407, 341, 733, 295, 1520, 486, 1009, 4871, 561, 490, 17832, 498, 264, 1500, 3061, 13, 50828], "temperature": 0.0, "avg_logprob": -0.2929058983212426, "compression_ratio": 1.5433526011560694, "no_speech_prob": 0.002275259466841817}, {"id": 75, "seek": 59792, "start": 607.1999999999999, "end": 616.88, "text": " But there are, say, you know, less crucial things like maybe like small style checks or", "tokens": [50828, 583, 456, 366, 11, 584, 11, 291, 458, 11, 1570, 11462, 721, 411, 1310, 411, 1359, 3758, 13834, 420, 51312], "temperature": 0.0, "avg_logprob": -0.2929058983212426, "compression_ratio": 1.5433526011560694, "no_speech_prob": 0.002275259466841817}, {"id": 76, "seek": 59792, "start": 616.88, "end": 624.24, "text": " like small typos that we will not stop publishing for. People, writers still get the reports for", "tokens": [51312, 411, 1359, 2125, 329, 300, 321, 486, 406, 1590, 17832, 337, 13, 3432, 11, 13491, 920, 483, 264, 7122, 337, 51680], "temperature": 0.0, "avg_logprob": -0.2929058983212426, "compression_ratio": 1.5433526011560694, "no_speech_prob": 0.002275259466841817}, {"id": 77, "seek": 62424, "start": 624.96, "end": 628.8, "text": " this, and they will fix it, but it won't stop publishing.", "tokens": [50400, 341, 11, 293, 436, 486, 3191, 309, 11, 457, 309, 1582, 380, 1590, 17832, 13, 50592], "temperature": 0.0, "avg_logprob": -0.13031872510910034, "compression_ratio": 1.5924170616113744, "no_speech_prob": 0.0005668072844855487}, {"id": 78, "seek": 62424, "start": 631.92, "end": 639.28, "text": " And one of the great strengths of Graph customization, this can be done at various levels.", "tokens": [50748, 400, 472, 295, 264, 869, 16986, 295, 21884, 39387, 11, 341, 393, 312, 1096, 412, 3683, 4358, 13, 51116], "temperature": 0.0, "avg_logprob": -0.13031872510910034, "compression_ratio": 1.5924170616113744, "no_speech_prob": 0.0005668072844855487}, {"id": 79, "seek": 62424, "start": 639.28, "end": 645.04, "text": " So first of all, the look and feel can be customized using various themes. As you can see here,", "tokens": [51116, 407, 700, 295, 439, 11, 264, 574, 293, 841, 393, 312, 30581, 1228, 3683, 13544, 13, 1018, 291, 393, 536, 510, 11, 51404], "temperature": 0.0, "avg_logprob": -0.13031872510910034, "compression_ratio": 1.5924170616113744, "no_speech_prob": 0.0005668072844855487}, {"id": 80, "seek": 62424, "start": 645.04, "end": 653.52, "text": " two fairly different looking websites. We can establish various page templates where we see", "tokens": [51404, 732, 6457, 819, 1237, 12891, 13, 492, 393, 8327, 3683, 3028, 21165, 689, 321, 536, 51828], "temperature": 0.0, "avg_logprob": -0.13031872510910034, "compression_ratio": 1.5924170616113744, "no_speech_prob": 0.0005668072844855487}, {"id": 81, "seek": 65352, "start": 653.52, "end": 664.8, "text": " that there is recurring content of a certain shape. We also build custom components for the UI.", "tokens": [50364, 300, 456, 307, 32279, 2701, 295, 257, 1629, 3909, 13, 492, 611, 1322, 2375, 6677, 337, 264, 15682, 13, 50928], "temperature": 0.0, "avg_logprob": -0.10785179788416083, "compression_ratio": 1.368421052631579, "no_speech_prob": 0.0004415060393512249}, {"id": 82, "seek": 65352, "start": 665.52, "end": 673.76, "text": " So if we identify, for example, a component we built last year was for decision trees.", "tokens": [50964, 407, 498, 321, 5876, 11, 337, 1365, 11, 257, 6542, 321, 3094, 1036, 1064, 390, 337, 3537, 5852, 13, 51376], "temperature": 0.0, "avg_logprob": -0.10785179788416083, "compression_ratio": 1.368421052631579, "no_speech_prob": 0.0004415060393512249}, {"id": 83, "seek": 67376, "start": 673.76, "end": 684.16, "text": " So for example, for people doing tech support internally or for people trying to choose their", "tokens": [50364, 407, 337, 1365, 11, 337, 561, 884, 7553, 1406, 19501, 420, 337, 561, 1382, 281, 2826, 641, 50884], "temperature": 0.0, "avg_logprob": -0.18464374542236328, "compression_ratio": 1.5485714285714285, "no_speech_prob": 0.0017991909990087152}, {"id": 84, "seek": 67376, "start": 684.16, "end": 690.4, "text": " particular online payments integration with Adien, they would need to either read a few", "tokens": [50884, 1729, 2950, 14348, 10980, 365, 1999, 1053, 11, 436, 576, 643, 281, 2139, 1401, 257, 1326, 51196], "temperature": 0.0, "avg_logprob": -0.18464374542236328, "compression_ratio": 1.5485714285714285, "no_speech_prob": 0.0017991909990087152}, {"id": 85, "seek": 67376, "start": 690.4, "end": 696.16, "text": " pages or they could take this, like answer a few questions, and they'll get a recommended", "tokens": [51196, 7183, 420, 436, 727, 747, 341, 11, 411, 1867, 257, 1326, 1651, 11, 293, 436, 603, 483, 257, 9628, 51484], "temperature": 0.0, "avg_logprob": -0.18464374542236328, "compression_ratio": 1.5485714285714285, "no_speech_prob": 0.0017991909990087152}, {"id": 86, "seek": 69616, "start": 696.16, "end": 704.24, "text": " integration. So that kind of decision tree component is something that we built for Graph.", "tokens": [50364, 10980, 13, 407, 300, 733, 295, 3537, 4230, 6542, 307, 746, 300, 321, 3094, 337, 21884, 13, 50768], "temperature": 0.0, "avg_logprob": -0.11394907877995418, "compression_ratio": 1.6172248803827751, "no_speech_prob": 0.0013223818968981504}, {"id": 87, "seek": 69616, "start": 705.12, "end": 708.3199999999999, "text": " And because we have a single code base that can work with several repos,", "tokens": [50812, 400, 570, 321, 362, 257, 2167, 3089, 3096, 300, 393, 589, 365, 2940, 1085, 329, 11, 50972], "temperature": 0.0, "avg_logprob": -0.11394907877995418, "compression_ratio": 1.6172248803827751, "no_speech_prob": 0.0013223818968981504}, {"id": 88, "seek": 69616, "start": 709.92, "end": 715.4399999999999, "text": " that component can be enabled on various websites, so whichever ones need it.", "tokens": [51052, 300, 6542, 393, 312, 15172, 322, 3683, 12891, 11, 370, 24123, 2306, 643, 309, 13, 51328], "temperature": 0.0, "avg_logprob": -0.11394907877995418, "compression_ratio": 1.6172248803827751, "no_speech_prob": 0.0013223818968981504}, {"id": 89, "seek": 69616, "start": 717.04, "end": 723.92, "text": " And then also another neat thing is the extensibility using plugins, which means that we can add", "tokens": [51408, 400, 550, 611, 1071, 10654, 551, 307, 264, 1279, 694, 2841, 1228, 33759, 11, 597, 1355, 300, 321, 393, 909, 51752], "temperature": 0.0, "avg_logprob": -0.11394907877995418, "compression_ratio": 1.6172248803827751, "no_speech_prob": 0.0013223818968981504}, {"id": 90, "seek": 72392, "start": 724.88, "end": 734.3199999999999, "text": " new functionality in a modular way. We particularly use this for the internal knowledge base for Hub", "tokens": [50412, 777, 14980, 294, 257, 31111, 636, 13, 492, 4098, 764, 341, 337, 264, 6920, 3601, 3096, 337, 18986, 50884], "temperature": 0.0, "avg_logprob": -0.0908258730365384, "compression_ratio": 1.548913043478261, "no_speech_prob": 0.0007105962140485644}, {"id": 91, "seek": 72392, "start": 736.7199999999999, "end": 743.28, "text": " to create integrations with other tools we use internally. So for example, to allow colleagues", "tokens": [51004, 281, 1884, 3572, 763, 365, 661, 3873, 321, 764, 19501, 13, 407, 337, 1365, 11, 281, 2089, 7734, 51332], "temperature": 0.0, "avg_logprob": -0.0908258730365384, "compression_ratio": 1.548913043478261, "no_speech_prob": 0.0007105962140485644}, {"id": 92, "seek": 72392, "start": 743.28, "end": 750.8, "text": " to easily embed content from, say, the issue tracker or from the internal stack overflow,", "tokens": [51332, 281, 3612, 12240, 2701, 490, 11, 584, 11, 264, 2734, 37516, 420, 490, 264, 6920, 8630, 37772, 11, 51708], "temperature": 0.0, "avg_logprob": -0.0908258730365384, "compression_ratio": 1.548913043478261, "no_speech_prob": 0.0007105962140485644}, {"id": 93, "seek": 75080, "start": 750.8, "end": 756.8, "text": " because like I said, we want Hub to be the go-to place for knowledge sharing internally,", "tokens": [50364, 570, 411, 286, 848, 11, 321, 528, 18986, 281, 312, 264, 352, 12, 1353, 1081, 337, 3601, 5414, 19501, 11, 50664], "temperature": 0.0, "avg_logprob": -0.10070136698280893, "compression_ratio": 1.5391304347826087, "no_speech_prob": 0.0003553815186023712}, {"id": 94, "seek": 75080, "start": 756.8, "end": 763.1999999999999, "text": " and therefore it needs to provide good connections to all the other tools that are used within the", "tokens": [50664, 293, 4412, 309, 2203, 281, 2893, 665, 9271, 281, 439, 264, 661, 3873, 300, 366, 1143, 1951, 264, 50984], "temperature": 0.0, "avg_logprob": -0.10070136698280893, "compression_ratio": 1.5391304347826087, "no_speech_prob": 0.0003553815186023712}, {"id": 95, "seek": 75080, "start": 763.1999999999999, "end": 768.4799999999999, "text": " company. Now, all of this, of course, does not come without these challenges.", "tokens": [50984, 2237, 13, 823, 11, 439, 295, 341, 11, 295, 1164, 11, 775, 406, 808, 1553, 613, 4759, 13, 51248], "temperature": 0.0, "avg_logprob": -0.10070136698280893, "compression_ratio": 1.5391304347826087, "no_speech_prob": 0.0003553815186023712}, {"id": 96, "seek": 75080, "start": 771.04, "end": 780.3199999999999, "text": " The team has grown probably about five times because there was one developer when Alexey", "tokens": [51376, 440, 1469, 575, 7709, 1391, 466, 1732, 1413, 570, 456, 390, 472, 10754, 562, 5202, 2030, 51840], "temperature": 0.0, "avg_logprob": -0.10070136698280893, "compression_ratio": 1.5391304347826087, "no_speech_prob": 0.0003553815186023712}, {"id": 97, "seek": 78032, "start": 780.32, "end": 791.2800000000001, "text": " gave his talk in 2018. And we now have five developers working on the various projects.", "tokens": [50364, 2729, 702, 751, 294, 6096, 13, 400, 321, 586, 362, 1732, 8849, 1364, 322, 264, 3683, 4455, 13, 50912], "temperature": 0.0, "avg_logprob": -0.09505281081566444, "compression_ratio": 1.3211678832116789, "no_speech_prob": 0.00034204122493974864}, {"id": 98, "seek": 78032, "start": 793.12, "end": 800.5600000000001, "text": " Part of getting here was defining and enforcing workflows so that everyone works consistently", "tokens": [51004, 4100, 295, 1242, 510, 390, 17827, 293, 25495, 2175, 43461, 370, 300, 1518, 1985, 14961, 51376], "temperature": 0.0, "avg_logprob": -0.09505281081566444, "compression_ratio": 1.3211678832116789, "no_speech_prob": 0.00034204122493974864}, {"id": 99, "seek": 80056, "start": 801.52, "end": 808.7199999999999, "text": " and predictably, which also helps, makes for easier troubleshooting.", "tokens": [50412, 293, 6069, 1188, 11, 597, 611, 3665, 11, 1669, 337, 3571, 15379, 47011, 13, 50772], "temperature": 0.0, "avg_logprob": -0.16087728617142658, "compression_ratio": 1.4259259259259258, "no_speech_prob": 0.01042642816901207}, {"id": 100, "seek": 80056, "start": 810.64, "end": 815.8399999999999, "text": " Another challenge that came with us having offices across the world meant that", "tokens": [50868, 3996, 3430, 300, 1361, 365, 505, 1419, 14434, 2108, 264, 1002, 4140, 300, 51128], "temperature": 0.0, "avg_logprob": -0.16087728617142658, "compression_ratio": 1.4259259259259258, "no_speech_prob": 0.01042642816901207}, {"id": 101, "seek": 80056, "start": 818.2399999999999, "end": 826.0, "text": " if the internal documentation was hosted in the Netherlands, our colleagues over in", "tokens": [51248, 498, 264, 6920, 14333, 390, 19204, 294, 264, 20873, 11, 527, 7734, 670, 294, 51636], "temperature": 0.0, "avg_logprob": -0.16087728617142658, "compression_ratio": 1.4259259259259258, "no_speech_prob": 0.01042642816901207}, {"id": 102, "seek": 82600, "start": 826.56, "end": 830.96, "text": " Australia or Singapore were having to wait quite a long time", "tokens": [50392, 7060, 420, 14491, 645, 1419, 281, 1699, 1596, 257, 938, 565, 50612], "temperature": 0.0, "avg_logprob": -0.13414797959504304, "compression_ratio": 1.4367088607594938, "no_speech_prob": 0.0013136181514710188}, {"id": 103, "seek": 82600, "start": 833.68, "end": 843.76, "text": " to see the content that they needed. And this came back as a pain point from the users. So", "tokens": [50748, 281, 536, 264, 2701, 300, 436, 2978, 13, 400, 341, 1361, 646, 382, 257, 1822, 935, 490, 264, 5022, 13, 407, 51252], "temperature": 0.0, "avg_logprob": -0.13414797959504304, "compression_ratio": 1.4367088607594938, "no_speech_prob": 0.0013136181514710188}, {"id": 104, "seek": 82600, "start": 846.08, "end": 853.44, "text": " we started deploying the internal documentation to service in APAC as well.", "tokens": [51368, 321, 1409, 34198, 264, 6920, 14333, 281, 2643, 294, 5372, 4378, 382, 731, 13, 51736], "temperature": 0.0, "avg_logprob": -0.13414797959504304, "compression_ratio": 1.4367088607594938, "no_speech_prob": 0.0013136181514710188}, {"id": 105, "seek": 85344, "start": 853.44, "end": 861.0400000000001, "text": " So then we also had to deal with thinking changes across services worldwide. So we've done that one", "tokens": [50364, 407, 550, 321, 611, 632, 281, 2028, 365, 1953, 2962, 2108, 3328, 13485, 13, 407, 321, 600, 1096, 300, 472, 50744], "temperature": 0.0, "avg_logprob": -0.1478555098823879, "compression_ratio": 1.45, "no_speech_prob": 0.0005584176979027689}, {"id": 106, "seek": 85344, "start": 861.0400000000001, "end": 874.4000000000001, "text": " too. Right. Moving on to people and how they work together. And Graf does enable various ways of", "tokens": [50744, 886, 13, 1779, 13, 14242, 322, 281, 561, 293, 577, 436, 589, 1214, 13, 400, 8985, 69, 775, 9528, 3683, 2098, 295, 51412], "temperature": 0.0, "avg_logprob": -0.1478555098823879, "compression_ratio": 1.45, "no_speech_prob": 0.0005584176979027689}, {"id": 107, "seek": 85344, "start": 874.4000000000001, "end": 882.5600000000001, "text": " collaborating and managing content. And for this part, I'm going to look at the internal docs", "tokens": [51412, 30188, 293, 11642, 2701, 13, 400, 337, 341, 644, 11, 286, 478, 516, 281, 574, 412, 264, 6920, 45623, 51820], "temperature": 0.0, "avg_logprob": -0.1478555098823879, "compression_ratio": 1.45, "no_speech_prob": 0.0005584176979027689}, {"id": 108, "seek": 88256, "start": 882.56, "end": 887.28, "text": " and the external docs in parallel so we can better see", "tokens": [50364, 293, 264, 8320, 45623, 294, 8952, 370, 321, 393, 1101, 536, 50600], "temperature": 0.0, "avg_logprob": -0.13918032469572844, "compression_ratio": 1.4759036144578312, "no_speech_prob": 0.0003767427406273782}, {"id": 109, "seek": 88256, "start": 890.88, "end": 898.2399999999999, "text": " the various characteristics depending on how people collaborate and how they create content.", "tokens": [50780, 264, 3683, 10891, 5413, 322, 577, 561, 18338, 293, 577, 436, 1884, 2701, 13, 51148], "temperature": 0.0, "avg_logprob": -0.13918032469572844, "compression_ratio": 1.4759036144578312, "no_speech_prob": 0.0003767427406273782}, {"id": 110, "seek": 88256, "start": 899.1199999999999, "end": 906.64, "text": " So for the internal documentation, it's run wiki style, which means that anyone can make changes.", "tokens": [51192, 407, 337, 264, 6920, 14333, 11, 309, 311, 1190, 261, 9850, 3758, 11, 597, 1355, 300, 2878, 393, 652, 2962, 13, 51568], "temperature": 0.0, "avg_logprob": -0.13918032469572844, "compression_ratio": 1.4759036144578312, "no_speech_prob": 0.0003767427406273782}, {"id": 111, "seek": 90664, "start": 907.6, "end": 913.4399999999999, "text": " People mostly make changes using the browser editor. We also accept poor requests, but", "tokens": [50412, 3432, 5240, 652, 2962, 1228, 264, 11185, 9839, 13, 492, 611, 3241, 4716, 12475, 11, 457, 50704], "temperature": 0.0, "avg_logprob": -0.12664400206671822, "compression_ratio": 1.6150234741784038, "no_speech_prob": 0.001532236929051578}, {"id": 112, "seek": 90664, "start": 914.4, "end": 918.16, "text": " relatively small percentage of people will raise a poor request.", "tokens": [50752, 7226, 1359, 9668, 295, 561, 486, 5300, 257, 4716, 5308, 13, 50940], "temperature": 0.0, "avg_logprob": -0.12664400206671822, "compression_ratio": 1.6150234741784038, "no_speech_prob": 0.001532236929051578}, {"id": 113, "seek": 90664, "start": 921.36, "end": 925.6, "text": " The internal documentation also has page and section owners visible at the top of the page so", "tokens": [51100, 440, 6920, 14333, 611, 575, 3028, 293, 3541, 7710, 8974, 412, 264, 1192, 295, 264, 3028, 370, 51312], "temperature": 0.0, "avg_logprob": -0.12664400206671822, "compression_ratio": 1.6150234741784038, "no_speech_prob": 0.001532236929051578}, {"id": 114, "seek": 90664, "start": 925.6, "end": 931.68, "text": " that people can easily find out who to contact if they have questions or if they spotted something", "tokens": [51312, 300, 561, 393, 3612, 915, 484, 567, 281, 3385, 498, 436, 362, 1651, 420, 498, 436, 21010, 746, 51616], "temperature": 0.0, "avg_logprob": -0.12664400206671822, "compression_ratio": 1.6150234741784038, "no_speech_prob": 0.001532236929051578}, {"id": 115, "seek": 93168, "start": 931.68, "end": 938.4, "text": " wrong on the page. And our colleagues from development have also set up", "tokens": [50364, 2085, 322, 264, 3028, 13, 400, 527, 7734, 490, 3250, 362, 611, 992, 493, 50700], "temperature": 0.0, "avg_logprob": -0.11923104524612427, "compression_ratio": 1.5204081632653061, "no_speech_prob": 0.001768317073583603}, {"id": 116, "seek": 93168, "start": 938.4, "end": 941.5999999999999, "text": " certain integrations with code repositories and internal tools", "tokens": [50700, 1629, 3572, 763, 365, 3089, 22283, 2083, 293, 6920, 3873, 50860], "temperature": 0.0, "avg_logprob": -0.11923104524612427, "compression_ratio": 1.5204081632653061, "no_speech_prob": 0.001768317073583603}, {"id": 117, "seek": 93168, "start": 944.2399999999999, "end": 951.68, "text": " to again facilitate this communication and knowledge sharing in one place.", "tokens": [50992, 281, 797, 20207, 341, 6101, 293, 3601, 5414, 294, 472, 1081, 13, 51364], "temperature": 0.0, "avg_logprob": -0.11923104524612427, "compression_ratio": 1.5204081632653061, "no_speech_prob": 0.001768317073583603}, {"id": 118, "seek": 93168, "start": 952.8, "end": 958.9599999999999, "text": " Now in terms of the external documentation, like I said, there is the group of technical", "tokens": [51420, 823, 294, 2115, 295, 264, 8320, 14333, 11, 411, 286, 848, 11, 456, 307, 264, 1594, 295, 6191, 51728], "temperature": 0.0, "avg_logprob": -0.11923104524612427, "compression_ratio": 1.5204081632653061, "no_speech_prob": 0.001768317073583603}, {"id": 119, "seek": 95896, "start": 958.96, "end": 966.32, "text": " writers who write and maintain the content. Now unlike Hub, unlike the people writing content", "tokens": [50364, 13491, 567, 2464, 293, 6909, 264, 2701, 13, 823, 8343, 18986, 11, 8343, 264, 561, 3579, 2701, 50732], "temperature": 0.0, "avg_logprob": -0.14751783231409585, "compression_ratio": 1.708133971291866, "no_speech_prob": 0.0011888566659763455}, {"id": 120, "seek": 95896, "start": 966.32, "end": 974.0, "text": " for Hub, people writing docs mostly use their ID. They commit their markdown changes and", "tokens": [50732, 337, 18986, 11, 561, 3579, 45623, 5240, 764, 641, 7348, 13, 814, 5599, 641, 1491, 5093, 2962, 293, 51116], "temperature": 0.0, "avg_logprob": -0.14751783231409585, "compression_ratio": 1.708133971291866, "no_speech_prob": 0.0011888566659763455}, {"id": 121, "seek": 95896, "start": 975.76, "end": 981.12, "text": " push them to the remote. They will check the state of the docs locally and all of that. So", "tokens": [51204, 2944, 552, 281, 264, 8607, 13, 814, 486, 1520, 264, 1785, 295, 264, 45623, 16143, 293, 439, 295, 300, 13, 407, 51472], "temperature": 0.0, "avg_logprob": -0.14751783231409585, "compression_ratio": 1.708133971291866, "no_speech_prob": 0.0011888566659763455}, {"id": 122, "seek": 95896, "start": 981.12, "end": 985.9200000000001, "text": " in other words, they use a doc's code approach to creating and maintaining content.", "tokens": [51472, 294, 661, 2283, 11, 436, 764, 257, 3211, 311, 3089, 3109, 281, 4084, 293, 14916, 2701, 13, 51712], "temperature": 0.0, "avg_logprob": -0.14751783231409585, "compression_ratio": 1.708133971291866, "no_speech_prob": 0.0011888566659763455}, {"id": 123, "seek": 98896, "start": 988.96, "end": 995.76, "text": " I kind of mentioned this before that we have a way for people to suggest changes internally.", "tokens": [50364, 286, 733, 295, 2835, 341, 949, 300, 321, 362, 257, 636, 337, 561, 281, 3402, 2962, 19501, 13, 50704], "temperature": 0.0, "avg_logprob": -0.1770122210184733, "compression_ratio": 1.4918032786885247, "no_speech_prob": 0.0006009109201841056}, {"id": 124, "seek": 98896, "start": 996.32, "end": 1006.88, "text": " So we have a technical writer on duty every week who reviews changes coming from colleagues.", "tokens": [50732, 407, 321, 362, 257, 6191, 9936, 322, 9776, 633, 1243, 567, 10229, 2962, 1348, 490, 7734, 13, 51260], "temperature": 0.0, "avg_logprob": -0.1770122210184733, "compression_ratio": 1.4918032786885247, "no_speech_prob": 0.0006009109201841056}, {"id": 125, "seek": 98896, "start": 1009.9200000000001, "end": 1014.8000000000001, "text": " Because there is this small group focusing on curating this content and they are quite,", "tokens": [51412, 1436, 456, 307, 341, 1359, 1594, 8416, 322, 1262, 990, 341, 2701, 293, 436, 366, 1596, 11, 51656], "temperature": 0.0, "avg_logprob": -0.1770122210184733, "compression_ratio": 1.4918032786885247, "no_speech_prob": 0.0006009109201841056}, {"id": 126, "seek": 101480, "start": 1015.4399999999999, "end": 1021.4399999999999, "text": " so like text-heavy-day tree documentation is code, there is a lot of reuse and parameterization", "tokens": [50396, 370, 411, 2487, 12, 37157, 12, 810, 4230, 14333, 307, 3089, 11, 456, 307, 257, 688, 295, 26225, 293, 13075, 2144, 50696], "temperature": 0.0, "avg_logprob": -0.18519157521864948, "compression_ratio": 1.646153846153846, "no_speech_prob": 0.0005790901486761868}, {"id": 127, "seek": 101480, "start": 1022.56, "end": 1029.12, "text": " in the external documentation trying to find that sweet spot, that balance between", "tokens": [50752, 294, 264, 8320, 14333, 1382, 281, 915, 300, 3844, 4008, 11, 300, 4772, 1296, 51080], "temperature": 0.0, "avg_logprob": -0.18519157521864948, "compression_ratio": 1.646153846153846, "no_speech_prob": 0.0005790901486761868}, {"id": 128, "seek": 101480, "start": 1033.76, "end": 1039.36, "text": " writing content in a scalable way, so reducing the maintenance burden but also without", "tokens": [51312, 3579, 2701, 294, 257, 38481, 636, 11, 370, 12245, 264, 11258, 12578, 457, 611, 1553, 51592], "temperature": 0.0, "avg_logprob": -0.18519157521864948, "compression_ratio": 1.646153846153846, "no_speech_prob": 0.0005790901486761868}, {"id": 129, "seek": 101480, "start": 1040.3999999999999, "end": 1043.6, "text": " increasing the cognitive load for maintenance too much.", "tokens": [51644, 5662, 264, 15605, 3677, 337, 11258, 886, 709, 13, 51804], "temperature": 0.0, "avg_logprob": -0.18519157521864948, "compression_ratio": 1.646153846153846, "no_speech_prob": 0.0005790901486761868}, {"id": 130, "seek": 104480, "start": 1045.36, "end": 1055.28, "text": " But also an interesting thing that has, well, interesting thing that has happened since 2018", "tokens": [50392, 583, 611, 364, 1880, 551, 300, 575, 11, 731, 11, 1880, 551, 300, 575, 2011, 1670, 6096, 50888], "temperature": 0.0, "avg_logprob": -0.2372152010599772, "compression_ratio": 1.603658536585366, "no_speech_prob": 0.0007113436586223543}, {"id": 131, "seek": 104480, "start": 1055.28, "end": 1062.56, "text": " is that Agen as a company went from being a payments company to a financial technology", "tokens": [50888, 307, 300, 316, 1766, 382, 257, 2237, 1437, 490, 885, 257, 14348, 2237, 281, 257, 4669, 2899, 51252], "temperature": 0.0, "avg_logprob": -0.2372152010599772, "compression_ratio": 1.603658536585366, "no_speech_prob": 0.0007113436586223543}, {"id": 132, "seek": 104480, "start": 1062.56, "end": 1069.12, "text": " platform. So this means that on the one hand, the payments products stayed, became,", "tokens": [51252, 3663, 13, 407, 341, 1355, 300, 322, 264, 472, 1011, 11, 264, 14348, 3383, 9181, 11, 3062, 11, 51580], "temperature": 0.0, "avg_logprob": -0.2372152010599772, "compression_ratio": 1.603658536585366, "no_speech_prob": 0.0007113436586223543}, {"id": 133, "seek": 106912, "start": 1070.08, "end": 1074.8, "text": " so like the bread and butter of what the company does and the basis for a lot of other products.", "tokens": [50412, 370, 411, 264, 5961, 293, 5517, 295, 437, 264, 2237, 775, 293, 264, 5143, 337, 257, 688, 295, 661, 3383, 13, 50648], "temperature": 0.0, "avg_logprob": -0.15478897094726562, "compression_ratio": 1.7395348837209301, "no_speech_prob": 0.0011929197935387492}, {"id": 134, "seek": 106912, "start": 1075.76, "end": 1085.9199999999998, "text": " And those products had more and more releases, so there have been iterations, several versions", "tokens": [50696, 400, 729, 3383, 632, 544, 293, 544, 16952, 11, 370, 456, 362, 668, 36540, 11, 2940, 9606, 51204], "temperature": 0.0, "avg_logprob": -0.15478897094726562, "compression_ratio": 1.7395348837209301, "no_speech_prob": 0.0011929197935387492}, {"id": 135, "seek": 106912, "start": 1085.9199999999998, "end": 1093.12, "text": " to document. But on the other hand, extending into financial products meant that a series of other", "tokens": [51204, 281, 4166, 13, 583, 322, 264, 661, 1011, 11, 24360, 666, 4669, 3383, 4140, 300, 257, 2638, 295, 661, 51564], "temperature": 0.0, "avg_logprob": -0.15478897094726562, "compression_ratio": 1.7395348837209301, "no_speech_prob": 0.0011929197935387492}, {"id": 136, "seek": 106912, "start": 1093.12, "end": 1097.6799999999998, "text": " new products were built which also needed documentation. So there has been a lot of", "tokens": [51564, 777, 3383, 645, 3094, 597, 611, 2978, 14333, 13, 407, 456, 575, 668, 257, 688, 295, 51792], "temperature": 0.0, "avg_logprob": -0.15478897094726562, "compression_ratio": 1.7395348837209301, "no_speech_prob": 0.0011929197935387492}, {"id": 137, "seek": 109768, "start": 1097.76, "end": 1106.96, "text": " content growth along both of these axes. So let's have a look at how the company growth has,", "tokens": [50368, 2701, 4599, 2051, 1293, 295, 613, 35387, 13, 407, 718, 311, 362, 257, 574, 412, 577, 264, 2237, 4599, 575, 11, 50828], "temperature": 0.0, "avg_logprob": -0.11358432921152266, "compression_ratio": 1.5204678362573099, "no_speech_prob": 0.0006100015016272664}, {"id": 138, "seek": 109768, "start": 1106.96, "end": 1113.04, "text": " is reflected in documentation as well. So in terms of internal documentation,", "tokens": [50828, 307, 15502, 294, 14333, 382, 731, 13, 407, 294, 2115, 295, 6920, 14333, 11, 51132], "temperature": 0.0, "avg_logprob": -0.11358432921152266, "compression_ratio": 1.5204678362573099, "no_speech_prob": 0.0006100015016272664}, {"id": 139, "seek": 109768, "start": 1114.88, "end": 1122.5600000000002, "text": " we all use it, right? So the fact that the company has grown about three times since 2018", "tokens": [51224, 321, 439, 764, 309, 11, 558, 30, 407, 264, 1186, 300, 264, 2237, 575, 7709, 466, 1045, 1413, 1670, 6096, 51608], "temperature": 0.0, "avg_logprob": -0.11358432921152266, "compression_ratio": 1.5204678362573099, "no_speech_prob": 0.0006100015016272664}, {"id": 140, "seek": 112256, "start": 1122.56, "end": 1128.8, "text": " means that the audience has also grown just as much. The content itself has", "tokens": [50364, 1355, 300, 264, 4034, 575, 611, 7709, 445, 382, 709, 13, 440, 2701, 2564, 575, 50676], "temperature": 0.0, "avg_logprob": -0.0843690037727356, "compression_ratio": 1.432748538011696, "no_speech_prob": 0.0015529588563367724}, {"id": 141, "seek": 112256, "start": 1130.3999999999999, "end": 1135.36, "text": " grown two and a half times. Last I checked with the product specialist for Hub,", "tokens": [50756, 7709, 732, 293, 257, 1922, 1413, 13, 5264, 286, 10033, 365, 264, 1674, 17008, 337, 18986, 11, 51004], "temperature": 0.0, "avg_logprob": -0.0843690037727356, "compression_ratio": 1.432748538011696, "no_speech_prob": 0.0015529588563367724}, {"id": 142, "seek": 112256, "start": 1136.08, "end": 1143.9199999999998, "text": " we had more than 12,000 pages. That is a lot of content. And those 12,000 pages have been", "tokens": [51040, 321, 632, 544, 813, 2272, 11, 1360, 7183, 13, 663, 307, 257, 688, 295, 2701, 13, 400, 729, 2272, 11, 1360, 7183, 362, 668, 51432], "temperature": 0.0, "avg_logprob": -0.0843690037727356, "compression_ratio": 1.432748538011696, "no_speech_prob": 0.0015529588563367724}, {"id": 143, "seek": 114392, "start": 1143.92, "end": 1154.4, "text": " written by over 3,000 people in the last four years. Yeah, I was quite surprised when I first", "tokens": [50364, 3720, 538, 670, 805, 11, 1360, 561, 294, 264, 1036, 1451, 924, 13, 865, 11, 286, 390, 1596, 6100, 562, 286, 700, 50888], "temperature": 0.0, "avg_logprob": -0.09199110406344055, "compression_ratio": 1.4108108108108108, "no_speech_prob": 0.00404573418200016}, {"id": 144, "seek": 114392, "start": 1154.4, "end": 1161.04, "text": " saw these numbers. Now for the external documentation, the audience has also increased", "tokens": [50888, 1866, 613, 3547, 13, 823, 337, 264, 8320, 14333, 11, 264, 4034, 575, 611, 6505, 51220], "temperature": 0.0, "avg_logprob": -0.09199110406344055, "compression_ratio": 1.4108108108108108, "no_speech_prob": 0.00404573418200016}, {"id": 145, "seek": 114392, "start": 1161.04, "end": 1167.52, "text": " even more than the internal one. So this is another aspect of how company growth", "tokens": [51220, 754, 544, 813, 264, 6920, 472, 13, 407, 341, 307, 1071, 4171, 295, 577, 2237, 4599, 51544], "temperature": 0.0, "avg_logprob": -0.09199110406344055, "compression_ratio": 1.4108108108108108, "no_speech_prob": 0.00404573418200016}, {"id": 146, "seek": 116752, "start": 1168.4, "end": 1176.0, "text": " can be seen in docs analytics. The amount of content we have in the docs has also increased", "tokens": [50408, 393, 312, 1612, 294, 45623, 15370, 13, 440, 2372, 295, 2701, 321, 362, 294, 264, 45623, 575, 611, 6505, 50788], "temperature": 0.0, "avg_logprob": -0.09356489915114183, "compression_ratio": 1.5081967213114753, "no_speech_prob": 0.00212455028668046}, {"id": 147, "seek": 116752, "start": 1176.0, "end": 1184.0, "text": " undoubtedly with all the new versions, all the new products. But somehow in a more controlled,", "tokens": [50788, 35211, 365, 439, 264, 777, 9606, 11, 439, 264, 777, 3383, 13, 583, 6063, 294, 257, 544, 10164, 11, 51188], "temperature": 0.0, "avg_logprob": -0.09356489915114183, "compression_ratio": 1.5081967213114753, "no_speech_prob": 0.00212455028668046}, {"id": 148, "seek": 116752, "start": 1184.0, "end": 1190.8, "text": " curated way. And maybe when we look at the challenges in the next slides, it might become", "tokens": [51188, 47851, 636, 13, 400, 1310, 562, 321, 574, 412, 264, 4759, 294, 264, 958, 9788, 11, 309, 1062, 1813, 51528], "temperature": 0.0, "avg_logprob": -0.09356489915114183, "compression_ratio": 1.5081967213114753, "no_speech_prob": 0.00212455028668046}, {"id": 149, "seek": 119080, "start": 1190.8, "end": 1197.28, "text": " more apparent why the growth for external documentation has been a bit more controlled.", "tokens": [50364, 544, 18335, 983, 264, 4599, 337, 8320, 14333, 575, 668, 257, 857, 544, 10164, 13, 50688], "temperature": 0.0, "avg_logprob": -0.12189285378707082, "compression_ratio": 1.5280898876404494, "no_speech_prob": 0.0038687700871378183}, {"id": 150, "seek": 119080, "start": 1198.72, "end": 1207.84, "text": " And of course, definitely worth mentioning that more than 350 colleagues have suggested changes", "tokens": [50760, 400, 295, 1164, 11, 2138, 3163, 18315, 300, 544, 813, 18065, 7734, 362, 10945, 2962, 51216], "temperature": 0.0, "avg_logprob": -0.12189285378707082, "compression_ratio": 1.5280898876404494, "no_speech_prob": 0.0038687700871378183}, {"id": 151, "seek": 119080, "start": 1208.6399999999999, "end": 1214.08, "text": " in the last three and a bit years because the suggest changes flow is a bit more recent.", "tokens": [51256, 294, 264, 1036, 1045, 293, 257, 857, 924, 570, 264, 3402, 2962, 3095, 307, 257, 857, 544, 5162, 13, 51528], "temperature": 0.0, "avg_logprob": -0.12189285378707082, "compression_ratio": 1.5280898876404494, "no_speech_prob": 0.0038687700871378183}, {"id": 152, "seek": 121408, "start": 1214.6399999999999, "end": 1221.1999999999998, "text": " So we get on average 100 people a year making suggestions and that is very, very valuable to", "tokens": [50392, 407, 321, 483, 322, 4274, 2319, 561, 257, 1064, 1455, 13396, 293, 300, 307, 588, 11, 588, 8263, 281, 50720], "temperature": 0.0, "avg_logprob": -0.09863694508870442, "compression_ratio": 1.574585635359116, "no_speech_prob": 0.0009781348053365946}, {"id": 153, "seek": 121408, "start": 1221.1999999999998, "end": 1230.8799999999999, "text": " us because with thousands of pages of documentation, the help that we get from people suggesting", "tokens": [50720, 505, 570, 365, 5383, 295, 7183, 295, 14333, 11, 264, 854, 300, 321, 483, 490, 561, 18094, 51204], "temperature": 0.0, "avg_logprob": -0.09863694508870442, "compression_ratio": 1.574585635359116, "no_speech_prob": 0.0009781348053365946}, {"id": 154, "seek": 121408, "start": 1230.8799999999999, "end": 1240.6399999999999, "text": " changes is invaluable. And now let's look at the challenges that come with the growth in number", "tokens": [51204, 2962, 307, 40367, 13, 400, 586, 718, 311, 574, 412, 264, 4759, 300, 808, 365, 264, 4599, 294, 1230, 51692], "temperature": 0.0, "avg_logprob": -0.09863694508870442, "compression_ratio": 1.574585635359116, "no_speech_prob": 0.0009781348053365946}, {"id": 155, "seek": 124064, "start": 1240.64, "end": 1246.96, "text": " of people and growth in content. So again, looking at hub, the internal documentation,", "tokens": [50364, 295, 561, 293, 4599, 294, 2701, 13, 407, 797, 11, 1237, 412, 11838, 11, 264, 6920, 14333, 11, 50680], "temperature": 0.0, "avg_logprob": -0.11699482564176067, "compression_ratio": 1.6180257510729614, "no_speech_prob": 0.0007749476935714483}, {"id": 156, "seek": 124064, "start": 1248.72, "end": 1254.88, "text": " or the last four years I've taught us is that we need to have a good strategy for content ownership", "tokens": [50768, 420, 264, 1036, 1451, 924, 286, 600, 5928, 505, 307, 300, 321, 643, 281, 362, 257, 665, 5206, 337, 2701, 15279, 51076], "temperature": 0.0, "avg_logprob": -0.11699482564176067, "compression_ratio": 1.6180257510729614, "no_speech_prob": 0.0007749476935714483}, {"id": 157, "seek": 124064, "start": 1254.88, "end": 1261.8400000000001, "text": " long term because time passes and people come, people go, but the content remains. And there", "tokens": [51076, 938, 1433, 570, 565, 11335, 293, 561, 808, 11, 561, 352, 11, 457, 264, 2701, 7023, 13, 400, 456, 51424], "temperature": 0.0, "avg_logprob": -0.11699482564176067, "compression_ratio": 1.6180257510729614, "no_speech_prob": 0.0007749476935714483}, {"id": 158, "seek": 124064, "start": 1261.8400000000001, "end": 1268.16, "text": " needs to be a plan in place for what happens to that who becomes responsible for it. There's also", "tokens": [51424, 2203, 281, 312, 257, 1393, 294, 1081, 337, 437, 2314, 281, 300, 567, 3643, 6250, 337, 309, 13, 821, 311, 611, 51740], "temperature": 0.0, "avg_logprob": -0.11699482564176067, "compression_ratio": 1.6180257510729614, "no_speech_prob": 0.0007749476935714483}, {"id": 159, "seek": 126816, "start": 1268.16, "end": 1273.8400000000001, "text": " the issue of broken links. So I was saying earlier that in the external documentation,", "tokens": [50364, 264, 2734, 295, 5463, 6123, 13, 407, 286, 390, 1566, 3071, 300, 294, 264, 8320, 14333, 11, 50648], "temperature": 0.0, "avg_logprob": -0.07541267170625575, "compression_ratio": 1.7302325581395348, "no_speech_prob": 0.001485715969465673}, {"id": 160, "seek": 126816, "start": 1273.8400000000001, "end": 1279.3600000000001, "text": " we never publish a broken link. And that is true. But with internal documentation, we don't have", "tokens": [50648, 321, 1128, 11374, 257, 5463, 2113, 13, 400, 300, 307, 2074, 13, 583, 365, 6920, 14333, 11, 321, 500, 380, 362, 50924], "temperature": 0.0, "avg_logprob": -0.07541267170625575, "compression_ratio": 1.7302325581395348, "no_speech_prob": 0.001485715969465673}, {"id": 161, "seek": 126816, "start": 1280.0800000000002, "end": 1286.16, "text": " that kind of flow in place because the editing flow is also different. And we are looking into", "tokens": [50960, 300, 733, 295, 3095, 294, 1081, 570, 264, 10000, 3095, 307, 611, 819, 13, 400, 321, 366, 1237, 666, 51264], "temperature": 0.0, "avg_logprob": -0.07541267170625575, "compression_ratio": 1.7302325581395348, "no_speech_prob": 0.001485715969465673}, {"id": 162, "seek": 126816, "start": 1286.16, "end": 1293.76, "text": " possible ways that we can let people know when links that they have in sections that they own", "tokens": [51264, 1944, 2098, 300, 321, 393, 718, 561, 458, 562, 6123, 300, 436, 362, 294, 10863, 300, 436, 1065, 51644], "temperature": 0.0, "avg_logprob": -0.07541267170625575, "compression_ratio": 1.7302325581395348, "no_speech_prob": 0.001485715969465673}, {"id": 163, "seek": 129376, "start": 1293.76, "end": 1299.84, "text": " are broken. This normally happens when other parts of the internal documentation that they", "tokens": [50364, 366, 5463, 13, 639, 5646, 2314, 562, 661, 3166, 295, 264, 6920, 14333, 300, 436, 50668], "temperature": 0.0, "avg_logprob": -0.09429515325106107, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0024155178107321262}, {"id": 164, "seek": 129376, "start": 1299.84, "end": 1306.4, "text": " refer to have been restructured, pages have been removed or reorganized. So yeah, that's", "tokens": [50668, 2864, 281, 362, 668, 1472, 46847, 11, 7183, 362, 668, 7261, 420, 41203, 1602, 13, 407, 1338, 11, 300, 311, 50996], "temperature": 0.0, "avg_logprob": -0.09429515325106107, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0024155178107321262}, {"id": 165, "seek": 129376, "start": 1306.4, "end": 1313.92, "text": " definitely something we're looking into. Also, empowering people to write good content is important", "tokens": [50996, 2138, 746, 321, 434, 1237, 666, 13, 2743, 11, 28261, 561, 281, 2464, 665, 2701, 307, 1021, 51372], "temperature": 0.0, "avg_logprob": -0.09429515325106107, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0024155178107321262}, {"id": 166, "seek": 129376, "start": 1315.6, "end": 1320.8799999999999, "text": " and making them feel responsible for the content that they've written because writing the content", "tokens": [51456, 293, 1455, 552, 841, 6250, 337, 264, 2701, 300, 436, 600, 3720, 570, 3579, 264, 2701, 51720], "temperature": 0.0, "avg_logprob": -0.09429515325106107, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0024155178107321262}, {"id": 167, "seek": 132088, "start": 1320.88, "end": 1329.0400000000002, "text": " is not enough. It's great that they have written it. But this mindset that once you've written", "tokens": [50364, 307, 406, 1547, 13, 467, 311, 869, 300, 436, 362, 3720, 309, 13, 583, 341, 12543, 300, 1564, 291, 600, 3720, 50772], "temperature": 0.0, "avg_logprob": -0.09390379726022914, "compression_ratio": 1.5666666666666667, "no_speech_prob": 0.00014142290456220508}, {"id": 168, "seek": 132088, "start": 1329.0400000000002, "end": 1337.44, "text": " something, you're responsible for it is something that we need to work on a bit more.", "tokens": [50772, 746, 11, 291, 434, 6250, 337, 309, 307, 746, 300, 321, 643, 281, 589, 322, 257, 857, 544, 13, 51192], "temperature": 0.0, "avg_logprob": -0.09390379726022914, "compression_ratio": 1.5666666666666667, "no_speech_prob": 0.00014142290456220508}, {"id": 169, "seek": 132088, "start": 1339.5200000000002, "end": 1345.1200000000001, "text": " Now, in terms of the external documentation, one of the pain points that we see from feedback is that", "tokens": [51296, 823, 11, 294, 2115, 295, 264, 8320, 14333, 11, 472, 295, 264, 1822, 2793, 300, 321, 536, 490, 5824, 307, 300, 51576], "temperature": 0.0, "avg_logprob": -0.09390379726022914, "compression_ratio": 1.5666666666666667, "no_speech_prob": 0.00014142290456220508}, {"id": 170, "seek": 134512, "start": 1345.76, "end": 1352.8799999999999, "text": " it's easy to pull out of sync with other platforms that we have. So for example,", "tokens": [50396, 309, 311, 1858, 281, 2235, 484, 295, 20271, 365, 661, 9473, 300, 321, 362, 13, 407, 337, 1365, 11, 50752], "temperature": 0.0, "avg_logprob": -0.12672396500905356, "compression_ratio": 1.5980861244019138, "no_speech_prob": 0.00124556221999228}, {"id": 171, "seek": 134512, "start": 1352.8799999999999, "end": 1357.76, "text": " documentation versus the marketing website or versus the internal documentation. And this is", "tokens": [50752, 14333, 5717, 264, 6370, 3144, 420, 5717, 264, 6920, 14333, 13, 400, 341, 307, 50996], "temperature": 0.0, "avg_logprob": -0.12672396500905356, "compression_ratio": 1.5980861244019138, "no_speech_prob": 0.00124556221999228}, {"id": 172, "seek": 134512, "start": 1357.76, "end": 1360.7199999999998, "text": " because the same information is maintained manually by different people.", "tokens": [50996, 570, 264, 912, 1589, 307, 17578, 16945, 538, 819, 561, 13, 51144], "temperature": 0.0, "avg_logprob": -0.12672396500905356, "compression_ratio": 1.5980861244019138, "no_speech_prob": 0.00124556221999228}, {"id": 173, "seek": 134512, "start": 1363.4399999999998, "end": 1374.1599999999999, "text": " Needing to scale complex content means that we need to have some way of having the same", "tokens": [51280, 1734, 9794, 281, 4373, 3997, 2701, 1355, 300, 321, 643, 281, 362, 512, 636, 295, 1419, 264, 912, 51816], "temperature": 0.0, "avg_logprob": -0.12672396500905356, "compression_ratio": 1.5980861244019138, "no_speech_prob": 0.00124556221999228}, {"id": 174, "seek": 137416, "start": 1374.16, "end": 1379.52, "text": " information being shown everywhere, offering a consistent experience in terms of navigation and", "tokens": [50364, 1589, 885, 4898, 5315, 11, 8745, 257, 8398, 1752, 294, 2115, 295, 17346, 293, 50632], "temperature": 0.0, "avg_logprob": -0.07523155212402344, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0006850959034636617}, {"id": 175, "seek": 137416, "start": 1379.52, "end": 1387.2, "text": " things like that. We already have ideas for how to tackle this. I'm going to defer this to the last", "tokens": [50632, 721, 411, 300, 13, 492, 1217, 362, 3487, 337, 577, 281, 14896, 341, 13, 286, 478, 516, 281, 25704, 341, 281, 264, 1036, 51016], "temperature": 0.0, "avg_logprob": -0.07523155212402344, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0006850959034636617}, {"id": 176, "seek": 137416, "start": 1387.2, "end": 1394.64, "text": " section about the future. Something else that we get is I was saying with the passing of time,", "tokens": [51016, 3541, 466, 264, 2027, 13, 6595, 1646, 300, 321, 483, 307, 286, 390, 1566, 365, 264, 8437, 295, 565, 11, 51388], "temperature": 0.0, "avg_logprob": -0.07523155212402344, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0006850959034636617}, {"id": 177, "seek": 137416, "start": 1394.64, "end": 1399.2, "text": " several software versions, we find that users do ask for older versions. So versioning is something", "tokens": [51388, 2940, 4722, 9606, 11, 321, 915, 300, 5022, 360, 1029, 337, 4906, 9606, 13, 407, 3037, 278, 307, 746, 51616], "temperature": 0.0, "avg_logprob": -0.07523155212402344, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0006850959034636617}, {"id": 178, "seek": 139920, "start": 1399.28, "end": 1405.52, "text": " that we're also working on. Versioning for documentation. And that can be a whole separate", "tokens": [50368, 300, 321, 434, 611, 1364, 322, 13, 35965, 278, 337, 14333, 13, 400, 300, 393, 312, 257, 1379, 4994, 50680], "temperature": 0.0, "avg_logprob": -0.07464681038489708, "compression_ratio": 1.4791666666666667, "no_speech_prob": 0.0015389187028631568}, {"id": 179, "seek": 139920, "start": 1405.52, "end": 1413.3600000000001, "text": " talk in itself. So maybe see you next year. And as you might have seen, I've been avoiding the last", "tokens": [50680, 751, 294, 2564, 13, 407, 1310, 536, 291, 958, 1064, 13, 400, 382, 291, 1062, 362, 1612, 11, 286, 600, 668, 20220, 264, 1036, 51072], "temperature": 0.0, "avg_logprob": -0.07464681038489708, "compression_ratio": 1.4791666666666667, "no_speech_prob": 0.0015389187028631568}, {"id": 180, "seek": 139920, "start": 1413.3600000000001, "end": 1420.4, "text": " point for both because finding relevant content quickly is a continuing challenge, especially", "tokens": [51072, 935, 337, 1293, 570, 5006, 7340, 2701, 2661, 307, 257, 9289, 3430, 11, 2318, 51424], "temperature": 0.0, "avg_logprob": -0.07464681038489708, "compression_ratio": 1.4791666666666667, "no_speech_prob": 0.0015389187028631568}, {"id": 181, "seek": 142040, "start": 1420.48, "end": 1429.3600000000001, "text": " in a climate of growth. And that is where search and information architecture have to be", "tokens": [50368, 294, 257, 5659, 295, 4599, 13, 400, 300, 307, 689, 3164, 293, 1589, 9482, 362, 281, 312, 50812], "temperature": 0.0, "avg_logprob": -0.10045138158296284, "compression_ratio": 1.6548223350253808, "no_speech_prob": 0.015588708221912384}, {"id": 182, "seek": 142040, "start": 1430.48, "end": 1437.2800000000002, "text": " on point. And continuously iterating on that and seeing what works, what doesn't work for people", "tokens": [50868, 322, 935, 13, 400, 15684, 17138, 990, 322, 300, 293, 2577, 437, 1985, 11, 437, 1177, 380, 589, 337, 561, 51208], "temperature": 0.0, "avg_logprob": -0.10045138158296284, "compression_ratio": 1.6548223350253808, "no_speech_prob": 0.015588708221912384}, {"id": 183, "seek": 142040, "start": 1438.48, "end": 1441.52, "text": " is a core part. But then also looking at how to", "tokens": [51268, 307, 257, 4965, 644, 13, 583, 550, 611, 1237, 412, 577, 281, 51420], "temperature": 0.0, "avg_logprob": -0.10045138158296284, "compression_ratio": 1.6548223350253808, "no_speech_prob": 0.015588708221912384}, {"id": 184, "seek": 142040, "start": 1442.8000000000002, "end": 1446.96, "text": " show people only the information that is relevant to them is something we're also exploring.", "tokens": [51484, 855, 561, 787, 264, 1589, 300, 307, 7340, 281, 552, 307, 746, 321, 434, 611, 12736, 13, 51692], "temperature": 0.0, "avg_logprob": -0.10045138158296284, "compression_ratio": 1.6548223350253808, "no_speech_prob": 0.015588708221912384}, {"id": 185, "seek": 144696, "start": 1447.6000000000001, "end": 1454.56, "text": " Now, in terms of collaboration with the open source community, we have a direct relationship", "tokens": [50396, 823, 11, 294, 2115, 295, 9363, 365, 264, 1269, 4009, 1768, 11, 321, 362, 257, 2047, 2480, 50744], "temperature": 0.0, "avg_logprob": -0.15272405942281086, "compression_ratio": 1.5168539325842696, "no_speech_prob": 0.00028145743999630213}, {"id": 186, "seek": 144696, "start": 1454.56, "end": 1462.08, "text": " with the graph project maintainers. We've sponsored building certain plugins, which we", "tokens": [50744, 365, 264, 4295, 1716, 6909, 433, 13, 492, 600, 16621, 2390, 1629, 33759, 11, 597, 321, 51120], "temperature": 0.0, "avg_logprob": -0.15272405942281086, "compression_ratio": 1.5168539325842696, "no_speech_prob": 0.00028145743999630213}, {"id": 187, "seek": 144696, "start": 1465.28, "end": 1473.44, "text": " have then open sourced. So some plugins are for our own internal use because they are very", "tokens": [51280, 362, 550, 1269, 11006, 1232, 13, 407, 512, 33759, 366, 337, 527, 1065, 6920, 764, 570, 436, 366, 588, 51688], "temperature": 0.0, "avg_logprob": -0.15272405942281086, "compression_ratio": 1.5168539325842696, "no_speech_prob": 0.00028145743999630213}, {"id": 188, "seek": 147344, "start": 1473.44, "end": 1479.52, "text": " business case specific. But we've also collaborated on plugins that we've then open sourced.", "tokens": [50364, 1606, 1389, 2685, 13, 583, 321, 600, 611, 42463, 322, 33759, 300, 321, 600, 550, 1269, 11006, 1232, 13, 50668], "temperature": 0.0, "avg_logprob": -0.08505341334220691, "compression_ratio": 1.54337899543379, "no_speech_prob": 0.0004994309274479747}, {"id": 189, "seek": 147344, "start": 1481.6000000000001, "end": 1485.92, "text": " And we also contribute bug fixes to the code repository.", "tokens": [50772, 400, 321, 611, 10586, 7426, 32539, 281, 264, 3089, 25841, 13, 50988], "temperature": 0.0, "avg_logprob": -0.08505341334220691, "compression_ratio": 1.54337899543379, "no_speech_prob": 0.0004994309274479747}, {"id": 190, "seek": 147344, "start": 1489.28, "end": 1496.48, "text": " Moving on to look at the future, I'm only going to look at the biggest challenge that I am very", "tokens": [51156, 14242, 322, 281, 574, 412, 264, 2027, 11, 286, 478, 787, 516, 281, 574, 412, 264, 3880, 3430, 300, 286, 669, 588, 51516], "temperature": 0.0, "avg_logprob": -0.08505341334220691, "compression_ratio": 1.54337899543379, "no_speech_prob": 0.0004994309274479747}, {"id": 191, "seek": 147344, "start": 1496.48, "end": 1501.44, "text": " excited about tackling, which is scaling consistently across all the platforms that we have.", "tokens": [51516, 2919, 466, 34415, 11, 597, 307, 21589, 14961, 2108, 439, 264, 9473, 300, 321, 362, 13, 51764], "temperature": 0.0, "avg_logprob": -0.08505341334220691, "compression_ratio": 1.54337899543379, "no_speech_prob": 0.0004994309274479747}, {"id": 192, "seek": 150144, "start": 1502.4, "end": 1506.0, "text": " And now that I'm looking at this diagram, it kind of looks a bit like a present, doesn't it?", "tokens": [50412, 400, 586, 300, 286, 478, 1237, 412, 341, 10686, 11, 309, 733, 295, 1542, 257, 857, 411, 257, 1974, 11, 1177, 380, 309, 30, 50592], "temperature": 0.0, "avg_logprob": -0.12007819905000575, "compression_ratio": 1.5324074074074074, "no_speech_prob": 0.001900727627798915}, {"id": 193, "seek": 150144, "start": 1507.2, "end": 1514.72, "text": " With a hat. So this inconsistency that I was saying, we're starting to see", "tokens": [50652, 2022, 257, 2385, 13, 407, 341, 22039, 468, 3020, 300, 286, 390, 1566, 11, 321, 434, 2891, 281, 536, 51028], "temperature": 0.0, "avg_logprob": -0.12007819905000575, "compression_ratio": 1.5324074074074074, "no_speech_prob": 0.001900727627798915}, {"id": 194, "seek": 150144, "start": 1515.52, "end": 1519.04, "text": " between the different platforms, not all of which are running on graph.", "tokens": [51068, 1296, 264, 819, 9473, 11, 406, 439, 295, 597, 366, 2614, 322, 4295, 13, 51244], "temperature": 0.0, "avg_logprob": -0.12007819905000575, "compression_ratio": 1.5324074074074074, "no_speech_prob": 0.001900727627798915}, {"id": 195, "seek": 150144, "start": 1520.96, "end": 1527.68, "text": " We want to create a single source of truth. And the interface for inputting the information", "tokens": [51340, 492, 528, 281, 1884, 257, 2167, 4009, 295, 3494, 13, 400, 264, 9226, 337, 4846, 783, 264, 1589, 51676], "temperature": 0.0, "avg_logprob": -0.12007819905000575, "compression_ratio": 1.5324074074074074, "no_speech_prob": 0.001900727627798915}, {"id": 196, "seek": 152768, "start": 1527.68, "end": 1535.8400000000001, "text": " for the single source of truth is probably also going to be an instance of graph using", "tokens": [50364, 337, 264, 2167, 4009, 295, 3494, 307, 1391, 611, 516, 281, 312, 364, 5197, 295, 4295, 1228, 50772], "temperature": 0.0, "avg_logprob": -0.059130759178837644, "compression_ratio": 1.691588785046729, "no_speech_prob": 0.001078302855603397}, {"id": 197, "seek": 152768, "start": 1535.8400000000001, "end": 1541.68, "text": " the same one code base that I was mentioning at the beginning. So this is for the kind of", "tokens": [50772, 264, 912, 472, 3089, 3096, 300, 286, 390, 18315, 412, 264, 2863, 13, 407, 341, 307, 337, 264, 733, 295, 51064], "temperature": 0.0, "avg_logprob": -0.059130759178837644, "compression_ratio": 1.691588785046729, "no_speech_prob": 0.001078302855603397}, {"id": 198, "seek": 152768, "start": 1541.68, "end": 1546.16, "text": " information that cannot be generated automatically from code. So this is not for things like API", "tokens": [51064, 1589, 300, 2644, 312, 10833, 6772, 490, 3089, 13, 407, 341, 307, 406, 337, 721, 411, 9362, 51288], "temperature": 0.0, "avg_logprob": -0.059130759178837644, "compression_ratio": 1.691588785046729, "no_speech_prob": 0.001078302855603397}, {"id": 199, "seek": 152768, "start": 1546.16, "end": 1553.68, "text": " reference. This is for things like emerging properties of various features. So something", "tokens": [51288, 6408, 13, 639, 307, 337, 721, 411, 14989, 7221, 295, 3683, 4122, 13, 407, 746, 51664], "temperature": 0.0, "avg_logprob": -0.059130759178837644, "compression_ratio": 1.691588785046729, "no_speech_prob": 0.001078302855603397}, {"id": 200, "seek": 155368, "start": 1553.68, "end": 1561.04, "text": " that is not just a flag in the code. This is something that the product teams will be responsible", "tokens": [50364, 300, 307, 406, 445, 257, 7166, 294, 264, 3089, 13, 639, 307, 746, 300, 264, 1674, 5491, 486, 312, 6250, 50732], "temperature": 0.0, "avg_logprob": -0.10569208721781886, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.000878544757142663}, {"id": 201, "seek": 155368, "start": 1561.04, "end": 1570.0800000000002, "text": " for. And having using graph for this means that they'll be able to have the same familiar user", "tokens": [50732, 337, 13, 400, 1419, 1228, 4295, 337, 341, 1355, 300, 436, 603, 312, 1075, 281, 362, 264, 912, 4963, 4195, 51184], "temperature": 0.0, "avg_logprob": -0.10569208721781886, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.000878544757142663}, {"id": 202, "seek": 155368, "start": 1570.0800000000002, "end": 1577.1200000000001, "text": " experience when inputting information about their product as well. So then in the future,", "tokens": [51184, 1752, 562, 4846, 783, 1589, 466, 641, 1674, 382, 731, 13, 407, 550, 294, 264, 2027, 11, 51536], "temperature": 0.0, "avg_logprob": -0.10569208721781886, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.000878544757142663}, {"id": 203, "seek": 155368, "start": 1578.0800000000002, "end": 1582.0800000000002, "text": " other systems, whether they're running graph or not, will be able to use the same information", "tokens": [51584, 661, 3652, 11, 1968, 436, 434, 2614, 4295, 420, 406, 11, 486, 312, 1075, 281, 764, 264, 912, 1589, 51784], "temperature": 0.0, "avg_logprob": -0.10569208721781886, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.000878544757142663}, {"id": 204, "seek": 158208, "start": 1583.04, "end": 1593.28, "text": " that will be accurately rendered in all these different portals. So maybe see you in another four", "tokens": [50412, 300, 486, 312, 20095, 28748, 294, 439, 613, 819, 2436, 1124, 13, 407, 1310, 536, 291, 294, 1071, 1451, 50924], "temperature": 0.0, "avg_logprob": -0.08658908843994141, "compression_ratio": 1.3868613138686132, "no_speech_prob": 0.0007768251816742122}, {"id": 205, "seek": 158208, "start": 1593.28, "end": 1607.6, "text": " years to tell you how this one went. So let's move on to the Q&A session. Thank you for your", "tokens": [50924, 924, 281, 980, 291, 577, 341, 472, 1437, 13, 407, 718, 311, 1286, 322, 281, 264, 1249, 5, 32, 5481, 13, 1044, 291, 337, 428, 51640], "temperature": 0.0, "avg_logprob": -0.08658908843994141, "compression_ratio": 1.3868613138686132, "no_speech_prob": 0.0007768251816742122}, {"id": 206, "seek": 160760, "start": 1607.6, "end": 1609.6, "text": " attention and see you in a bit.", "tokens": [50364, 3202, 293, 536, 291, 294, 257, 857, 13, 50464], "temperature": 0.0, "avg_logprob": -0.36871706114874947, "compression_ratio": 1.23, "no_speech_prob": 0.0230543315410614}, {"id": 207, "seek": 160760, "start": 1626.1599999999999, "end": 1635.36, "text": " Okay, so thank you. I think that we have so we just have a couple of minutes for questions.", "tokens": [51292, 1033, 11, 370, 1309, 291, 13, 286, 519, 300, 321, 362, 370, 321, 445, 362, 257, 1916, 295, 2077, 337, 1651, 13, 51752], "temperature": 0.0, "avg_logprob": -0.36871706114874947, "compression_ratio": 1.23, "no_speech_prob": 0.0230543315410614}, {"id": 208, "seek": 163536, "start": 1636.32, "end": 1642.4799999999998, "text": " And then in three minutes, we'll get into the next talk. So if you have any questions,", "tokens": [50412, 400, 550, 294, 1045, 2077, 11, 321, 603, 483, 666, 264, 958, 751, 13, 407, 498, 291, 362, 604, 1651, 11, 50720], "temperature": 0.0, "avg_logprob": -0.21028946895225376, "compression_ratio": 1.5636363636363637, "no_speech_prob": 0.036752671003341675}, {"id": 209, "seek": 163536, "start": 1646.1599999999999, "end": 1647.6, "text": " don't hesitate to put it in the chat.", "tokens": [50904, 500, 380, 20842, 281, 829, 309, 294, 264, 5081, 13, 50976], "temperature": 0.0, "avg_logprob": -0.21028946895225376, "compression_ratio": 1.5636363636363637, "no_speech_prob": 0.036752671003341675}, {"id": 210, "seek": 163536, "start": 1650.6399999999999, "end": 1653.12, "text": " In three minutes, we'll get into the next talk.", "tokens": [51128, 682, 1045, 2077, 11, 321, 603, 483, 666, 264, 958, 751, 13, 51252], "temperature": 0.0, "avg_logprob": -0.21028946895225376, "compression_ratio": 1.5636363636363637, "no_speech_prob": 0.036752671003341675}, {"id": 211, "seek": 165312, "start": 1654.0, "end": 1667.6, "text": " Yeah, I did put a question. Me, Andrea, the speaker, have put a question in my own talk.", "tokens": [50408, 865, 11, 286, 630, 829, 257, 1168, 13, 1923, 11, 24215, 11, 264, 8145, 11, 362, 829, 257, 1168, 294, 452, 1065, 751, 13, 51088], "temperature": 0.0, "avg_logprob": -0.21456830397896146, "compression_ratio": 1.4456521739130435, "no_speech_prob": 0.005188878159970045}, {"id": 212, "seek": 165312, "start": 1667.6, "end": 1672.2399999999998, "text": " Because I was wondering, I was curious how many people would already be familiar and", "tokens": [51088, 1436, 286, 390, 6359, 11, 286, 390, 6369, 577, 867, 561, 576, 1217, 312, 4963, 293, 51320], "temperature": 0.0, "avg_logprob": -0.21456830397896146, "compression_ratio": 1.4456521739130435, "no_speech_prob": 0.005188878159970045}, {"id": 213, "seek": 165312, "start": 1672.2399999999998, "end": 1676.2399999999998, "text": " with graph because me, like myself, I only found out about it when I started my current job.", "tokens": [51320, 365, 4295, 570, 385, 11, 411, 2059, 11, 286, 787, 1352, 484, 466, 309, 562, 286, 1409, 452, 2190, 1691, 13, 51520], "temperature": 0.0, "avg_logprob": -0.21456830397896146, "compression_ratio": 1.4456521739130435, "no_speech_prob": 0.005188878159970045}, {"id": 214, "seek": 167624, "start": 1676.96, "end": 1682.8, "text": " So, yeah, I was just curious within the community if there are people who use it,", "tokens": [50400, 407, 11, 1338, 11, 286, 390, 445, 6369, 1951, 264, 1768, 498, 456, 366, 561, 567, 764, 309, 11, 50692], "temperature": 0.0, "avg_logprob": -0.24155624492748365, "compression_ratio": 1.497142857142857, "no_speech_prob": 0.03402587026357651}, {"id": 215, "seek": 167624, "start": 1682.8, "end": 1686.8, "text": " but it seems that it's, well, at least amongst the people here is not that", "tokens": [50692, 457, 309, 2544, 300, 309, 311, 11, 731, 11, 412, 1935, 12918, 264, 561, 510, 307, 406, 300, 50892], "temperature": 0.0, "avg_logprob": -0.24155624492748365, "compression_ratio": 1.497142857142857, "no_speech_prob": 0.03402587026357651}, {"id": 216, "seek": 167624, "start": 1689.04, "end": 1689.52, "text": " well-known.", "tokens": [51004, 731, 12, 6861, 13, 51028], "temperature": 0.0, "avg_logprob": -0.24155624492748365, "compression_ratio": 1.497142857142857, "no_speech_prob": 0.03402587026357651}, {"id": 217, "seek": 167624, "start": 1698.16, "end": 1704.32, "text": " Indeed, on Mayan, at least I didn't know about it. Since we started talking about it at first", "tokens": [51460, 15061, 11, 322, 1891, 282, 11, 412, 1935, 286, 994, 380, 458, 466, 309, 13, 4162, 321, 1409, 1417, 466, 309, 412, 700, 51768], "temperature": 0.0, "avg_logprob": -0.24155624492748365, "compression_ratio": 1.497142857142857, "no_speech_prob": 0.03402587026357651}, {"id": 218, "seek": 170432, "start": 1705.28, "end": 1709.9199999999998, "text": " I think it was one or two years ago, but it's nice to see that it's also evolving.", "tokens": [50412, 286, 519, 309, 390, 472, 420, 732, 924, 2057, 11, 457, 309, 311, 1481, 281, 536, 300, 309, 311, 611, 21085, 13, 50644], "temperature": 0.0, "avg_logprob": -0.3669652039150022, "compression_ratio": 1.347457627118644, "no_speech_prob": 0.09345311671495438}, {"id": 219, "seek": 170432, "start": 1722.96, "end": 1724.3999999999999, "text": " Yeah, there has been one.", "tokens": [51296, 865, 11, 456, 575, 668, 472, 13, 51368], "temperature": 0.0, "avg_logprob": -0.3669652039150022, "compression_ratio": 1.347457627118644, "no_speech_prob": 0.09345311671495438}, {"id": 220, "seek": 170432, "start": 1729.52, "end": 1731.12, "text": " Yeah, sorry, there is a bit of a quarrel, I think.", "tokens": [51624, 865, 11, 2597, 11, 456, 307, 257, 857, 295, 257, 4723, 4419, 11, 286, 519, 13, 51704], "temperature": 0.0, "avg_logprob": -0.3669652039150022, "compression_ratio": 1.347457627118644, "no_speech_prob": 0.09345311671495438}, {"id": 221, "seek": 173112, "start": 1732.08, "end": 1736.08, "text": " Yeah, I'm not sure which stream to mute.", "tokens": [50412, 865, 11, 286, 478, 406, 988, 597, 4309, 281, 24523, 13, 50612], "temperature": 0.0, "avg_logprob": -0.21402532760411092, "compression_ratio": 1.4145077720207253, "no_speech_prob": 0.015095959417521954}, {"id": 222, "seek": 173112, "start": 1737.52, "end": 1740.6399999999999, "text": " Should one of us maybe read the question that was asked in the chat?", "tokens": [50684, 6454, 472, 295, 505, 1310, 1401, 264, 1168, 300, 390, 2351, 294, 264, 5081, 30, 50840], "temperature": 0.0, "avg_logprob": -0.21402532760411092, "compression_ratio": 1.4145077720207253, "no_speech_prob": 0.015095959417521954}, {"id": 223, "seek": 173112, "start": 1747.84, "end": 1752.4799999999998, "text": " So, the question from Mungal, is there any integration with ECM CSP products to include", "tokens": [51200, 407, 11, 264, 1168, 490, 376, 1063, 304, 11, 307, 456, 604, 10980, 365, 19081, 44, 9460, 47, 3383, 281, 4090, 51432], "temperature": 0.0, "avg_logprob": -0.21402532760411092, "compression_ratio": 1.4145077720207253, "no_speech_prob": 0.015095959417521954}, {"id": 224, "seek": 173112, "start": 1752.4799999999998, "end": 1756.3999999999999, "text": " documents and preview on the website? I can see that NextCloud is provided,", "tokens": [51432, 8512, 293, 14281, 322, 264, 3144, 30, 286, 393, 536, 300, 3087, 32787, 307, 5649, 11, 51628], "temperature": 0.0, "avg_logprob": -0.21402532760411092, "compression_ratio": 1.4145077720207253, "no_speech_prob": 0.015095959417521954}, {"id": 225, "seek": 175640, "start": 1756.5600000000002, "end": 1760.8000000000002, "text": " but only for backup purposes.", "tokens": [50372, 457, 787, 337, 14807, 9932, 13, 50584], "temperature": 0.0, "avg_logprob": -0.2018263662183607, "compression_ratio": 1.434065934065934, "no_speech_prob": 0.003859536023810506}, {"id": 226, "seek": 175640, "start": 1764.16, "end": 1773.92, "text": " Yeah, so, like I said, we do use NextCloud, but we don't embed it in the", "tokens": [50752, 865, 11, 370, 11, 411, 286, 848, 11, 321, 360, 764, 3087, 32787, 11, 457, 321, 500, 380, 12240, 309, 294, 264, 51240], "temperature": 0.0, "avg_logprob": -0.2018263662183607, "compression_ratio": 1.434065934065934, "no_speech_prob": 0.003859536023810506}, {"id": 227, "seek": 175640, "start": 1774.64, "end": 1778.48, "text": " internal knowledge base per se. So, for any need to access that, we link out.", "tokens": [51276, 6920, 3601, 3096, 680, 369, 13, 407, 11, 337, 604, 643, 281, 2105, 300, 11, 321, 2113, 484, 13, 51468], "temperature": 0.0, "avg_logprob": -0.2018263662183607, "compression_ratio": 1.434065934065934, "no_speech_prob": 0.003859536023810506}, {"id": 228, "seek": 175640, "start": 1779.3600000000001, "end": 1782.96, "text": " I'm pretty sure part of the reason for that is because some NextCloud files have", "tokens": [51512, 286, 478, 1238, 988, 644, 295, 264, 1778, 337, 300, 307, 570, 512, 3087, 32787, 7098, 362, 51692], "temperature": 0.0, "avg_logprob": -0.2018263662183607, "compression_ratio": 1.434065934065934, "no_speech_prob": 0.003859536023810506}, {"id": 229, "seek": 178296, "start": 1782.96, "end": 1789.2, "text": " restricted access and having this double layer of access restriction", "tokens": [50364, 20608, 2105, 293, 1419, 341, 3834, 4583, 295, 2105, 29529, 50676], "temperature": 0.0, "avg_logprob": -0.2236739520368905, "compression_ratio": 1.4746835443037976, "no_speech_prob": 0.005403169430792332}, {"id": 230, "seek": 178296, "start": 1790.56, "end": 1796.24, "text": " was seemed a bit unnecessary, but I don't think we've had requests for it either.", "tokens": [50744, 390, 6576, 257, 857, 19350, 11, 457, 286, 500, 380, 519, 321, 600, 632, 12475, 337, 309, 2139, 13, 51028], "temperature": 0.0, "avg_logprob": -0.2236739520368905, "compression_ratio": 1.4746835443037976, "no_speech_prob": 0.005403169430792332}, {"id": 231, "seek": 178296, "start": 1800.16, "end": 1806.4, "text": " Cool, so, I think that no, if anyone wants to ask some questions, we have the room", "tokens": [51224, 8561, 11, 370, 11, 286, 519, 300, 572, 11, 498, 2878, 2738, 281, 1029, 512, 1651, 11, 321, 362, 264, 1808, 51536], "temperature": 0.0, "avg_logprob": -0.2236739520368905, "compression_ratio": 1.4746835443037976, "no_speech_prob": 0.005403169430792332}, {"id": 232, "seek": 180640, "start": 1807.2800000000002, "end": 1814.16, "text": " that we are discussing in, which is now open. So, I guess that you can take questions here.", "tokens": [50408, 300, 321, 366, 10850, 294, 11, 597, 307, 586, 1269, 13, 407, 11, 286, 2041, 300, 291, 393, 747, 1651, 510, 13, 50752], "temperature": 0.0, "avg_logprob": -0.20687665644380235, "compression_ratio": 1.5324675324675325, "no_speech_prob": 0.0842554122209549}, {"id": 233, "seek": 180640, "start": 1814.16, "end": 1819.2, "text": " On my end, I will switch to the next talk for the dev room. So, thanks a lot, Andrea,", "tokens": [50752, 1282, 452, 917, 11, 286, 486, 3679, 281, 264, 958, 751, 337, 264, 1905, 1808, 13, 407, 11, 3231, 257, 688, 11, 24215, 11, 51004], "temperature": 0.0, "avg_logprob": -0.20687665644380235, "compression_ratio": 1.5324675324675325, "no_speech_prob": 0.0842554122209549}, {"id": 234, "seek": 180640, "start": 1819.2, "end": 1823.44, "text": " for coming and thanks for your presentation. It should be online on the website very soon,", "tokens": [51004, 337, 1348, 293, 3231, 337, 428, 5860, 13, 467, 820, 312, 2950, 322, 264, 3144, 588, 2321, 11, 51216], "temperature": 0.0, "avg_logprob": -0.20687665644380235, "compression_ratio": 1.5324675324675325, "no_speech_prob": 0.0842554122209549}, {"id": 235, "seek": 180640, "start": 1824.16, "end": 1829.6000000000001, "text": " if I'm not mistaken. Yeah, thanks for having me. I'll see you around. Thank you. Bye.", "tokens": [51252, 498, 286, 478, 406, 21333, 13, 865, 11, 3231, 337, 1419, 385, 13, 286, 603, 536, 291, 926, 13, 1044, 291, 13, 4621, 13, 51524], "temperature": 0.0, "avg_logprob": -0.20687665644380235, "compression_ratio": 1.5324675324675325, "no_speech_prob": 0.0842554122209549}, {"id": 236, "seek": 186640, "start": 1866.4, "end": 1867.2, "text": " Bye.", "tokens": [50380, 4621, 13, 50404], "temperature": 0.0, "avg_logprob": -0.9588758468627929, "compression_ratio": 0.3333333333333333, "no_speech_prob": 0.9345953464508057}, {"id": 237, "seek": 189640, "start": 1896.4, "end": 1897.7800000000002, "text": " you", "tokens": [50404, 291, 50433], "temperature": 0.0, "avg_logprob": -0.9598405957221985, "compression_ratio": 0.2727272727272727, "no_speech_prob": 0.9452734589576721}], "language": "en"}