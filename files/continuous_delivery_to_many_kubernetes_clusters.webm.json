{"text": " Hello. Thank you for coming to my talk. It's not a TED talk, but it's just my talk. Continuous delivery to many Kubernetes clusters. My name is Carlos Sanchez and I'm here to talk to you about our live experience, real world. I'm not here to sell you anything. So at least I'll try to tell you if I have time some of the mistakes we made too. She's not all beautiful and wonderful. So I'm a principal scientist at Adobe Experience Manager Cloud Service. I'll talk a little bit about the product. On the open source side, I started the Jenkins Kubernetes plug-in. Anybody heard about Jenkins? Yes, some people probably, yeah. Okay. And I'm a Kubernetes. Anybody heard about Kubernetes? Yeah? Okay. Anybody using Kubernetes in production? So I'm a long time contributor to open source. There are multiple projects on Jenkins, Apache Foundation and all that. So a quick intro to what Adobe Experience Manager is because people, every time I say Adobe, people say Photoshop and PDF and Flash, yeah. So that's not any of those, right? So this is a content management system that you probably never heard of, but it's powering 80% of the 4100 and it's very, very enterprise. I'm not expecting people to know, but this is widely used because it's based in a lot of open source. It's a distributed OSGI application that was started many years ago and uses a lot of components of open source from the Apache Foundation and we contribute back to those components like Felix, Apache Felix, Sling and a few things about content management there. And it has a huge market of extension developers, people that are writing their own Java code that then runs on Adobe Experience Manager and AM. So when I joined Adobe, the goal was, let's move this into a cloud service and this is running AM on Kubernetes. We're running currently on Azure and we have 35 clusters and growing very quickly because this is a content management. We run it in multiple regions, right now 11, so multiple ones in the US, Europe, Australia, Singapore, Japan, whatever, because people want to have low latency between their users and the content. And then another interesting fact is that we have the Kubernetes clusters. We don't run them directly. We build stuff on top of them and we have a different team at Adobe that manages Kubernetes for us. Some curiosities is like customers can run their own code, so we are running this for them and we take their code and run it inside our processes. So we have to limit clusters permissions for security and we have several security concerns because this is a very multi-tenant setup. Each customer can have multiple environments, multiple copies and they can self-service, so they can deploy new environments whenever they want, they can update them and do a few things, so it's not just us controlling what is running, it's also the customers. Each customer can have three or more Kubernetes namespaces where these environments run and this, I like to call this a micromanolith. So we don't run a big service that spans like thousands of instances, we run slightly different versions of the same service over a thousand, ten thousand times. So micromanolith defines it very well. And then we use namespace Kubernetes namespaces to provide the scope on network isolation, quotas, permissions and so on. Now internally we have multiple teams building services, so different services have different requirements, they have people can use different languages and we are more in a philosophy of you build it, you run it. And we are basically doing each services post as an API or we follow the Kubernetes operator patterns. We also use to split the monolith, we use a lot of init containers and sidecars, if you know in Kubernetes you can run multiple containers at the same time, so the main application runs in one container and then we have to apply division of concern, many sidecars that do different things. And it's an easy way to split separate concerns without having to rewrite your whole architecture to go to a fully network-based, micro-service oriented architecture. So on the continuous delivery side, which is probably what you are interested in here, we are running, we are moving to a, from a generally release to, I mean we are pushing changes daily multiple times, right? Not only, not just the application, the application may be slower to move, but on the operational side and all the services and operators, micro-service, all these things, all of them together, any of them at any point in time, any day can receive changes. So we use Jenkins for CI CD in some places, we have Tecton, you heard about that in one of the talks before, it's another open source project to do workflows on Kubernetes, to orchestrate some pipelines and we also started using Argo CD for some new micro-services. We follow a GitOps process, so where most of the configuration is a storing Git and it's reconciling each commit, right? And we use a pull versus push model to scale. And I'll go through this in a bit. We have a combination of multiple things being deployed to the clusters. We have the AM application that is deployed with a Helm chart. We have operation services that are on operators and services and all the other things that are not the application. These are deployed using Kubernetes files but templatized. And we are also using customized and Argo CD for some new micro-services. On the Helm side, we use the Helm operator. So in each namespace, we use the Helm operator CRDs to do a more state-based installation of Helm. So we create the CRD and the Helm operator is going to install the application based on the parameters on the CRD. A word of advice is don't mix application and infrastructure, infrastructural configuration on the same package because if you cannot enforce the same Helm chart for old tenants. For example, as I mentioned before, customers can decide when to update things, right? So we have some customers in older releases and some once in newer releases. This is something that we want to change. But in the meantime, if we want to update a specific version of something in an old release, it's hard when this is already packaged on Helm. So we built a solution for this. So from the platform level, we can go and manipulate this Helm chart. So we can have overrides and this is easy to do when you have the Helm operator. So you can inject, whenever there's a request to install a new Helm chart, we change parameters. So we change both Helm values. This is easy. Instead of passing some values, you pass different ones. Or you can use customized patches. And this is also support from the Helm operator. This is also support for customized patches. And customized patches are very interesting because they allow you to patch any Kubernetes resource. So even if there was no previous Helm value defined for it. So if we want to change a sidecar container image version across the whole fleet, we just have to change the patch. And this patch is going to be applied to all the clusters, all the namespaces. And all the Helm charts that were installed are going to get reinstalled with the right version that we want. So we do this combination of both Helm chart and then operational values on the other hand. Very important for us was the shift left mentality, right? Detecting problems as soon as possible. Not waiting for developers to push things to production because the cost increases. So we run checks as soon as we can on pull requests. So this is still fresh in your memory when you make a change and something is broken. You want to catch it as soon as possible. And we do this by generating all these templates. We have some tests that generate these templates and then apply tests, multiple tests on them. The most basic check that you can run is the apply QCTL, apply the right run. This will tell you if the manifest is wrong in some very obvious way. So if it's valid or it's not valid. Cube conform is a tool that will allow you to validate the Kubernetes schemas. So this is the successor of Kubeval. Anybody heard about Kubeval or Kubeconform? Okay. So this is very useful for if you have custom CRDs or just to make sure typical problems are you, you miss the jammer indentation and now it's not valid anymore and then you catch this on a PR. You just run this and it will tell you, you know, this property is missing or this is property is in the wrong place because everybody loves jammer, right? Conf test is another tool for open policy agents. Any people familiar with open policy agents? Open policy, OPA. So OPA allows you to write policies where you can go and pretty much check anything in any structure file. In the case of Kubernetes, you could say, I don't know, don't mount, don't run the pod as root. Make sure you don't mount secrets as environment variables or with files. Make sure, enforce that all the pods have some labels. Any random thing that you can think of, you can do it. And like, don't pull from Docker Hub, pull from the internal registry. You can do that with Conf test and OPA policies. The only problem is that it uses the regular language that if you haven't heard of, it's very painful to work with, but it works great once you try to figure out. We added another tool which is called Pluto. Pluto is just a CLI that will tell you what API versions have been deprecated or removed. So if you are running, if you are thinking about upgrading Kubernetes, you run Pluto and it will tell you, you know, this is deprecated, it's going to be removed in this version and so on. So you can enforce that. We built a tool that we call Git init, which is our own version of a GitOps pool. So we have the Kubernetes definitions storing Git and we deploy these to blob stores across regions. So they are pulled in each cluster. And Git init is a deployment that runs continuously on each namespace. We have around 10,000 namespaces in our fleet. So it basically pulls the blob, applies the changes and does this thing every so often. And an example of why we do a pool versus pool, because pushing to all the clusters, we have a job that does this and it runs in parallel, like in 20 threads or something, and still takes like five hours to run. So we cannot push things when we want. On Argo CD, we have a newcast platform that allows you to do Argo CD-based microservices. Argo CD, basically, this would create a new Git repo, it would come with some templates and that would get deployed with Argo CD to the cluster. And this is for us, we are thinking about moving this way and each team will have their own Git repo, because right now we have mostly centralized operators and everything. And this is good for the, okay, you go on your own direction, you do whatever you want, you build it, you run it. On the other hand, it's a bit tricky because when we decide or figure out something is problematic, we cannot just centrally say, you know, on this Git repo tell me who is doing this and let's change it. But we are moving towards that direction. Let me skip this and talk a bit about progressive delivery. So progressive delivery is a way, well, it's something that, it's a name for something that you've probably heard of, which is canary rollouts and doing percentage-based rollouts, feature flags, blue ring, so basically don't update everybody at the same time because you can break everybody. So we can do rollouts to different customer groups in separate waves and we can also do rollouts to percentage of customers. By default, we have a time-based rollout that goes from dev to stage to prod candidate after a period of time. And this is running on Jenkins and ensures that things have been running on dev on stage before we merge them to prod. I mean, this is very basic. What we built was feature flags at the namespace level. We have 10,000 namespaces and then the Kubernetes definition templates. So what we allow developers to do is for each namespace, they can decide, I want to roll out this change to this environment, dev, stage, or prod, or I want to deploy this change to a specific cluster or by template namespace type of, yeah, type of namespace or a percentage. And this is just using templates on Kubernetes objects. So an example is, in this case, a rule, sorry, a Kubernetes definition where you can have a template that is as full version or bar version, or you can enable a container, a sidecar container, or disable it. And then at the bottom, you can see the rules. So by default, we want full version to be 1.0, but for the namespace, all the namespaces on the dev environment, we want that to be 1.1. So this allows us to quickly roll out changes, but progressively. We can also do it for percentiles. So in this case, we could say, I want all the namespaces in dev and all the namespaces in a stage to have this full version 1.1 and enable matter rule true, but for prod, I only want 5%. So I roll out a change to 5% of prod, and then I can continue after that. So this has proven really useful for developers to test in safely, increases development in speed, PRs are much faster, so it's all great. And we are thinking about, well, we're thinking, we are working on getting ARGOR rollouts also at the deployment level. ARGOR rollouts allows you to do blue-green and canary rollouts, where you can say, progress the number of pods over a period of time, so instead of changing, I don't know, 10 pods at the same time, because one by one, and if you have a service mesh, you can go even more fine-grained and say, I want 5% of the traffic to go to the old version, to the new version, everything else to the old version, and keep progressing that and do automatic rollbacks. So, yes. So, yeah. With the service mesh, you can fine-tune the traffic percentages, but with Kubernetes services, you can still do it. It's just that we are limited with the number of pods. So to sum up, Shift left on Garrail, so keeping people safe on what they are doing, this increases development speed, reduces the issues that you are going to have in production, and you're never going to prevent having issues in production. What you can prevent is how many customers are affected and how fast you can fix them, right? So for us, what was very useful is the progressive delivery techniques, like canaries, percent of rollouts, or automated rollbacks, and the automation to do this, control and progressive rollout, pays off over time. So I think we have one minute for questions. Or you can find me afterwards. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 12.4, "text": " Hello. Thank you for coming to my talk. It's not a TED talk, but it's just my talk. Continuous", "tokens": [2425, 13, 1044, 291, 337, 1348, 281, 452, 751, 13, 467, 311, 406, 257, 43036, 751, 11, 457, 309, 311, 445, 452, 751, 13, 14674, 12549], "temperature": 0.0, "avg_logprob": -0.24514092625798406, "compression_ratio": 1.431578947368421, "no_speech_prob": 0.3499877452850342}, {"id": 1, "seek": 0, "start": 12.4, "end": 17.56, "text": " delivery to many Kubernetes clusters. My name is Carlos Sanchez and I'm here to talk to", "tokens": [8982, 281, 867, 23145, 23313, 13, 1222, 1315, 307, 19646, 5271, 30196, 293, 286, 478, 510, 281, 751, 281], "temperature": 0.0, "avg_logprob": -0.24514092625798406, "compression_ratio": 1.431578947368421, "no_speech_prob": 0.3499877452850342}, {"id": 2, "seek": 0, "start": 17.56, "end": 25.32, "text": " you about our live experience, real world. I'm not here to sell you anything. So at least", "tokens": [291, 466, 527, 1621, 1752, 11, 957, 1002, 13, 286, 478, 406, 510, 281, 3607, 291, 1340, 13, 407, 412, 1935], "temperature": 0.0, "avg_logprob": -0.24514092625798406, "compression_ratio": 1.431578947368421, "no_speech_prob": 0.3499877452850342}, {"id": 3, "seek": 2532, "start": 25.32, "end": 31.32, "text": " I'll try to tell you if I have time some of the mistakes we made too. She's not all beautiful", "tokens": [286, 603, 853, 281, 980, 291, 498, 286, 362, 565, 512, 295, 264, 8038, 321, 1027, 886, 13, 1240, 311, 406, 439, 2238], "temperature": 0.0, "avg_logprob": -0.226602201876433, "compression_ratio": 1.46, "no_speech_prob": 0.0011656132992357016}, {"id": 4, "seek": 2532, "start": 31.32, "end": 38.16, "text": " and wonderful. So I'm a principal scientist at Adobe Experience Manager Cloud Service.", "tokens": [293, 3715, 13, 407, 286, 478, 257, 9716, 12662, 412, 24862, 28503, 13821, 8061, 9561, 13], "temperature": 0.0, "avg_logprob": -0.226602201876433, "compression_ratio": 1.46, "no_speech_prob": 0.0011656132992357016}, {"id": 5, "seek": 2532, "start": 38.16, "end": 46.6, "text": " I'll talk a little bit about the product. On the open source side, I started the Jenkins", "tokens": [286, 603, 751, 257, 707, 857, 466, 264, 1674, 13, 1282, 264, 1269, 4009, 1252, 11, 286, 1409, 264, 41273], "temperature": 0.0, "avg_logprob": -0.226602201876433, "compression_ratio": 1.46, "no_speech_prob": 0.0011656132992357016}, {"id": 6, "seek": 2532, "start": 46.6, "end": 54.32, "text": " Kubernetes plug-in. Anybody heard about Jenkins? Yes, some people probably, yeah. Okay. And I'm", "tokens": [23145, 5452, 12, 259, 13, 19082, 2198, 466, 41273, 30, 1079, 11, 512, 561, 1391, 11, 1338, 13, 1033, 13, 400, 286, 478], "temperature": 0.0, "avg_logprob": -0.226602201876433, "compression_ratio": 1.46, "no_speech_prob": 0.0011656132992357016}, {"id": 7, "seek": 5432, "start": 54.32, "end": 60.24, "text": " a Kubernetes. Anybody heard about Kubernetes? Yeah? Okay. Anybody using Kubernetes in production?", "tokens": [257, 23145, 13, 19082, 2198, 466, 23145, 30, 865, 30, 1033, 13, 19082, 1228, 23145, 294, 4265, 30], "temperature": 0.0, "avg_logprob": -0.2737813374352834, "compression_ratio": 1.4467005076142132, "no_speech_prob": 0.0002838033251464367}, {"id": 8, "seek": 5432, "start": 60.24, "end": 69.56, "text": " So I'm a long time contributor to open source. There are multiple projects on Jenkins, Apache", "tokens": [407, 286, 478, 257, 938, 565, 42859, 281, 1269, 4009, 13, 821, 366, 3866, 4455, 322, 41273, 11, 46597], "temperature": 0.0, "avg_logprob": -0.2737813374352834, "compression_ratio": 1.4467005076142132, "no_speech_prob": 0.0002838033251464367}, {"id": 9, "seek": 5432, "start": 69.56, "end": 76.52, "text": " Foundation and all that. So a quick intro to what Adobe Experience Manager is because people,", "tokens": [10335, 293, 439, 300, 13, 407, 257, 1702, 12897, 281, 437, 24862, 28503, 13821, 307, 570, 561, 11], "temperature": 0.0, "avg_logprob": -0.2737813374352834, "compression_ratio": 1.4467005076142132, "no_speech_prob": 0.0002838033251464367}, {"id": 10, "seek": 7652, "start": 76.52, "end": 89.16, "text": " every time I say Adobe, people say Photoshop and PDF and Flash, yeah. So that's not any", "tokens": [633, 565, 286, 584, 24862, 11, 561, 584, 20821, 293, 17752, 293, 20232, 11, 1338, 13, 407, 300, 311, 406, 604], "temperature": 0.0, "avg_logprob": -0.23704356617397732, "compression_ratio": 1.4105263157894736, "no_speech_prob": 0.00013332166417967528}, {"id": 11, "seek": 7652, "start": 89.16, "end": 96.0, "text": " of those, right? So this is a content management system that you probably never heard of, but", "tokens": [295, 729, 11, 558, 30, 407, 341, 307, 257, 2701, 4592, 1185, 300, 291, 1391, 1128, 2198, 295, 11, 457], "temperature": 0.0, "avg_logprob": -0.23704356617397732, "compression_ratio": 1.4105263157894736, "no_speech_prob": 0.00013332166417967528}, {"id": 12, "seek": 7652, "start": 96.0, "end": 103.08, "text": " it's powering 80% of the 4100 and it's very, very enterprise. I'm not expecting people", "tokens": [309, 311, 1347, 278, 4688, 4, 295, 264, 1017, 6879, 293, 309, 311, 588, 11, 588, 14132, 13, 286, 478, 406, 9650, 561], "temperature": 0.0, "avg_logprob": -0.23704356617397732, "compression_ratio": 1.4105263157894736, "no_speech_prob": 0.00013332166417967528}, {"id": 13, "seek": 10308, "start": 103.08, "end": 112.36, "text": " to know, but this is widely used because it's based in a lot of open source. It's a distributed", "tokens": [281, 458, 11, 457, 341, 307, 13371, 1143, 570, 309, 311, 2361, 294, 257, 688, 295, 1269, 4009, 13, 467, 311, 257, 12631], "temperature": 0.0, "avg_logprob": -0.2018306058995864, "compression_ratio": 1.6106194690265487, "no_speech_prob": 0.00023869371216278523}, {"id": 14, "seek": 10308, "start": 112.36, "end": 118.0, "text": " OSGI application that was started many years ago and uses a lot of components of open source", "tokens": [12731, 26252, 3861, 300, 390, 1409, 867, 924, 2057, 293, 4960, 257, 688, 295, 6677, 295, 1269, 4009], "temperature": 0.0, "avg_logprob": -0.2018306058995864, "compression_ratio": 1.6106194690265487, "no_speech_prob": 0.00023869371216278523}, {"id": 15, "seek": 10308, "start": 118.0, "end": 124.84, "text": " from the Apache Foundation and we contribute back to those components like Felix, Apache", "tokens": [490, 264, 46597, 10335, 293, 321, 10586, 646, 281, 729, 6677, 411, 30169, 11, 46597], "temperature": 0.0, "avg_logprob": -0.2018306058995864, "compression_ratio": 1.6106194690265487, "no_speech_prob": 0.00023869371216278523}, {"id": 16, "seek": 10308, "start": 124.84, "end": 131.8, "text": " Felix, Sling and a few things about content management there. And it has a huge market", "tokens": [30169, 11, 318, 1688, 293, 257, 1326, 721, 466, 2701, 4592, 456, 13, 400, 309, 575, 257, 2603, 2142], "temperature": 0.0, "avg_logprob": -0.2018306058995864, "compression_ratio": 1.6106194690265487, "no_speech_prob": 0.00023869371216278523}, {"id": 17, "seek": 13180, "start": 131.8, "end": 137.64000000000001, "text": " of extension developers, people that are writing their own Java code that then runs on Adobe", "tokens": [295, 10320, 8849, 11, 561, 300, 366, 3579, 641, 1065, 10745, 3089, 300, 550, 6676, 322, 24862], "temperature": 0.0, "avg_logprob": -0.19465568589001167, "compression_ratio": 1.521186440677966, "no_speech_prob": 0.0001228148612426594}, {"id": 18, "seek": 13180, "start": 137.64000000000001, "end": 146.12, "text": " Experience Manager and AM. So when I joined Adobe, the goal was, let's move this into", "tokens": [28503, 13821, 293, 6475, 13, 407, 562, 286, 6869, 24862, 11, 264, 3387, 390, 11, 718, 311, 1286, 341, 666], "temperature": 0.0, "avg_logprob": -0.19465568589001167, "compression_ratio": 1.521186440677966, "no_speech_prob": 0.0001228148612426594}, {"id": 19, "seek": 13180, "start": 146.12, "end": 153.68, "text": " a cloud service and this is running AM on Kubernetes. We're running currently on Azure", "tokens": [257, 4588, 2643, 293, 341, 307, 2614, 6475, 322, 23145, 13, 492, 434, 2614, 4362, 322, 11969], "temperature": 0.0, "avg_logprob": -0.19465568589001167, "compression_ratio": 1.521186440677966, "no_speech_prob": 0.0001228148612426594}, {"id": 20, "seek": 13180, "start": 153.68, "end": 160.64000000000001, "text": " and we have 35 clusters and growing very quickly because this is a content management. We run", "tokens": [293, 321, 362, 6976, 23313, 293, 4194, 588, 2661, 570, 341, 307, 257, 2701, 4592, 13, 492, 1190], "temperature": 0.0, "avg_logprob": -0.19465568589001167, "compression_ratio": 1.521186440677966, "no_speech_prob": 0.0001228148612426594}, {"id": 21, "seek": 16064, "start": 160.64, "end": 167.39999999999998, "text": " it in multiple regions, right now 11, so multiple ones in the US, Europe, Australia, Singapore,", "tokens": [309, 294, 3866, 10682, 11, 558, 586, 2975, 11, 370, 3866, 2306, 294, 264, 2546, 11, 3315, 11, 7060, 11, 14491, 11], "temperature": 0.0, "avg_logprob": -0.22026959587545955, "compression_ratio": 1.5517241379310345, "no_speech_prob": 0.0004108357825316489}, {"id": 22, "seek": 16064, "start": 167.39999999999998, "end": 176.16, "text": " Japan, whatever, because people want to have low latency between their users and the content.", "tokens": [3367, 11, 2035, 11, 570, 561, 528, 281, 362, 2295, 27043, 1296, 641, 5022, 293, 264, 2701, 13], "temperature": 0.0, "avg_logprob": -0.22026959587545955, "compression_ratio": 1.5517241379310345, "no_speech_prob": 0.0004108357825316489}, {"id": 23, "seek": 16064, "start": 176.16, "end": 182.79999999999998, "text": " And then another interesting fact is that we have the Kubernetes clusters. We don't", "tokens": [400, 550, 1071, 1880, 1186, 307, 300, 321, 362, 264, 23145, 23313, 13, 492, 500, 380], "temperature": 0.0, "avg_logprob": -0.22026959587545955, "compression_ratio": 1.5517241379310345, "no_speech_prob": 0.0004108357825316489}, {"id": 24, "seek": 16064, "start": 182.79999999999998, "end": 187.32, "text": " run them directly. We build stuff on top of them and we have a different team at Adobe", "tokens": [1190, 552, 3838, 13, 492, 1322, 1507, 322, 1192, 295, 552, 293, 321, 362, 257, 819, 1469, 412, 24862], "temperature": 0.0, "avg_logprob": -0.22026959587545955, "compression_ratio": 1.5517241379310345, "no_speech_prob": 0.0004108357825316489}, {"id": 25, "seek": 18732, "start": 187.32, "end": 195.12, "text": " that manages Kubernetes for us. Some curiosities is like customers can run their own code,", "tokens": [300, 22489, 23145, 337, 505, 13, 2188, 13625, 1088, 307, 411, 4581, 393, 1190, 641, 1065, 3089, 11], "temperature": 0.0, "avg_logprob": -0.1394757906595866, "compression_ratio": 1.6071428571428572, "no_speech_prob": 0.0001285775942960754}, {"id": 26, "seek": 18732, "start": 195.12, "end": 202.64, "text": " so we are running this for them and we take their code and run it inside our processes.", "tokens": [370, 321, 366, 2614, 341, 337, 552, 293, 321, 747, 641, 3089, 293, 1190, 309, 1854, 527, 7555, 13], "temperature": 0.0, "avg_logprob": -0.1394757906595866, "compression_ratio": 1.6071428571428572, "no_speech_prob": 0.0001285775942960754}, {"id": 27, "seek": 18732, "start": 202.64, "end": 208.56, "text": " So we have to limit clusters permissions for security and we have several security concerns", "tokens": [407, 321, 362, 281, 4948, 23313, 32723, 337, 3825, 293, 321, 362, 2940, 3825, 7389], "temperature": 0.0, "avg_logprob": -0.1394757906595866, "compression_ratio": 1.6071428571428572, "no_speech_prob": 0.0001285775942960754}, {"id": 28, "seek": 20856, "start": 208.56, "end": 217.72, "text": " because this is a very multi-tenant setup. Each customer can have multiple environments,", "tokens": [570, 341, 307, 257, 588, 4825, 12, 1147, 394, 8657, 13, 6947, 5474, 393, 362, 3866, 12388, 11], "temperature": 0.0, "avg_logprob": -0.15248056737388052, "compression_ratio": 1.7376237623762376, "no_speech_prob": 0.0004033886652905494}, {"id": 29, "seek": 20856, "start": 217.72, "end": 224.56, "text": " multiple copies and they can self-service, so they can deploy new environments whenever", "tokens": [3866, 14341, 293, 436, 393, 2698, 12, 39279, 11, 370, 436, 393, 7274, 777, 12388, 5699], "temperature": 0.0, "avg_logprob": -0.15248056737388052, "compression_ratio": 1.7376237623762376, "no_speech_prob": 0.0004033886652905494}, {"id": 30, "seek": 20856, "start": 224.56, "end": 229.64000000000001, "text": " they want, they can update them and do a few things, so it's not just us controlling what", "tokens": [436, 528, 11, 436, 393, 5623, 552, 293, 360, 257, 1326, 721, 11, 370, 309, 311, 406, 445, 505, 14905, 437], "temperature": 0.0, "avg_logprob": -0.15248056737388052, "compression_ratio": 1.7376237623762376, "no_speech_prob": 0.0004033886652905494}, {"id": 31, "seek": 20856, "start": 229.64000000000001, "end": 234.68, "text": " is running, it's also the customers. Each customer can have three or more Kubernetes", "tokens": [307, 2614, 11, 309, 311, 611, 264, 4581, 13, 6947, 5474, 393, 362, 1045, 420, 544, 23145], "temperature": 0.0, "avg_logprob": -0.15248056737388052, "compression_ratio": 1.7376237623762376, "no_speech_prob": 0.0004033886652905494}, {"id": 32, "seek": 23468, "start": 234.68, "end": 241.8, "text": " namespaces where these environments run and this, I like to call this a micromanolith.", "tokens": [5288, 79, 2116, 689, 613, 12388, 1190, 293, 341, 11, 286, 411, 281, 818, 341, 257, 3123, 81, 4277, 29131, 13], "temperature": 0.0, "avg_logprob": -0.21905721467116784, "compression_ratio": 1.6635514018691588, "no_speech_prob": 0.0004953386960551143}, {"id": 33, "seek": 23468, "start": 241.8, "end": 248.96, "text": " So we don't run a big service that spans like thousands of instances, we run slightly", "tokens": [407, 321, 500, 380, 1190, 257, 955, 2643, 300, 44086, 411, 5383, 295, 14519, 11, 321, 1190, 4748], "temperature": 0.0, "avg_logprob": -0.21905721467116784, "compression_ratio": 1.6635514018691588, "no_speech_prob": 0.0004953386960551143}, {"id": 34, "seek": 23468, "start": 248.96, "end": 257.36, "text": " different versions of the same service over a thousand, ten thousand times. So micromanolith", "tokens": [819, 9606, 295, 264, 912, 2643, 670, 257, 4714, 11, 2064, 4714, 1413, 13, 407, 3123, 81, 4277, 29131], "temperature": 0.0, "avg_logprob": -0.21905721467116784, "compression_ratio": 1.6635514018691588, "no_speech_prob": 0.0004953386960551143}, {"id": 35, "seek": 23468, "start": 257.36, "end": 264.4, "text": " defines it very well. And then we use namespace Kubernetes namespaces to provide the scope", "tokens": [23122, 309, 588, 731, 13, 400, 550, 321, 764, 5288, 17940, 23145, 5288, 79, 2116, 281, 2893, 264, 11923], "temperature": 0.0, "avg_logprob": -0.21905721467116784, "compression_ratio": 1.6635514018691588, "no_speech_prob": 0.0004953386960551143}, {"id": 36, "seek": 26440, "start": 264.4, "end": 268.84, "text": " on network isolation, quotas, permissions and so on.", "tokens": [322, 3209, 16001, 11, 9641, 296, 11, 32723, 293, 370, 322, 13], "temperature": 0.0, "avg_logprob": -0.24472017923990885, "compression_ratio": 1.642156862745098, "no_speech_prob": 0.00029543187702074647}, {"id": 37, "seek": 26440, "start": 268.84, "end": 276.84, "text": " Now internally we have multiple teams building services, so different services have different", "tokens": [823, 19501, 321, 362, 3866, 5491, 2390, 3328, 11, 370, 819, 3328, 362, 819], "temperature": 0.0, "avg_logprob": -0.24472017923990885, "compression_ratio": 1.642156862745098, "no_speech_prob": 0.00029543187702074647}, {"id": 38, "seek": 26440, "start": 276.84, "end": 282.23999999999995, "text": " requirements, they have people can use different languages and we are more in a philosophy", "tokens": [7728, 11, 436, 362, 561, 393, 764, 819, 8650, 293, 321, 366, 544, 294, 257, 10675], "temperature": 0.0, "avg_logprob": -0.24472017923990885, "compression_ratio": 1.642156862745098, "no_speech_prob": 0.00029543187702074647}, {"id": 39, "seek": 26440, "start": 282.23999999999995, "end": 290.15999999999997, "text": " of you build it, you run it. And we are basically doing each services post as an API or we follow", "tokens": [295, 291, 1322, 309, 11, 291, 1190, 309, 13, 400, 321, 366, 1936, 884, 1184, 3328, 2183, 382, 364, 9362, 420, 321, 1524], "temperature": 0.0, "avg_logprob": -0.24472017923990885, "compression_ratio": 1.642156862745098, "no_speech_prob": 0.00029543187702074647}, {"id": 40, "seek": 29016, "start": 290.16, "end": 294.44, "text": " the Kubernetes operator patterns.", "tokens": [264, 23145, 12973, 8294, 13], "temperature": 0.0, "avg_logprob": -0.17010025075964025, "compression_ratio": 1.6685082872928176, "no_speech_prob": 0.00019806819909717888}, {"id": 41, "seek": 29016, "start": 294.44, "end": 301.28000000000003, "text": " We also use to split the monolith, we use a lot of init containers and sidecars, if", "tokens": [492, 611, 764, 281, 7472, 264, 1108, 29131, 11, 321, 764, 257, 688, 295, 3157, 17089, 293, 1252, 66, 685, 11, 498], "temperature": 0.0, "avg_logprob": -0.17010025075964025, "compression_ratio": 1.6685082872928176, "no_speech_prob": 0.00019806819909717888}, {"id": 42, "seek": 29016, "start": 301.28000000000003, "end": 307.28000000000003, "text": " you know in Kubernetes you can run multiple containers at the same time, so the main application", "tokens": [291, 458, 294, 23145, 291, 393, 1190, 3866, 17089, 412, 264, 912, 565, 11, 370, 264, 2135, 3861], "temperature": 0.0, "avg_logprob": -0.17010025075964025, "compression_ratio": 1.6685082872928176, "no_speech_prob": 0.00019806819909717888}, {"id": 43, "seek": 29016, "start": 307.28000000000003, "end": 312.92, "text": " runs in one container and then we have to apply division of concern, many sidecars that", "tokens": [6676, 294, 472, 10129, 293, 550, 321, 362, 281, 3079, 10044, 295, 3136, 11, 867, 1252, 66, 685, 300], "temperature": 0.0, "avg_logprob": -0.17010025075964025, "compression_ratio": 1.6685082872928176, "no_speech_prob": 0.00019806819909717888}, {"id": 44, "seek": 31292, "start": 312.92, "end": 320.6, "text": " do different things. And it's an easy way to split separate concerns without having", "tokens": [360, 819, 721, 13, 400, 309, 311, 364, 1858, 636, 281, 7472, 4994, 7389, 1553, 1419], "temperature": 0.0, "avg_logprob": -0.21049852219838944, "compression_ratio": 1.46524064171123, "no_speech_prob": 0.00018026864563580602}, {"id": 45, "seek": 31292, "start": 320.6, "end": 328.44, "text": " to rewrite your whole architecture to go to a fully network-based, micro-service oriented", "tokens": [281, 28132, 428, 1379, 9482, 281, 352, 281, 257, 4498, 3209, 12, 6032, 11, 4532, 12, 39279, 21841], "temperature": 0.0, "avg_logprob": -0.21049852219838944, "compression_ratio": 1.46524064171123, "no_speech_prob": 0.00018026864563580602}, {"id": 46, "seek": 31292, "start": 328.44, "end": 331.16, "text": " architecture.", "tokens": [9482, 13], "temperature": 0.0, "avg_logprob": -0.21049852219838944, "compression_ratio": 1.46524064171123, "no_speech_prob": 0.00018026864563580602}, {"id": 47, "seek": 31292, "start": 331.16, "end": 337.64, "text": " So on the continuous delivery side, which is probably what you are interested in here,", "tokens": [407, 322, 264, 10957, 8982, 1252, 11, 597, 307, 1391, 437, 291, 366, 3102, 294, 510, 11], "temperature": 0.0, "avg_logprob": -0.21049852219838944, "compression_ratio": 1.46524064171123, "no_speech_prob": 0.00018026864563580602}, {"id": 48, "seek": 33764, "start": 337.64, "end": 344.56, "text": " we are running, we are moving to a, from a generally release to, I mean we are pushing", "tokens": [321, 366, 2614, 11, 321, 366, 2684, 281, 257, 11, 490, 257, 5101, 4374, 281, 11, 286, 914, 321, 366, 7380], "temperature": 0.0, "avg_logprob": -0.20962578909737722, "compression_ratio": 1.704225352112676, "no_speech_prob": 0.0001758732250891626}, {"id": 49, "seek": 33764, "start": 344.56, "end": 352.47999999999996, "text": " changes daily multiple times, right? Not only, not just the application, the application", "tokens": [2962, 5212, 3866, 1413, 11, 558, 30, 1726, 787, 11, 406, 445, 264, 3861, 11, 264, 3861], "temperature": 0.0, "avg_logprob": -0.20962578909737722, "compression_ratio": 1.704225352112676, "no_speech_prob": 0.0001758732250891626}, {"id": 50, "seek": 33764, "start": 352.47999999999996, "end": 359.56, "text": " may be slower to move, but on the operational side and all the services and operators, micro-service,", "tokens": [815, 312, 14009, 281, 1286, 11, 457, 322, 264, 16607, 1252, 293, 439, 264, 3328, 293, 19077, 11, 4532, 12, 39279, 11], "temperature": 0.0, "avg_logprob": -0.20962578909737722, "compression_ratio": 1.704225352112676, "no_speech_prob": 0.0001758732250891626}, {"id": 51, "seek": 33764, "start": 359.56, "end": 366.2, "text": " all these things, all of them together, any of them at any point in time, any day can", "tokens": [439, 613, 721, 11, 439, 295, 552, 1214, 11, 604, 295, 552, 412, 604, 935, 294, 565, 11, 604, 786, 393], "temperature": 0.0, "avg_logprob": -0.20962578909737722, "compression_ratio": 1.704225352112676, "no_speech_prob": 0.0001758732250891626}, {"id": 52, "seek": 36620, "start": 366.2, "end": 369.64, "text": " receive changes.", "tokens": [4774, 2962, 13], "temperature": 0.0, "avg_logprob": -0.20441471563803182, "compression_ratio": 1.4314720812182742, "no_speech_prob": 0.00018918115529231727}, {"id": 53, "seek": 36620, "start": 369.64, "end": 377.64, "text": " So we use Jenkins for CI CD in some places, we have Tecton, you heard about that in one", "tokens": [407, 321, 764, 41273, 337, 37777, 6743, 294, 512, 3190, 11, 321, 362, 314, 557, 266, 11, 291, 2198, 466, 300, 294, 472], "temperature": 0.0, "avg_logprob": -0.20441471563803182, "compression_ratio": 1.4314720812182742, "no_speech_prob": 0.00018918115529231727}, {"id": 54, "seek": 36620, "start": 377.64, "end": 384.44, "text": " of the talks before, it's another open source project to do workflows on Kubernetes, to", "tokens": [295, 264, 6686, 949, 11, 309, 311, 1071, 1269, 4009, 1716, 281, 360, 43461, 322, 23145, 11, 281], "temperature": 0.0, "avg_logprob": -0.20441471563803182, "compression_ratio": 1.4314720812182742, "no_speech_prob": 0.00018918115529231727}, {"id": 55, "seek": 36620, "start": 384.44, "end": 392.84, "text": " orchestrate some pipelines and we also started using Argo CD for some new micro-services.", "tokens": [14161, 4404, 512, 40168, 293, 321, 611, 1409, 1228, 1587, 1571, 6743, 337, 512, 777, 4532, 12, 82, 47480, 13], "temperature": 0.0, "avg_logprob": -0.20441471563803182, "compression_ratio": 1.4314720812182742, "no_speech_prob": 0.00018918115529231727}, {"id": 56, "seek": 39284, "start": 392.84, "end": 399.56, "text": " We follow a GitOps process, so where most of the configuration is a storing Git and", "tokens": [492, 1524, 257, 16939, 36179, 1399, 11, 370, 689, 881, 295, 264, 11694, 307, 257, 26085, 16939, 293], "temperature": 0.0, "avg_logprob": -0.19452491363921723, "compression_ratio": 1.4682926829268292, "no_speech_prob": 0.00014902354450896382}, {"id": 57, "seek": 39284, "start": 399.56, "end": 406.76, "text": " it's reconciling each commit, right? And we use a pull versus push model to scale. And", "tokens": [309, 311, 9993, 3208, 278, 1184, 5599, 11, 558, 30, 400, 321, 764, 257, 2235, 5717, 2944, 2316, 281, 4373, 13, 400], "temperature": 0.0, "avg_logprob": -0.19452491363921723, "compression_ratio": 1.4682926829268292, "no_speech_prob": 0.00014902354450896382}, {"id": 58, "seek": 39284, "start": 406.76, "end": 410.76, "text": " I'll go through this in a bit.", "tokens": [286, 603, 352, 807, 341, 294, 257, 857, 13], "temperature": 0.0, "avg_logprob": -0.19452491363921723, "compression_ratio": 1.4682926829268292, "no_speech_prob": 0.00014902354450896382}, {"id": 59, "seek": 39284, "start": 410.76, "end": 417.67999999999995, "text": " We have a combination of multiple things being deployed to the clusters. We have the AM application", "tokens": [492, 362, 257, 6562, 295, 3866, 721, 885, 17826, 281, 264, 23313, 13, 492, 362, 264, 6475, 3861], "temperature": 0.0, "avg_logprob": -0.19452491363921723, "compression_ratio": 1.4682926829268292, "no_speech_prob": 0.00014902354450896382}, {"id": 60, "seek": 41768, "start": 417.68, "end": 424.24, "text": " that is deployed with a Helm chart. We have operation services that are on operators and", "tokens": [300, 307, 17826, 365, 257, 6128, 76, 6927, 13, 492, 362, 6916, 3328, 300, 366, 322, 19077, 293], "temperature": 0.0, "avg_logprob": -0.20055296801138614, "compression_ratio": 1.565934065934066, "no_speech_prob": 0.00015358423115685582}, {"id": 61, "seek": 41768, "start": 424.24, "end": 430.48, "text": " services and all the other things that are not the application. These are deployed using", "tokens": [3328, 293, 439, 264, 661, 721, 300, 366, 406, 264, 3861, 13, 1981, 366, 17826, 1228], "temperature": 0.0, "avg_logprob": -0.20055296801138614, "compression_ratio": 1.565934065934066, "no_speech_prob": 0.00015358423115685582}, {"id": 62, "seek": 41768, "start": 430.48, "end": 437.08, "text": " Kubernetes files but templatized. And we are also using customized and Argo CD for some", "tokens": [23145, 7098, 457, 9100, 267, 1602, 13, 400, 321, 366, 611, 1228, 30581, 293, 1587, 1571, 6743, 337, 512], "temperature": 0.0, "avg_logprob": -0.20055296801138614, "compression_ratio": 1.565934065934066, "no_speech_prob": 0.00015358423115685582}, {"id": 63, "seek": 41768, "start": 437.08, "end": 440.8, "text": " new micro-services.", "tokens": [777, 4532, 12, 82, 47480, 13], "temperature": 0.0, "avg_logprob": -0.20055296801138614, "compression_ratio": 1.565934065934066, "no_speech_prob": 0.00015358423115685582}, {"id": 64, "seek": 44080, "start": 440.8, "end": 448.8, "text": " On the Helm side, we use the Helm operator. So in each namespace, we use the Helm operator", "tokens": [1282, 264, 6128, 76, 1252, 11, 321, 764, 264, 6128, 76, 12973, 13, 407, 294, 1184, 5288, 17940, 11, 321, 764, 264, 6128, 76, 12973], "temperature": 0.0, "avg_logprob": -0.1523541149340178, "compression_ratio": 1.7254901960784315, "no_speech_prob": 0.0002448379818815738}, {"id": 65, "seek": 44080, "start": 448.8, "end": 459.92, "text": " CRDs to do a more state-based installation of Helm. So we create the CRD and the Helm", "tokens": [14123, 35, 82, 281, 360, 257, 544, 1785, 12, 6032, 13260, 295, 6128, 76, 13, 407, 321, 1884, 264, 14123, 35, 293, 264, 6128, 76], "temperature": 0.0, "avg_logprob": -0.1523541149340178, "compression_ratio": 1.7254901960784315, "no_speech_prob": 0.0002448379818815738}, {"id": 66, "seek": 44080, "start": 459.92, "end": 465.32, "text": " operator is going to install the application based on the parameters on the CRD. A word", "tokens": [12973, 307, 516, 281, 3625, 264, 3861, 2361, 322, 264, 9834, 322, 264, 14123, 35, 13, 316, 1349], "temperature": 0.0, "avg_logprob": -0.1523541149340178, "compression_ratio": 1.7254901960784315, "no_speech_prob": 0.0002448379818815738}, {"id": 67, "seek": 46532, "start": 465.32, "end": 474.96, "text": " of advice is don't mix application and infrastructure, infrastructural configuration on the same package", "tokens": [295, 5192, 307, 500, 380, 2890, 3861, 293, 6896, 11, 6534, 1757, 1807, 11694, 322, 264, 912, 7372], "temperature": 0.0, "avg_logprob": -0.1538867496308826, "compression_ratio": 1.6111111111111112, "no_speech_prob": 5.5866803450044245e-05}, {"id": 68, "seek": 46532, "start": 474.96, "end": 481.52, "text": " because if you cannot enforce the same Helm chart for old tenants. For example, as I mentioned", "tokens": [570, 498, 291, 2644, 24825, 264, 912, 6128, 76, 6927, 337, 1331, 31216, 13, 1171, 1365, 11, 382, 286, 2835], "temperature": 0.0, "avg_logprob": -0.1538867496308826, "compression_ratio": 1.6111111111111112, "no_speech_prob": 5.5866803450044245e-05}, {"id": 69, "seek": 46532, "start": 481.52, "end": 488.03999999999996, "text": " before, customers can decide when to update things, right? So we have some customers in", "tokens": [949, 11, 4581, 393, 4536, 562, 281, 5623, 721, 11, 558, 30, 407, 321, 362, 512, 4581, 294], "temperature": 0.0, "avg_logprob": -0.1538867496308826, "compression_ratio": 1.6111111111111112, "no_speech_prob": 5.5866803450044245e-05}, {"id": 70, "seek": 46532, "start": 488.03999999999996, "end": 492.88, "text": " older releases and some once in newer releases. This is something that we want to change.", "tokens": [4906, 16952, 293, 512, 1564, 294, 17628, 16952, 13, 639, 307, 746, 300, 321, 528, 281, 1319, 13], "temperature": 0.0, "avg_logprob": -0.1538867496308826, "compression_ratio": 1.6111111111111112, "no_speech_prob": 5.5866803450044245e-05}, {"id": 71, "seek": 49288, "start": 492.88, "end": 498.92, "text": " But in the meantime, if we want to update a specific version of something in an old", "tokens": [583, 294, 264, 14991, 11, 498, 321, 528, 281, 5623, 257, 2685, 3037, 295, 746, 294, 364, 1331], "temperature": 0.0, "avg_logprob": -0.12673481772927678, "compression_ratio": 1.48, "no_speech_prob": 0.00012346958101261407}, {"id": 72, "seek": 49288, "start": 498.92, "end": 509.56, "text": " release, it's hard when this is already packaged on Helm. So we built a solution for this.", "tokens": [4374, 11, 309, 311, 1152, 562, 341, 307, 1217, 38162, 322, 6128, 76, 13, 407, 321, 3094, 257, 3827, 337, 341, 13], "temperature": 0.0, "avg_logprob": -0.12673481772927678, "compression_ratio": 1.48, "no_speech_prob": 0.00012346958101261407}, {"id": 73, "seek": 49288, "start": 509.56, "end": 515.64, "text": " So from the platform level, we can go and manipulate this Helm chart. So we can have", "tokens": [407, 490, 264, 3663, 1496, 11, 321, 393, 352, 293, 20459, 341, 6128, 76, 6927, 13, 407, 321, 393, 362], "temperature": 0.0, "avg_logprob": -0.12673481772927678, "compression_ratio": 1.48, "no_speech_prob": 0.00012346958101261407}, {"id": 74, "seek": 51564, "start": 515.64, "end": 524.56, "text": " overrides and this is easy to do when you have the Helm operator. So you can inject,", "tokens": [670, 81, 1875, 293, 341, 307, 1858, 281, 360, 562, 291, 362, 264, 6128, 76, 12973, 13, 407, 291, 393, 10711, 11], "temperature": 0.0, "avg_logprob": -0.1634249739594512, "compression_ratio": 1.6650943396226414, "no_speech_prob": 0.0001292368833674118}, {"id": 75, "seek": 51564, "start": 524.56, "end": 530.8, "text": " whenever there's a request to install a new Helm chart, we change parameters. So we change", "tokens": [5699, 456, 311, 257, 5308, 281, 3625, 257, 777, 6128, 76, 6927, 11, 321, 1319, 9834, 13, 407, 321, 1319], "temperature": 0.0, "avg_logprob": -0.1634249739594512, "compression_ratio": 1.6650943396226414, "no_speech_prob": 0.0001292368833674118}, {"id": 76, "seek": 51564, "start": 530.8, "end": 537.56, "text": " both Helm values. This is easy. Instead of passing some values, you pass different ones.", "tokens": [1293, 6128, 76, 4190, 13, 639, 307, 1858, 13, 7156, 295, 8437, 512, 4190, 11, 291, 1320, 819, 2306, 13], "temperature": 0.0, "avg_logprob": -0.1634249739594512, "compression_ratio": 1.6650943396226414, "no_speech_prob": 0.0001292368833674118}, {"id": 77, "seek": 51564, "start": 537.56, "end": 542.84, "text": " Or you can use customized patches. And this is also support from the Helm operator. This", "tokens": [1610, 291, 393, 764, 30581, 26531, 13, 400, 341, 307, 611, 1406, 490, 264, 6128, 76, 12973, 13, 639], "temperature": 0.0, "avg_logprob": -0.1634249739594512, "compression_ratio": 1.6650943396226414, "no_speech_prob": 0.0001292368833674118}, {"id": 78, "seek": 54284, "start": 542.84, "end": 547.4, "text": " is also support for customized patches. And customized patches are very interesting because", "tokens": [307, 611, 1406, 337, 30581, 26531, 13, 400, 30581, 26531, 366, 588, 1880, 570], "temperature": 0.0, "avg_logprob": -0.11680309946944074, "compression_ratio": 1.6116071428571428, "no_speech_prob": 0.00011876587814185768}, {"id": 79, "seek": 54284, "start": 547.4, "end": 554.6800000000001, "text": " they allow you to patch any Kubernetes resource. So even if there was no previous Helm value", "tokens": [436, 2089, 291, 281, 9972, 604, 23145, 7684, 13, 407, 754, 498, 456, 390, 572, 3894, 6128, 76, 2158], "temperature": 0.0, "avg_logprob": -0.11680309946944074, "compression_ratio": 1.6116071428571428, "no_speech_prob": 0.00011876587814185768}, {"id": 80, "seek": 54284, "start": 554.6800000000001, "end": 561.76, "text": " defined for it. So if we want to change a sidecar container image version across the", "tokens": [7642, 337, 309, 13, 407, 498, 321, 528, 281, 1319, 257, 1252, 6166, 10129, 3256, 3037, 2108, 264], "temperature": 0.0, "avg_logprob": -0.11680309946944074, "compression_ratio": 1.6116071428571428, "no_speech_prob": 0.00011876587814185768}, {"id": 81, "seek": 54284, "start": 561.76, "end": 568.2, "text": " whole fleet, we just have to change the patch. And this patch is going to be applied to all", "tokens": [1379, 19396, 11, 321, 445, 362, 281, 1319, 264, 9972, 13, 400, 341, 9972, 307, 516, 281, 312, 6456, 281, 439], "temperature": 0.0, "avg_logprob": -0.11680309946944074, "compression_ratio": 1.6116071428571428, "no_speech_prob": 0.00011876587814185768}, {"id": 82, "seek": 56820, "start": 568.2, "end": 574.84, "text": " the clusters, all the namespaces. And all the Helm charts that were installed are going", "tokens": [264, 23313, 11, 439, 264, 5288, 79, 2116, 13, 400, 439, 264, 6128, 76, 17767, 300, 645, 8899, 366, 516], "temperature": 0.0, "avg_logprob": -0.1297590325518352, "compression_ratio": 1.6057692307692308, "no_speech_prob": 8.221165626309812e-05}, {"id": 83, "seek": 56820, "start": 574.84, "end": 580.44, "text": " to get reinstalled with the right version that we want. So we do this combination of both", "tokens": [281, 483, 35056, 8907, 365, 264, 558, 3037, 300, 321, 528, 13, 407, 321, 360, 341, 6562, 295, 1293], "temperature": 0.0, "avg_logprob": -0.1297590325518352, "compression_ratio": 1.6057692307692308, "no_speech_prob": 8.221165626309812e-05}, {"id": 84, "seek": 56820, "start": 580.44, "end": 588.48, "text": " Helm chart and then operational values on the other hand.", "tokens": [6128, 76, 6927, 293, 550, 16607, 4190, 322, 264, 661, 1011, 13], "temperature": 0.0, "avg_logprob": -0.1297590325518352, "compression_ratio": 1.6057692307692308, "no_speech_prob": 8.221165626309812e-05}, {"id": 85, "seek": 56820, "start": 588.48, "end": 595.12, "text": " Very important for us was the shift left mentality, right? Detecting problems as soon as possible.", "tokens": [4372, 1021, 337, 505, 390, 264, 5513, 1411, 21976, 11, 558, 30, 4237, 557, 278, 2740, 382, 2321, 382, 1944, 13], "temperature": 0.0, "avg_logprob": -0.1297590325518352, "compression_ratio": 1.6057692307692308, "no_speech_prob": 8.221165626309812e-05}, {"id": 86, "seek": 59512, "start": 595.12, "end": 602.36, "text": " Not waiting for developers to push things to production because the cost increases.", "tokens": [1726, 3806, 337, 8849, 281, 2944, 721, 281, 4265, 570, 264, 2063, 8637, 13], "temperature": 0.0, "avg_logprob": -0.13083136225321207, "compression_ratio": 1.6278026905829597, "no_speech_prob": 0.00025613830075599253}, {"id": 87, "seek": 59512, "start": 602.36, "end": 609.28, "text": " So we run checks as soon as we can on pull requests. So this is still fresh in your memory", "tokens": [407, 321, 1190, 13834, 382, 2321, 382, 321, 393, 322, 2235, 12475, 13, 407, 341, 307, 920, 4451, 294, 428, 4675], "temperature": 0.0, "avg_logprob": -0.13083136225321207, "compression_ratio": 1.6278026905829597, "no_speech_prob": 0.00025613830075599253}, {"id": 88, "seek": 59512, "start": 609.28, "end": 615.68, "text": " when you make a change and something is broken. You want to catch it as soon as possible.", "tokens": [562, 291, 652, 257, 1319, 293, 746, 307, 5463, 13, 509, 528, 281, 3745, 309, 382, 2321, 382, 1944, 13], "temperature": 0.0, "avg_logprob": -0.13083136225321207, "compression_ratio": 1.6278026905829597, "no_speech_prob": 0.00025613830075599253}, {"id": 89, "seek": 59512, "start": 615.68, "end": 622.4, "text": " And we do this by generating all these templates. We have some tests that generate these templates", "tokens": [400, 321, 360, 341, 538, 17746, 439, 613, 21165, 13, 492, 362, 512, 6921, 300, 8460, 613, 21165], "temperature": 0.0, "avg_logprob": -0.13083136225321207, "compression_ratio": 1.6278026905829597, "no_speech_prob": 0.00025613830075599253}, {"id": 90, "seek": 62240, "start": 622.4, "end": 629.76, "text": " and then apply tests, multiple tests on them.", "tokens": [293, 550, 3079, 6921, 11, 3866, 6921, 322, 552, 13], "temperature": 0.0, "avg_logprob": -0.22751436077180456, "compression_ratio": 1.4155844155844155, "no_speech_prob": 0.0004502110241446644}, {"id": 91, "seek": 62240, "start": 629.76, "end": 636.56, "text": " The most basic check that you can run is the apply QCTL, apply the right run. This will", "tokens": [440, 881, 3875, 1520, 300, 291, 393, 1190, 307, 264, 3079, 1249, 10259, 43, 11, 3079, 264, 558, 1190, 13, 639, 486], "temperature": 0.0, "avg_logprob": -0.22751436077180456, "compression_ratio": 1.4155844155844155, "no_speech_prob": 0.0004502110241446644}, {"id": 92, "seek": 62240, "start": 636.56, "end": 644.1999999999999, "text": " tell you if the manifest is wrong in some very obvious way. So if it's valid or it's", "tokens": [980, 291, 498, 264, 10067, 307, 2085, 294, 512, 588, 6322, 636, 13, 407, 498, 309, 311, 7363, 420, 309, 311], "temperature": 0.0, "avg_logprob": -0.22751436077180456, "compression_ratio": 1.4155844155844155, "no_speech_prob": 0.0004502110241446644}, {"id": 93, "seek": 64420, "start": 644.2, "end": 652.5200000000001, "text": " not valid. Cube conform is a tool that will allow you to validate the Kubernetes schemas.", "tokens": [406, 7363, 13, 33003, 18975, 307, 257, 2290, 300, 486, 2089, 291, 281, 29562, 264, 23145, 22627, 296, 13], "temperature": 0.0, "avg_logprob": -0.24842619560134244, "compression_ratio": 1.4722222222222223, "no_speech_prob": 0.00037200996302999556}, {"id": 94, "seek": 64420, "start": 652.5200000000001, "end": 659.1600000000001, "text": " So this is the successor of Kubeval. Anybody heard about Kubeval or Kubeconform? Okay.", "tokens": [407, 341, 307, 264, 31864, 295, 591, 1977, 3337, 13, 19082, 2198, 466, 591, 1977, 3337, 420, 591, 1977, 1671, 837, 30, 1033, 13], "temperature": 0.0, "avg_logprob": -0.24842619560134244, "compression_ratio": 1.4722222222222223, "no_speech_prob": 0.00037200996302999556}, {"id": 95, "seek": 64420, "start": 659.1600000000001, "end": 668.24, "text": " So this is very useful for if you have custom CRDs or just to make sure typical problems", "tokens": [407, 341, 307, 588, 4420, 337, 498, 291, 362, 2375, 14123, 35, 82, 420, 445, 281, 652, 988, 7476, 2740], "temperature": 0.0, "avg_logprob": -0.24842619560134244, "compression_ratio": 1.4722222222222223, "no_speech_prob": 0.00037200996302999556}, {"id": 96, "seek": 66824, "start": 668.24, "end": 674.32, "text": " are you, you miss the jammer indentation and now it's not valid anymore and then you catch", "tokens": [366, 291, 11, 291, 1713, 264, 7872, 936, 44494, 399, 293, 586, 309, 311, 406, 7363, 3602, 293, 550, 291, 3745], "temperature": 0.0, "avg_logprob": -0.26596264506495276, "compression_ratio": 1.599078341013825, "no_speech_prob": 0.0008200617739930749}, {"id": 97, "seek": 66824, "start": 674.32, "end": 678.88, "text": " this on a PR. You just run this and it will tell you, you know, this property is missing", "tokens": [341, 322, 257, 11568, 13, 509, 445, 1190, 341, 293, 309, 486, 980, 291, 11, 291, 458, 11, 341, 4707, 307, 5361], "temperature": 0.0, "avg_logprob": -0.26596264506495276, "compression_ratio": 1.599078341013825, "no_speech_prob": 0.0008200617739930749}, {"id": 98, "seek": 66824, "start": 678.88, "end": 686.0, "text": " or this is property is in the wrong place because everybody loves jammer, right?", "tokens": [420, 341, 307, 4707, 307, 294, 264, 2085, 1081, 570, 2201, 6752, 7872, 936, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.26596264506495276, "compression_ratio": 1.599078341013825, "no_speech_prob": 0.0008200617739930749}, {"id": 99, "seek": 66824, "start": 686.0, "end": 692.88, "text": " Conf test is another tool for open policy agents. Any people familiar with open policy", "tokens": [11701, 1500, 307, 1071, 2290, 337, 1269, 3897, 12554, 13, 2639, 561, 4963, 365, 1269, 3897], "temperature": 0.0, "avg_logprob": -0.26596264506495276, "compression_ratio": 1.599078341013825, "no_speech_prob": 0.0008200617739930749}, {"id": 100, "seek": 69288, "start": 692.88, "end": 708.08, "text": " agents? Open policy, OPA. So OPA allows you to write policies where you can go and pretty", "tokens": [12554, 30, 7238, 3897, 11, 422, 10297, 13, 407, 422, 10297, 4045, 291, 281, 2464, 7657, 689, 291, 393, 352, 293, 1238], "temperature": 0.0, "avg_logprob": -0.22708283299985138, "compression_ratio": 1.2794117647058822, "no_speech_prob": 0.0006764462450519204}, {"id": 101, "seek": 69288, "start": 708.08, "end": 714.64, "text": " much check anything in any structure file. In the case of Kubernetes, you could say,", "tokens": [709, 1520, 1340, 294, 604, 3877, 3991, 13, 682, 264, 1389, 295, 23145, 11, 291, 727, 584, 11], "temperature": 0.0, "avg_logprob": -0.22708283299985138, "compression_ratio": 1.2794117647058822, "no_speech_prob": 0.0006764462450519204}, {"id": 102, "seek": 71464, "start": 714.64, "end": 722.68, "text": " I don't know, don't mount, don't run the pod as root. Make sure you don't mount secrets", "tokens": [286, 500, 380, 458, 11, 500, 380, 3746, 11, 500, 380, 1190, 264, 2497, 382, 5593, 13, 4387, 988, 291, 500, 380, 3746, 14093], "temperature": 0.0, "avg_logprob": -0.23138839320132606, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.00015011656796559691}, {"id": 103, "seek": 71464, "start": 722.68, "end": 728.76, "text": " as environment variables or with files. Make sure, enforce that all the pods have some", "tokens": [382, 2823, 9102, 420, 365, 7098, 13, 4387, 988, 11, 24825, 300, 439, 264, 31925, 362, 512], "temperature": 0.0, "avg_logprob": -0.23138839320132606, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.00015011656796559691}, {"id": 104, "seek": 71464, "start": 728.76, "end": 736.56, "text": " labels. Any random thing that you can think of, you can do it. And like, don't pull from", "tokens": [16949, 13, 2639, 4974, 551, 300, 291, 393, 519, 295, 11, 291, 393, 360, 309, 13, 400, 411, 11, 500, 380, 2235, 490], "temperature": 0.0, "avg_logprob": -0.23138839320132606, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.00015011656796559691}, {"id": 105, "seek": 71464, "start": 736.56, "end": 744.6, "text": " Docker Hub, pull from the internal registry. You can do that with Conf test and OPA policies.", "tokens": [33772, 18986, 11, 2235, 490, 264, 6920, 36468, 13, 509, 393, 360, 300, 365, 11701, 1500, 293, 422, 10297, 7657, 13], "temperature": 0.0, "avg_logprob": -0.23138839320132606, "compression_ratio": 1.676056338028169, "no_speech_prob": 0.00015011656796559691}, {"id": 106, "seek": 74460, "start": 744.6, "end": 749.24, "text": " The only problem is that it uses the regular language that if you haven't heard of, it's", "tokens": [440, 787, 1154, 307, 300, 309, 4960, 264, 3890, 2856, 300, 498, 291, 2378, 380, 2198, 295, 11, 309, 311], "temperature": 0.0, "avg_logprob": -0.18850905319740033, "compression_ratio": 1.511111111111111, "no_speech_prob": 0.00023105986474547535}, {"id": 107, "seek": 74460, "start": 749.24, "end": 759.64, "text": " very painful to work with, but it works great once you try to figure out.", "tokens": [588, 11697, 281, 589, 365, 11, 457, 309, 1985, 869, 1564, 291, 853, 281, 2573, 484, 13], "temperature": 0.0, "avg_logprob": -0.18850905319740033, "compression_ratio": 1.511111111111111, "no_speech_prob": 0.00023105986474547535}, {"id": 108, "seek": 74460, "start": 759.64, "end": 765.36, "text": " We added another tool which is called Pluto. Pluto is just a CLI that will tell you what", "tokens": [492, 3869, 1071, 2290, 597, 307, 1219, 41205, 13, 41205, 307, 445, 257, 12855, 40, 300, 486, 980, 291, 437], "temperature": 0.0, "avg_logprob": -0.18850905319740033, "compression_ratio": 1.511111111111111, "no_speech_prob": 0.00023105986474547535}, {"id": 109, "seek": 74460, "start": 765.36, "end": 770.96, "text": " API versions have been deprecated or removed. So if you are running, if you are thinking", "tokens": [9362, 9606, 362, 668, 1367, 13867, 770, 420, 7261, 13, 407, 498, 291, 366, 2614, 11, 498, 291, 366, 1953], "temperature": 0.0, "avg_logprob": -0.18850905319740033, "compression_ratio": 1.511111111111111, "no_speech_prob": 0.00023105986474547535}, {"id": 110, "seek": 77096, "start": 770.96, "end": 776.2800000000001, "text": " about upgrading Kubernetes, you run Pluto and it will tell you, you know, this is deprecated,", "tokens": [466, 36249, 23145, 11, 291, 1190, 41205, 293, 309, 486, 980, 291, 11, 291, 458, 11, 341, 307, 1367, 13867, 770, 11], "temperature": 0.0, "avg_logprob": -0.22098963910883124, "compression_ratio": 1.5707762557077625, "no_speech_prob": 0.0002497324603609741}, {"id": 111, "seek": 77096, "start": 776.2800000000001, "end": 784.0400000000001, "text": " it's going to be removed in this version and so on. So you can enforce that.", "tokens": [309, 311, 516, 281, 312, 7261, 294, 341, 3037, 293, 370, 322, 13, 407, 291, 393, 24825, 300, 13], "temperature": 0.0, "avg_logprob": -0.22098963910883124, "compression_ratio": 1.5707762557077625, "no_speech_prob": 0.0002497324603609741}, {"id": 112, "seek": 77096, "start": 784.0400000000001, "end": 790.96, "text": " We built a tool that we call Git init, which is our own version of a GitOps pool. So we", "tokens": [492, 3094, 257, 2290, 300, 321, 818, 16939, 3157, 11, 597, 307, 527, 1065, 3037, 295, 257, 16939, 36179, 7005, 13, 407, 321], "temperature": 0.0, "avg_logprob": -0.22098963910883124, "compression_ratio": 1.5707762557077625, "no_speech_prob": 0.0002497324603609741}, {"id": 113, "seek": 77096, "start": 790.96, "end": 795.36, "text": " have the Kubernetes definitions storing Git and we deploy these to blob stores across", "tokens": [362, 264, 23145, 21988, 26085, 16939, 293, 321, 7274, 613, 281, 46115, 9512, 2108], "temperature": 0.0, "avg_logprob": -0.22098963910883124, "compression_ratio": 1.5707762557077625, "no_speech_prob": 0.0002497324603609741}, {"id": 114, "seek": 79536, "start": 795.36, "end": 803.36, "text": " regions. So they are pulled in each cluster. And Git init is a deployment that runs continuously", "tokens": [10682, 13, 407, 436, 366, 7373, 294, 1184, 13630, 13, 400, 16939, 3157, 307, 257, 19317, 300, 6676, 15684], "temperature": 0.0, "avg_logprob": -0.18292687998877633, "compression_ratio": 1.4766839378238341, "no_speech_prob": 0.00015143555356189609}, {"id": 115, "seek": 79536, "start": 803.36, "end": 811.36, "text": " on each namespace. We have around 10,000 namespaces in our fleet. So it basically pulls the blob,", "tokens": [322, 1184, 5288, 17940, 13, 492, 362, 926, 1266, 11, 1360, 5288, 79, 2116, 294, 527, 19396, 13, 407, 309, 1936, 16982, 264, 46115, 11], "temperature": 0.0, "avg_logprob": -0.18292687998877633, "compression_ratio": 1.4766839378238341, "no_speech_prob": 0.00015143555356189609}, {"id": 116, "seek": 79536, "start": 811.36, "end": 819.76, "text": " applies the changes and does this thing every so often. And an example of why we do a pool", "tokens": [13165, 264, 2962, 293, 775, 341, 551, 633, 370, 2049, 13, 400, 364, 1365, 295, 983, 321, 360, 257, 7005], "temperature": 0.0, "avg_logprob": -0.18292687998877633, "compression_ratio": 1.4766839378238341, "no_speech_prob": 0.00015143555356189609}, {"id": 117, "seek": 81976, "start": 819.76, "end": 825.56, "text": " versus pool, because pushing to all the clusters, we have a job that does this and it runs in", "tokens": [5717, 7005, 11, 570, 7380, 281, 439, 264, 23313, 11, 321, 362, 257, 1691, 300, 775, 341, 293, 309, 6676, 294], "temperature": 0.0, "avg_logprob": -0.2103152758833291, "compression_ratio": 1.4943820224719102, "no_speech_prob": 0.00027928868075832725}, {"id": 118, "seek": 81976, "start": 825.56, "end": 832.52, "text": " parallel, like in 20 threads or something, and still takes like five hours to run. So", "tokens": [8952, 11, 411, 294, 945, 19314, 420, 746, 11, 293, 920, 2516, 411, 1732, 2496, 281, 1190, 13, 407], "temperature": 0.0, "avg_logprob": -0.2103152758833291, "compression_ratio": 1.4943820224719102, "no_speech_prob": 0.00027928868075832725}, {"id": 119, "seek": 81976, "start": 832.52, "end": 841.72, "text": " we cannot push things when we want. On Argo CD, we have a newcast platform that allows", "tokens": [321, 2644, 2944, 721, 562, 321, 528, 13, 1282, 1587, 1571, 6743, 11, 321, 362, 257, 777, 3734, 3663, 300, 4045], "temperature": 0.0, "avg_logprob": -0.2103152758833291, "compression_ratio": 1.4943820224719102, "no_speech_prob": 0.00027928868075832725}, {"id": 120, "seek": 84172, "start": 841.72, "end": 851.96, "text": " you to do Argo CD-based microservices. Argo CD, basically, this would create a new Git", "tokens": [291, 281, 360, 1587, 1571, 6743, 12, 6032, 15547, 47480, 13, 1587, 1571, 6743, 11, 1936, 11, 341, 576, 1884, 257, 777, 16939], "temperature": 0.0, "avg_logprob": -0.20722090114246716, "compression_ratio": 1.6108597285067874, "no_speech_prob": 0.00010093194578075781}, {"id": 121, "seek": 84172, "start": 851.96, "end": 856.28, "text": " repo, it would come with some templates and that would get deployed with Argo CD to the", "tokens": [49040, 11, 309, 576, 808, 365, 512, 21165, 293, 300, 576, 483, 17826, 365, 1587, 1571, 6743, 281, 264], "temperature": 0.0, "avg_logprob": -0.20722090114246716, "compression_ratio": 1.6108597285067874, "no_speech_prob": 0.00010093194578075781}, {"id": 122, "seek": 84172, "start": 856.28, "end": 863.8000000000001, "text": " cluster. And this is for us, we are thinking about moving this way and each team will have", "tokens": [13630, 13, 400, 341, 307, 337, 505, 11, 321, 366, 1953, 466, 2684, 341, 636, 293, 1184, 1469, 486, 362], "temperature": 0.0, "avg_logprob": -0.20722090114246716, "compression_ratio": 1.6108597285067874, "no_speech_prob": 0.00010093194578075781}, {"id": 123, "seek": 84172, "start": 863.8000000000001, "end": 869.0400000000001, "text": " their own Git repo, because right now we have mostly centralized operators and everything.", "tokens": [641, 1065, 16939, 49040, 11, 570, 558, 586, 321, 362, 5240, 32395, 19077, 293, 1203, 13], "temperature": 0.0, "avg_logprob": -0.20722090114246716, "compression_ratio": 1.6108597285067874, "no_speech_prob": 0.00010093194578075781}, {"id": 124, "seek": 86904, "start": 869.04, "end": 873.4399999999999, "text": " And this is good for the, okay, you go on your own direction, you do whatever you want,", "tokens": [400, 341, 307, 665, 337, 264, 11, 1392, 11, 291, 352, 322, 428, 1065, 3513, 11, 291, 360, 2035, 291, 528, 11], "temperature": 0.0, "avg_logprob": -0.18118342349403782, "compression_ratio": 1.5814977973568283, "no_speech_prob": 0.00019515739404596388}, {"id": 125, "seek": 86904, "start": 873.4399999999999, "end": 878.16, "text": " you build it, you run it. On the other hand, it's a bit tricky because when we decide or", "tokens": [291, 1322, 309, 11, 291, 1190, 309, 13, 1282, 264, 661, 1011, 11, 309, 311, 257, 857, 12414, 570, 562, 321, 4536, 420], "temperature": 0.0, "avg_logprob": -0.18118342349403782, "compression_ratio": 1.5814977973568283, "no_speech_prob": 0.00019515739404596388}, {"id": 126, "seek": 86904, "start": 878.16, "end": 884.4, "text": " figure out something is problematic, we cannot just centrally say, you know, on this Git", "tokens": [2573, 484, 746, 307, 19011, 11, 321, 2644, 445, 32199, 379, 584, 11, 291, 458, 11, 322, 341, 16939], "temperature": 0.0, "avg_logprob": -0.18118342349403782, "compression_ratio": 1.5814977973568283, "no_speech_prob": 0.00019515739404596388}, {"id": 127, "seek": 86904, "start": 884.4, "end": 893.88, "text": " repo tell me who is doing this and let's change it. But we are moving towards that direction.", "tokens": [49040, 980, 385, 567, 307, 884, 341, 293, 718, 311, 1319, 309, 13, 583, 321, 366, 2684, 3030, 300, 3513, 13], "temperature": 0.0, "avg_logprob": -0.18118342349403782, "compression_ratio": 1.5814977973568283, "no_speech_prob": 0.00019515739404596388}, {"id": 128, "seek": 89388, "start": 893.88, "end": 903.4399999999999, "text": " Let me skip this and talk a bit about progressive delivery. So progressive delivery is a way,", "tokens": [961, 385, 10023, 341, 293, 751, 257, 857, 466, 16131, 8982, 13, 407, 16131, 8982, 307, 257, 636, 11], "temperature": 0.0, "avg_logprob": -0.23845183428596048, "compression_ratio": 1.6556603773584906, "no_speech_prob": 0.00014363601803779602}, {"id": 129, "seek": 89388, "start": 903.4399999999999, "end": 907.32, "text": " well, it's something that, it's a name for something that you've probably heard of, which", "tokens": [731, 11, 309, 311, 746, 300, 11, 309, 311, 257, 1315, 337, 746, 300, 291, 600, 1391, 2198, 295, 11, 597], "temperature": 0.0, "avg_logprob": -0.23845183428596048, "compression_ratio": 1.6556603773584906, "no_speech_prob": 0.00014363601803779602}, {"id": 130, "seek": 89388, "start": 907.32, "end": 916.84, "text": " is canary rollouts and doing percentage-based rollouts, feature flags, blue ring, so basically", "tokens": [307, 393, 822, 3373, 7711, 293, 884, 9668, 12, 6032, 3373, 7711, 11, 4111, 23265, 11, 3344, 4875, 11, 370, 1936], "temperature": 0.0, "avg_logprob": -0.23845183428596048, "compression_ratio": 1.6556603773584906, "no_speech_prob": 0.00014363601803779602}, {"id": 131, "seek": 89388, "start": 916.84, "end": 922.88, "text": " don't update everybody at the same time because you can break everybody.", "tokens": [500, 380, 5623, 2201, 412, 264, 912, 565, 570, 291, 393, 1821, 2201, 13], "temperature": 0.0, "avg_logprob": -0.23845183428596048, "compression_ratio": 1.6556603773584906, "no_speech_prob": 0.00014363601803779602}, {"id": 132, "seek": 92288, "start": 922.88, "end": 927.96, "text": " So we can do rollouts to different customer groups in separate waves and we can also do", "tokens": [407, 321, 393, 360, 3373, 7711, 281, 819, 5474, 3935, 294, 4994, 9417, 293, 321, 393, 611, 360], "temperature": 0.0, "avg_logprob": -0.16694651950489392, "compression_ratio": 1.691588785046729, "no_speech_prob": 0.0003530596732161939}, {"id": 133, "seek": 92288, "start": 927.96, "end": 935.8, "text": " rollouts to percentage of customers. By default, we have a time-based rollout that goes from", "tokens": [3373, 7711, 281, 9668, 295, 4581, 13, 3146, 7576, 11, 321, 362, 257, 565, 12, 6032, 3373, 346, 300, 1709, 490], "temperature": 0.0, "avg_logprob": -0.16694651950489392, "compression_ratio": 1.691588785046729, "no_speech_prob": 0.0003530596732161939}, {"id": 134, "seek": 92288, "start": 935.8, "end": 941.32, "text": " dev to stage to prod candidate after a period of time. And this is running on Jenkins and", "tokens": [1905, 281, 3233, 281, 15792, 11532, 934, 257, 2896, 295, 565, 13, 400, 341, 307, 2614, 322, 41273, 293], "temperature": 0.0, "avg_logprob": -0.16694651950489392, "compression_ratio": 1.691588785046729, "no_speech_prob": 0.0003530596732161939}, {"id": 135, "seek": 92288, "start": 941.32, "end": 946.48, "text": " ensures that things have been running on dev on stage before we merge them to prod. I mean,", "tokens": [28111, 300, 721, 362, 668, 2614, 322, 1905, 322, 3233, 949, 321, 22183, 552, 281, 15792, 13, 286, 914, 11], "temperature": 0.0, "avg_logprob": -0.16694651950489392, "compression_ratio": 1.691588785046729, "no_speech_prob": 0.0003530596732161939}, {"id": 136, "seek": 94648, "start": 946.48, "end": 954.48, "text": " this is very basic. What we built was feature flags at the namespace level. We have 10,000", "tokens": [341, 307, 588, 3875, 13, 708, 321, 3094, 390, 4111, 23265, 412, 264, 5288, 17940, 1496, 13, 492, 362, 1266, 11, 1360], "temperature": 0.0, "avg_logprob": -0.20395650583155014, "compression_ratio": 1.5082872928176796, "no_speech_prob": 0.0001674765517236665}, {"id": 137, "seek": 94648, "start": 954.48, "end": 962.64, "text": " namespaces and then the Kubernetes definition templates. So what we allow developers to", "tokens": [5288, 79, 2116, 293, 550, 264, 23145, 7123, 21165, 13, 407, 437, 321, 2089, 8849, 281], "temperature": 0.0, "avg_logprob": -0.20395650583155014, "compression_ratio": 1.5082872928176796, "no_speech_prob": 0.0001674765517236665}, {"id": 138, "seek": 94648, "start": 962.64, "end": 971.2, "text": " do is for each namespace, they can decide, I want to roll out this change to this environment,", "tokens": [360, 307, 337, 1184, 5288, 17940, 11, 436, 393, 4536, 11, 286, 528, 281, 3373, 484, 341, 1319, 281, 341, 2823, 11], "temperature": 0.0, "avg_logprob": -0.20395650583155014, "compression_ratio": 1.5082872928176796, "no_speech_prob": 0.0001674765517236665}, {"id": 139, "seek": 97120, "start": 971.2, "end": 977.12, "text": " dev, stage, or prod, or I want to deploy this change to a specific cluster or by template", "tokens": [1905, 11, 3233, 11, 420, 15792, 11, 420, 286, 528, 281, 7274, 341, 1319, 281, 257, 2685, 13630, 420, 538, 12379], "temperature": 0.0, "avg_logprob": -0.19034079430808484, "compression_ratio": 1.550561797752809, "no_speech_prob": 0.00016352749662473798}, {"id": 140, "seek": 97120, "start": 977.12, "end": 985.08, "text": " namespace type of, yeah, type of namespace or a percentage. And this is just using templates", "tokens": [5288, 17940, 2010, 295, 11, 1338, 11, 2010, 295, 5288, 17940, 420, 257, 9668, 13, 400, 341, 307, 445, 1228, 21165], "temperature": 0.0, "avg_logprob": -0.19034079430808484, "compression_ratio": 1.550561797752809, "no_speech_prob": 0.00016352749662473798}, {"id": 141, "seek": 97120, "start": 985.08, "end": 993.6400000000001, "text": " on Kubernetes objects. So an example is, in this case, a rule, sorry, a Kubernetes definition", "tokens": [322, 23145, 6565, 13, 407, 364, 1365, 307, 11, 294, 341, 1389, 11, 257, 4978, 11, 2597, 11, 257, 23145, 7123], "temperature": 0.0, "avg_logprob": -0.19034079430808484, "compression_ratio": 1.550561797752809, "no_speech_prob": 0.00016352749662473798}, {"id": 142, "seek": 99364, "start": 993.64, "end": 1001.8, "text": " where you can have a template that is as full version or bar version, or you can enable", "tokens": [689, 291, 393, 362, 257, 12379, 300, 307, 382, 1577, 3037, 420, 2159, 3037, 11, 420, 291, 393, 9528], "temperature": 0.0, "avg_logprob": -0.14404762034513513, "compression_ratio": 1.7277227722772277, "no_speech_prob": 3.976902735303156e-05}, {"id": 143, "seek": 99364, "start": 1001.8, "end": 1006.24, "text": " a container, a sidecar container, or disable it. And then at the bottom, you can see the", "tokens": [257, 10129, 11, 257, 1252, 6166, 10129, 11, 420, 28362, 309, 13, 400, 550, 412, 264, 2767, 11, 291, 393, 536, 264], "temperature": 0.0, "avg_logprob": -0.14404762034513513, "compression_ratio": 1.7277227722772277, "no_speech_prob": 3.976902735303156e-05}, {"id": 144, "seek": 99364, "start": 1006.24, "end": 1012.8, "text": " rules. So by default, we want full version to be 1.0, but for the namespace, all the", "tokens": [4474, 13, 407, 538, 7576, 11, 321, 528, 1577, 3037, 281, 312, 502, 13, 15, 11, 457, 337, 264, 5288, 17940, 11, 439, 264], "temperature": 0.0, "avg_logprob": -0.14404762034513513, "compression_ratio": 1.7277227722772277, "no_speech_prob": 3.976902735303156e-05}, {"id": 145, "seek": 99364, "start": 1012.8, "end": 1018.84, "text": " namespaces on the dev environment, we want that to be 1.1. So this allows us to quickly", "tokens": [5288, 79, 2116, 322, 264, 1905, 2823, 11, 321, 528, 300, 281, 312, 502, 13, 16, 13, 407, 341, 4045, 505, 281, 2661], "temperature": 0.0, "avg_logprob": -0.14404762034513513, "compression_ratio": 1.7277227722772277, "no_speech_prob": 3.976902735303156e-05}, {"id": 146, "seek": 101884, "start": 1018.84, "end": 1025.48, "text": " roll out changes, but progressively. We can also do it for percentiles. So in this case,", "tokens": [3373, 484, 2962, 11, 457, 46667, 13, 492, 393, 611, 360, 309, 337, 3043, 4680, 13, 407, 294, 341, 1389, 11], "temperature": 0.0, "avg_logprob": -0.1480836490593334, "compression_ratio": 1.6422018348623852, "no_speech_prob": 0.00018793047638610005}, {"id": 147, "seek": 101884, "start": 1025.48, "end": 1031.24, "text": " we could say, I want all the namespaces in dev and all the namespaces in a stage to have", "tokens": [321, 727, 584, 11, 286, 528, 439, 264, 5288, 79, 2116, 294, 1905, 293, 439, 264, 5288, 79, 2116, 294, 257, 3233, 281, 362], "temperature": 0.0, "avg_logprob": -0.1480836490593334, "compression_ratio": 1.6422018348623852, "no_speech_prob": 0.00018793047638610005}, {"id": 148, "seek": 101884, "start": 1031.24, "end": 1037.6000000000001, "text": " this full version 1.1 and enable matter rule true, but for prod, I only want 5%. So I roll", "tokens": [341, 1577, 3037, 502, 13, 16, 293, 9528, 1871, 4978, 2074, 11, 457, 337, 15792, 11, 286, 787, 528, 1025, 6856, 407, 286, 3373], "temperature": 0.0, "avg_logprob": -0.1480836490593334, "compression_ratio": 1.6422018348623852, "no_speech_prob": 0.00018793047638610005}, {"id": 149, "seek": 101884, "start": 1037.6000000000001, "end": 1047.1200000000001, "text": " out a change to 5% of prod, and then I can continue after that. So this has proven really", "tokens": [484, 257, 1319, 281, 1025, 4, 295, 15792, 11, 293, 550, 286, 393, 2354, 934, 300, 13, 407, 341, 575, 12785, 534], "temperature": 0.0, "avg_logprob": -0.1480836490593334, "compression_ratio": 1.6422018348623852, "no_speech_prob": 0.00018793047638610005}, {"id": 150, "seek": 104712, "start": 1047.12, "end": 1055.1999999999998, "text": " useful for developers to test in safely, increases development in speed, PRs are much faster,", "tokens": [4420, 337, 8849, 281, 1500, 294, 11750, 11, 8637, 3250, 294, 3073, 11, 11568, 82, 366, 709, 4663, 11], "temperature": 0.0, "avg_logprob": -0.23198890686035156, "compression_ratio": 1.5449438202247192, "no_speech_prob": 0.0003642287047114223}, {"id": 151, "seek": 104712, "start": 1055.1999999999998, "end": 1064.2399999999998, "text": " so it's all great. And we are thinking about, well, we're thinking, we are working on getting", "tokens": [370, 309, 311, 439, 869, 13, 400, 321, 366, 1953, 466, 11, 731, 11, 321, 434, 1953, 11, 321, 366, 1364, 322, 1242], "temperature": 0.0, "avg_logprob": -0.23198890686035156, "compression_ratio": 1.5449438202247192, "no_speech_prob": 0.0003642287047114223}, {"id": 152, "seek": 104712, "start": 1064.2399999999998, "end": 1069.56, "text": " ARGOR rollouts also at the deployment level. ARGOR rollouts allows you to do blue-green", "tokens": [8943, 38, 2483, 3373, 7711, 611, 412, 264, 19317, 1496, 13, 8943, 38, 2483, 3373, 7711, 4045, 291, 281, 360, 3344, 12, 27399], "temperature": 0.0, "avg_logprob": -0.23198890686035156, "compression_ratio": 1.5449438202247192, "no_speech_prob": 0.0003642287047114223}, {"id": 153, "seek": 106956, "start": 1069.56, "end": 1079.9199999999998, "text": " and canary rollouts, where you can say, progress the number of pods over a period of time,", "tokens": [293, 393, 822, 3373, 7711, 11, 689, 291, 393, 584, 11, 4205, 264, 1230, 295, 31925, 670, 257, 2896, 295, 565, 11], "temperature": 0.0, "avg_logprob": -0.13229344367980958, "compression_ratio": 1.6635514018691588, "no_speech_prob": 0.00016558192146476358}, {"id": 154, "seek": 106956, "start": 1079.9199999999998, "end": 1084.76, "text": " so instead of changing, I don't know, 10 pods at the same time, because one by one, and", "tokens": [370, 2602, 295, 4473, 11, 286, 500, 380, 458, 11, 1266, 31925, 412, 264, 912, 565, 11, 570, 472, 538, 472, 11, 293], "temperature": 0.0, "avg_logprob": -0.13229344367980958, "compression_ratio": 1.6635514018691588, "no_speech_prob": 0.00016558192146476358}, {"id": 155, "seek": 106956, "start": 1084.76, "end": 1090.12, "text": " if you have a service mesh, you can go even more fine-grained and say, I want 5% of the", "tokens": [498, 291, 362, 257, 2643, 17407, 11, 291, 393, 352, 754, 544, 2489, 12, 20735, 2001, 293, 584, 11, 286, 528, 1025, 4, 295, 264], "temperature": 0.0, "avg_logprob": -0.13229344367980958, "compression_ratio": 1.6635514018691588, "no_speech_prob": 0.00016558192146476358}, {"id": 156, "seek": 106956, "start": 1090.12, "end": 1094.9199999999998, "text": " traffic to go to the old version, to the new version, everything else to the old version,", "tokens": [6419, 281, 352, 281, 264, 1331, 3037, 11, 281, 264, 777, 3037, 11, 1203, 1646, 281, 264, 1331, 3037, 11], "temperature": 0.0, "avg_logprob": -0.13229344367980958, "compression_ratio": 1.6635514018691588, "no_speech_prob": 0.00016558192146476358}, {"id": 157, "seek": 109492, "start": 1094.92, "end": 1104.6000000000001, "text": " and keep progressing that and do automatic rollbacks. So, yes. So, yeah. With the service", "tokens": [293, 1066, 36305, 300, 293, 360, 12509, 3373, 17758, 13, 407, 11, 2086, 13, 407, 11, 1338, 13, 2022, 264, 2643], "temperature": 0.0, "avg_logprob": -0.21246626112196182, "compression_ratio": 1.545045045045045, "no_speech_prob": 0.0002045682049356401}, {"id": 158, "seek": 109492, "start": 1104.6000000000001, "end": 1110.5600000000002, "text": " mesh, you can fine-tune the traffic percentages, but with Kubernetes services, you can still", "tokens": [17407, 11, 291, 393, 2489, 12, 83, 2613, 264, 6419, 42270, 11, 457, 365, 23145, 3328, 11, 291, 393, 920], "temperature": 0.0, "avg_logprob": -0.21246626112196182, "compression_ratio": 1.545045045045045, "no_speech_prob": 0.0002045682049356401}, {"id": 159, "seek": 109492, "start": 1110.5600000000002, "end": 1115.04, "text": " do it. It's just that we are limited with the number of pods.", "tokens": [360, 309, 13, 467, 311, 445, 300, 321, 366, 5567, 365, 264, 1230, 295, 31925, 13], "temperature": 0.0, "avg_logprob": -0.21246626112196182, "compression_ratio": 1.545045045045045, "no_speech_prob": 0.0002045682049356401}, {"id": 160, "seek": 109492, "start": 1115.04, "end": 1122.96, "text": " So to sum up, Shift left on Garrail, so keeping people safe on what they are doing, this increases", "tokens": [407, 281, 2408, 493, 11, 28304, 1411, 322, 7995, 44765, 11, 370, 5145, 561, 3273, 322, 437, 436, 366, 884, 11, 341, 8637], "temperature": 0.0, "avg_logprob": -0.21246626112196182, "compression_ratio": 1.545045045045045, "no_speech_prob": 0.0002045682049356401}, {"id": 161, "seek": 112296, "start": 1122.96, "end": 1129.08, "text": " development speed, reduces the issues that you are going to have in production, and you're", "tokens": [3250, 3073, 11, 18081, 264, 2663, 300, 291, 366, 516, 281, 362, 294, 4265, 11, 293, 291, 434], "temperature": 0.0, "avg_logprob": -0.17035587822518697, "compression_ratio": 1.6604651162790698, "no_speech_prob": 0.00024651805870234966}, {"id": 162, "seek": 112296, "start": 1129.08, "end": 1136.96, "text": " never going to prevent having issues in production. What you can prevent is how many customers", "tokens": [1128, 516, 281, 4871, 1419, 2663, 294, 4265, 13, 708, 291, 393, 4871, 307, 577, 867, 4581], "temperature": 0.0, "avg_logprob": -0.17035587822518697, "compression_ratio": 1.6604651162790698, "no_speech_prob": 0.00024651805870234966}, {"id": 163, "seek": 112296, "start": 1136.96, "end": 1144.72, "text": " are affected and how fast you can fix them, right? So for us, what was very useful is", "tokens": [366, 8028, 293, 577, 2370, 291, 393, 3191, 552, 11, 558, 30, 407, 337, 505, 11, 437, 390, 588, 4420, 307], "temperature": 0.0, "avg_logprob": -0.17035587822518697, "compression_ratio": 1.6604651162790698, "no_speech_prob": 0.00024651805870234966}, {"id": 164, "seek": 112296, "start": 1144.72, "end": 1149.44, "text": " the progressive delivery techniques, like canaries, percent of rollouts, or automated", "tokens": [264, 16131, 8982, 7512, 11, 411, 393, 4889, 11, 3043, 295, 3373, 7711, 11, 420, 18473], "temperature": 0.0, "avg_logprob": -0.17035587822518697, "compression_ratio": 1.6604651162790698, "no_speech_prob": 0.00024651805870234966}, {"id": 165, "seek": 114944, "start": 1149.44, "end": 1157.1200000000001, "text": " rollbacks, and the automation to do this, control and progressive rollout, pays off", "tokens": [3373, 17758, 11, 293, 264, 17769, 281, 360, 341, 11, 1969, 293, 16131, 3373, 346, 11, 10604, 766], "temperature": 0.0, "avg_logprob": -0.3179619598388672, "compression_ratio": 1.326241134751773, "no_speech_prob": 0.0004127712454646826}, {"id": 166, "seek": 114944, "start": 1157.1200000000001, "end": 1168.3200000000002, "text": " over time. So I think we have one minute for questions. Or you can find me afterwards.", "tokens": [670, 565, 13, 407, 286, 519, 321, 362, 472, 3456, 337, 1651, 13, 1610, 291, 393, 915, 385, 10543, 13], "temperature": 0.0, "avg_logprob": -0.3179619598388672, "compression_ratio": 1.326241134751773, "no_speech_prob": 0.0004127712454646826}, {"id": 167, "seek": 116832, "start": 1168.32, "end": 1179.76, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 50936], "temperature": 0.0, "avg_logprob": -0.840022087097168, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.00552859203889966}], "language": "en"}