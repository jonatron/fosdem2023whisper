{"text": " My name is Giles Herron, I work for Cisco, but let's try and forget about that for a moment. Because this is open source, this is not your regular sort of traditional Cisco stuff, hence pitching it here. So the project's called Media Streaming Mesh, I'll give links to it at the end. I've been running it for a while, but it's quite kind of a skunk work, so it's really not loud enough. Oh yeah, yeah, it slipped right down, hasn't it? I'll put it here and then, or if I'm a bit super loud on the recording. Yeah, so kind of skunk works, it's really me and a couple of developers now. And really where it comes from was, we were looking at Kubernetes so that the group are working, everything we do really is cloud native, and so when I took a look at Kubernetes, my main impression was that here was something that was very much based on supporting web applications. Even if you look at like liveness checks in Kubernetes, they're like TCP or HTTP. And so I was like, well, okay, so how would we do real-time media in that? And one way I look at it is to say, well, you can divide the world into two by two matrices, whatever you're looking at. And if you look at apps and say, well, you've got real-time, you've got non-real-time, you've got interactive apps and streaming apps, they're just sort of pub-sub stuff. And really, back to Kubernetes, it's very much in that top-left corner, it's all about web apps. So how do we do real-time apps? And so that was where the project started, initially looking at anything real-time, so including online games, it could have been stock trading or whatever. But then in terms of focus, we decided then, let's focus on real-time media, and by that really anything RTP-based, so hence being here. So that could be WebRTC, it could be SIP, but equally it can be RTSP, it can be live video, that sort of thing. And so then we'll say, well, how would we support this in Kubernetes today? So everyone's really big, one of the big things at the moment in Kubernetes is service meshes. So I'm guessing who here's played with service meshes at all? Anyone? One or two? Yes. So what the service mesh does is it terminates your TCP or HTTP connections at each pod, and so rather than sort of routing across your Kubernetes cluster, you kind of go hot by hot through web proxies. So you get security, you get good stats, that sort of thing at the price of complexity. The challenge is these service meshes, they'll work for TCP apps, they're great for HTTP apps because you can go in and do URL routing, that kind of stuff, don't support UDP and they certainly don't support real-time media apps. So the next thing to say is, well, what if we don't bother with a service mesh and we'll just use regular Kube proxy and node port? So this is the standard NAT that Kubernetes uses. So what Kubernetes typically does is it gives a service like a persistent IP address. So rather than relying on DNS, which obviously you can cache things, you put a persistent IP address on a service and then you have ephemeral IP addresses for your individual pods that support that service, and the way you get from one to the other is NATting, which for those of us who are network people, makes us throw up a little in our mouths. But the challenge there is these do work, again, for the basic services. I put that in yellow, there's a challenge which is that typically when you expose things externally from your cluster, you use these high port numbers in node port, which is pretty messy. You want to use well-known ones, of course, or you prefer to, but they don't support real-time media. And I guess this is no surprise to anyone in this room, but if you're doing things like SIP and RTSP, what you'll typically see is that there'll be a TCP channel that'll be negotiated. Well, it can be TCP, it can be UDP, but it will negotiate the media ports. So the challenge there is those media port negotiations are completely invisible to the NAT, and so that will break if you try and deploy it this way. So what I've seen some people in the industry do, so people deploying onto Kubernetes with conferencing solutions, is they'll use host networking. And that just works, right? You put everything in the host name space, everything's good, there's no NAT, we're all happy. Okay, so why not do that? Big issue is, oops, you can only put one media part on each node, because if you want to have multiple media parts all exposing the same port, well, you've only got one instance of that port on the host. So that's okay if you're going to run on VMs, you're going to size your VMs down to the right size for one media pod, and there's the cost of having many more nodes in your clusters, but if you're deploying onto bare metal, that's going to suck. So what we came up with MediaStreamMesh said, let's focus on this real-time media, let's support multiple media pods per node. Let's also maybe support the other services, either directly or in combination with a service mesh. But yeah, let's really make this our focus. And what was I trying to do? Really take everything that we get in service meshes in Kubernetes, so that's really good observability and security so you can crit stuff when it goes out of the node, you can check all your performance metrics and that kind of stuff. That's great for debugging, troubleshooting, securing your network, but what we wanted to do was provide the lower latency of factory proxy at the UDP or RTP layer, not TCP, so I don't know, terminating TCP, and we wanted it to be really light. So we looked at how do we decompose it so that we can put this right out at the edge of the network, because some of our use cases are people saying, well, we've got a camera in a coffee shop, and we want to stream that somewhere, and we want to run it on a little node running K3S like a little Raspberry Pi or something. So can we get this down to a small enough footprint? So in terms of use cases, obviously real-time collaboration, so we haven't yet done WebRTC, that would be my disclaimer. If anyone wants to help us port it into this, that would be great, you can take some like PON and port it into this framework. We're working on contribution video, so that is very high bandwidth video, typically in TV production studios, that kind of stuff, and what those people want to do is fairly nuts in terms of you can have something like 4K uncompressed video, which I think is about 12 gigabits per second, and you can't drop a packet and you can't jitter. So probably we have to do something special on the network there, so we're working on things like zero copy from one pod to another, and then using Intel's DPDK out to the network. Some challenges there, I guess, in terms of normally in Kubernetes is what you hand between pods as IP packets. In this case, we'd be handing around raw video frames, so it's a bit different. And then as well as that contribution side, then the distribution. So how do you, if I'm watching a football, I don't want it to lag. How do I get the live video feed, at least out to the CDN caches, to minimize the lag, but possibly even then going RTP right out to the user? I guess some of the challenges there are what protocols we use. Do we do RTP over quick, or do we look at the stuff that's going on? I don't know, anyone here has seen ITF at the moment are working on media over quick. We had an interim a few days ago. So that won't necessarily use RTP, because quick gives you a lot of what RTP gives you anyway. So that might be the solution there. But as I mentioned earlier, this sort of retailer industrial edge, where you've got large numbers of cameras in one site, like I was in Las Vegas for Cisco Live earlier this year, and you walk into a casino. If you've ever seen how many cameras there are in a casino, it's just like nuts, they're watching you from every possible angle. Or it could be a coffee shop with one camera, but you've got a thousand coffee shops, whatever. As I say, we've kind of dropped out of this kind of non-RTP stuff, but there is obviously scope to address that in the future. So in live videos, I say the contribution stuff, one of the challenges there is a lot of this stuff is actually hardware, not software. So a video camera is a real hardware thing, and a mixing desk might be a real hardware thing. So how do we integrate that? Interconnecting coders in the cloud, that seems like a really obvious use case. That distribution of live streams, but also potentially distributing rights to the client. But as I say, video surveillance, that seems pretty easy and tractable, and that's what we're demoing now. So our initial implementation, we have RTSP, and we can stream stuff from cameras and replicate it to multiple places. So the classic use case, you might be saying, well okay, cameras are cheap, humans are expensive. So if I'm in a casino and I've got 100,000 cameras, pick a crazy number. I don't have 10,000 people who watch 10 screens, because that's going to be too expensive. So maybe I only have 10 people, but then we need to have a way that if some kind of machine learning algorithm spots there's something that shouldn't be happening, or thinks it might be, then at that point, like a human can start looking at it. And the other great thing, of course, with going through proxies, is the proxies have a lot of replication for you. So if you have one proxy per node, that can be our replication point, and one of the other challenges with Kubernetes is that it really doesn't do multicast. And so the multicast solution isn't really tractable. And in fact, in this environment, you probably don't want to do multicast. So I know today that's what people mostly deploy, but it's a very odd multicast set up. Because you imagine you're an airport and you've got 10,000 cameras, but each camera has only been watched by like one app at all times, and maybe one or two humans, whatever it might be. That's a very odd multicast deployment to have 10,000 multicast groups, and each one's only got a couple of subscribers. So maybe proxies are an easier way to do it. So how have we built it? Yeah. So the software architecture, so we have a whole bunch of components, and what we try to say is decompose it into what do we put where in Kubernetes. So services run sort of one per cluster, demon sets run one per node, and then potentially you can have stuff running in the application pod, but we try and keep the footprint there very low. So the initial thing is how do we put anything in the pod? How do we make sure we intercept traffic? So what we have there is an admission webhook and a CNI plug-in, so when a pod gets created, we have an annotation that we put on the YAML file for the pod that says, OK, this is one of our pods. So the admission webhook will intercept that, and when the pod gets instantiated, it will have our stub in the pod as well as the app. But we also then have a chain CNI plug-in, and actually in the network dev room, I was there just now, somebody was literally talking about the chain CNI plug-in, so the idea is that you run whatever normal network you want for Kubernetes, and this little plug-in, all it does is add in the IP tables or EBPF rules that we're going to use to redirect that control plane traffic into our stub, and in some cases redirect the actual data plane traffic. And of course, once it starts, it gets redirected and everything's good. So in our control plane, we wanted to build one per cluster to minimize footprint. Today it basically calls out to the Kubernetes API and Core DNS, so if you're connecting in and you're saying, OK, I'm going to this URL, we want to figure out which active running pod support that URL, so that's what that piece does. So you're effectively, your RTSP sessions say from your app, the stub intercepts that TCP connection. It uses GRPC to pump the data messages or the actual payloads of the RTSP control plane into our control plane, and then we use GRPC again to program the proxies. We've written it in Golang. Say initially we've got RTSP, we used GoRTSPlib, because again, why build it from scratch? We took the GoRTSP library, and I'm guessing for any other plug-in, we'll do the same, we'll just look for existing libraries in Golang that we can plug in. What we'd like to do though, and this is up for discussion, it'd be great if people had feedback at the end or hit me offline. What I feel is there's actually two different things we're doing here. One is we've got this dynamic protocol, whatever it is, RTSP or SIP, but on the other side we've got how do we map this stuff into Kubernetes? So if you think about it, the handoff from one to the other is if you have a logical graph saying we've got this sender for a stream, and here are our receivers. What we want to do is decompose that and say how does that map onto Kubernetes? So which receivers are on which nodes? So how do we build that tree where we're doing the kind of application layer multicast? And so I think ideally we'd want to separate those two. So the control plane will have the plug-in that we put in for RTSP or SIP or whatever, but then the controller will take care of mapping that onto Kubernetes. And the nice thing then is we could use that control plane to support multiple controllers, multiple control planes, but we could also use it in non-Kubernetes environment. So firstly we've externalized any Kubernetes dependencies using XDS, which is the Envoy protocol for configuring Envoy. But also if you think about it, why does it have to be Kubernetes? If you have remote edge proxies, so you've got a global network with edge proxies doing your media proxies, why couldn't you control those for a more centralized place? The stub is to say it's a stub. So why do we call it a stub? Because it's small. So we wrote this in Rust using Tojo and Tonic and all that stuff, keeps the memory footprint low and it avoids any latency spikes because we figured if garbage collection kicks in that's going to be a problem, but I didn't want to be writing in C in 2023. There are some cases, it does intercept the control plane, but there are some cases where it intercepts the data plane as well. So RTSP as an example, there's an option to stream everything over one TCP socket. So what we can do is we can capture all that traffic and then send it over UDP through our network so we can do all the replication and everything. But there might be other cases where for example you want to monitor right at the pod or you want to do again for like TV type stuff, you want to do your live, live video replication right from the edge because you don't want any shared paths so that you don't risk having dropouts and I think that's about it on that one. So the RTP proxy now, I guess this is pretty straightforward, I mean the one we have at the moment is written in Golang, it's just a prototype. I intend to throw that one away and again, go to asynchronous Rust. The big thing here is, you know, back to the control plane, I was talking about having plugins for the protocols. So my thesis is that for success in this project, what we'd need is that we make it easy for people to contribute. So you shouldn't have to read all of my code-based contribute. What you should be able to do is say, okay, I've just got this one plugin I want to put in for my control plane protocol and here's a well-defined API that I can plug it in. But when it comes to data plane, what we're thinking is use wasm as our plugin so that then if you've got a plugin that does, whether it's encryption or whether it's validating the RTP header fields, whatever it is, you should be able to just plug that in again with a very simple API into a filter chain that's built dynamically in the proxy. Now obviously, modulo, the issue of course of performance, again, back to zero copying and all that stuff, do you really want to be copying each packet as you pass it down a filter chain? So that's something we'll probably have to think about. But as I say, I think really the key success would be to drive a filter ecosystem where people can contribute their own filters. I did a bit of work at the moment, here's come across Quilkin, which is a Google for Games project. And it does basically proxying for games. And most of that, the only way to sort of modify it was to really get into the code. And I don't want people to have to get into the code here. I want to have a really simple API. So how it works ultimately in this case would be we'd have this framework of the proxy, we'd have the filter chain. So we strip off whatever the headers are, it could be typical RTP of a UDP or it could be some quick, it could be raw RTP within the node, so we strip off any headers and then we just pass it through a filter chain where each part of the filter chain does its role. As I say, the key challenge there is going to be how do we make that perform at scale. So I think that's about it. And yeah, the goal here is that we can really deploy real-time media apps in Kubernetes and make it work, which doesn't seem to work so well today. It's very much a work in progress, it's an open source, it's all there. You can, I don't think I need to stick a new video on the website, but the GitHub's there. And really, anyone who wants to contribute, I know what it is, because as I said, I think more people is going to help us get there faster. I think if we firstly get the architecture right, then hopefully make it easy for people to contribute, then hopefully we can scale this. So do please join in. So that's that. Thank you. And to, yeah, do ask any questions while the next person's coming up. Can you repeat the question? Can you say about the quality of the project? Yeah, so at this point, very much better. I'm doing some integration work at the moment with another team within Cisco that wants to use this for something. So I guess that's where we'll start to really shake the bugs out. And that, but that again is RTSP, so, you know, really be interested in other people contributing other protocols. The integration with the other open source, like the Melio.cs, do you think it will change for these? Yeah, with other open source projects. I think in terms of how it would integrate, I guess it's down to that project and how it fits, because we've very much separated the control plane and data plane. So if the other projects have also done that, then I guess we could, that control plane could plug into what we're doing. Again today, it would have to be Golang, because that's what a control plane is written in. But even for that, again, we could look at other models to plug it in, or at least if the APIs to our data plane are clean enough, then equally just contribute the whole thing as a blob if it wasn't Golang.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 10.0, "text": " My name is Giles Herron, I work for Cisco, but let's try and forget about that for a", "tokens": [50364, 1222, 1315, 307, 460, 4680, 3204, 2044, 11, 286, 589, 337, 38528, 11, 457, 718, 311, 853, 293, 2870, 466, 300, 337, 257, 50864], "temperature": 0.0, "avg_logprob": -0.2830539047718048, "compression_ratio": 1.5535714285714286, "no_speech_prob": 0.21732985973358154}, {"id": 1, "seek": 0, "start": 10.0, "end": 11.0, "text": " moment.", "tokens": [50864, 1623, 13, 50914], "temperature": 0.0, "avg_logprob": -0.2830539047718048, "compression_ratio": 1.5535714285714286, "no_speech_prob": 0.21732985973358154}, {"id": 2, "seek": 0, "start": 11.0, "end": 15.76, "text": " Because this is open source, this is not your regular sort of traditional Cisco stuff,", "tokens": [50914, 1436, 341, 307, 1269, 4009, 11, 341, 307, 406, 428, 3890, 1333, 295, 5164, 38528, 1507, 11, 51152], "temperature": 0.0, "avg_logprob": -0.2830539047718048, "compression_ratio": 1.5535714285714286, "no_speech_prob": 0.21732985973358154}, {"id": 3, "seek": 0, "start": 15.76, "end": 18.44, "text": " hence pitching it here.", "tokens": [51152, 16678, 37499, 309, 510, 13, 51286], "temperature": 0.0, "avg_logprob": -0.2830539047718048, "compression_ratio": 1.5535714285714286, "no_speech_prob": 0.21732985973358154}, {"id": 4, "seek": 0, "start": 18.44, "end": 21.8, "text": " So the project's called Media Streaming Mesh, I'll give links to it at the end.", "tokens": [51286, 407, 264, 1716, 311, 1219, 14741, 24904, 278, 376, 14935, 11, 286, 603, 976, 6123, 281, 309, 412, 264, 917, 13, 51454], "temperature": 0.0, "avg_logprob": -0.2830539047718048, "compression_ratio": 1.5535714285714286, "no_speech_prob": 0.21732985973358154}, {"id": 5, "seek": 0, "start": 21.8, "end": 25.92, "text": " I've been running it for a while, but it's quite kind of a skunk work, so it's really", "tokens": [51454, 286, 600, 668, 2614, 309, 337, 257, 1339, 11, 457, 309, 311, 1596, 733, 295, 257, 1110, 3197, 589, 11, 370, 309, 311, 534, 51660], "temperature": 0.0, "avg_logprob": -0.2830539047718048, "compression_ratio": 1.5535714285714286, "no_speech_prob": 0.21732985973358154}, {"id": 6, "seek": 0, "start": 25.92, "end": 26.92, "text": " not loud enough.", "tokens": [51660, 406, 6588, 1547, 13, 51710], "temperature": 0.0, "avg_logprob": -0.2830539047718048, "compression_ratio": 1.5535714285714286, "no_speech_prob": 0.21732985973358154}, {"id": 7, "seek": 0, "start": 26.92, "end": 29.92, "text": " Oh yeah, yeah, it slipped right down, hasn't it?", "tokens": [51710, 876, 1338, 11, 1338, 11, 309, 28989, 558, 760, 11, 6132, 380, 309, 30, 51860], "temperature": 0.0, "avg_logprob": -0.2830539047718048, "compression_ratio": 1.5535714285714286, "no_speech_prob": 0.21732985973358154}, {"id": 8, "seek": 2992, "start": 30.840000000000003, "end": 37.120000000000005, "text": " I'll put it here and then, or if I'm a bit super loud on the recording.", "tokens": [50410, 286, 603, 829, 309, 510, 293, 550, 11, 420, 498, 286, 478, 257, 857, 1687, 6588, 322, 264, 6613, 13, 50724], "temperature": 0.0, "avg_logprob": -0.2519231276078658, "compression_ratio": 1.6450381679389312, "no_speech_prob": 0.0007190595497377217}, {"id": 9, "seek": 2992, "start": 37.120000000000005, "end": 43.760000000000005, "text": " Yeah, so kind of skunk works, it's really me and a couple of developers now.", "tokens": [50724, 865, 11, 370, 733, 295, 1110, 3197, 1985, 11, 309, 311, 534, 385, 293, 257, 1916, 295, 8849, 586, 13, 51056], "temperature": 0.0, "avg_logprob": -0.2519231276078658, "compression_ratio": 1.6450381679389312, "no_speech_prob": 0.0007190595497377217}, {"id": 10, "seek": 2992, "start": 43.760000000000005, "end": 47.68000000000001, "text": " And really where it comes from was, we were looking at Kubernetes so that the group are", "tokens": [51056, 400, 534, 689, 309, 1487, 490, 390, 11, 321, 645, 1237, 412, 23145, 370, 300, 264, 1594, 366, 51252], "temperature": 0.0, "avg_logprob": -0.2519231276078658, "compression_ratio": 1.6450381679389312, "no_speech_prob": 0.0007190595497377217}, {"id": 11, "seek": 2992, "start": 47.68000000000001, "end": 52.64, "text": " working, everything we do really is cloud native, and so when I took a look at Kubernetes,", "tokens": [51252, 1364, 11, 1203, 321, 360, 534, 307, 4588, 8470, 11, 293, 370, 562, 286, 1890, 257, 574, 412, 23145, 11, 51500], "temperature": 0.0, "avg_logprob": -0.2519231276078658, "compression_ratio": 1.6450381679389312, "no_speech_prob": 0.0007190595497377217}, {"id": 12, "seek": 2992, "start": 52.64, "end": 56.32000000000001, "text": " my main impression was that here was something that was very much based on supporting web", "tokens": [51500, 452, 2135, 9995, 390, 300, 510, 390, 746, 300, 390, 588, 709, 2361, 322, 7231, 3670, 51684], "temperature": 0.0, "avg_logprob": -0.2519231276078658, "compression_ratio": 1.6450381679389312, "no_speech_prob": 0.0007190595497377217}, {"id": 13, "seek": 2992, "start": 56.32000000000001, "end": 57.32000000000001, "text": " applications.", "tokens": [51684, 5821, 13, 51734], "temperature": 0.0, "avg_logprob": -0.2519231276078658, "compression_ratio": 1.6450381679389312, "no_speech_prob": 0.0007190595497377217}, {"id": 14, "seek": 5732, "start": 57.72, "end": 63.36, "text": " Even if you look at like liveness checks in Kubernetes, they're like TCP or HTTP.", "tokens": [50384, 2754, 498, 291, 574, 412, 411, 1621, 1287, 13834, 294, 23145, 11, 436, 434, 411, 48965, 420, 33283, 13, 50666], "temperature": 0.0, "avg_logprob": -0.2108294686605764, "compression_ratio": 1.8612903225806452, "no_speech_prob": 0.0029737367294728756}, {"id": 15, "seek": 5732, "start": 63.36, "end": 67.24, "text": " And so I was like, well, okay, so how would we do real-time media in that?", "tokens": [50666, 400, 370, 286, 390, 411, 11, 731, 11, 1392, 11, 370, 577, 576, 321, 360, 957, 12, 3766, 3021, 294, 300, 30, 50860], "temperature": 0.0, "avg_logprob": -0.2108294686605764, "compression_ratio": 1.8612903225806452, "no_speech_prob": 0.0029737367294728756}, {"id": 16, "seek": 5732, "start": 67.24, "end": 70.2, "text": " And one way I look at it is to say, well, you can divide the world into two by two matrices,", "tokens": [50860, 400, 472, 636, 286, 574, 412, 309, 307, 281, 584, 11, 731, 11, 291, 393, 9845, 264, 1002, 666, 732, 538, 732, 32284, 11, 51008], "temperature": 0.0, "avg_logprob": -0.2108294686605764, "compression_ratio": 1.8612903225806452, "no_speech_prob": 0.0029737367294728756}, {"id": 17, "seek": 5732, "start": 70.2, "end": 71.2, "text": " whatever you're looking at.", "tokens": [51008, 2035, 291, 434, 1237, 412, 13, 51058], "temperature": 0.0, "avg_logprob": -0.2108294686605764, "compression_ratio": 1.8612903225806452, "no_speech_prob": 0.0029737367294728756}, {"id": 18, "seek": 5732, "start": 71.2, "end": 75.68, "text": " And if you look at apps and say, well, you've got real-time, you've got non-real-time, you've", "tokens": [51058, 400, 498, 291, 574, 412, 7733, 293, 584, 11, 731, 11, 291, 600, 658, 957, 12, 3766, 11, 291, 600, 658, 2107, 12, 9342, 12, 3766, 11, 291, 600, 51282], "temperature": 0.0, "avg_logprob": -0.2108294686605764, "compression_ratio": 1.8612903225806452, "no_speech_prob": 0.0029737367294728756}, {"id": 19, "seek": 5732, "start": 75.68, "end": 79.56, "text": " got interactive apps and streaming apps, they're just sort of pub-sub stuff.", "tokens": [51282, 658, 15141, 7733, 293, 11791, 7733, 11, 436, 434, 445, 1333, 295, 1535, 12, 30131, 1507, 13, 51476], "temperature": 0.0, "avg_logprob": -0.2108294686605764, "compression_ratio": 1.8612903225806452, "no_speech_prob": 0.0029737367294728756}, {"id": 20, "seek": 5732, "start": 79.56, "end": 83.48, "text": " And really, back to Kubernetes, it's very much in that top-left corner, it's all about", "tokens": [51476, 400, 534, 11, 646, 281, 23145, 11, 309, 311, 588, 709, 294, 300, 1192, 12, 41761, 4538, 11, 309, 311, 439, 466, 51672], "temperature": 0.0, "avg_logprob": -0.2108294686605764, "compression_ratio": 1.8612903225806452, "no_speech_prob": 0.0029737367294728756}, {"id": 21, "seek": 5732, "start": 83.48, "end": 84.48, "text": " web apps.", "tokens": [51672, 3670, 7733, 13, 51722], "temperature": 0.0, "avg_logprob": -0.2108294686605764, "compression_ratio": 1.8612903225806452, "no_speech_prob": 0.0029737367294728756}, {"id": 22, "seek": 5732, "start": 84.48, "end": 86.68, "text": " So how do we do real-time apps?", "tokens": [51722, 407, 577, 360, 321, 360, 957, 12, 3766, 7733, 30, 51832], "temperature": 0.0, "avg_logprob": -0.2108294686605764, "compression_ratio": 1.8612903225806452, "no_speech_prob": 0.0029737367294728756}, {"id": 23, "seek": 8668, "start": 86.68, "end": 91.64, "text": " And so that was where the project started, initially looking at anything real-time, so", "tokens": [50364, 400, 370, 300, 390, 689, 264, 1716, 1409, 11, 9105, 1237, 412, 1340, 957, 12, 3766, 11, 370, 50612], "temperature": 0.0, "avg_logprob": -0.18898697753450763, "compression_ratio": 1.6416382252559727, "no_speech_prob": 0.0007405041251331568}, {"id": 24, "seek": 8668, "start": 91.64, "end": 94.96000000000001, "text": " including online games, it could have been stock trading or whatever.", "tokens": [50612, 3009, 2950, 2813, 11, 309, 727, 362, 668, 4127, 9529, 420, 2035, 13, 50778], "temperature": 0.0, "avg_logprob": -0.18898697753450763, "compression_ratio": 1.6416382252559727, "no_speech_prob": 0.0007405041251331568}, {"id": 25, "seek": 8668, "start": 94.96000000000001, "end": 100.16000000000001, "text": " But then in terms of focus, we decided then, let's focus on real-time media, and by that", "tokens": [50778, 583, 550, 294, 2115, 295, 1879, 11, 321, 3047, 550, 11, 718, 311, 1879, 322, 957, 12, 3766, 3021, 11, 293, 538, 300, 51038], "temperature": 0.0, "avg_logprob": -0.18898697753450763, "compression_ratio": 1.6416382252559727, "no_speech_prob": 0.0007405041251331568}, {"id": 26, "seek": 8668, "start": 100.16000000000001, "end": 103.96000000000001, "text": " really anything RTP-based, so hence being here.", "tokens": [51038, 534, 1340, 497, 16804, 12, 6032, 11, 370, 16678, 885, 510, 13, 51228], "temperature": 0.0, "avg_logprob": -0.18898697753450763, "compression_ratio": 1.6416382252559727, "no_speech_prob": 0.0007405041251331568}, {"id": 27, "seek": 8668, "start": 103.96000000000001, "end": 109.4, "text": " So that could be WebRTC, it could be SIP, but equally it can be RTSP, it can be live", "tokens": [51228, 407, 300, 727, 312, 9573, 49, 18238, 11, 309, 727, 312, 318, 9139, 11, 457, 12309, 309, 393, 312, 497, 7327, 47, 11, 309, 393, 312, 1621, 51500], "temperature": 0.0, "avg_logprob": -0.18898697753450763, "compression_ratio": 1.6416382252559727, "no_speech_prob": 0.0007405041251331568}, {"id": 28, "seek": 8668, "start": 109.4, "end": 112.56, "text": " video, that sort of thing.", "tokens": [51500, 960, 11, 300, 1333, 295, 551, 13, 51658], "temperature": 0.0, "avg_logprob": -0.18898697753450763, "compression_ratio": 1.6416382252559727, "no_speech_prob": 0.0007405041251331568}, {"id": 29, "seek": 8668, "start": 112.56, "end": 115.80000000000001, "text": " And so then we'll say, well, how would we support this in Kubernetes today?", "tokens": [51658, 400, 370, 550, 321, 603, 584, 11, 731, 11, 577, 576, 321, 1406, 341, 294, 23145, 965, 30, 51820], "temperature": 0.0, "avg_logprob": -0.18898697753450763, "compression_ratio": 1.6416382252559727, "no_speech_prob": 0.0007405041251331568}, {"id": 30, "seek": 11580, "start": 115.8, "end": 120.72, "text": " So everyone's really big, one of the big things at the moment in Kubernetes is service", "tokens": [50364, 407, 1518, 311, 534, 955, 11, 472, 295, 264, 955, 721, 412, 264, 1623, 294, 23145, 307, 2643, 50610], "temperature": 0.0, "avg_logprob": -0.1767565653874324, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.005573843140155077}, {"id": 31, "seek": 11580, "start": 120.72, "end": 121.72, "text": " meshes.", "tokens": [50610, 3813, 8076, 13, 50660], "temperature": 0.0, "avg_logprob": -0.1767565653874324, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.005573843140155077}, {"id": 32, "seek": 11580, "start": 121.72, "end": 125.67999999999999, "text": " So I'm guessing who here's played with service meshes at all?", "tokens": [50660, 407, 286, 478, 17939, 567, 510, 311, 3737, 365, 2643, 3813, 8076, 412, 439, 30, 50858], "temperature": 0.0, "avg_logprob": -0.1767565653874324, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.005573843140155077}, {"id": 33, "seek": 11580, "start": 125.67999999999999, "end": 126.67999999999999, "text": " Anyone?", "tokens": [50858, 14643, 30, 50908], "temperature": 0.0, "avg_logprob": -0.1767565653874324, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.005573843140155077}, {"id": 34, "seek": 11580, "start": 126.67999999999999, "end": 127.67999999999999, "text": " One or two?", "tokens": [50908, 1485, 420, 732, 30, 50958], "temperature": 0.0, "avg_logprob": -0.1767565653874324, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.005573843140155077}, {"id": 35, "seek": 11580, "start": 127.67999999999999, "end": 128.68, "text": " Yes.", "tokens": [50958, 1079, 13, 51008], "temperature": 0.0, "avg_logprob": -0.1767565653874324, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.005573843140155077}, {"id": 36, "seek": 11580, "start": 128.68, "end": 132.51999999999998, "text": " So what the service mesh does is it terminates your TCP or HTTP connections at each pod,", "tokens": [51008, 407, 437, 264, 2643, 17407, 775, 307, 309, 10761, 1024, 428, 48965, 420, 33283, 9271, 412, 1184, 2497, 11, 51200], "temperature": 0.0, "avg_logprob": -0.1767565653874324, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.005573843140155077}, {"id": 37, "seek": 11580, "start": 132.51999999999998, "end": 136.44, "text": " and so rather than sort of routing across your Kubernetes cluster, you kind of go hot", "tokens": [51200, 293, 370, 2831, 813, 1333, 295, 32722, 2108, 428, 23145, 13630, 11, 291, 733, 295, 352, 2368, 51396], "temperature": 0.0, "avg_logprob": -0.1767565653874324, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.005573843140155077}, {"id": 38, "seek": 11580, "start": 136.44, "end": 138.76, "text": " by hot through web proxies.", "tokens": [51396, 538, 2368, 807, 3670, 447, 87, 530, 13, 51512], "temperature": 0.0, "avg_logprob": -0.1767565653874324, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.005573843140155077}, {"id": 39, "seek": 11580, "start": 138.76, "end": 143.32, "text": " So you get security, you get good stats, that sort of thing at the price of complexity.", "tokens": [51512, 407, 291, 483, 3825, 11, 291, 483, 665, 18152, 11, 300, 1333, 295, 551, 412, 264, 3218, 295, 14024, 13, 51740], "temperature": 0.0, "avg_logprob": -0.1767565653874324, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.005573843140155077}, {"id": 40, "seek": 14332, "start": 143.32, "end": 148.28, "text": " The challenge is these service meshes, they'll work for TCP apps, they're great for HTTP", "tokens": [50364, 440, 3430, 307, 613, 2643, 3813, 8076, 11, 436, 603, 589, 337, 48965, 7733, 11, 436, 434, 869, 337, 33283, 50612], "temperature": 0.0, "avg_logprob": -0.14747588336467743, "compression_ratio": 1.6813559322033897, "no_speech_prob": 0.0015229231212288141}, {"id": 41, "seek": 14332, "start": 148.28, "end": 153.48, "text": " apps because you can go in and do URL routing, that kind of stuff, don't support UDP and", "tokens": [50612, 7733, 570, 291, 393, 352, 294, 293, 360, 12905, 32722, 11, 300, 733, 295, 1507, 11, 500, 380, 1406, 624, 11373, 293, 50872], "temperature": 0.0, "avg_logprob": -0.14747588336467743, "compression_ratio": 1.6813559322033897, "no_speech_prob": 0.0015229231212288141}, {"id": 42, "seek": 14332, "start": 153.48, "end": 156.28, "text": " they certainly don't support real-time media apps.", "tokens": [50872, 436, 3297, 500, 380, 1406, 957, 12, 3766, 3021, 7733, 13, 51012], "temperature": 0.0, "avg_logprob": -0.14747588336467743, "compression_ratio": 1.6813559322033897, "no_speech_prob": 0.0015229231212288141}, {"id": 43, "seek": 14332, "start": 156.28, "end": 159.56, "text": " So the next thing to say is, well, what if we don't bother with a service mesh and we'll", "tokens": [51012, 407, 264, 958, 551, 281, 584, 307, 11, 731, 11, 437, 498, 321, 500, 380, 8677, 365, 257, 2643, 17407, 293, 321, 603, 51176], "temperature": 0.0, "avg_logprob": -0.14747588336467743, "compression_ratio": 1.6813559322033897, "no_speech_prob": 0.0015229231212288141}, {"id": 44, "seek": 14332, "start": 159.56, "end": 161.76, "text": " just use regular Kube proxy and node port?", "tokens": [51176, 445, 764, 3890, 591, 1977, 29690, 293, 9984, 2436, 30, 51286], "temperature": 0.0, "avg_logprob": -0.14747588336467743, "compression_ratio": 1.6813559322033897, "no_speech_prob": 0.0015229231212288141}, {"id": 45, "seek": 14332, "start": 161.76, "end": 164.12, "text": " So this is the standard NAT that Kubernetes uses.", "tokens": [51286, 407, 341, 307, 264, 3832, 14500, 300, 23145, 4960, 13, 51404], "temperature": 0.0, "avg_logprob": -0.14747588336467743, "compression_ratio": 1.6813559322033897, "no_speech_prob": 0.0015229231212288141}, {"id": 46, "seek": 14332, "start": 164.12, "end": 169.48, "text": " So what Kubernetes typically does is it gives a service like a persistent IP address.", "tokens": [51404, 407, 437, 23145, 5850, 775, 307, 309, 2709, 257, 2643, 411, 257, 24315, 8671, 2985, 13, 51672], "temperature": 0.0, "avg_logprob": -0.14747588336467743, "compression_ratio": 1.6813559322033897, "no_speech_prob": 0.0015229231212288141}, {"id": 47, "seek": 16948, "start": 169.48, "end": 173.56, "text": " So rather than relying on DNS, which obviously you can cache things, you put a persistent", "tokens": [50364, 407, 2831, 813, 24140, 322, 35153, 11, 597, 2745, 291, 393, 19459, 721, 11, 291, 829, 257, 24315, 50568], "temperature": 0.0, "avg_logprob": -0.19298525456781987, "compression_ratio": 1.7810650887573964, "no_speech_prob": 0.028419701382517815}, {"id": 48, "seek": 16948, "start": 173.56, "end": 177.48, "text": " IP address on a service and then you have ephemeral IP addresses for your individual", "tokens": [50568, 8671, 2985, 322, 257, 2643, 293, 550, 291, 362, 308, 41245, 2790, 8671, 16862, 337, 428, 2609, 50764], "temperature": 0.0, "avg_logprob": -0.19298525456781987, "compression_ratio": 1.7810650887573964, "no_speech_prob": 0.028419701382517815}, {"id": 49, "seek": 16948, "start": 177.48, "end": 181.16, "text": " pods that support that service, and the way you get from one to the other is NATting,", "tokens": [50764, 31925, 300, 1406, 300, 2643, 11, 293, 264, 636, 291, 483, 490, 472, 281, 264, 661, 307, 14500, 783, 11, 50948], "temperature": 0.0, "avg_logprob": -0.19298525456781987, "compression_ratio": 1.7810650887573964, "no_speech_prob": 0.028419701382517815}, {"id": 50, "seek": 16948, "start": 181.16, "end": 184.67999999999998, "text": " which for those of us who are network people, makes us throw up a little in our mouths.", "tokens": [50948, 597, 337, 729, 295, 505, 567, 366, 3209, 561, 11, 1669, 505, 3507, 493, 257, 707, 294, 527, 33171, 13, 51124], "temperature": 0.0, "avg_logprob": -0.19298525456781987, "compression_ratio": 1.7810650887573964, "no_speech_prob": 0.028419701382517815}, {"id": 51, "seek": 16948, "start": 184.67999999999998, "end": 190.12, "text": " But the challenge there is these do work, again, for the basic services.", "tokens": [51124, 583, 264, 3430, 456, 307, 613, 360, 589, 11, 797, 11, 337, 264, 3875, 3328, 13, 51396], "temperature": 0.0, "avg_logprob": -0.19298525456781987, "compression_ratio": 1.7810650887573964, "no_speech_prob": 0.028419701382517815}, {"id": 52, "seek": 16948, "start": 190.12, "end": 194.12, "text": " I put that in yellow, there's a challenge which is that typically when you expose things", "tokens": [51396, 286, 829, 300, 294, 5566, 11, 456, 311, 257, 3430, 597, 307, 300, 5850, 562, 291, 19219, 721, 51596], "temperature": 0.0, "avg_logprob": -0.19298525456781987, "compression_ratio": 1.7810650887573964, "no_speech_prob": 0.028419701382517815}, {"id": 53, "seek": 16948, "start": 194.12, "end": 198.28, "text": " externally from your cluster, you use these high port numbers in node port, which is pretty", "tokens": [51596, 40899, 490, 428, 13630, 11, 291, 764, 613, 1090, 2436, 3547, 294, 9984, 2436, 11, 597, 307, 1238, 51804], "temperature": 0.0, "avg_logprob": -0.19298525456781987, "compression_ratio": 1.7810650887573964, "no_speech_prob": 0.028419701382517815}, {"id": 54, "seek": 19828, "start": 198.36, "end": 199.56, "text": " messy.", "tokens": [50368, 16191, 13, 50428], "temperature": 0.0, "avg_logprob": -0.15847688872238685, "compression_ratio": 1.6905537459283388, "no_speech_prob": 0.03178531676530838}, {"id": 55, "seek": 19828, "start": 199.56, "end": 203.52, "text": " You want to use well-known ones, of course, or you prefer to, but they don't support", "tokens": [50428, 509, 528, 281, 764, 731, 12, 6861, 2306, 11, 295, 1164, 11, 420, 291, 4382, 281, 11, 457, 436, 500, 380, 1406, 50626], "temperature": 0.0, "avg_logprob": -0.15847688872238685, "compression_ratio": 1.6905537459283388, "no_speech_prob": 0.03178531676530838}, {"id": 56, "seek": 19828, "start": 203.52, "end": 204.52, "text": " real-time media.", "tokens": [50626, 957, 12, 3766, 3021, 13, 50676], "temperature": 0.0, "avg_logprob": -0.15847688872238685, "compression_ratio": 1.6905537459283388, "no_speech_prob": 0.03178531676530838}, {"id": 57, "seek": 19828, "start": 204.52, "end": 207.88, "text": " And I guess this is no surprise to anyone in this room, but if you're doing things like", "tokens": [50676, 400, 286, 2041, 341, 307, 572, 6365, 281, 2878, 294, 341, 1808, 11, 457, 498, 291, 434, 884, 721, 411, 50844], "temperature": 0.0, "avg_logprob": -0.15847688872238685, "compression_ratio": 1.6905537459283388, "no_speech_prob": 0.03178531676530838}, {"id": 58, "seek": 19828, "start": 207.88, "end": 212.12, "text": " SIP and RTSP, what you'll typically see is that there'll be a TCP channel that'll be", "tokens": [50844, 318, 9139, 293, 497, 7327, 47, 11, 437, 291, 603, 5850, 536, 307, 300, 456, 603, 312, 257, 48965, 2269, 300, 603, 312, 51056], "temperature": 0.0, "avg_logprob": -0.15847688872238685, "compression_ratio": 1.6905537459283388, "no_speech_prob": 0.03178531676530838}, {"id": 59, "seek": 19828, "start": 212.12, "end": 213.12, "text": " negotiated.", "tokens": [51056, 39028, 13, 51106], "temperature": 0.0, "avg_logprob": -0.15847688872238685, "compression_ratio": 1.6905537459283388, "no_speech_prob": 0.03178531676530838}, {"id": 60, "seek": 19828, "start": 213.12, "end": 217.4, "text": " Well, it can be TCP, it can be UDP, but it will negotiate the media ports.", "tokens": [51106, 1042, 11, 309, 393, 312, 48965, 11, 309, 393, 312, 624, 11373, 11, 457, 309, 486, 21713, 264, 3021, 18160, 13, 51320], "temperature": 0.0, "avg_logprob": -0.15847688872238685, "compression_ratio": 1.6905537459283388, "no_speech_prob": 0.03178531676530838}, {"id": 61, "seek": 19828, "start": 217.4, "end": 220.84, "text": " So the challenge there is those media port negotiations are completely invisible to the", "tokens": [51320, 407, 264, 3430, 456, 307, 729, 3021, 2436, 20476, 366, 2584, 14603, 281, 264, 51492], "temperature": 0.0, "avg_logprob": -0.15847688872238685, "compression_ratio": 1.6905537459283388, "no_speech_prob": 0.03178531676530838}, {"id": 62, "seek": 19828, "start": 220.84, "end": 225.2, "text": " NAT, and so that will break if you try and deploy it this way.", "tokens": [51492, 14500, 11, 293, 370, 300, 486, 1821, 498, 291, 853, 293, 7274, 309, 341, 636, 13, 51710], "temperature": 0.0, "avg_logprob": -0.15847688872238685, "compression_ratio": 1.6905537459283388, "no_speech_prob": 0.03178531676530838}, {"id": 63, "seek": 22520, "start": 225.23999999999998, "end": 230.51999999999998, "text": " So what I've seen some people in the industry do, so people deploying onto Kubernetes with", "tokens": [50366, 407, 437, 286, 600, 1612, 512, 561, 294, 264, 3518, 360, 11, 370, 561, 34198, 3911, 23145, 365, 50630], "temperature": 0.0, "avg_logprob": -0.17079767540319643, "compression_ratio": 1.6360655737704919, "no_speech_prob": 0.001607714220881462}, {"id": 64, "seek": 22520, "start": 230.51999999999998, "end": 234.11999999999998, "text": " conferencing solutions, is they'll use host networking.", "tokens": [50630, 13765, 13644, 6547, 11, 307, 436, 603, 764, 3975, 17985, 13, 50810], "temperature": 0.0, "avg_logprob": -0.17079767540319643, "compression_ratio": 1.6360655737704919, "no_speech_prob": 0.001607714220881462}, {"id": 65, "seek": 22520, "start": 234.11999999999998, "end": 235.11999999999998, "text": " And that just works, right?", "tokens": [50810, 400, 300, 445, 1985, 11, 558, 30, 50860], "temperature": 0.0, "avg_logprob": -0.17079767540319643, "compression_ratio": 1.6360655737704919, "no_speech_prob": 0.001607714220881462}, {"id": 66, "seek": 22520, "start": 235.11999999999998, "end": 238.92, "text": " You put everything in the host name space, everything's good, there's no NAT, we're all", "tokens": [50860, 509, 829, 1203, 294, 264, 3975, 1315, 1901, 11, 1203, 311, 665, 11, 456, 311, 572, 14500, 11, 321, 434, 439, 51050], "temperature": 0.0, "avg_logprob": -0.17079767540319643, "compression_ratio": 1.6360655737704919, "no_speech_prob": 0.001607714220881462}, {"id": 67, "seek": 22520, "start": 238.92, "end": 239.92, "text": " happy.", "tokens": [51050, 2055, 13, 51100], "temperature": 0.0, "avg_logprob": -0.17079767540319643, "compression_ratio": 1.6360655737704919, "no_speech_prob": 0.001607714220881462}, {"id": 68, "seek": 22520, "start": 239.92, "end": 241.92, "text": " Okay, so why not do that?", "tokens": [51100, 1033, 11, 370, 983, 406, 360, 300, 30, 51200], "temperature": 0.0, "avg_logprob": -0.17079767540319643, "compression_ratio": 1.6360655737704919, "no_speech_prob": 0.001607714220881462}, {"id": 69, "seek": 22520, "start": 241.92, "end": 247.23999999999998, "text": " Big issue is, oops, you can only put one media part on each node, because if you want to", "tokens": [51200, 5429, 2734, 307, 11, 34166, 11, 291, 393, 787, 829, 472, 3021, 644, 322, 1184, 9984, 11, 570, 498, 291, 528, 281, 51466], "temperature": 0.0, "avg_logprob": -0.17079767540319643, "compression_ratio": 1.6360655737704919, "no_speech_prob": 0.001607714220881462}, {"id": 70, "seek": 22520, "start": 247.23999999999998, "end": 250.48, "text": " have multiple media parts all exposing the same port, well, you've only got one instance", "tokens": [51466, 362, 3866, 3021, 3166, 439, 33178, 264, 912, 2436, 11, 731, 11, 291, 600, 787, 658, 472, 5197, 51628], "temperature": 0.0, "avg_logprob": -0.17079767540319643, "compression_ratio": 1.6360655737704919, "no_speech_prob": 0.001607714220881462}, {"id": 71, "seek": 22520, "start": 250.48, "end": 252.2, "text": " of that port on the host.", "tokens": [51628, 295, 300, 2436, 322, 264, 3975, 13, 51714], "temperature": 0.0, "avg_logprob": -0.17079767540319643, "compression_ratio": 1.6360655737704919, "no_speech_prob": 0.001607714220881462}, {"id": 72, "seek": 25220, "start": 252.2, "end": 256.68, "text": " So that's okay if you're going to run on VMs, you're going to size your VMs down to", "tokens": [50364, 407, 300, 311, 1392, 498, 291, 434, 516, 281, 1190, 322, 18038, 82, 11, 291, 434, 516, 281, 2744, 428, 18038, 82, 760, 281, 50588], "temperature": 0.0, "avg_logprob": -0.18061372637748718, "compression_ratio": 1.7481481481481482, "no_speech_prob": 0.00231149117462337}, {"id": 73, "seek": 25220, "start": 256.68, "end": 261.08, "text": " the right size for one media pod, and there's the cost of having many more nodes in your", "tokens": [50588, 264, 558, 2744, 337, 472, 3021, 2497, 11, 293, 456, 311, 264, 2063, 295, 1419, 867, 544, 13891, 294, 428, 50808], "temperature": 0.0, "avg_logprob": -0.18061372637748718, "compression_ratio": 1.7481481481481482, "no_speech_prob": 0.00231149117462337}, {"id": 74, "seek": 25220, "start": 261.08, "end": 264.64, "text": " clusters, but if you're deploying onto bare metal, that's going to suck.", "tokens": [50808, 23313, 11, 457, 498, 291, 434, 34198, 3911, 6949, 5760, 11, 300, 311, 516, 281, 9967, 13, 50986], "temperature": 0.0, "avg_logprob": -0.18061372637748718, "compression_ratio": 1.7481481481481482, "no_speech_prob": 0.00231149117462337}, {"id": 75, "seek": 25220, "start": 264.64, "end": 270.12, "text": " So what we came up with MediaStreamMesh said, let's focus on this real-time media, let's", "tokens": [50986, 407, 437, 321, 1361, 493, 365, 14741, 4520, 1572, 44, 14935, 848, 11, 718, 311, 1879, 322, 341, 957, 12, 3766, 3021, 11, 718, 311, 51260], "temperature": 0.0, "avg_logprob": -0.18061372637748718, "compression_ratio": 1.7481481481481482, "no_speech_prob": 0.00231149117462337}, {"id": 76, "seek": 25220, "start": 270.12, "end": 273.15999999999997, "text": " support multiple media pods per node.", "tokens": [51260, 1406, 3866, 3021, 31925, 680, 9984, 13, 51412], "temperature": 0.0, "avg_logprob": -0.18061372637748718, "compression_ratio": 1.7481481481481482, "no_speech_prob": 0.00231149117462337}, {"id": 77, "seek": 25220, "start": 273.15999999999997, "end": 277.2, "text": " Let's also maybe support the other services, either directly or in combination with a service", "tokens": [51412, 961, 311, 611, 1310, 1406, 264, 661, 3328, 11, 2139, 3838, 420, 294, 6562, 365, 257, 2643, 51614], "temperature": 0.0, "avg_logprob": -0.18061372637748718, "compression_ratio": 1.7481481481481482, "no_speech_prob": 0.00231149117462337}, {"id": 78, "seek": 25220, "start": 277.2, "end": 278.2, "text": " mesh.", "tokens": [51614, 17407, 13, 51664], "temperature": 0.0, "avg_logprob": -0.18061372637748718, "compression_ratio": 1.7481481481481482, "no_speech_prob": 0.00231149117462337}, {"id": 79, "seek": 27820, "start": 278.88, "end": 282.96, "text": " But yeah, let's really make this our focus.", "tokens": [50398, 583, 1338, 11, 718, 311, 534, 652, 341, 527, 1879, 13, 50602], "temperature": 0.0, "avg_logprob": -0.1977017875609359, "compression_ratio": 1.632996632996633, "no_speech_prob": 0.0031523911748081446}, {"id": 80, "seek": 27820, "start": 282.96, "end": 285.15999999999997, "text": " And what was I trying to do?", "tokens": [50602, 400, 437, 390, 286, 1382, 281, 360, 30, 50712], "temperature": 0.0, "avg_logprob": -0.1977017875609359, "compression_ratio": 1.632996632996633, "no_speech_prob": 0.0031523911748081446}, {"id": 81, "seek": 27820, "start": 285.15999999999997, "end": 288.76, "text": " Really take everything that we get in service meshes in Kubernetes, so that's really good", "tokens": [50712, 4083, 747, 1203, 300, 321, 483, 294, 2643, 3813, 8076, 294, 23145, 11, 370, 300, 311, 534, 665, 50892], "temperature": 0.0, "avg_logprob": -0.1977017875609359, "compression_ratio": 1.632996632996633, "no_speech_prob": 0.0031523911748081446}, {"id": 82, "seek": 27820, "start": 288.76, "end": 293.68, "text": " observability and security so you can crit stuff when it goes out of the node, you can", "tokens": [50892, 9951, 2310, 293, 3825, 370, 291, 393, 3113, 1507, 562, 309, 1709, 484, 295, 264, 9984, 11, 291, 393, 51138], "temperature": 0.0, "avg_logprob": -0.1977017875609359, "compression_ratio": 1.632996632996633, "no_speech_prob": 0.0031523911748081446}, {"id": 83, "seek": 27820, "start": 293.68, "end": 297.96, "text": " check all your performance metrics and that kind of stuff.", "tokens": [51138, 1520, 439, 428, 3389, 16367, 293, 300, 733, 295, 1507, 13, 51352], "temperature": 0.0, "avg_logprob": -0.1977017875609359, "compression_ratio": 1.632996632996633, "no_speech_prob": 0.0031523911748081446}, {"id": 84, "seek": 27820, "start": 297.96, "end": 301.56, "text": " That's great for debugging, troubleshooting, securing your network, but what we wanted", "tokens": [51352, 663, 311, 869, 337, 45592, 11, 15379, 47011, 11, 33640, 428, 3209, 11, 457, 437, 321, 1415, 51532], "temperature": 0.0, "avg_logprob": -0.1977017875609359, "compression_ratio": 1.632996632996633, "no_speech_prob": 0.0031523911748081446}, {"id": 85, "seek": 27820, "start": 301.56, "end": 306.76, "text": " to do was provide the lower latency of factory proxy at the UDP or RTP layer, not TCP, so", "tokens": [51532, 281, 360, 390, 2893, 264, 3126, 27043, 295, 9265, 29690, 412, 264, 624, 11373, 420, 497, 16804, 4583, 11, 406, 48965, 11, 370, 51792], "temperature": 0.0, "avg_logprob": -0.1977017875609359, "compression_ratio": 1.632996632996633, "no_speech_prob": 0.0031523911748081446}, {"id": 86, "seek": 30676, "start": 306.76, "end": 310.68, "text": " I don't know, terminating TCP, and we wanted it to be really light.", "tokens": [50364, 286, 500, 380, 458, 11, 1433, 8205, 48965, 11, 293, 321, 1415, 309, 281, 312, 534, 1442, 13, 50560], "temperature": 0.0, "avg_logprob": -0.17763478415352957, "compression_ratio": 1.668639053254438, "no_speech_prob": 0.004791736602783203}, {"id": 87, "seek": 30676, "start": 310.68, "end": 313.76, "text": " So we looked at how do we decompose it so that we can put this right out at the edge", "tokens": [50560, 407, 321, 2956, 412, 577, 360, 321, 22867, 541, 309, 370, 300, 321, 393, 829, 341, 558, 484, 412, 264, 4691, 50714], "temperature": 0.0, "avg_logprob": -0.17763478415352957, "compression_ratio": 1.668639053254438, "no_speech_prob": 0.004791736602783203}, {"id": 88, "seek": 30676, "start": 313.76, "end": 317.0, "text": " of the network, because some of our use cases are people saying, well, we've got a camera", "tokens": [50714, 295, 264, 3209, 11, 570, 512, 295, 527, 764, 3331, 366, 561, 1566, 11, 731, 11, 321, 600, 658, 257, 2799, 50876], "temperature": 0.0, "avg_logprob": -0.17763478415352957, "compression_ratio": 1.668639053254438, "no_speech_prob": 0.004791736602783203}, {"id": 89, "seek": 30676, "start": 317.0, "end": 320.88, "text": " in a coffee shop, and we want to stream that somewhere, and we want to run it on a little", "tokens": [50876, 294, 257, 4982, 3945, 11, 293, 321, 528, 281, 4309, 300, 4079, 11, 293, 321, 528, 281, 1190, 309, 322, 257, 707, 51070], "temperature": 0.0, "avg_logprob": -0.17763478415352957, "compression_ratio": 1.668639053254438, "no_speech_prob": 0.004791736602783203}, {"id": 90, "seek": 30676, "start": 320.88, "end": 324.2, "text": " node running K3S like a little Raspberry Pi or something.", "tokens": [51070, 9984, 2614, 591, 18, 50, 411, 257, 707, 41154, 17741, 420, 746, 13, 51236], "temperature": 0.0, "avg_logprob": -0.17763478415352957, "compression_ratio": 1.668639053254438, "no_speech_prob": 0.004791736602783203}, {"id": 91, "seek": 30676, "start": 324.2, "end": 328.56, "text": " So can we get this down to a small enough footprint?", "tokens": [51236, 407, 393, 321, 483, 341, 760, 281, 257, 1359, 1547, 24222, 30, 51454], "temperature": 0.0, "avg_logprob": -0.17763478415352957, "compression_ratio": 1.668639053254438, "no_speech_prob": 0.004791736602783203}, {"id": 92, "seek": 30676, "start": 328.56, "end": 333.84, "text": " So in terms of use cases, obviously real-time collaboration, so we haven't yet done WebRTC,", "tokens": [51454, 407, 294, 2115, 295, 764, 3331, 11, 2745, 957, 12, 3766, 9363, 11, 370, 321, 2378, 380, 1939, 1096, 9573, 49, 18238, 11, 51718], "temperature": 0.0, "avg_logprob": -0.17763478415352957, "compression_ratio": 1.668639053254438, "no_speech_prob": 0.004791736602783203}, {"id": 93, "seek": 30676, "start": 333.84, "end": 335.68, "text": " that would be my disclaimer.", "tokens": [51718, 300, 576, 312, 452, 40896, 13, 51810], "temperature": 0.0, "avg_logprob": -0.17763478415352957, "compression_ratio": 1.668639053254438, "no_speech_prob": 0.004791736602783203}, {"id": 94, "seek": 33568, "start": 335.68, "end": 338.56, "text": " If anyone wants to help us port it into this, that would be great, you can take some like", "tokens": [50364, 759, 2878, 2738, 281, 854, 505, 2436, 309, 666, 341, 11, 300, 576, 312, 869, 11, 291, 393, 747, 512, 411, 50508], "temperature": 0.0, "avg_logprob": -0.19548375153344524, "compression_ratio": 1.6548042704626333, "no_speech_prob": 0.003328740829601884}, {"id": 95, "seek": 33568, "start": 338.56, "end": 342.28000000000003, "text": " PON and port it into this framework.", "tokens": [50508, 430, 1928, 293, 2436, 309, 666, 341, 8388, 13, 50694], "temperature": 0.0, "avg_logprob": -0.19548375153344524, "compression_ratio": 1.6548042704626333, "no_speech_prob": 0.003328740829601884}, {"id": 96, "seek": 33568, "start": 342.28000000000003, "end": 348.84000000000003, "text": " We're working on contribution video, so that is very high bandwidth video, typically in", "tokens": [50694, 492, 434, 1364, 322, 13150, 960, 11, 370, 300, 307, 588, 1090, 23647, 960, 11, 5850, 294, 51022], "temperature": 0.0, "avg_logprob": -0.19548375153344524, "compression_ratio": 1.6548042704626333, "no_speech_prob": 0.003328740829601884}, {"id": 97, "seek": 33568, "start": 348.84000000000003, "end": 353.24, "text": " TV production studios, that kind of stuff, and what those people want to do is fairly", "tokens": [51022, 3558, 4265, 24593, 11, 300, 733, 295, 1507, 11, 293, 437, 729, 561, 528, 281, 360, 307, 6457, 51242], "temperature": 0.0, "avg_logprob": -0.19548375153344524, "compression_ratio": 1.6548042704626333, "no_speech_prob": 0.003328740829601884}, {"id": 98, "seek": 33568, "start": 353.24, "end": 357.64, "text": " nuts in terms of you can have something like 4K uncompressed video, which I think is about", "tokens": [51242, 10483, 294, 2115, 295, 291, 393, 362, 746, 411, 1017, 42, 8585, 79, 3805, 960, 11, 597, 286, 519, 307, 466, 51462], "temperature": 0.0, "avg_logprob": -0.19548375153344524, "compression_ratio": 1.6548042704626333, "no_speech_prob": 0.003328740829601884}, {"id": 99, "seek": 33568, "start": 357.64, "end": 361.4, "text": " 12 gigabits per second, and you can't drop a packet and you can't jitter.", "tokens": [51462, 2272, 8741, 455, 1208, 680, 1150, 11, 293, 291, 393, 380, 3270, 257, 20300, 293, 291, 393, 380, 361, 3904, 13, 51650], "temperature": 0.0, "avg_logprob": -0.19548375153344524, "compression_ratio": 1.6548042704626333, "no_speech_prob": 0.003328740829601884}, {"id": 100, "seek": 36140, "start": 361.4, "end": 365.79999999999995, "text": " So probably we have to do something special on the network there, so we're working on", "tokens": [50364, 407, 1391, 321, 362, 281, 360, 746, 2121, 322, 264, 3209, 456, 11, 370, 321, 434, 1364, 322, 50584], "temperature": 0.0, "avg_logprob": -0.1787385008388892, "compression_ratio": 1.6375404530744337, "no_speech_prob": 0.06649307906627655}, {"id": 101, "seek": 36140, "start": 365.79999999999995, "end": 373.2, "text": " things like zero copy from one pod to another, and then using Intel's DPDK out to the network.", "tokens": [50584, 721, 411, 4018, 5055, 490, 472, 2497, 281, 1071, 11, 293, 550, 1228, 19762, 311, 413, 17349, 42, 484, 281, 264, 3209, 13, 50954], "temperature": 0.0, "avg_logprob": -0.1787385008388892, "compression_ratio": 1.6375404530744337, "no_speech_prob": 0.06649307906627655}, {"id": 102, "seek": 36140, "start": 373.2, "end": 376.76, "text": " Some challenges there, I guess, in terms of normally in Kubernetes is what you hand between", "tokens": [50954, 2188, 4759, 456, 11, 286, 2041, 11, 294, 2115, 295, 5646, 294, 23145, 307, 437, 291, 1011, 1296, 51132], "temperature": 0.0, "avg_logprob": -0.1787385008388892, "compression_ratio": 1.6375404530744337, "no_speech_prob": 0.06649307906627655}, {"id": 103, "seek": 36140, "start": 376.76, "end": 378.67999999999995, "text": " pods as IP packets.", "tokens": [51132, 31925, 382, 8671, 30364, 13, 51228], "temperature": 0.0, "avg_logprob": -0.1787385008388892, "compression_ratio": 1.6375404530744337, "no_speech_prob": 0.06649307906627655}, {"id": 104, "seek": 36140, "start": 378.67999999999995, "end": 383.59999999999997, "text": " In this case, we'd be handing around raw video frames, so it's a bit different.", "tokens": [51228, 682, 341, 1389, 11, 321, 1116, 312, 34774, 926, 8936, 960, 12083, 11, 370, 309, 311, 257, 857, 819, 13, 51474], "temperature": 0.0, "avg_logprob": -0.1787385008388892, "compression_ratio": 1.6375404530744337, "no_speech_prob": 0.06649307906627655}, {"id": 105, "seek": 36140, "start": 383.59999999999997, "end": 386.44, "text": " And then as well as that contribution side, then the distribution.", "tokens": [51474, 400, 550, 382, 731, 382, 300, 13150, 1252, 11, 550, 264, 7316, 13, 51616], "temperature": 0.0, "avg_logprob": -0.1787385008388892, "compression_ratio": 1.6375404530744337, "no_speech_prob": 0.06649307906627655}, {"id": 106, "seek": 36140, "start": 386.44, "end": 389.79999999999995, "text": " So how do you, if I'm watching a football, I don't want it to lag.", "tokens": [51616, 407, 577, 360, 291, 11, 498, 286, 478, 1976, 257, 7346, 11, 286, 500, 380, 528, 309, 281, 8953, 13, 51784], "temperature": 0.0, "avg_logprob": -0.1787385008388892, "compression_ratio": 1.6375404530744337, "no_speech_prob": 0.06649307906627655}, {"id": 107, "seek": 38980, "start": 389.8, "end": 395.12, "text": " How do I get the live video feed, at least out to the CDN caches, to minimize the lag,", "tokens": [50364, 1012, 360, 286, 483, 264, 1621, 960, 3154, 11, 412, 1935, 484, 281, 264, 6743, 45, 269, 13272, 11, 281, 17522, 264, 8953, 11, 50630], "temperature": 0.0, "avg_logprob": -0.1670320243166204, "compression_ratio": 1.5612648221343874, "no_speech_prob": 0.016219671815633774}, {"id": 108, "seek": 38980, "start": 395.12, "end": 399.48, "text": " but possibly even then going RTP right out to the user?", "tokens": [50630, 457, 6264, 754, 550, 516, 497, 16804, 558, 484, 281, 264, 4195, 30, 50848], "temperature": 0.0, "avg_logprob": -0.1670320243166204, "compression_ratio": 1.5612648221343874, "no_speech_prob": 0.016219671815633774}, {"id": 109, "seek": 38980, "start": 399.48, "end": 402.56, "text": " I guess some of the challenges there are what protocols we use.", "tokens": [50848, 286, 2041, 512, 295, 264, 4759, 456, 366, 437, 20618, 321, 764, 13, 51002], "temperature": 0.0, "avg_logprob": -0.1670320243166204, "compression_ratio": 1.5612648221343874, "no_speech_prob": 0.016219671815633774}, {"id": 110, "seek": 38980, "start": 402.56, "end": 408.44, "text": " Do we do RTP over quick, or do we look at the stuff that's going on?", "tokens": [51002, 1144, 321, 360, 497, 16804, 670, 1702, 11, 420, 360, 321, 574, 412, 264, 1507, 300, 311, 516, 322, 30, 51296], "temperature": 0.0, "avg_logprob": -0.1670320243166204, "compression_ratio": 1.5612648221343874, "no_speech_prob": 0.016219671815633774}, {"id": 111, "seek": 38980, "start": 408.44, "end": 413.08000000000004, "text": " I don't know, anyone here has seen ITF at the moment are working on media over quick.", "tokens": [51296, 286, 500, 380, 458, 11, 2878, 510, 575, 1612, 6783, 37, 412, 264, 1623, 366, 1364, 322, 3021, 670, 1702, 13, 51528], "temperature": 0.0, "avg_logprob": -0.1670320243166204, "compression_ratio": 1.5612648221343874, "no_speech_prob": 0.016219671815633774}, {"id": 112, "seek": 38980, "start": 413.08000000000004, "end": 415.92, "text": " We had an interim a few days ago.", "tokens": [51528, 492, 632, 364, 33500, 257, 1326, 1708, 2057, 13, 51670], "temperature": 0.0, "avg_logprob": -0.1670320243166204, "compression_ratio": 1.5612648221343874, "no_speech_prob": 0.016219671815633774}, {"id": 113, "seek": 41592, "start": 415.92, "end": 419.6, "text": " So that won't necessarily use RTP, because quick gives you a lot of what RTP gives you", "tokens": [50364, 407, 300, 1582, 380, 4725, 764, 497, 16804, 11, 570, 1702, 2709, 291, 257, 688, 295, 437, 497, 16804, 2709, 291, 50548], "temperature": 0.0, "avg_logprob": -0.1911459423246838, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.07887813448905945}, {"id": 114, "seek": 41592, "start": 419.6, "end": 420.6, "text": " anyway.", "tokens": [50548, 4033, 13, 50598], "temperature": 0.0, "avg_logprob": -0.1911459423246838, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.07887813448905945}, {"id": 115, "seek": 41592, "start": 420.6, "end": 422.36, "text": " So that might be the solution there.", "tokens": [50598, 407, 300, 1062, 312, 264, 3827, 456, 13, 50686], "temperature": 0.0, "avg_logprob": -0.1911459423246838, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.07887813448905945}, {"id": 116, "seek": 41592, "start": 422.36, "end": 425.84000000000003, "text": " But as I mentioned earlier, this sort of retailer industrial edge, where you've got large numbers", "tokens": [50686, 583, 382, 286, 2835, 3071, 11, 341, 1333, 295, 45467, 9987, 4691, 11, 689, 291, 600, 658, 2416, 3547, 50860], "temperature": 0.0, "avg_logprob": -0.1911459423246838, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.07887813448905945}, {"id": 117, "seek": 41592, "start": 425.84000000000003, "end": 431.68, "text": " of cameras in one site, like I was in Las Vegas for Cisco Live earlier this year, and", "tokens": [50860, 295, 8622, 294, 472, 3621, 11, 411, 286, 390, 294, 10663, 15841, 337, 38528, 10385, 3071, 341, 1064, 11, 293, 51152], "temperature": 0.0, "avg_logprob": -0.1911459423246838, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.07887813448905945}, {"id": 118, "seek": 41592, "start": 431.68, "end": 432.68, "text": " you walk into a casino.", "tokens": [51152, 291, 1792, 666, 257, 36278, 13, 51202], "temperature": 0.0, "avg_logprob": -0.1911459423246838, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.07887813448905945}, {"id": 119, "seek": 41592, "start": 432.68, "end": 436.08000000000004, "text": " If you've ever seen how many cameras there are in a casino, it's just like nuts, they're", "tokens": [51202, 759, 291, 600, 1562, 1612, 577, 867, 8622, 456, 366, 294, 257, 36278, 11, 309, 311, 445, 411, 10483, 11, 436, 434, 51372], "temperature": 0.0, "avg_logprob": -0.1911459423246838, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.07887813448905945}, {"id": 120, "seek": 41592, "start": 436.08000000000004, "end": 438.20000000000005, "text": " watching you from every possible angle.", "tokens": [51372, 1976, 291, 490, 633, 1944, 5802, 13, 51478], "temperature": 0.0, "avg_logprob": -0.1911459423246838, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.07887813448905945}, {"id": 121, "seek": 41592, "start": 438.20000000000005, "end": 442.08000000000004, "text": " Or it could be a coffee shop with one camera, but you've got a thousand coffee shops, whatever.", "tokens": [51478, 1610, 309, 727, 312, 257, 4982, 3945, 365, 472, 2799, 11, 457, 291, 600, 658, 257, 4714, 4982, 14457, 11, 2035, 13, 51672], "temperature": 0.0, "avg_logprob": -0.1911459423246838, "compression_ratio": 1.709090909090909, "no_speech_prob": 0.07887813448905945}, {"id": 122, "seek": 44208, "start": 442.32, "end": 448.52, "text": " As I say, we've kind of dropped out of this kind of non-RTP stuff, but there is obviously", "tokens": [50376, 1018, 286, 584, 11, 321, 600, 733, 295, 8119, 484, 295, 341, 733, 295, 2107, 12, 49, 16804, 1507, 11, 457, 456, 307, 2745, 50686], "temperature": 0.0, "avg_logprob": -0.22818446350097657, "compression_ratio": 1.768060836501901, "no_speech_prob": 0.059863459318876266}, {"id": 123, "seek": 44208, "start": 448.52, "end": 450.68, "text": " scope to address that in the future.", "tokens": [50686, 11923, 281, 2985, 300, 294, 264, 2027, 13, 50794], "temperature": 0.0, "avg_logprob": -0.22818446350097657, "compression_ratio": 1.768060836501901, "no_speech_prob": 0.059863459318876266}, {"id": 124, "seek": 44208, "start": 450.68, "end": 455.36, "text": " So in live videos, I say the contribution stuff, one of the challenges there is a lot", "tokens": [50794, 407, 294, 1621, 2145, 11, 286, 584, 264, 13150, 1507, 11, 472, 295, 264, 4759, 456, 307, 257, 688, 51028], "temperature": 0.0, "avg_logprob": -0.22818446350097657, "compression_ratio": 1.768060836501901, "no_speech_prob": 0.059863459318876266}, {"id": 125, "seek": 44208, "start": 455.36, "end": 457.2, "text": " of this stuff is actually hardware, not software.", "tokens": [51028, 295, 341, 1507, 307, 767, 8837, 11, 406, 4722, 13, 51120], "temperature": 0.0, "avg_logprob": -0.22818446350097657, "compression_ratio": 1.768060836501901, "no_speech_prob": 0.059863459318876266}, {"id": 126, "seek": 44208, "start": 457.2, "end": 460.91999999999996, "text": " So a video camera is a real hardware thing, and a mixing desk might be a real hardware", "tokens": [51120, 407, 257, 960, 2799, 307, 257, 957, 8837, 551, 11, 293, 257, 11983, 10026, 1062, 312, 257, 957, 8837, 51306], "temperature": 0.0, "avg_logprob": -0.22818446350097657, "compression_ratio": 1.768060836501901, "no_speech_prob": 0.059863459318876266}, {"id": 127, "seek": 44208, "start": 460.91999999999996, "end": 461.91999999999996, "text": " thing.", "tokens": [51306, 551, 13, 51356], "temperature": 0.0, "avg_logprob": -0.22818446350097657, "compression_ratio": 1.768060836501901, "no_speech_prob": 0.059863459318876266}, {"id": 128, "seek": 44208, "start": 461.91999999999996, "end": 464.68, "text": " So how do we integrate that?", "tokens": [51356, 407, 577, 360, 321, 13365, 300, 30, 51494], "temperature": 0.0, "avg_logprob": -0.22818446350097657, "compression_ratio": 1.768060836501901, "no_speech_prob": 0.059863459318876266}, {"id": 129, "seek": 44208, "start": 464.68, "end": 468.36, "text": " Interconnecting coders in the cloud, that seems like a really obvious use case.", "tokens": [51494, 5751, 9826, 278, 17656, 433, 294, 264, 4588, 11, 300, 2544, 411, 257, 534, 6322, 764, 1389, 13, 51678], "temperature": 0.0, "avg_logprob": -0.22818446350097657, "compression_ratio": 1.768060836501901, "no_speech_prob": 0.059863459318876266}, {"id": 130, "seek": 46836, "start": 468.36, "end": 473.76, "text": " That distribution of live streams, but also potentially distributing rights to the client.", "tokens": [50364, 663, 7316, 295, 1621, 15842, 11, 457, 611, 7263, 41406, 4601, 281, 264, 6423, 13, 50634], "temperature": 0.0, "avg_logprob": -0.196981689453125, "compression_ratio": 1.6233333333333333, "no_speech_prob": 0.02025768905878067}, {"id": 131, "seek": 46836, "start": 473.76, "end": 478.76, "text": " But as I say, video surveillance, that seems pretty easy and tractable, and that's what", "tokens": [50634, 583, 382, 286, 584, 11, 960, 18475, 11, 300, 2544, 1238, 1858, 293, 24207, 712, 11, 293, 300, 311, 437, 50884], "temperature": 0.0, "avg_logprob": -0.196981689453125, "compression_ratio": 1.6233333333333333, "no_speech_prob": 0.02025768905878067}, {"id": 132, "seek": 46836, "start": 478.76, "end": 480.76, "text": " we're demoing now.", "tokens": [50884, 321, 434, 10723, 278, 586, 13, 50984], "temperature": 0.0, "avg_logprob": -0.196981689453125, "compression_ratio": 1.6233333333333333, "no_speech_prob": 0.02025768905878067}, {"id": 133, "seek": 46836, "start": 480.76, "end": 485.40000000000003, "text": " So our initial implementation, we have RTSP, and we can stream stuff from cameras and replicate", "tokens": [50984, 407, 527, 5883, 11420, 11, 321, 362, 497, 7327, 47, 11, 293, 321, 393, 4309, 1507, 490, 8622, 293, 25356, 51216], "temperature": 0.0, "avg_logprob": -0.196981689453125, "compression_ratio": 1.6233333333333333, "no_speech_prob": 0.02025768905878067}, {"id": 134, "seek": 46836, "start": 485.40000000000003, "end": 486.40000000000003, "text": " it to multiple places.", "tokens": [51216, 309, 281, 3866, 3190, 13, 51266], "temperature": 0.0, "avg_logprob": -0.196981689453125, "compression_ratio": 1.6233333333333333, "no_speech_prob": 0.02025768905878067}, {"id": 135, "seek": 46836, "start": 486.40000000000003, "end": 492.72, "text": " So the classic use case, you might be saying, well okay, cameras are cheap, humans are expensive.", "tokens": [51266, 407, 264, 7230, 764, 1389, 11, 291, 1062, 312, 1566, 11, 731, 1392, 11, 8622, 366, 7084, 11, 6255, 366, 5124, 13, 51582], "temperature": 0.0, "avg_logprob": -0.196981689453125, "compression_ratio": 1.6233333333333333, "no_speech_prob": 0.02025768905878067}, {"id": 136, "seek": 46836, "start": 492.72, "end": 496.44, "text": " So if I'm in a casino and I've got 100,000 cameras, pick a crazy number.", "tokens": [51582, 407, 498, 286, 478, 294, 257, 36278, 293, 286, 600, 658, 2319, 11, 1360, 8622, 11, 1888, 257, 3219, 1230, 13, 51768], "temperature": 0.0, "avg_logprob": -0.196981689453125, "compression_ratio": 1.6233333333333333, "no_speech_prob": 0.02025768905878067}, {"id": 137, "seek": 49644, "start": 496.44, "end": 500.68, "text": " I don't have 10,000 people who watch 10 screens, because that's going to be too expensive.", "tokens": [50364, 286, 500, 380, 362, 1266, 11, 1360, 561, 567, 1159, 1266, 11171, 11, 570, 300, 311, 516, 281, 312, 886, 5124, 13, 50576], "temperature": 0.0, "avg_logprob": -0.16616727264834122, "compression_ratio": 1.7540453074433657, "no_speech_prob": 0.007146445568650961}, {"id": 138, "seek": 49644, "start": 500.68, "end": 505.28, "text": " So maybe I only have 10 people, but then we need to have a way that if some kind of machine", "tokens": [50576, 407, 1310, 286, 787, 362, 1266, 561, 11, 457, 550, 321, 643, 281, 362, 257, 636, 300, 498, 512, 733, 295, 3479, 50806], "temperature": 0.0, "avg_logprob": -0.16616727264834122, "compression_ratio": 1.7540453074433657, "no_speech_prob": 0.007146445568650961}, {"id": 139, "seek": 49644, "start": 505.28, "end": 509.28, "text": " learning algorithm spots there's something that shouldn't be happening, or thinks it", "tokens": [50806, 2539, 9284, 10681, 456, 311, 746, 300, 4659, 380, 312, 2737, 11, 420, 7309, 309, 51006], "temperature": 0.0, "avg_logprob": -0.16616727264834122, "compression_ratio": 1.7540453074433657, "no_speech_prob": 0.007146445568650961}, {"id": 140, "seek": 49644, "start": 509.28, "end": 514.56, "text": " might be, then at that point, like a human can start looking at it.", "tokens": [51006, 1062, 312, 11, 550, 412, 300, 935, 11, 411, 257, 1952, 393, 722, 1237, 412, 309, 13, 51270], "temperature": 0.0, "avg_logprob": -0.16616727264834122, "compression_ratio": 1.7540453074433657, "no_speech_prob": 0.007146445568650961}, {"id": 141, "seek": 49644, "start": 514.56, "end": 520.16, "text": " And the other great thing, of course, with going through proxies, is the proxies have", "tokens": [51270, 400, 264, 661, 869, 551, 11, 295, 1164, 11, 365, 516, 807, 447, 87, 530, 11, 307, 264, 447, 87, 530, 362, 51550], "temperature": 0.0, "avg_logprob": -0.16616727264834122, "compression_ratio": 1.7540453074433657, "no_speech_prob": 0.007146445568650961}, {"id": 142, "seek": 49644, "start": 520.16, "end": 521.4, "text": " a lot of replication for you.", "tokens": [51550, 257, 688, 295, 39911, 337, 291, 13, 51612], "temperature": 0.0, "avg_logprob": -0.16616727264834122, "compression_ratio": 1.7540453074433657, "no_speech_prob": 0.007146445568650961}, {"id": 143, "seek": 49644, "start": 521.4, "end": 525.36, "text": " So if you have one proxy per node, that can be our replication point, and one of the other", "tokens": [51612, 407, 498, 291, 362, 472, 29690, 680, 9984, 11, 300, 393, 312, 527, 39911, 935, 11, 293, 472, 295, 264, 661, 51810], "temperature": 0.0, "avg_logprob": -0.16616727264834122, "compression_ratio": 1.7540453074433657, "no_speech_prob": 0.007146445568650961}, {"id": 144, "seek": 52536, "start": 525.4, "end": 529.84, "text": " challenges with Kubernetes is that it really doesn't do multicast.", "tokens": [50366, 4759, 365, 23145, 307, 300, 309, 534, 1177, 380, 360, 30608, 525, 13, 50588], "temperature": 0.0, "avg_logprob": -0.18268502143121534, "compression_ratio": 1.6702127659574468, "no_speech_prob": 0.00909804180264473}, {"id": 145, "seek": 52536, "start": 529.84, "end": 533.12, "text": " And so the multicast solution isn't really tractable.", "tokens": [50588, 400, 370, 264, 30608, 525, 3827, 1943, 380, 534, 24207, 712, 13, 50752], "temperature": 0.0, "avg_logprob": -0.18268502143121534, "compression_ratio": 1.6702127659574468, "no_speech_prob": 0.00909804180264473}, {"id": 146, "seek": 52536, "start": 533.12, "end": 536.96, "text": " And in fact, in this environment, you probably don't want to do multicast.", "tokens": [50752, 400, 294, 1186, 11, 294, 341, 2823, 11, 291, 1391, 500, 380, 528, 281, 360, 30608, 525, 13, 50944], "temperature": 0.0, "avg_logprob": -0.18268502143121534, "compression_ratio": 1.6702127659574468, "no_speech_prob": 0.00909804180264473}, {"id": 147, "seek": 52536, "start": 536.96, "end": 542.84, "text": " So I know today that's what people mostly deploy, but it's a very odd multicast set up.", "tokens": [50944, 407, 286, 458, 965, 300, 311, 437, 561, 5240, 7274, 11, 457, 309, 311, 257, 588, 7401, 30608, 525, 992, 493, 13, 51238], "temperature": 0.0, "avg_logprob": -0.18268502143121534, "compression_ratio": 1.6702127659574468, "no_speech_prob": 0.00909804180264473}, {"id": 148, "seek": 52536, "start": 542.84, "end": 546.6800000000001, "text": " Because you imagine you're an airport and you've got 10,000 cameras, but each camera", "tokens": [51238, 1436, 291, 3811, 291, 434, 364, 10155, 293, 291, 600, 658, 1266, 11, 1360, 8622, 11, 457, 1184, 2799, 51430], "temperature": 0.0, "avg_logprob": -0.18268502143121534, "compression_ratio": 1.6702127659574468, "no_speech_prob": 0.00909804180264473}, {"id": 149, "seek": 52536, "start": 546.6800000000001, "end": 550.72, "text": " has only been watched by like one app at all times, and maybe one or two humans, whatever", "tokens": [51430, 575, 787, 668, 6337, 538, 411, 472, 724, 412, 439, 1413, 11, 293, 1310, 472, 420, 732, 6255, 11, 2035, 51632], "temperature": 0.0, "avg_logprob": -0.18268502143121534, "compression_ratio": 1.6702127659574468, "no_speech_prob": 0.00909804180264473}, {"id": 150, "seek": 52536, "start": 550.72, "end": 551.72, "text": " it might be.", "tokens": [51632, 309, 1062, 312, 13, 51682], "temperature": 0.0, "avg_logprob": -0.18268502143121534, "compression_ratio": 1.6702127659574468, "no_speech_prob": 0.00909804180264473}, {"id": 151, "seek": 55172, "start": 551.72, "end": 555.84, "text": " That's a very odd multicast deployment to have 10,000 multicast groups, and each one's", "tokens": [50364, 663, 311, 257, 588, 7401, 30608, 525, 19317, 281, 362, 1266, 11, 1360, 30608, 525, 3935, 11, 293, 1184, 472, 311, 50570], "temperature": 0.0, "avg_logprob": -0.16876265662057058, "compression_ratio": 1.697749196141479, "no_speech_prob": 0.001277846284210682}, {"id": 152, "seek": 55172, "start": 555.84, "end": 557.6800000000001, "text": " only got a couple of subscribers.", "tokens": [50570, 787, 658, 257, 1916, 295, 11092, 13, 50662], "temperature": 0.0, "avg_logprob": -0.16876265662057058, "compression_ratio": 1.697749196141479, "no_speech_prob": 0.001277846284210682}, {"id": 153, "seek": 55172, "start": 557.6800000000001, "end": 562.6800000000001, "text": " So maybe proxies are an easier way to do it.", "tokens": [50662, 407, 1310, 447, 87, 530, 366, 364, 3571, 636, 281, 360, 309, 13, 50912], "temperature": 0.0, "avg_logprob": -0.16876265662057058, "compression_ratio": 1.697749196141479, "no_speech_prob": 0.001277846284210682}, {"id": 154, "seek": 55172, "start": 562.6800000000001, "end": 563.6800000000001, "text": " So how have we built it?", "tokens": [50912, 407, 577, 362, 321, 3094, 309, 30, 50962], "temperature": 0.0, "avg_logprob": -0.16876265662057058, "compression_ratio": 1.697749196141479, "no_speech_prob": 0.001277846284210682}, {"id": 155, "seek": 55172, "start": 563.6800000000001, "end": 564.6800000000001, "text": " Yeah.", "tokens": [50962, 865, 13, 51012], "temperature": 0.0, "avg_logprob": -0.16876265662057058, "compression_ratio": 1.697749196141479, "no_speech_prob": 0.001277846284210682}, {"id": 156, "seek": 55172, "start": 564.6800000000001, "end": 569.48, "text": " So the software architecture, so we have a whole bunch of components, and what we try", "tokens": [51012, 407, 264, 4722, 9482, 11, 370, 321, 362, 257, 1379, 3840, 295, 6677, 11, 293, 437, 321, 853, 51252], "temperature": 0.0, "avg_logprob": -0.16876265662057058, "compression_ratio": 1.697749196141479, "no_speech_prob": 0.001277846284210682}, {"id": 157, "seek": 55172, "start": 569.48, "end": 572.84, "text": " to say is decompose it into what do we put where in Kubernetes.", "tokens": [51252, 281, 584, 307, 22867, 541, 309, 666, 437, 360, 321, 829, 689, 294, 23145, 13, 51420], "temperature": 0.0, "avg_logprob": -0.16876265662057058, "compression_ratio": 1.697749196141479, "no_speech_prob": 0.001277846284210682}, {"id": 158, "seek": 55172, "start": 572.84, "end": 578.28, "text": " So services run sort of one per cluster, demon sets run one per node, and then potentially", "tokens": [51420, 407, 3328, 1190, 1333, 295, 472, 680, 13630, 11, 14283, 6352, 1190, 472, 680, 9984, 11, 293, 550, 7263, 51692], "temperature": 0.0, "avg_logprob": -0.16876265662057058, "compression_ratio": 1.697749196141479, "no_speech_prob": 0.001277846284210682}, {"id": 159, "seek": 55172, "start": 578.28, "end": 581.4, "text": " you can have stuff running in the application pod, but we try and keep the footprint there", "tokens": [51692, 291, 393, 362, 1507, 2614, 294, 264, 3861, 2497, 11, 457, 321, 853, 293, 1066, 264, 24222, 456, 51848], "temperature": 0.0, "avg_logprob": -0.16876265662057058, "compression_ratio": 1.697749196141479, "no_speech_prob": 0.001277846284210682}, {"id": 160, "seek": 58140, "start": 581.4399999999999, "end": 583.4399999999999, "text": " very low.", "tokens": [50366, 588, 2295, 13, 50466], "temperature": 0.0, "avg_logprob": -0.1645072545760717, "compression_ratio": 1.8397212543554007, "no_speech_prob": 0.08989761024713516}, {"id": 161, "seek": 58140, "start": 583.4399999999999, "end": 587.16, "text": " So the initial thing is how do we put anything in the pod?", "tokens": [50466, 407, 264, 5883, 551, 307, 577, 360, 321, 829, 1340, 294, 264, 2497, 30, 50652], "temperature": 0.0, "avg_logprob": -0.1645072545760717, "compression_ratio": 1.8397212543554007, "no_speech_prob": 0.08989761024713516}, {"id": 162, "seek": 58140, "start": 587.16, "end": 589.4399999999999, "text": " How do we make sure we intercept traffic?", "tokens": [50652, 1012, 360, 321, 652, 988, 321, 24700, 6419, 30, 50766], "temperature": 0.0, "avg_logprob": -0.1645072545760717, "compression_ratio": 1.8397212543554007, "no_speech_prob": 0.08989761024713516}, {"id": 163, "seek": 58140, "start": 589.4399999999999, "end": 594.3199999999999, "text": " So what we have there is an admission webhook and a CNI plug-in, so when a pod gets created,", "tokens": [50766, 407, 437, 321, 362, 456, 307, 364, 24668, 3670, 71, 1212, 293, 257, 14589, 40, 5452, 12, 259, 11, 370, 562, 257, 2497, 2170, 2942, 11, 51010], "temperature": 0.0, "avg_logprob": -0.1645072545760717, "compression_ratio": 1.8397212543554007, "no_speech_prob": 0.08989761024713516}, {"id": 164, "seek": 58140, "start": 594.3199999999999, "end": 597.84, "text": " we have an annotation that we put on the YAML file for the pod that says, OK, this is one", "tokens": [51010, 321, 362, 364, 48654, 300, 321, 829, 322, 264, 398, 2865, 43, 3991, 337, 264, 2497, 300, 1619, 11, 2264, 11, 341, 307, 472, 51186], "temperature": 0.0, "avg_logprob": -0.1645072545760717, "compression_ratio": 1.8397212543554007, "no_speech_prob": 0.08989761024713516}, {"id": 165, "seek": 58140, "start": 597.84, "end": 598.84, "text": " of our pods.", "tokens": [51186, 295, 527, 31925, 13, 51236], "temperature": 0.0, "avg_logprob": -0.1645072545760717, "compression_ratio": 1.8397212543554007, "no_speech_prob": 0.08989761024713516}, {"id": 166, "seek": 58140, "start": 598.84, "end": 603.0, "text": " So the admission webhook will intercept that, and when the pod gets instantiated, it will", "tokens": [51236, 407, 264, 24668, 3670, 71, 1212, 486, 24700, 300, 11, 293, 562, 264, 2497, 2170, 9836, 72, 770, 11, 309, 486, 51444], "temperature": 0.0, "avg_logprob": -0.1645072545760717, "compression_ratio": 1.8397212543554007, "no_speech_prob": 0.08989761024713516}, {"id": 167, "seek": 58140, "start": 603.0, "end": 605.4, "text": " have our stub in the pod as well as the app.", "tokens": [51444, 362, 527, 20266, 294, 264, 2497, 382, 731, 382, 264, 724, 13, 51564], "temperature": 0.0, "avg_logprob": -0.1645072545760717, "compression_ratio": 1.8397212543554007, "no_speech_prob": 0.08989761024713516}, {"id": 168, "seek": 58140, "start": 605.4, "end": 609.1999999999999, "text": " But we also then have a chain CNI plug-in, and actually in the network dev room, I was", "tokens": [51564, 583, 321, 611, 550, 362, 257, 5021, 14589, 40, 5452, 12, 259, 11, 293, 767, 294, 264, 3209, 1905, 1808, 11, 286, 390, 51754], "temperature": 0.0, "avg_logprob": -0.1645072545760717, "compression_ratio": 1.8397212543554007, "no_speech_prob": 0.08989761024713516}, {"id": 169, "seek": 60920, "start": 609.24, "end": 613.44, "text": " there just now, somebody was literally talking about the chain CNI plug-in, so the idea is", "tokens": [50366, 456, 445, 586, 11, 2618, 390, 3736, 1417, 466, 264, 5021, 14589, 40, 5452, 12, 259, 11, 370, 264, 1558, 307, 50576], "temperature": 0.0, "avg_logprob": -0.19044881253629117, "compression_ratio": 1.6390977443609023, "no_speech_prob": 0.0031858065631240606}, {"id": 170, "seek": 60920, "start": 613.44, "end": 618.2, "text": " that you run whatever normal network you want for Kubernetes, and this little plug-in,", "tokens": [50576, 300, 291, 1190, 2035, 2710, 3209, 291, 528, 337, 23145, 11, 293, 341, 707, 5452, 12, 259, 11, 50814], "temperature": 0.0, "avg_logprob": -0.19044881253629117, "compression_ratio": 1.6390977443609023, "no_speech_prob": 0.0031858065631240606}, {"id": 171, "seek": 60920, "start": 618.2, "end": 622.5600000000001, "text": " all it does is add in the IP tables or EBPF rules that we're going to use to redirect", "tokens": [50814, 439, 309, 775, 307, 909, 294, 264, 8671, 8020, 420, 50148, 47, 37, 4474, 300, 321, 434, 516, 281, 764, 281, 29066, 51032], "temperature": 0.0, "avg_logprob": -0.19044881253629117, "compression_ratio": 1.6390977443609023, "no_speech_prob": 0.0031858065631240606}, {"id": 172, "seek": 60920, "start": 622.5600000000001, "end": 628.5600000000001, "text": " that control plane traffic into our stub, and in some cases redirect the actual data", "tokens": [51032, 300, 1969, 5720, 6419, 666, 527, 20266, 11, 293, 294, 512, 3331, 29066, 264, 3539, 1412, 51332], "temperature": 0.0, "avg_logprob": -0.19044881253629117, "compression_ratio": 1.6390977443609023, "no_speech_prob": 0.0031858065631240606}, {"id": 173, "seek": 60920, "start": 628.5600000000001, "end": 629.5600000000001, "text": " plane traffic.", "tokens": [51332, 5720, 6419, 13, 51382], "temperature": 0.0, "avg_logprob": -0.19044881253629117, "compression_ratio": 1.6390977443609023, "no_speech_prob": 0.0031858065631240606}, {"id": 174, "seek": 60920, "start": 629.5600000000001, "end": 634.88, "text": " And of course, once it starts, it gets redirected and everything's good.", "tokens": [51382, 400, 295, 1164, 11, 1564, 309, 3719, 11, 309, 2170, 29066, 292, 293, 1203, 311, 665, 13, 51648], "temperature": 0.0, "avg_logprob": -0.19044881253629117, "compression_ratio": 1.6390977443609023, "no_speech_prob": 0.0031858065631240606}, {"id": 175, "seek": 63488, "start": 634.88, "end": 639.4, "text": " So in our control plane, we wanted to build one per cluster to minimize footprint.", "tokens": [50364, 407, 294, 527, 1969, 5720, 11, 321, 1415, 281, 1322, 472, 680, 13630, 281, 17522, 24222, 13, 50590], "temperature": 0.0, "avg_logprob": -0.20627144092821892, "compression_ratio": 1.630225080385852, "no_speech_prob": 0.3224405348300934}, {"id": 176, "seek": 63488, "start": 639.4, "end": 643.48, "text": " Today it basically calls out to the Kubernetes API and Core DNS, so if you're connecting", "tokens": [50590, 2692, 309, 1936, 5498, 484, 281, 264, 23145, 9362, 293, 14798, 35153, 11, 370, 498, 291, 434, 11015, 50794], "temperature": 0.0, "avg_logprob": -0.20627144092821892, "compression_ratio": 1.630225080385852, "no_speech_prob": 0.3224405348300934}, {"id": 177, "seek": 63488, "start": 643.48, "end": 647.8, "text": " in and you're saying, OK, I'm going to this URL, we want to figure out which active running", "tokens": [50794, 294, 293, 291, 434, 1566, 11, 2264, 11, 286, 478, 516, 281, 341, 12905, 11, 321, 528, 281, 2573, 484, 597, 4967, 2614, 51010], "temperature": 0.0, "avg_logprob": -0.20627144092821892, "compression_ratio": 1.630225080385852, "no_speech_prob": 0.3224405348300934}, {"id": 178, "seek": 63488, "start": 647.8, "end": 651.12, "text": " pod support that URL, so that's what that piece does.", "tokens": [51010, 2497, 1406, 300, 12905, 11, 370, 300, 311, 437, 300, 2522, 775, 13, 51176], "temperature": 0.0, "avg_logprob": -0.20627144092821892, "compression_ratio": 1.630225080385852, "no_speech_prob": 0.3224405348300934}, {"id": 179, "seek": 63488, "start": 651.12, "end": 655.8, "text": " So you're effectively, your RTSP sessions say from your app, the stub intercepts that", "tokens": [51176, 407, 291, 434, 8659, 11, 428, 497, 7327, 47, 11081, 584, 490, 428, 724, 11, 264, 20266, 24700, 82, 300, 51410], "temperature": 0.0, "avg_logprob": -0.20627144092821892, "compression_ratio": 1.630225080385852, "no_speech_prob": 0.3224405348300934}, {"id": 180, "seek": 63488, "start": 655.8, "end": 656.8, "text": " TCP connection.", "tokens": [51410, 48965, 4984, 13, 51460], "temperature": 0.0, "avg_logprob": -0.20627144092821892, "compression_ratio": 1.630225080385852, "no_speech_prob": 0.3224405348300934}, {"id": 181, "seek": 63488, "start": 656.8, "end": 663.76, "text": " It uses GRPC to pump the data messages or the actual payloads of the RTSP control plane", "tokens": [51460, 467, 4960, 10903, 12986, 281, 5889, 264, 1412, 7897, 420, 264, 3539, 30918, 82, 295, 264, 497, 7327, 47, 1969, 5720, 51808], "temperature": 0.0, "avg_logprob": -0.20627144092821892, "compression_ratio": 1.630225080385852, "no_speech_prob": 0.3224405348300934}, {"id": 182, "seek": 66376, "start": 663.76, "end": 670.52, "text": " into our control plane, and then we use GRPC again to program the proxies.", "tokens": [50364, 666, 527, 1969, 5720, 11, 293, 550, 321, 764, 10903, 12986, 797, 281, 1461, 264, 447, 87, 530, 13, 50702], "temperature": 0.0, "avg_logprob": -0.22158640567387375, "compression_ratio": 1.5418502202643172, "no_speech_prob": 0.006701941601932049}, {"id": 183, "seek": 66376, "start": 670.52, "end": 672.92, "text": " We've written it in Golang.", "tokens": [50702, 492, 600, 3720, 309, 294, 36319, 656, 13, 50822], "temperature": 0.0, "avg_logprob": -0.22158640567387375, "compression_ratio": 1.5418502202643172, "no_speech_prob": 0.006701941601932049}, {"id": 184, "seek": 66376, "start": 672.92, "end": 678.72, "text": " Say initially we've got RTSP, we used GoRTSPlib, because again, why build it from scratch?", "tokens": [50822, 6463, 9105, 321, 600, 658, 497, 7327, 47, 11, 321, 1143, 1037, 49, 7327, 47, 38270, 11, 570, 797, 11, 983, 1322, 309, 490, 8459, 30, 51112], "temperature": 0.0, "avg_logprob": -0.22158640567387375, "compression_ratio": 1.5418502202643172, "no_speech_prob": 0.006701941601932049}, {"id": 185, "seek": 66376, "start": 678.72, "end": 682.84, "text": " We took the GoRTSP library, and I'm guessing for any other plug-in, we'll do the same,", "tokens": [51112, 492, 1890, 264, 1037, 49, 7327, 47, 6405, 11, 293, 286, 478, 17939, 337, 604, 661, 5452, 12, 259, 11, 321, 603, 360, 264, 912, 11, 51318], "temperature": 0.0, "avg_logprob": -0.22158640567387375, "compression_ratio": 1.5418502202643172, "no_speech_prob": 0.006701941601932049}, {"id": 186, "seek": 66376, "start": 682.84, "end": 688.8, "text": " we'll just look for existing libraries in Golang that we can plug in.", "tokens": [51318, 321, 603, 445, 574, 337, 6741, 15148, 294, 36319, 656, 300, 321, 393, 5452, 294, 13, 51616], "temperature": 0.0, "avg_logprob": -0.22158640567387375, "compression_ratio": 1.5418502202643172, "no_speech_prob": 0.006701941601932049}, {"id": 187, "seek": 68880, "start": 689.56, "end": 695.3599999999999, "text": " What we'd like to do though, and this is up for discussion, it'd be great if people", "tokens": [50402, 708, 321, 1116, 411, 281, 360, 1673, 11, 293, 341, 307, 493, 337, 5017, 11, 309, 1116, 312, 869, 498, 561, 50692], "temperature": 0.0, "avg_logprob": -0.17174219681044756, "compression_ratio": 1.5740740740740742, "no_speech_prob": 0.033894117921590805}, {"id": 188, "seek": 68880, "start": 695.3599999999999, "end": 699.52, "text": " had feedback at the end or hit me offline.", "tokens": [50692, 632, 5824, 412, 264, 917, 420, 2045, 385, 21857, 13, 50900], "temperature": 0.0, "avg_logprob": -0.17174219681044756, "compression_ratio": 1.5740740740740742, "no_speech_prob": 0.033894117921590805}, {"id": 189, "seek": 68880, "start": 699.52, "end": 701.88, "text": " What I feel is there's actually two different things we're doing here.", "tokens": [50900, 708, 286, 841, 307, 456, 311, 767, 732, 819, 721, 321, 434, 884, 510, 13, 51018], "temperature": 0.0, "avg_logprob": -0.17174219681044756, "compression_ratio": 1.5740740740740742, "no_speech_prob": 0.033894117921590805}, {"id": 190, "seek": 68880, "start": 701.88, "end": 706.7199999999999, "text": " One is we've got this dynamic protocol, whatever it is, RTSP or SIP, but on the other side", "tokens": [51018, 1485, 307, 321, 600, 658, 341, 8546, 10336, 11, 2035, 309, 307, 11, 497, 7327, 47, 420, 318, 9139, 11, 457, 322, 264, 661, 1252, 51260], "temperature": 0.0, "avg_logprob": -0.17174219681044756, "compression_ratio": 1.5740740740740742, "no_speech_prob": 0.033894117921590805}, {"id": 191, "seek": 68880, "start": 706.7199999999999, "end": 709.4799999999999, "text": " we've got how do we map this stuff into Kubernetes?", "tokens": [51260, 321, 600, 658, 577, 360, 321, 4471, 341, 1507, 666, 23145, 30, 51398], "temperature": 0.0, "avg_logprob": -0.17174219681044756, "compression_ratio": 1.5740740740740742, "no_speech_prob": 0.033894117921590805}, {"id": 192, "seek": 68880, "start": 709.4799999999999, "end": 714.8, "text": " So if you think about it, the handoff from one to the other is if you have a logical", "tokens": [51398, 407, 498, 291, 519, 466, 309, 11, 264, 1011, 4506, 490, 472, 281, 264, 661, 307, 498, 291, 362, 257, 14978, 51664], "temperature": 0.0, "avg_logprob": -0.17174219681044756, "compression_ratio": 1.5740740740740742, "no_speech_prob": 0.033894117921590805}, {"id": 193, "seek": 71480, "start": 714.8, "end": 719.0799999999999, "text": " graph saying we've got this sender for a stream, and here are our receivers.", "tokens": [50364, 4295, 1566, 321, 600, 658, 341, 2845, 260, 337, 257, 4309, 11, 293, 510, 366, 527, 49196, 13, 50578], "temperature": 0.0, "avg_logprob": -0.15806629851057724, "compression_ratio": 1.8042813455657492, "no_speech_prob": 0.059748366475105286}, {"id": 194, "seek": 71480, "start": 719.0799999999999, "end": 722.4799999999999, "text": " What we want to do is decompose that and say how does that map onto Kubernetes?", "tokens": [50578, 708, 321, 528, 281, 360, 307, 22867, 541, 300, 293, 584, 577, 775, 300, 4471, 3911, 23145, 30, 50748], "temperature": 0.0, "avg_logprob": -0.15806629851057724, "compression_ratio": 1.8042813455657492, "no_speech_prob": 0.059748366475105286}, {"id": 195, "seek": 71480, "start": 722.4799999999999, "end": 724.3599999999999, "text": " So which receivers are on which nodes?", "tokens": [50748, 407, 597, 49196, 366, 322, 597, 13891, 30, 50842], "temperature": 0.0, "avg_logprob": -0.15806629851057724, "compression_ratio": 1.8042813455657492, "no_speech_prob": 0.059748366475105286}, {"id": 196, "seek": 71480, "start": 724.3599999999999, "end": 728.4799999999999, "text": " So how do we build that tree where we're doing the kind of application layer multicast?", "tokens": [50842, 407, 577, 360, 321, 1322, 300, 4230, 689, 321, 434, 884, 264, 733, 295, 3861, 4583, 30608, 525, 30, 51048], "temperature": 0.0, "avg_logprob": -0.15806629851057724, "compression_ratio": 1.8042813455657492, "no_speech_prob": 0.059748366475105286}, {"id": 197, "seek": 71480, "start": 728.4799999999999, "end": 732.0, "text": " And so I think ideally we'd want to separate those two.", "tokens": [51048, 400, 370, 286, 519, 22915, 321, 1116, 528, 281, 4994, 729, 732, 13, 51224], "temperature": 0.0, "avg_logprob": -0.15806629851057724, "compression_ratio": 1.8042813455657492, "no_speech_prob": 0.059748366475105286}, {"id": 198, "seek": 71480, "start": 732.0, "end": 736.04, "text": " So the control plane will have the plug-in that we put in for RTSP or SIP or whatever,", "tokens": [51224, 407, 264, 1969, 5720, 486, 362, 264, 5452, 12, 259, 300, 321, 829, 294, 337, 497, 7327, 47, 420, 318, 9139, 420, 2035, 11, 51426], "temperature": 0.0, "avg_logprob": -0.15806629851057724, "compression_ratio": 1.8042813455657492, "no_speech_prob": 0.059748366475105286}, {"id": 199, "seek": 71480, "start": 736.04, "end": 739.64, "text": " but then the controller will take care of mapping that onto Kubernetes.", "tokens": [51426, 457, 550, 264, 10561, 486, 747, 1127, 295, 18350, 300, 3911, 23145, 13, 51606], "temperature": 0.0, "avg_logprob": -0.15806629851057724, "compression_ratio": 1.8042813455657492, "no_speech_prob": 0.059748366475105286}, {"id": 200, "seek": 71480, "start": 739.64, "end": 744.28, "text": " And the nice thing then is we could use that control plane to support multiple controllers,", "tokens": [51606, 400, 264, 1481, 551, 550, 307, 321, 727, 764, 300, 1969, 5720, 281, 1406, 3866, 26903, 11, 51838], "temperature": 0.0, "avg_logprob": -0.15806629851057724, "compression_ratio": 1.8042813455657492, "no_speech_prob": 0.059748366475105286}, {"id": 201, "seek": 74428, "start": 744.28, "end": 748.48, "text": " multiple control planes, but we could also use it in non-Kubernetes environment.", "tokens": [50364, 3866, 1969, 14952, 11, 457, 321, 727, 611, 764, 309, 294, 2107, 12, 42, 22457, 2823, 13, 50574], "temperature": 0.0, "avg_logprob": -0.19314345291682652, "compression_ratio": 1.626865671641791, "no_speech_prob": 0.0021229626145213842}, {"id": 202, "seek": 74428, "start": 748.48, "end": 753.1999999999999, "text": " So firstly we've externalized any Kubernetes dependencies using XDS, which is the Envoy", "tokens": [50574, 407, 27376, 321, 600, 8320, 1602, 604, 23145, 36606, 1228, 1783, 11844, 11, 597, 307, 264, 2193, 35176, 50810], "temperature": 0.0, "avg_logprob": -0.19314345291682652, "compression_ratio": 1.626865671641791, "no_speech_prob": 0.0021229626145213842}, {"id": 203, "seek": 74428, "start": 753.1999999999999, "end": 756.04, "text": " protocol for configuring Envoy.", "tokens": [50810, 10336, 337, 6662, 1345, 2193, 35176, 13, 50952], "temperature": 0.0, "avg_logprob": -0.19314345291682652, "compression_ratio": 1.626865671641791, "no_speech_prob": 0.0021229626145213842}, {"id": 204, "seek": 74428, "start": 756.04, "end": 760.04, "text": " But also if you think about it, why does it have to be Kubernetes?", "tokens": [50952, 583, 611, 498, 291, 519, 466, 309, 11, 983, 775, 309, 362, 281, 312, 23145, 30, 51152], "temperature": 0.0, "avg_logprob": -0.19314345291682652, "compression_ratio": 1.626865671641791, "no_speech_prob": 0.0021229626145213842}, {"id": 205, "seek": 74428, "start": 760.04, "end": 765.4, "text": " If you have remote edge proxies, so you've got a global network with edge proxies doing", "tokens": [51152, 759, 291, 362, 8607, 4691, 447, 87, 530, 11, 370, 291, 600, 658, 257, 4338, 3209, 365, 4691, 447, 87, 530, 884, 51420], "temperature": 0.0, "avg_logprob": -0.19314345291682652, "compression_ratio": 1.626865671641791, "no_speech_prob": 0.0021229626145213842}, {"id": 206, "seek": 74428, "start": 765.4, "end": 770.3199999999999, "text": " your media proxies, why couldn't you control those for a more centralized place?", "tokens": [51420, 428, 3021, 447, 87, 530, 11, 983, 2809, 380, 291, 1969, 729, 337, 257, 544, 32395, 1081, 30, 51666], "temperature": 0.0, "avg_logprob": -0.19314345291682652, "compression_ratio": 1.626865671641791, "no_speech_prob": 0.0021229626145213842}, {"id": 207, "seek": 77032, "start": 771.32, "end": 774.6, "text": " The stub is to say it's a stub.", "tokens": [50414, 440, 20266, 307, 281, 584, 309, 311, 257, 20266, 13, 50578], "temperature": 0.0, "avg_logprob": -0.2116306732440817, "compression_ratio": 1.6015037593984962, "no_speech_prob": 0.00221215165220201}, {"id": 208, "seek": 77032, "start": 774.6, "end": 776.1600000000001, "text": " So why do we call it a stub?", "tokens": [50578, 407, 983, 360, 321, 818, 309, 257, 20266, 30, 50656], "temperature": 0.0, "avg_logprob": -0.2116306732440817, "compression_ratio": 1.6015037593984962, "no_speech_prob": 0.00221215165220201}, {"id": 209, "seek": 77032, "start": 776.1600000000001, "end": 777.36, "text": " Because it's small.", "tokens": [50656, 1436, 309, 311, 1359, 13, 50716], "temperature": 0.0, "avg_logprob": -0.2116306732440817, "compression_ratio": 1.6015037593984962, "no_speech_prob": 0.00221215165220201}, {"id": 210, "seek": 77032, "start": 777.36, "end": 784.2800000000001, "text": " So we wrote this in Rust using Tojo and Tonic and all that stuff, keeps the memory footprint", "tokens": [50716, 407, 321, 4114, 341, 294, 34952, 1228, 1407, 5134, 293, 11385, 299, 293, 439, 300, 1507, 11, 5965, 264, 4675, 24222, 51062], "temperature": 0.0, "avg_logprob": -0.2116306732440817, "compression_ratio": 1.6015037593984962, "no_speech_prob": 0.00221215165220201}, {"id": 211, "seek": 77032, "start": 784.2800000000001, "end": 788.5200000000001, "text": " low and it avoids any latency spikes because we figured if garbage collection kicks in", "tokens": [51062, 2295, 293, 309, 3641, 3742, 604, 27043, 28997, 570, 321, 8932, 498, 14150, 5765, 21293, 294, 51274], "temperature": 0.0, "avg_logprob": -0.2116306732440817, "compression_ratio": 1.6015037593984962, "no_speech_prob": 0.00221215165220201}, {"id": 212, "seek": 77032, "start": 788.5200000000001, "end": 794.96, "text": " that's going to be a problem, but I didn't want to be writing in C in 2023.", "tokens": [51274, 300, 311, 516, 281, 312, 257, 1154, 11, 457, 286, 994, 380, 528, 281, 312, 3579, 294, 383, 294, 44377, 13, 51596], "temperature": 0.0, "avg_logprob": -0.2116306732440817, "compression_ratio": 1.6015037593984962, "no_speech_prob": 0.00221215165220201}, {"id": 213, "seek": 77032, "start": 794.96, "end": 799.6800000000001, "text": " There are some cases, it does intercept the control plane, but there are some cases where", "tokens": [51596, 821, 366, 512, 3331, 11, 309, 775, 24700, 264, 1969, 5720, 11, 457, 456, 366, 512, 3331, 689, 51832], "temperature": 0.0, "avg_logprob": -0.2116306732440817, "compression_ratio": 1.6015037593984962, "no_speech_prob": 0.00221215165220201}, {"id": 214, "seek": 79968, "start": 799.7199999999999, "end": 801.3199999999999, "text": " it intercepts the data plane as well.", "tokens": [50366, 309, 24700, 82, 264, 1412, 5720, 382, 731, 13, 50446], "temperature": 0.0, "avg_logprob": -0.18149422539605034, "compression_ratio": 1.7913907284768211, "no_speech_prob": 0.011287937872111797}, {"id": 215, "seek": 79968, "start": 801.3199999999999, "end": 806.7199999999999, "text": " So RTSP as an example, there's an option to stream everything over one TCP socket.", "tokens": [50446, 407, 497, 7327, 47, 382, 364, 1365, 11, 456, 311, 364, 3614, 281, 4309, 1203, 670, 472, 48965, 19741, 13, 50716], "temperature": 0.0, "avg_logprob": -0.18149422539605034, "compression_ratio": 1.7913907284768211, "no_speech_prob": 0.011287937872111797}, {"id": 216, "seek": 79968, "start": 806.7199999999999, "end": 810.4, "text": " So what we can do is we can capture all that traffic and then send it over UDP through", "tokens": [50716, 407, 437, 321, 393, 360, 307, 321, 393, 7983, 439, 300, 6419, 293, 550, 2845, 309, 670, 624, 11373, 807, 50900], "temperature": 0.0, "avg_logprob": -0.18149422539605034, "compression_ratio": 1.7913907284768211, "no_speech_prob": 0.011287937872111797}, {"id": 217, "seek": 79968, "start": 810.4, "end": 813.8, "text": " our network so we can do all the replication and everything.", "tokens": [50900, 527, 3209, 370, 321, 393, 360, 439, 264, 39911, 293, 1203, 13, 51070], "temperature": 0.0, "avg_logprob": -0.18149422539605034, "compression_ratio": 1.7913907284768211, "no_speech_prob": 0.011287937872111797}, {"id": 218, "seek": 79968, "start": 813.8, "end": 817.88, "text": " But there might be other cases where for example you want to monitor right at the pod or you", "tokens": [51070, 583, 456, 1062, 312, 661, 3331, 689, 337, 1365, 291, 528, 281, 6002, 558, 412, 264, 2497, 420, 291, 51274], "temperature": 0.0, "avg_logprob": -0.18149422539605034, "compression_ratio": 1.7913907284768211, "no_speech_prob": 0.011287937872111797}, {"id": 219, "seek": 79968, "start": 817.88, "end": 822.9599999999999, "text": " want to do again for like TV type stuff, you want to do your live, live video replication", "tokens": [51274, 528, 281, 360, 797, 337, 411, 3558, 2010, 1507, 11, 291, 528, 281, 360, 428, 1621, 11, 1621, 960, 39911, 51528], "temperature": 0.0, "avg_logprob": -0.18149422539605034, "compression_ratio": 1.7913907284768211, "no_speech_prob": 0.011287937872111797}, {"id": 220, "seek": 79968, "start": 822.9599999999999, "end": 827.76, "text": " right from the edge because you don't want any shared paths so that you don't risk having", "tokens": [51528, 558, 490, 264, 4691, 570, 291, 500, 380, 528, 604, 5507, 14518, 370, 300, 291, 500, 380, 3148, 1419, 51768], "temperature": 0.0, "avg_logprob": -0.18149422539605034, "compression_ratio": 1.7913907284768211, "no_speech_prob": 0.011287937872111797}, {"id": 221, "seek": 82776, "start": 827.76, "end": 834.64, "text": " dropouts and I think that's about it on that one.", "tokens": [50364, 3270, 7711, 293, 286, 519, 300, 311, 466, 309, 322, 300, 472, 13, 50708], "temperature": 0.0, "avg_logprob": -0.23057378507127949, "compression_ratio": 1.5625, "no_speech_prob": 0.007401331793516874}, {"id": 222, "seek": 82776, "start": 834.64, "end": 839.84, "text": " So the RTP proxy now, I guess this is pretty straightforward, I mean the one we have at", "tokens": [50708, 407, 264, 497, 16804, 29690, 586, 11, 286, 2041, 341, 307, 1238, 15325, 11, 286, 914, 264, 472, 321, 362, 412, 50968], "temperature": 0.0, "avg_logprob": -0.23057378507127949, "compression_ratio": 1.5625, "no_speech_prob": 0.007401331793516874}, {"id": 223, "seek": 82776, "start": 839.84, "end": 842.4399999999999, "text": " the moment is written in Golang, it's just a prototype.", "tokens": [50968, 264, 1623, 307, 3720, 294, 36319, 656, 11, 309, 311, 445, 257, 19475, 13, 51098], "temperature": 0.0, "avg_logprob": -0.23057378507127949, "compression_ratio": 1.5625, "no_speech_prob": 0.007401331793516874}, {"id": 224, "seek": 82776, "start": 842.4399999999999, "end": 847.24, "text": " I intend to throw that one away and again, go to asynchronous Rust.", "tokens": [51098, 286, 19759, 281, 3507, 300, 472, 1314, 293, 797, 11, 352, 281, 49174, 34952, 13, 51338], "temperature": 0.0, "avg_logprob": -0.23057378507127949, "compression_ratio": 1.5625, "no_speech_prob": 0.007401331793516874}, {"id": 225, "seek": 82776, "start": 847.24, "end": 850.12, "text": " The big thing here is, you know, back to the control plane, I was talking about having", "tokens": [51338, 440, 955, 551, 510, 307, 11, 291, 458, 11, 646, 281, 264, 1969, 5720, 11, 286, 390, 1417, 466, 1419, 51482], "temperature": 0.0, "avg_logprob": -0.23057378507127949, "compression_ratio": 1.5625, "no_speech_prob": 0.007401331793516874}, {"id": 226, "seek": 82776, "start": 850.12, "end": 852.12, "text": " plugins for the protocols.", "tokens": [51482, 33759, 337, 264, 20618, 13, 51582], "temperature": 0.0, "avg_logprob": -0.23057378507127949, "compression_ratio": 1.5625, "no_speech_prob": 0.007401331793516874}, {"id": 227, "seek": 85212, "start": 852.16, "end": 858.64, "text": " So my thesis is that for success in this project, what we'd need is that we make it easy for", "tokens": [50366, 407, 452, 22288, 307, 300, 337, 2245, 294, 341, 1716, 11, 437, 321, 1116, 643, 307, 300, 321, 652, 309, 1858, 337, 50690], "temperature": 0.0, "avg_logprob": -0.16937215563277125, "compression_ratio": 1.7483443708609272, "no_speech_prob": 0.07044949382543564}, {"id": 228, "seek": 85212, "start": 858.64, "end": 859.64, "text": " people to contribute.", "tokens": [50690, 561, 281, 10586, 13, 50740], "temperature": 0.0, "avg_logprob": -0.16937215563277125, "compression_ratio": 1.7483443708609272, "no_speech_prob": 0.07044949382543564}, {"id": 229, "seek": 85212, "start": 859.64, "end": 862.88, "text": " So you shouldn't have to read all of my code-based contribute.", "tokens": [50740, 407, 291, 4659, 380, 362, 281, 1401, 439, 295, 452, 3089, 12, 6032, 10586, 13, 50902], "temperature": 0.0, "avg_logprob": -0.16937215563277125, "compression_ratio": 1.7483443708609272, "no_speech_prob": 0.07044949382543564}, {"id": 230, "seek": 85212, "start": 862.88, "end": 865.4, "text": " What you should be able to do is say, okay, I've just got this one plugin I want to put", "tokens": [50902, 708, 291, 820, 312, 1075, 281, 360, 307, 584, 11, 1392, 11, 286, 600, 445, 658, 341, 472, 23407, 286, 528, 281, 829, 51028], "temperature": 0.0, "avg_logprob": -0.16937215563277125, "compression_ratio": 1.7483443708609272, "no_speech_prob": 0.07044949382543564}, {"id": 231, "seek": 85212, "start": 865.4, "end": 869.72, "text": " in for my control plane protocol and here's a well-defined API that I can plug it in.", "tokens": [51028, 294, 337, 452, 1969, 5720, 10336, 293, 510, 311, 257, 731, 12, 37716, 9362, 300, 286, 393, 5452, 309, 294, 13, 51244], "temperature": 0.0, "avg_logprob": -0.16937215563277125, "compression_ratio": 1.7483443708609272, "no_speech_prob": 0.07044949382543564}, {"id": 232, "seek": 85212, "start": 869.72, "end": 874.36, "text": " But when it comes to data plane, what we're thinking is use wasm as our plugin so that", "tokens": [51244, 583, 562, 309, 1487, 281, 1412, 5720, 11, 437, 321, 434, 1953, 307, 764, 390, 76, 382, 527, 23407, 370, 300, 51476], "temperature": 0.0, "avg_logprob": -0.16937215563277125, "compression_ratio": 1.7483443708609272, "no_speech_prob": 0.07044949382543564}, {"id": 233, "seek": 85212, "start": 874.36, "end": 878.76, "text": " then if you've got a plugin that does, whether it's encryption or whether it's validating", "tokens": [51476, 550, 498, 291, 600, 658, 257, 23407, 300, 775, 11, 1968, 309, 311, 29575, 420, 1968, 309, 311, 7363, 990, 51696], "temperature": 0.0, "avg_logprob": -0.16937215563277125, "compression_ratio": 1.7483443708609272, "no_speech_prob": 0.07044949382543564}, {"id": 234, "seek": 87876, "start": 878.76, "end": 882.24, "text": " the RTP header fields, whatever it is, you should be able to just plug that in again", "tokens": [50364, 264, 497, 16804, 23117, 7909, 11, 2035, 309, 307, 11, 291, 820, 312, 1075, 281, 445, 5452, 300, 294, 797, 50538], "temperature": 0.0, "avg_logprob": -0.18067679228606048, "compression_ratio": 1.6584615384615384, "no_speech_prob": 0.011879274621605873}, {"id": 235, "seek": 87876, "start": 882.24, "end": 889.12, "text": " with a very simple API into a filter chain that's built dynamically in the proxy.", "tokens": [50538, 365, 257, 588, 2199, 9362, 666, 257, 6608, 5021, 300, 311, 3094, 43492, 294, 264, 29690, 13, 50882], "temperature": 0.0, "avg_logprob": -0.18067679228606048, "compression_ratio": 1.6584615384615384, "no_speech_prob": 0.011879274621605873}, {"id": 236, "seek": 87876, "start": 889.12, "end": 894.28, "text": " Now obviously, modulo, the issue of course of performance, again, back to zero copying", "tokens": [50882, 823, 2745, 11, 1072, 13455, 11, 264, 2734, 295, 1164, 295, 3389, 11, 797, 11, 646, 281, 4018, 27976, 51140], "temperature": 0.0, "avg_logprob": -0.18067679228606048, "compression_ratio": 1.6584615384615384, "no_speech_prob": 0.011879274621605873}, {"id": 237, "seek": 87876, "start": 894.28, "end": 897.84, "text": " and all that stuff, do you really want to be copying each packet as you pass it down", "tokens": [51140, 293, 439, 300, 1507, 11, 360, 291, 534, 528, 281, 312, 27976, 1184, 20300, 382, 291, 1320, 309, 760, 51318], "temperature": 0.0, "avg_logprob": -0.18067679228606048, "compression_ratio": 1.6584615384615384, "no_speech_prob": 0.011879274621605873}, {"id": 238, "seek": 87876, "start": 897.84, "end": 898.84, "text": " a filter chain?", "tokens": [51318, 257, 6608, 5021, 30, 51368], "temperature": 0.0, "avg_logprob": -0.18067679228606048, "compression_ratio": 1.6584615384615384, "no_speech_prob": 0.011879274621605873}, {"id": 239, "seek": 87876, "start": 898.84, "end": 901.0, "text": " So that's something we'll probably have to think about.", "tokens": [51368, 407, 300, 311, 746, 321, 603, 1391, 362, 281, 519, 466, 13, 51476], "temperature": 0.0, "avg_logprob": -0.18067679228606048, "compression_ratio": 1.6584615384615384, "no_speech_prob": 0.011879274621605873}, {"id": 240, "seek": 87876, "start": 901.0, "end": 904.52, "text": " But as I say, I think really the key success would be to drive a filter ecosystem where", "tokens": [51476, 583, 382, 286, 584, 11, 286, 519, 534, 264, 2141, 2245, 576, 312, 281, 3332, 257, 6608, 11311, 689, 51652], "temperature": 0.0, "avg_logprob": -0.18067679228606048, "compression_ratio": 1.6584615384615384, "no_speech_prob": 0.011879274621605873}, {"id": 241, "seek": 87876, "start": 904.52, "end": 907.16, "text": " people can contribute their own filters.", "tokens": [51652, 561, 393, 10586, 641, 1065, 15995, 13, 51784], "temperature": 0.0, "avg_logprob": -0.18067679228606048, "compression_ratio": 1.6584615384615384, "no_speech_prob": 0.011879274621605873}, {"id": 242, "seek": 90716, "start": 907.16, "end": 911.68, "text": " I did a bit of work at the moment, here's come across Quilkin, which is a Google for", "tokens": [50364, 286, 630, 257, 857, 295, 589, 412, 264, 1623, 11, 510, 311, 808, 2108, 2326, 388, 5843, 11, 597, 307, 257, 3329, 337, 50590], "temperature": 0.0, "avg_logprob": -0.2656672176898726, "compression_ratio": 1.7350993377483444, "no_speech_prob": 0.016805874183773994}, {"id": 243, "seek": 90716, "start": 911.68, "end": 913.24, "text": " Games project.", "tokens": [50590, 12761, 1716, 13, 50668], "temperature": 0.0, "avg_logprob": -0.2656672176898726, "compression_ratio": 1.7350993377483444, "no_speech_prob": 0.016805874183773994}, {"id": 244, "seek": 90716, "start": 913.24, "end": 916.8399999999999, "text": " And it does basically proxying for games.", "tokens": [50668, 400, 309, 775, 1936, 447, 87, 1840, 337, 2813, 13, 50848], "temperature": 0.0, "avg_logprob": -0.2656672176898726, "compression_ratio": 1.7350993377483444, "no_speech_prob": 0.016805874183773994}, {"id": 245, "seek": 90716, "start": 916.8399999999999, "end": 921.4399999999999, "text": " And most of that, the only way to sort of modify it was to really get into the code.", "tokens": [50848, 400, 881, 295, 300, 11, 264, 787, 636, 281, 1333, 295, 16927, 309, 390, 281, 534, 483, 666, 264, 3089, 13, 51078], "temperature": 0.0, "avg_logprob": -0.2656672176898726, "compression_ratio": 1.7350993377483444, "no_speech_prob": 0.016805874183773994}, {"id": 246, "seek": 90716, "start": 921.4399999999999, "end": 923.16, "text": " And I don't want people to have to get into the code here.", "tokens": [51078, 400, 286, 500, 380, 528, 561, 281, 362, 281, 483, 666, 264, 3089, 510, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2656672176898726, "compression_ratio": 1.7350993377483444, "no_speech_prob": 0.016805874183773994}, {"id": 247, "seek": 90716, "start": 923.16, "end": 926.0, "text": " I want to have a really simple API.", "tokens": [51164, 286, 528, 281, 362, 257, 534, 2199, 9362, 13, 51306], "temperature": 0.0, "avg_logprob": -0.2656672176898726, "compression_ratio": 1.7350993377483444, "no_speech_prob": 0.016805874183773994}, {"id": 248, "seek": 90716, "start": 926.0, "end": 932.04, "text": " So how it works ultimately in this case would be we'd have this framework of the proxy,", "tokens": [51306, 407, 577, 309, 1985, 6284, 294, 341, 1389, 576, 312, 321, 1116, 362, 341, 8388, 295, 264, 29690, 11, 51608], "temperature": 0.0, "avg_logprob": -0.2656672176898726, "compression_ratio": 1.7350993377483444, "no_speech_prob": 0.016805874183773994}, {"id": 249, "seek": 90716, "start": 932.04, "end": 933.04, "text": " we'd have the filter chain.", "tokens": [51608, 321, 1116, 362, 264, 6608, 5021, 13, 51658], "temperature": 0.0, "avg_logprob": -0.2656672176898726, "compression_ratio": 1.7350993377483444, "no_speech_prob": 0.016805874183773994}, {"id": 250, "seek": 90716, "start": 933.04, "end": 936.24, "text": " So we strip off whatever the headers are, it could be typical RTP of a UDP or it could", "tokens": [51658, 407, 321, 12828, 766, 2035, 264, 45101, 366, 11, 309, 727, 312, 7476, 497, 16804, 295, 257, 624, 11373, 420, 309, 727, 51818], "temperature": 0.0, "avg_logprob": -0.2656672176898726, "compression_ratio": 1.7350993377483444, "no_speech_prob": 0.016805874183773994}, {"id": 251, "seek": 93624, "start": 936.24, "end": 941.08, "text": " be some quick, it could be raw RTP within the node, so we strip off any headers and", "tokens": [50364, 312, 512, 1702, 11, 309, 727, 312, 8936, 497, 16804, 1951, 264, 9984, 11, 370, 321, 12828, 766, 604, 45101, 293, 50606], "temperature": 0.0, "avg_logprob": -0.18300315695749203, "compression_ratio": 1.6601941747572815, "no_speech_prob": 0.00241259578615427}, {"id": 252, "seek": 93624, "start": 941.08, "end": 944.72, "text": " then we just pass it through a filter chain where each part of the filter chain does its", "tokens": [50606, 550, 321, 445, 1320, 309, 807, 257, 6608, 5021, 689, 1184, 644, 295, 264, 6608, 5021, 775, 1080, 50788], "temperature": 0.0, "avg_logprob": -0.18300315695749203, "compression_ratio": 1.6601941747572815, "no_speech_prob": 0.00241259578615427}, {"id": 253, "seek": 93624, "start": 944.72, "end": 945.72, "text": " role.", "tokens": [50788, 3090, 13, 50838], "temperature": 0.0, "avg_logprob": -0.18300315695749203, "compression_ratio": 1.6601941747572815, "no_speech_prob": 0.00241259578615427}, {"id": 254, "seek": 93624, "start": 945.72, "end": 949.4, "text": " As I say, the key challenge there is going to be how do we make that perform at scale.", "tokens": [50838, 1018, 286, 584, 11, 264, 2141, 3430, 456, 307, 516, 281, 312, 577, 360, 321, 652, 300, 2042, 412, 4373, 13, 51022], "temperature": 0.0, "avg_logprob": -0.18300315695749203, "compression_ratio": 1.6601941747572815, "no_speech_prob": 0.00241259578615427}, {"id": 255, "seek": 93624, "start": 949.4, "end": 953.32, "text": " So I think that's about it.", "tokens": [51022, 407, 286, 519, 300, 311, 466, 309, 13, 51218], "temperature": 0.0, "avg_logprob": -0.18300315695749203, "compression_ratio": 1.6601941747572815, "no_speech_prob": 0.00241259578615427}, {"id": 256, "seek": 93624, "start": 953.32, "end": 958.4, "text": " And yeah, the goal here is that we can really deploy real-time media apps in Kubernetes and", "tokens": [51218, 400, 1338, 11, 264, 3387, 510, 307, 300, 321, 393, 534, 7274, 957, 12, 3766, 3021, 7733, 294, 23145, 293, 51472], "temperature": 0.0, "avg_logprob": -0.18300315695749203, "compression_ratio": 1.6601941747572815, "no_speech_prob": 0.00241259578615427}, {"id": 257, "seek": 93624, "start": 958.4, "end": 963.0, "text": " make it work, which doesn't seem to work so well today.", "tokens": [51472, 652, 309, 589, 11, 597, 1177, 380, 1643, 281, 589, 370, 731, 965, 13, 51702], "temperature": 0.0, "avg_logprob": -0.18300315695749203, "compression_ratio": 1.6601941747572815, "no_speech_prob": 0.00241259578615427}, {"id": 258, "seek": 93624, "start": 963.0, "end": 965.84, "text": " It's very much a work in progress, it's an open source, it's all there.", "tokens": [51702, 467, 311, 588, 709, 257, 589, 294, 4205, 11, 309, 311, 364, 1269, 4009, 11, 309, 311, 439, 456, 13, 51844], "temperature": 0.0, "avg_logprob": -0.18300315695749203, "compression_ratio": 1.6601941747572815, "no_speech_prob": 0.00241259578615427}, {"id": 259, "seek": 96584, "start": 965.84, "end": 970.6, "text": " You can, I don't think I need to stick a new video on the website, but the GitHub's", "tokens": [50364, 509, 393, 11, 286, 500, 380, 519, 286, 643, 281, 2897, 257, 777, 960, 322, 264, 3144, 11, 457, 264, 23331, 311, 50602], "temperature": 0.0, "avg_logprob": -0.3040960279561706, "compression_ratio": 1.6613545816733069, "no_speech_prob": 0.182856947183609}, {"id": 260, "seek": 96584, "start": 970.6, "end": 971.6, "text": " there.", "tokens": [50602, 456, 13, 50652], "temperature": 0.0, "avg_logprob": -0.3040960279561706, "compression_ratio": 1.6613545816733069, "no_speech_prob": 0.182856947183609}, {"id": 261, "seek": 96584, "start": 971.6, "end": 976.88, "text": " And really, anyone who wants to contribute, I know what it is, because as I said, I think", "tokens": [50652, 400, 534, 11, 2878, 567, 2738, 281, 10586, 11, 286, 458, 437, 309, 307, 11, 570, 382, 286, 848, 11, 286, 519, 50916], "temperature": 0.0, "avg_logprob": -0.3040960279561706, "compression_ratio": 1.6613545816733069, "no_speech_prob": 0.182856947183609}, {"id": 262, "seek": 96584, "start": 976.88, "end": 978.64, "text": " more people is going to help us get there faster.", "tokens": [50916, 544, 561, 307, 516, 281, 854, 505, 483, 456, 4663, 13, 51004], "temperature": 0.0, "avg_logprob": -0.3040960279561706, "compression_ratio": 1.6613545816733069, "no_speech_prob": 0.182856947183609}, {"id": 263, "seek": 96584, "start": 978.64, "end": 982.1600000000001, "text": " I think if we firstly get the architecture right, then hopefully make it easy for people", "tokens": [51004, 286, 519, 498, 321, 27376, 483, 264, 9482, 558, 11, 550, 4696, 652, 309, 1858, 337, 561, 51180], "temperature": 0.0, "avg_logprob": -0.3040960279561706, "compression_ratio": 1.6613545816733069, "no_speech_prob": 0.182856947183609}, {"id": 264, "seek": 96584, "start": 982.1600000000001, "end": 984.52, "text": " to contribute, then hopefully we can scale this.", "tokens": [51180, 281, 10586, 11, 550, 4696, 321, 393, 4373, 341, 13, 51298], "temperature": 0.0, "avg_logprob": -0.3040960279561706, "compression_ratio": 1.6613545816733069, "no_speech_prob": 0.182856947183609}, {"id": 265, "seek": 96584, "start": 984.52, "end": 987.4, "text": " So do please join in.", "tokens": [51298, 407, 360, 1767, 3917, 294, 13, 51442], "temperature": 0.0, "avg_logprob": -0.3040960279561706, "compression_ratio": 1.6613545816733069, "no_speech_prob": 0.182856947183609}, {"id": 266, "seek": 96584, "start": 987.4, "end": 988.4, "text": " So that's that.", "tokens": [51442, 407, 300, 311, 300, 13, 51492], "temperature": 0.0, "avg_logprob": -0.3040960279561706, "compression_ratio": 1.6613545816733069, "no_speech_prob": 0.182856947183609}, {"id": 267, "seek": 96584, "start": 988.4, "end": 989.4, "text": " Thank you.", "tokens": [51492, 1044, 291, 13, 51542], "temperature": 0.0, "avg_logprob": -0.3040960279561706, "compression_ratio": 1.6613545816733069, "no_speech_prob": 0.182856947183609}, {"id": 268, "seek": 98940, "start": 989.4, "end": 1002.6, "text": " And to, yeah, do ask any questions while the next person's coming up.", "tokens": [50364, 400, 281, 11, 1338, 11, 360, 1029, 604, 1651, 1339, 264, 958, 954, 311, 1348, 493, 13, 51024], "temperature": 0.0, "avg_logprob": -0.4872388309902615, "compression_ratio": 1.4972677595628416, "no_speech_prob": 0.04936685040593147}, {"id": 269, "seek": 98940, "start": 1002.6, "end": 1006.4399999999999, "text": " Can you repeat the question?", "tokens": [51024, 1664, 291, 7149, 264, 1168, 30, 51216], "temperature": 0.0, "avg_logprob": -0.4872388309902615, "compression_ratio": 1.4972677595628416, "no_speech_prob": 0.04936685040593147}, {"id": 270, "seek": 98940, "start": 1006.4399999999999, "end": 1012.0799999999999, "text": " Can you say about the quality of the project?", "tokens": [51216, 1664, 291, 584, 466, 264, 3125, 295, 264, 1716, 30, 51498], "temperature": 0.0, "avg_logprob": -0.4872388309902615, "compression_ratio": 1.4972677595628416, "no_speech_prob": 0.04936685040593147}, {"id": 271, "seek": 98940, "start": 1012.0799999999999, "end": 1014.8, "text": " Yeah, so at this point, very much better.", "tokens": [51498, 865, 11, 370, 412, 341, 935, 11, 588, 709, 1101, 13, 51634], "temperature": 0.0, "avg_logprob": -0.4872388309902615, "compression_ratio": 1.4972677595628416, "no_speech_prob": 0.04936685040593147}, {"id": 272, "seek": 98940, "start": 1014.8, "end": 1017.84, "text": " I'm doing some integration work at the moment with another team within Cisco that wants", "tokens": [51634, 286, 478, 884, 512, 10980, 589, 412, 264, 1623, 365, 1071, 1469, 1951, 38528, 300, 2738, 51786], "temperature": 0.0, "avg_logprob": -0.4872388309902615, "compression_ratio": 1.4972677595628416, "no_speech_prob": 0.04936685040593147}, {"id": 273, "seek": 101784, "start": 1017.84, "end": 1018.84, "text": " to use this for something.", "tokens": [50364, 281, 764, 341, 337, 746, 13, 50414], "temperature": 0.0, "avg_logprob": -0.3728088443562136, "compression_ratio": 1.682170542635659, "no_speech_prob": 0.11566781997680664}, {"id": 274, "seek": 101784, "start": 1018.84, "end": 1022.1600000000001, "text": " So I guess that's where we'll start to really shake the bugs out.", "tokens": [50414, 407, 286, 2041, 300, 311, 689, 321, 603, 722, 281, 534, 10283, 264, 15120, 484, 13, 50580], "temperature": 0.0, "avg_logprob": -0.3728088443562136, "compression_ratio": 1.682170542635659, "no_speech_prob": 0.11566781997680664}, {"id": 275, "seek": 101784, "start": 1022.1600000000001, "end": 1027.44, "text": " And that, but that again is RTSP, so, you know, really be interested in other people", "tokens": [50580, 400, 300, 11, 457, 300, 797, 307, 497, 7327, 47, 11, 370, 11, 291, 458, 11, 534, 312, 3102, 294, 661, 561, 50844], "temperature": 0.0, "avg_logprob": -0.3728088443562136, "compression_ratio": 1.682170542635659, "no_speech_prob": 0.11566781997680664}, {"id": 276, "seek": 101784, "start": 1027.44, "end": 1030.92, "text": " contributing other protocols.", "tokens": [50844, 19270, 661, 20618, 13, 51018], "temperature": 0.0, "avg_logprob": -0.3728088443562136, "compression_ratio": 1.682170542635659, "no_speech_prob": 0.11566781997680664}, {"id": 277, "seek": 101784, "start": 1030.92, "end": 1036.48, "text": " The integration with the other open source, like the Melio.cs, do you think it will change", "tokens": [51018, 440, 10980, 365, 264, 661, 1269, 4009, 11, 411, 264, 7375, 1004, 13, 14368, 11, 360, 291, 519, 309, 486, 1319, 51296], "temperature": 0.0, "avg_logprob": -0.3728088443562136, "compression_ratio": 1.682170542635659, "no_speech_prob": 0.11566781997680664}, {"id": 278, "seek": 101784, "start": 1036.48, "end": 1037.48, "text": " for these?", "tokens": [51296, 337, 613, 30, 51346], "temperature": 0.0, "avg_logprob": -0.3728088443562136, "compression_ratio": 1.682170542635659, "no_speech_prob": 0.11566781997680664}, {"id": 279, "seek": 101784, "start": 1037.48, "end": 1040.0, "text": " Yeah, with other open source projects.", "tokens": [51346, 865, 11, 365, 661, 1269, 4009, 4455, 13, 51472], "temperature": 0.0, "avg_logprob": -0.3728088443562136, "compression_ratio": 1.682170542635659, "no_speech_prob": 0.11566781997680664}, {"id": 280, "seek": 101784, "start": 1040.0, "end": 1044.2, "text": " I think in terms of how it would integrate, I guess it's down to that project and how", "tokens": [51472, 286, 519, 294, 2115, 295, 577, 309, 576, 13365, 11, 286, 2041, 309, 311, 760, 281, 300, 1716, 293, 577, 51682], "temperature": 0.0, "avg_logprob": -0.3728088443562136, "compression_ratio": 1.682170542635659, "no_speech_prob": 0.11566781997680664}, {"id": 281, "seek": 104420, "start": 1044.2, "end": 1048.3600000000001, "text": " it fits, because we've very much separated the control plane and data plane.", "tokens": [50364, 309, 9001, 11, 570, 321, 600, 588, 709, 12005, 264, 1969, 5720, 293, 1412, 5720, 13, 50572], "temperature": 0.0, "avg_logprob": -0.21028095180705442, "compression_ratio": 1.7651515151515151, "no_speech_prob": 0.3840526342391968}, {"id": 282, "seek": 104420, "start": 1048.3600000000001, "end": 1052.48, "text": " So if the other projects have also done that, then I guess we could, that control plane", "tokens": [50572, 407, 498, 264, 661, 4455, 362, 611, 1096, 300, 11, 550, 286, 2041, 321, 727, 11, 300, 1969, 5720, 50778], "temperature": 0.0, "avg_logprob": -0.21028095180705442, "compression_ratio": 1.7651515151515151, "no_speech_prob": 0.3840526342391968}, {"id": 283, "seek": 104420, "start": 1052.48, "end": 1054.44, "text": " could plug into what we're doing.", "tokens": [50778, 727, 5452, 666, 437, 321, 434, 884, 13, 50876], "temperature": 0.0, "avg_logprob": -0.21028095180705442, "compression_ratio": 1.7651515151515151, "no_speech_prob": 0.3840526342391968}, {"id": 284, "seek": 104420, "start": 1054.44, "end": 1057.72, "text": " Again today, it would have to be Golang, because that's what a control plane is written in.", "tokens": [50876, 3764, 965, 11, 309, 576, 362, 281, 312, 36319, 656, 11, 570, 300, 311, 437, 257, 1969, 5720, 307, 3720, 294, 13, 51040], "temperature": 0.0, "avg_logprob": -0.21028095180705442, "compression_ratio": 1.7651515151515151, "no_speech_prob": 0.3840526342391968}, {"id": 285, "seek": 104420, "start": 1057.72, "end": 1061.24, "text": " But even for that, again, we could look at other models to plug it in, or at least if", "tokens": [51040, 583, 754, 337, 300, 11, 797, 11, 321, 727, 574, 412, 661, 5245, 281, 5452, 309, 294, 11, 420, 412, 1935, 498, 51216], "temperature": 0.0, "avg_logprob": -0.21028095180705442, "compression_ratio": 1.7651515151515151, "no_speech_prob": 0.3840526342391968}, {"id": 286, "seek": 104420, "start": 1061.24, "end": 1065.2, "text": " the APIs to our data plane are clean enough, then equally just contribute the whole thing", "tokens": [51216, 264, 21445, 281, 527, 1412, 5720, 366, 2541, 1547, 11, 550, 12309, 445, 10586, 264, 1379, 551, 51414], "temperature": 0.0, "avg_logprob": -0.21028095180705442, "compression_ratio": 1.7651515151515151, "no_speech_prob": 0.3840526342391968}, {"id": 287, "seek": 106520, "start": 1065.2, "end": 1066.4, "text": " as a blob if it wasn't Golang.", "tokens": [50364, 382, 257, 46115, 498, 309, 2067, 380, 36319, 656, 13, 50424], "temperature": 0.0, "avg_logprob": -0.4686386035038875, "compression_ratio": 0.7894736842105263, "no_speech_prob": 0.9063126444816589}], "language": "en"}