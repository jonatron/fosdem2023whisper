{"text": " The name of my talk is Postgres Observability. My intention is to show you what's great about Postgres and how it integrates well with observability, but also where some of the problems are. Obviously, in 25 minutes, it's not going to be an exhaustive presentation of all of the metrics in Postgres, but maybe I can give a bit of an introduction. So first of all, my name is Gregory Stark. I work for Ivan, which is a, so I work in the open source programs office, contributing to Postgres. Ivan is a data infrastructure hosting company. We host Postgres, but we also host a range of other data services, including some observabilities that it's all open source software, and we contribute back to the projects that we sell. So I'm sure in this room, most people have seen the cliched three pillars of observability. In a modern software, what people expect are their logs to be structured so they can send it to some sort of index, something like OpenSearch, some sort of indexed aggregate log system. They expect time series database to hold all their metrics with labels and well-defined semantics. They expect distributed tracing. Postgres is not so much of a modern, it's still actively developed and has modern relational database features, but for things like this, Postgres is going on almost 30 years now. Our logs, our metrics, our tracing tools predate most of these modern distributed system concepts. So what these look like in Postgres is we have very good logs, they're meant for a human to be reading in a text file. So we actually support JSON logs, but the actual error message, the actual log message will just be a string inside that JSON struct. All the JSON structured information, labels and so on are the metadata about the log line, things like process ID, session ID, the actual like table name being mentioned in the error, the actual, well actually current user is one of those columns, but if the error message mentions a user name or a table name or an index, it's just going to be part of the string. There's tons of metrics in Postgres, and I'll go into more detail, I'm mainly going to be talking about metrics here, but they're in SQL, they're not in like Prometheus exposition format or open metrics or anything like that. And then there's explain plans are basically a tracing tool, but it's meant for a human to be investigating on a single system, it doesn't integrate into any sort of distributed tracing tools. So I want to spend a little bit of time showing you what like the metrics in Postgres look like because it gives you, I can't show you all of them, there are hundreds and hundreds, probably thousands, but I want to give you a feel for like the kinds of in depth metrics that Postgres does provide. It does give you, there's a whole component inside Postgres whose job is to track metrics about your objects, your tables, indexes, functions, things like that. So those are mostly quantitative metrics, cumulative counters that are counting how many times events have occurred or how many seconds have elapsed while doing operations on your table. There are also other kinds of metrics that don't map so well to quantitative Prometheus-style metrics, and I'll show you, if I have time, I'll try and show a bit of why those are difficult to map to time series databases like Prometheus. The thing to understand is Postgres exposes these things through SQL. The way you access these metrics is by logging into the database and running SQL queries. So for example, this is pg.database, I realize you probably can't read it very well, but if you can, hopefully if you can see the general shape of it, I'll describe it, there's one line for each database inside the Postgres cluster. So there's a database called Postgres, there's a database called template one and database called template zero and another database with my username Stark. And each row of this table, it's actually a view, there's no storage attached to it, it's a dynamically generated table, a virtual table, say. Each row represents the metrics for that table. So it shows you the number of backends that are connected to that database, I think I said table before, I meant database, it shows you the number of backends connected to that database, that's a gauge in Prometheus parlance, you can go up and down, the number of transactions that have committed on that database, I think that's since the database start up actually, the number of transactions that have rolled back, the number of blocks that have been read on that database, the number of blocks that were hit in the shared memory cache, these are all, and actually this is truncated, there are many, well, there's a good number of more columns as well, but the key point is there's a row for each database and there's a bunch of metrics about that database. And then you can go into more detail, there's similar tables for, there's similar views to show you metrics about your tables, the number of sequential scans that have occurred on a table named PG bench branches in this case, and PG bench accounts, PG bench colors, so the number of sequential scans on that, each row is a table and this is showing the number of these various operations like sequential scans, tuples read, index scanned, for each of those tables. So in like Prometheus or other time series database world, you would probably want to make the relation name, the table name here, a label on your metric, you probably also want the schema name as a label, you might want the ID number, which is that first column as a label, you actually have a decision to make there, do you want the time series to be tied to the ID number or the name, so if you rename a table, is that a new time series or not? So the tool in Postgres world, like that mapping, those decisions are made somewhere, where the mapping has to be made is in an agent that connects to the database, runs SQL and exposes the data in Prometheus exposition format or open metrics, so the agent, the standard agent for Prometheus is called Postgres exporter and it has built in queries for these things, it has built in ideas about what the right labels are for the metrics and how to map these data types, these are actually all 8 byte integers which need to be mapped to floating point numbers for Prometheus, so like there's all kinds of hidden assumptions that Postgres exporter has to be making to map this data to the monitoring data, the data for Prometheus or M3 or whatever time series database you're using. I don't have time to go into like how you would use these particular metrics to understand your, like how to tune your database, but one point is, the way Postgres, like these metrics were originally designed, you were imagined to have a DBA logging into your database querying specific rows with a word clause, maybe doing calculations where you divide one by another to find out the number of tuples each sequential scan is returning and things like that and obviously in a modern observability world what you're actually going to do, what Postgres exporter actually does is just do select star with no where clause, takes all this data, dumps it into a time series database and then you do those same calculations but you do them in from QL or whatever the equivalent is in your observability tool and that gives you the same kind of flexibility but now you can look at how those metrics relate to metrics that came from other sources so you get a more global view, you can aggregate across multiples databases, you can aggregate across your Postgres databases and other systems. So a lot of the flexibility here that these are designed to give you is no longer relevant when you're just doing a simple select star and dumping it all into Prometheus. Sorry, there's more complicated metrics which don't really map well to tools like Prometheus or M3, Datadog, whatever. So this is PG stat activity, there's one row for each session, there's actually two, there's the same, just to explain what you're looking at the first results that there are the first half dozen or dozen columns and then the second set there is, I've elided after PID, I've elided those columns and showed you the next bunch of columns just because I wanted to actually make a point about one of those columns that would be way past the edge of the screen. So in PG stat activity you have one row per session on the database and obviously that already is difficult to put into Prometheus because you would be having time series come and go every time an application connects and disconnects. Probably what people actually, I think what Postgres exporter puts in the data is aggregates, it just puts an account of how many rows are present and then maybe account of how many, the minimum maximum of some of these columns. But there is data in here like the weight event type and weight event, those are text strings, inside Postgres those are actually ID numbers but they get presented to the user in a nice readable format which then if you want to make metrics of you probably then turn them back into numbers or you put them in labels, they're difficult to really make use of in a time series database. Some of them are quite important to have some idea, so there's information there that will show you in PG stat activity that will show you if a session is in a transaction, an idle and you really do want to know if there's a session that's idle in transaction for a long period of time. So what most people do there is have an aggregate, they have one gauge for the maximum, the longest time that any session has been idle in transaction. So just to be clear what we're talking about here is Postgres exporter which is connecting to Postgres QL and querying PG stat user tables, PG stat user indexes, PG stat activity, all the various views that start with PG stat, it can also, Postgres exporter is very flexible, you can configure customized queries to query other views that like some of the PG stat views you might want more detail than the default queries. So it doesn't actually include all those table statistics by default if you have an application where your schema is fairly static and you have a reasonable number of tables to do that with, you can quite reasonably get all of those columns, put them in Prometheus and be able to do all kinds of nice graphs and visualizations, but that's not standard. And if you're, on the other hand, you're an ISP with hundreds of customers and your customers create and drop tables without your control, then you can't really be trying to gather statistics like that because you're taking on an unbounded cardinality and time series coming and going without being able to control it. So the level of detail that you grab is very dependent on how you're using Postgres, whether you're a site with one key database that you want to optimize or many, many databases that you just want to monitor at a high level or an application that you're controlling versus applications that you're hosting for other people. It also means that many sites add queries in Postgres exported query, other data sources like what I've put in this diagram here is PGSTAT statements, which is an extension in Postgres, which gathers statistics for your queries. So the key in there is a query ID, which is like a hash of the query with the constants removed, and you can get long-lived statistics about which queries are taking a lot of time or doing a lot of ale, but that's, again, like a custom query that you would be adding. So I talked a bit about the map, like the difficulty mapping some of these metrics for me to use. There's other problems with, am I doing it for time? Am I doing it for time? There's, I don't, okay, there are, so I do want to talk a bit about the kinds of problems that we have. Some of the metrics don't map very well to Prometheus metrics. The fact that the metrics can be customized, and in fact kind of have to be customized because Postgres is used in different ways at different sites, means that there's no, there is a standard dashboard in Grafana for Postgres, but it's a very high-level dashboard. I think I do have a screenshot there, yeah. There is a dashboard for Postgres, but it, this is not showing individual tables and individual functions and so on, because on many sites that data wouldn't even be present. You have to add custom queries for it. It also means you have to deploy the agent. You have to run this side, this Go program alongside your database everywhere you deploy your database, or you could, depending on how you deploy it, you can deploy a single one for all your databases, or one for all the databases running on one host, so that mapping of which agent to, which agents metrics correspond to which actual database is entirely dependent on how you manage your deploys. The other problem that I've, the, I can't go into all of the problems, but the, the op, the Rezors contention, I gave names to each of these classes, but, so the Rezors contention problems are that Postgres, because it's exposing this information through SQL, means that you have to have a working SQL session in order to get the metrics. So when your system is not functioning correctly, you're very likely to also lose all your data, which you need to debug the problem. So if you're running low-end connections, or you're running into transaction wraparound, or the system is just out of memory, or getting disk errors, quite often you also lose all your metrics that would allow you to figure out which application component is using all the connections, or which table is it that needs to be vacuumed to recover from the transaction wraparound issue. I actually tried to, I've run into a problem where a table was locked by the application, and the custom queries needed that same lock. So the queries all disappeared, the metrics all disappeared, because the Postgres exporter was getting blocked on that lock. When I tried to recreate it for a demo, I actually found, oh, this is not a lock, this is, I actually caused the regression test on Postgres to fail, because one of the regression tests tries to drop a database. And the Postgres exporter keeps a connection to each database, because the metrics, like I said, you need a session, you need a connection to the database, so you need, in Postgres, each session is tied to a specific database. So if you have a dozen databases, it uses a dozen connections, and it keeps those connections, it's optional, it's to work around the problem that it might not be able to connect if you have a problem, but as a result, it has persistent connections to those databases, and the regression test failed when they tried to drop that database. And that could actually happen in production. If you try to do a deploy and roll out a new version of some data that drops a database and recreates it from scratch, if you have Postgres exporter running and it has a connection, you could run into the same kind of issue. So I'm hoping, I'm already working on something to replace Postgres exporter with a background worker inside Postgres, so you would be connecting directly to Postgres, you wouldn't have to deploy a separate program alongside it, and my goal is that that program would have standardized metrics. That program would have standardized metrics that every dashboard or visualization or alerting, so we could have mix-ins that have alert rules and visualizations, and it would be able to rely on standardized metrics that will always be present, and they would be exported directly from shared memory without going through the whole SQL infrastructure. So it would avoid depending on locks and transactions and all of the things that could interfere with or be interfered with by the application. It's still early days, I have a little proof of concept, but it's not going to be in the next version of Postgres, it's definitely experimental. The main difficulties are going to be sort of definitional problems of, for example, the table names, like I mentioned before, should a time series change when a table gets renamed? But in fact, I have a bigger problem because the table names are in the catalog, the schema catalog, they're not in shared memory, and they're not, we don't really want them in shared memory, that brings in the whole risk of character encoding changes and collations. So there's, it probably will only replace the core database metrics, and then you would still probably deploy a tool like Postgres Explorer only for your custom queries, only for more application level metrics, not monitoring core Postgres metrics. So my hope is that when you deploy Postgres, you can add it to your targets in Prometheus and not have to do any further operational work to get dashboards and alerts. Two more minutes. It feels like time is elastic here. So I skipped over, I mean, so this is the proof of concept. The telemetry server in the first PS listing there is a single process. It's a Postgres background worker that can be, you can connect to it and get metrics with just ID numbers for the tables. And the second example is Postgres Exporter, and you can see there's a session, there's a database session, and with Postgres Exporter, there's a database session for each database, and they're all idle. So even just reducing the number of sessions and reducing the number of processes involved is already quite a visible improvement. I think I have more information if people have questions or want to see something specific, but I tried to condense a much longer presentation to 25 minutes, so I've skipped over plenty of other information. If there's questions, that would be probably better than me just jumping around finding a slide. Okay, so any questions, thanks a lot for the great talk, it was pretty interesting. So any questions, anyone? Hello, my name is Brian, you spoke about metrics, is there any traces or any talk of traces in the future? I have ideas, I have plans, but they're all in my head, there's no code. Postgres does have explain plans, and explain plans are basically traces, but there's no way to, what we have today is you run something on the terminal and you see the plan for your query, and there's an extension that will dump the explain plans in the logs. So it wouldn't be much, it's a bit pie in the sky, but I don't see any reason we shouldn't be exporting that same information to a tracing server, and that basically just involves adding support for receiving the trace IDs, the spans, and creating spans for either plan nodes or certain kinds of plan nodes, there's a lot of, it's not well thought out plans. In my pie in the sky dream there is I want to be able to answer the question, which front end web API endpoint is causing sequential scans on this table over here, skipping the whole stack trace in the middle without having to dig all the way up. So we have a architecture in which we have Postgres databases which are short lived running in Docker containers, so the entire cluster basically will live and die for matters of possibly minutes or less. And we would like to know what the hell is going on with them, have you got any bright ideas? I admit I don't think I've seen anybody trying to do that with Prometheus. I mean it's not a best practice in Prometheus to have time series that keep changing, but you're kind of inevitably going to get a new bunch of time series with each database. I guess I need a better idea where you're looking. I don't think I have anything off the top of my head that you wouldn't have already thought about. Hi, where can we get your proof concept from and fill it with it and test it? I'm sorry, I didn't hear the question. Where can you get your proof of concept from to test it and fill it with it? I posted a patch to the mailing list. Postgres follows a fairly old school patch review process where patches are mailed to the hacker's mailing list. So it's easy to lose sight of patches if they get posted and it was months ago. I can send it to you if you want. You can probably find it on the mailing list if you search. It's pretty early days though. It's not really ready to use even for experimental production uses. With that integrated matrix, how do you expose the matrix to have an HTTP endpoint that exposed directly from Postgres? The current situation is it's a background worker and that background worker has a configuration option to specify a second port to listen on and it runs a very small embedded web server so it responds to normal HTTPS requests. I would want the normal Postgres port to respond so that your label, your target is just the database port. I expect, well, I actually have already heard a lot of pushback on that idea. A lot of Postgres installs are sort of old school where you probably have it firewalled and you don't want to have two different, you don't want to have a new service running on a port, the same port as the actual database, you want to have a port that you can firewall separately for your admin stack. It makes Prometheus very difficult to manage when you have a different port to get metrics about. So you have database running on port A and then you have metrics on port B and you have to have your dashboards and the targets and so on all configured to understand that the target with port B is actually the database on port A and you can add rewrite rules but then you have to manage those rewrite rules. But I don't really expect people to accept the idea of responding on the database port. There's also a general security principle involved of, it's almost always a terrible idea for security reasons to respond to two different protocols on the same port because a lot of security vulnerabilities have come about from arranging, like finding bugs where one side of a connection thinks you're talking protocol A and the other side thinks you're talking protocol B. So it's probably, there's big trade-offs to doing that. First of all, thanks a lot for the amazing talk, very insightful. Thanks for offering to modernize POSGRACE monitoring. You had a very good point there about standardizing on the metrics. I've been involved in the semantic conventions around open telemetry and other projects but in general, I'm curious to hear if you personally or Ivan or anyone else, what kind of effort is being done to standardize on database monitoring metrics, not specifically POSGRACE but databases in general, if you can share? I would be interested in that. I haven't heard anything on that front. That would be exciting. That would be a lot of work. I think there's a lot of, a lot of the interesting metrics are very, that would be difficult. I don't know, I haven't seen anything like that. Okay, so thanks a lot everyone.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 10.28, "text": " The name of my talk is Postgres Observability.", "tokens": [50364, 440, 1315, 295, 452, 751, 307, 10223, 45189, 42547, 2310, 13, 50878], "temperature": 0.0, "avg_logprob": -0.20344524913363987, "compression_ratio": 1.5027027027027027, "no_speech_prob": 0.25312110781669617}, {"id": 1, "seek": 0, "start": 10.28, "end": 17.6, "text": " My intention is to show you what's great about Postgres and how it integrates well with", "tokens": [50878, 1222, 7789, 307, 281, 855, 291, 437, 311, 869, 466, 10223, 45189, 293, 577, 309, 3572, 1024, 731, 365, 51244], "temperature": 0.0, "avg_logprob": -0.20344524913363987, "compression_ratio": 1.5027027027027027, "no_speech_prob": 0.25312110781669617}, {"id": 2, "seek": 0, "start": 17.6, "end": 21.52, "text": " observability, but also where some of the problems are.", "tokens": [51244, 9951, 2310, 11, 457, 611, 689, 512, 295, 264, 2740, 366, 13, 51440], "temperature": 0.0, "avg_logprob": -0.20344524913363987, "compression_ratio": 1.5027027027027027, "no_speech_prob": 0.25312110781669617}, {"id": 3, "seek": 0, "start": 21.52, "end": 27.560000000000002, "text": " Obviously, in 25 minutes, it's not going to be an exhaustive presentation of all of the", "tokens": [51440, 7580, 11, 294, 3552, 2077, 11, 309, 311, 406, 516, 281, 312, 364, 14687, 488, 5860, 295, 439, 295, 264, 51742], "temperature": 0.0, "avg_logprob": -0.20344524913363987, "compression_ratio": 1.5027027027027027, "no_speech_prob": 0.25312110781669617}, {"id": 4, "seek": 2756, "start": 27.56, "end": 31.939999999999998, "text": " metrics in Postgres, but maybe I can give a bit of an introduction.", "tokens": [50364, 16367, 294, 10223, 45189, 11, 457, 1310, 286, 393, 976, 257, 857, 295, 364, 9339, 13, 50583], "temperature": 0.0, "avg_logprob": -0.2415176514656313, "compression_ratio": 1.5964125560538116, "no_speech_prob": 0.05316700041294098}, {"id": 5, "seek": 2756, "start": 31.939999999999998, "end": 34.0, "text": " So first of all, my name is Gregory Stark.", "tokens": [50583, 407, 700, 295, 439, 11, 452, 1315, 307, 37915, 28967, 13, 50686], "temperature": 0.0, "avg_logprob": -0.2415176514656313, "compression_ratio": 1.5964125560538116, "no_speech_prob": 0.05316700041294098}, {"id": 6, "seek": 2756, "start": 34.0, "end": 41.12, "text": " I work for Ivan, which is a, so I work in the open source programs office, contributing", "tokens": [50686, 286, 589, 337, 28893, 11, 597, 307, 257, 11, 370, 286, 589, 294, 264, 1269, 4009, 4268, 3398, 11, 19270, 51042], "temperature": 0.0, "avg_logprob": -0.2415176514656313, "compression_ratio": 1.5964125560538116, "no_speech_prob": 0.05316700041294098}, {"id": 7, "seek": 2756, "start": 41.12, "end": 42.44, "text": " to Postgres.", "tokens": [51042, 281, 10223, 45189, 13, 51108], "temperature": 0.0, "avg_logprob": -0.2415176514656313, "compression_ratio": 1.5964125560538116, "no_speech_prob": 0.05316700041294098}, {"id": 8, "seek": 2756, "start": 42.44, "end": 49.04, "text": " Ivan is a data infrastructure hosting company.", "tokens": [51108, 28893, 307, 257, 1412, 6896, 16058, 2237, 13, 51438], "temperature": 0.0, "avg_logprob": -0.2415176514656313, "compression_ratio": 1.5964125560538116, "no_speech_prob": 0.05316700041294098}, {"id": 9, "seek": 2756, "start": 49.04, "end": 56.84, "text": " We host Postgres, but we also host a range of other data services, including some observabilities", "tokens": [51438, 492, 3975, 10223, 45189, 11, 457, 321, 611, 3975, 257, 3613, 295, 661, 1412, 3328, 11, 3009, 512, 9951, 6167, 51828], "temperature": 0.0, "avg_logprob": -0.2415176514656313, "compression_ratio": 1.5964125560538116, "no_speech_prob": 0.05316700041294098}, {"id": 10, "seek": 5684, "start": 56.84, "end": 67.84, "text": " that it's all open source software, and we contribute back to the projects that we sell.", "tokens": [50364, 300, 309, 311, 439, 1269, 4009, 4722, 11, 293, 321, 10586, 646, 281, 264, 4455, 300, 321, 3607, 13, 50914], "temperature": 0.0, "avg_logprob": -0.1653777469288219, "compression_ratio": 1.4754098360655739, "no_speech_prob": 0.005976767744868994}, {"id": 11, "seek": 5684, "start": 67.84, "end": 77.64, "text": " So I'm sure in this room, most people have seen the cliched three pillars of observability.", "tokens": [50914, 407, 286, 478, 988, 294, 341, 1808, 11, 881, 561, 362, 1612, 264, 39190, 292, 1045, 26729, 295, 9951, 2310, 13, 51404], "temperature": 0.0, "avg_logprob": -0.1653777469288219, "compression_ratio": 1.4754098360655739, "no_speech_prob": 0.005976767744868994}, {"id": 12, "seek": 5684, "start": 77.64, "end": 83.68, "text": " In a modern software, what people expect are their logs to be structured so they can send", "tokens": [51404, 682, 257, 4363, 4722, 11, 437, 561, 2066, 366, 641, 20820, 281, 312, 18519, 370, 436, 393, 2845, 51706], "temperature": 0.0, "avg_logprob": -0.1653777469288219, "compression_ratio": 1.4754098360655739, "no_speech_prob": 0.005976767744868994}, {"id": 13, "seek": 8368, "start": 83.68, "end": 92.4, "text": " it to some sort of index, something like OpenSearch, some sort of indexed aggregate log system.", "tokens": [50364, 309, 281, 512, 1333, 295, 8186, 11, 746, 411, 7238, 10637, 1178, 11, 512, 1333, 295, 8186, 292, 26118, 3565, 1185, 13, 50800], "temperature": 0.0, "avg_logprob": -0.17466961607641104, "compression_ratio": 1.6477732793522266, "no_speech_prob": 0.13999886810779572}, {"id": 14, "seek": 8368, "start": 92.4, "end": 97.2, "text": " They expect time series database to hold all their metrics with labels and well-defined", "tokens": [50800, 814, 2066, 565, 2638, 8149, 281, 1797, 439, 641, 16367, 365, 16949, 293, 731, 12, 37716, 51040], "temperature": 0.0, "avg_logprob": -0.17466961607641104, "compression_ratio": 1.6477732793522266, "no_speech_prob": 0.13999886810779572}, {"id": 15, "seek": 8368, "start": 97.2, "end": 98.2, "text": " semantics.", "tokens": [51040, 4361, 45298, 13, 51090], "temperature": 0.0, "avg_logprob": -0.17466961607641104, "compression_ratio": 1.6477732793522266, "no_speech_prob": 0.13999886810779572}, {"id": 16, "seek": 8368, "start": 98.2, "end": 101.60000000000001, "text": " They expect distributed tracing.", "tokens": [51090, 814, 2066, 12631, 25262, 13, 51260], "temperature": 0.0, "avg_logprob": -0.17466961607641104, "compression_ratio": 1.6477732793522266, "no_speech_prob": 0.13999886810779572}, {"id": 17, "seek": 8368, "start": 101.60000000000001, "end": 107.08000000000001, "text": " Postgres is not so much of a modern, it's still actively developed and has modern relational", "tokens": [51260, 10223, 45189, 307, 406, 370, 709, 295, 257, 4363, 11, 309, 311, 920, 13022, 4743, 293, 575, 4363, 38444, 51534], "temperature": 0.0, "avg_logprob": -0.17466961607641104, "compression_ratio": 1.6477732793522266, "no_speech_prob": 0.13999886810779572}, {"id": 18, "seek": 8368, "start": 107.08000000000001, "end": 113.64000000000001, "text": " database features, but for things like this, Postgres is going on almost 30 years now.", "tokens": [51534, 8149, 4122, 11, 457, 337, 721, 411, 341, 11, 10223, 45189, 307, 516, 322, 1920, 2217, 924, 586, 13, 51862], "temperature": 0.0, "avg_logprob": -0.17466961607641104, "compression_ratio": 1.6477732793522266, "no_speech_prob": 0.13999886810779572}, {"id": 19, "seek": 11364, "start": 114.6, "end": 124.28, "text": " Our logs, our metrics, our tracing tools predate most of these modern distributed system concepts.", "tokens": [50412, 2621, 20820, 11, 527, 16367, 11, 527, 25262, 3873, 3852, 473, 881, 295, 613, 4363, 12631, 1185, 10392, 13, 50896], "temperature": 0.0, "avg_logprob": -0.16919471740722655, "compression_ratio": 1.5751295336787565, "no_speech_prob": 0.053246576339006424}, {"id": 20, "seek": 11364, "start": 124.28, "end": 129.88, "text": " So what these look like in Postgres is we have very good logs, they're meant for a human", "tokens": [50896, 407, 437, 613, 574, 411, 294, 10223, 45189, 307, 321, 362, 588, 665, 20820, 11, 436, 434, 4140, 337, 257, 1952, 51176], "temperature": 0.0, "avg_logprob": -0.16919471740722655, "compression_ratio": 1.5751295336787565, "no_speech_prob": 0.053246576339006424}, {"id": 21, "seek": 11364, "start": 129.88, "end": 132.28, "text": " to be reading in a text file.", "tokens": [51176, 281, 312, 3760, 294, 257, 2487, 3991, 13, 51296], "temperature": 0.0, "avg_logprob": -0.16919471740722655, "compression_ratio": 1.5751295336787565, "no_speech_prob": 0.053246576339006424}, {"id": 22, "seek": 11364, "start": 132.28, "end": 137.92000000000002, "text": " So we actually support JSON logs, but the actual error message, the actual log message", "tokens": [51296, 407, 321, 767, 1406, 31828, 20820, 11, 457, 264, 3539, 6713, 3636, 11, 264, 3539, 3565, 3636, 51578], "temperature": 0.0, "avg_logprob": -0.16919471740722655, "compression_ratio": 1.5751295336787565, "no_speech_prob": 0.053246576339006424}, {"id": 23, "seek": 13792, "start": 137.92, "end": 142.6, "text": " will just be a string inside that JSON struct.", "tokens": [50364, 486, 445, 312, 257, 6798, 1854, 300, 31828, 6594, 13, 50598], "temperature": 0.0, "avg_logprob": -0.22225928950954127, "compression_ratio": 1.6030927835051547, "no_speech_prob": 0.1706266850233078}, {"id": 24, "seek": 13792, "start": 142.6, "end": 150.07999999999998, "text": " All the JSON structured information, labels and so on are the metadata about the log", "tokens": [50598, 1057, 264, 31828, 18519, 1589, 11, 16949, 293, 370, 322, 366, 264, 26603, 466, 264, 3565, 50972], "temperature": 0.0, "avg_logprob": -0.22225928950954127, "compression_ratio": 1.6030927835051547, "no_speech_prob": 0.1706266850233078}, {"id": 25, "seek": 13792, "start": 150.07999999999998, "end": 156.51999999999998, "text": " line, things like process ID, session ID, the actual like table name being mentioned", "tokens": [50972, 1622, 11, 721, 411, 1399, 7348, 11, 5481, 7348, 11, 264, 3539, 411, 3199, 1315, 885, 2835, 51294], "temperature": 0.0, "avg_logprob": -0.22225928950954127, "compression_ratio": 1.6030927835051547, "no_speech_prob": 0.1706266850233078}, {"id": 26, "seek": 13792, "start": 156.51999999999998, "end": 163.95999999999998, "text": " in the error, the actual, well actually current user is one of those columns, but if the error", "tokens": [51294, 294, 264, 6713, 11, 264, 3539, 11, 731, 767, 2190, 4195, 307, 472, 295, 729, 13766, 11, 457, 498, 264, 6713, 51666], "temperature": 0.0, "avg_logprob": -0.22225928950954127, "compression_ratio": 1.6030927835051547, "no_speech_prob": 0.1706266850233078}, {"id": 27, "seek": 16396, "start": 164.0, "end": 169.32000000000002, "text": " message mentions a user name or a table name or an index, it's just going to be part of", "tokens": [50366, 3636, 23844, 257, 4195, 1315, 420, 257, 3199, 1315, 420, 364, 8186, 11, 309, 311, 445, 516, 281, 312, 644, 295, 50632], "temperature": 0.0, "avg_logprob": -0.18585101040926846, "compression_ratio": 1.652, "no_speech_prob": 0.006278034299612045}, {"id": 28, "seek": 16396, "start": 169.32000000000002, "end": 172.24, "text": " the string.", "tokens": [50632, 264, 6798, 13, 50778], "temperature": 0.0, "avg_logprob": -0.18585101040926846, "compression_ratio": 1.652, "no_speech_prob": 0.006278034299612045}, {"id": 29, "seek": 16396, "start": 172.24, "end": 176.04000000000002, "text": " There's tons of metrics in Postgres, and I'll go into more detail, I'm mainly going", "tokens": [50778, 821, 311, 9131, 295, 16367, 294, 10223, 45189, 11, 293, 286, 603, 352, 666, 544, 2607, 11, 286, 478, 8704, 516, 50968], "temperature": 0.0, "avg_logprob": -0.18585101040926846, "compression_ratio": 1.652, "no_speech_prob": 0.006278034299612045}, {"id": 30, "seek": 16396, "start": 176.04000000000002, "end": 183.4, "text": " to be talking about metrics here, but they're in SQL, they're not in like Prometheus exposition", "tokens": [50968, 281, 312, 1417, 466, 16367, 510, 11, 457, 436, 434, 294, 19200, 11, 436, 434, 406, 294, 411, 2114, 649, 42209, 1278, 5830, 51336], "temperature": 0.0, "avg_logprob": -0.18585101040926846, "compression_ratio": 1.652, "no_speech_prob": 0.006278034299612045}, {"id": 31, "seek": 16396, "start": 183.4, "end": 186.68, "text": " format or open metrics or anything like that.", "tokens": [51336, 7877, 420, 1269, 16367, 420, 1340, 411, 300, 13, 51500], "temperature": 0.0, "avg_logprob": -0.18585101040926846, "compression_ratio": 1.652, "no_speech_prob": 0.006278034299612045}, {"id": 32, "seek": 16396, "start": 186.68, "end": 192.88, "text": " And then there's explain plans are basically a tracing tool, but it's meant for a human", "tokens": [51500, 400, 550, 456, 311, 2903, 5482, 366, 1936, 257, 25262, 2290, 11, 457, 309, 311, 4140, 337, 257, 1952, 51810], "temperature": 0.0, "avg_logprob": -0.18585101040926846, "compression_ratio": 1.652, "no_speech_prob": 0.006278034299612045}, {"id": 33, "seek": 19288, "start": 192.92, "end": 198.04, "text": " to be investigating on a single system, it doesn't integrate into any sort of distributed", "tokens": [50366, 281, 312, 22858, 322, 257, 2167, 1185, 11, 309, 1177, 380, 13365, 666, 604, 1333, 295, 12631, 50622], "temperature": 0.0, "avg_logprob": -0.1608426052591075, "compression_ratio": 1.6403508771929824, "no_speech_prob": 0.007897211238741875}, {"id": 34, "seek": 19288, "start": 198.04, "end": 200.6, "text": " tracing tools.", "tokens": [50622, 25262, 3873, 13, 50750], "temperature": 0.0, "avg_logprob": -0.1608426052591075, "compression_ratio": 1.6403508771929824, "no_speech_prob": 0.007897211238741875}, {"id": 35, "seek": 19288, "start": 200.6, "end": 207.04, "text": " So I want to spend a little bit of time showing you what like the metrics in Postgres look", "tokens": [50750, 407, 286, 528, 281, 3496, 257, 707, 857, 295, 565, 4099, 291, 437, 411, 264, 16367, 294, 10223, 45189, 574, 51072], "temperature": 0.0, "avg_logprob": -0.1608426052591075, "compression_ratio": 1.6403508771929824, "no_speech_prob": 0.007897211238741875}, {"id": 36, "seek": 19288, "start": 207.04, "end": 213.24, "text": " like because it gives you, I can't show you all of them, there are hundreds and hundreds,", "tokens": [51072, 411, 570, 309, 2709, 291, 11, 286, 393, 380, 855, 291, 439, 295, 552, 11, 456, 366, 6779, 293, 6779, 11, 51382], "temperature": 0.0, "avg_logprob": -0.1608426052591075, "compression_ratio": 1.6403508771929824, "no_speech_prob": 0.007897211238741875}, {"id": 37, "seek": 19288, "start": 213.24, "end": 219.68, "text": " probably thousands, but I want to give you a feel for like the kinds of in depth metrics", "tokens": [51382, 1391, 5383, 11, 457, 286, 528, 281, 976, 291, 257, 841, 337, 411, 264, 3685, 295, 294, 7161, 16367, 51704], "temperature": 0.0, "avg_logprob": -0.1608426052591075, "compression_ratio": 1.6403508771929824, "no_speech_prob": 0.007897211238741875}, {"id": 38, "seek": 21968, "start": 219.68, "end": 224.52, "text": " that Postgres does provide.", "tokens": [50364, 300, 10223, 45189, 775, 2893, 13, 50606], "temperature": 0.0, "avg_logprob": -0.17768794298171997, "compression_ratio": 1.5027624309392265, "no_speech_prob": 0.0023867774289101362}, {"id": 39, "seek": 21968, "start": 224.52, "end": 231.8, "text": " It does give you, there's a whole component inside Postgres whose job is to track metrics", "tokens": [50606, 467, 775, 976, 291, 11, 456, 311, 257, 1379, 6542, 1854, 10223, 45189, 6104, 1691, 307, 281, 2837, 16367, 50970], "temperature": 0.0, "avg_logprob": -0.17768794298171997, "compression_ratio": 1.5027624309392265, "no_speech_prob": 0.0023867774289101362}, {"id": 40, "seek": 21968, "start": 231.8, "end": 239.24, "text": " about your objects, your tables, indexes, functions, things like that.", "tokens": [50970, 466, 428, 6565, 11, 428, 8020, 11, 8186, 279, 11, 6828, 11, 721, 411, 300, 13, 51342], "temperature": 0.0, "avg_logprob": -0.17768794298171997, "compression_ratio": 1.5027624309392265, "no_speech_prob": 0.0023867774289101362}, {"id": 41, "seek": 21968, "start": 239.24, "end": 246.96, "text": " So those are mostly quantitative metrics, cumulative counters that are counting how", "tokens": [51342, 407, 729, 366, 5240, 27778, 16367, 11, 38379, 39338, 300, 366, 13251, 577, 51728], "temperature": 0.0, "avg_logprob": -0.17768794298171997, "compression_ratio": 1.5027624309392265, "no_speech_prob": 0.0023867774289101362}, {"id": 42, "seek": 24696, "start": 246.96, "end": 251.92000000000002, "text": " many times events have occurred or how many seconds have elapsed while doing operations", "tokens": [50364, 867, 1413, 3931, 362, 11068, 420, 577, 867, 3949, 362, 806, 2382, 292, 1339, 884, 7705, 50612], "temperature": 0.0, "avg_logprob": -0.15309054056803387, "compression_ratio": 1.5077720207253886, "no_speech_prob": 0.007503920700401068}, {"id": 43, "seek": 24696, "start": 251.92000000000002, "end": 255.28, "text": " on your table.", "tokens": [50612, 322, 428, 3199, 13, 50780], "temperature": 0.0, "avg_logprob": -0.15309054056803387, "compression_ratio": 1.5077720207253886, "no_speech_prob": 0.007503920700401068}, {"id": 44, "seek": 24696, "start": 255.28, "end": 265.28000000000003, "text": " There are also other kinds of metrics that don't map so well to quantitative Prometheus-style", "tokens": [50780, 821, 366, 611, 661, 3685, 295, 16367, 300, 500, 380, 4471, 370, 731, 281, 27778, 2114, 649, 42209, 12, 15014, 51280], "temperature": 0.0, "avg_logprob": -0.15309054056803387, "compression_ratio": 1.5077720207253886, "no_speech_prob": 0.007503920700401068}, {"id": 45, "seek": 24696, "start": 265.28000000000003, "end": 271.36, "text": " metrics, and I'll show you, if I have time, I'll try and show a bit of why those are difficult", "tokens": [51280, 16367, 11, 293, 286, 603, 855, 291, 11, 498, 286, 362, 565, 11, 286, 603, 853, 293, 855, 257, 857, 295, 983, 729, 366, 2252, 51584], "temperature": 0.0, "avg_logprob": -0.15309054056803387, "compression_ratio": 1.5077720207253886, "no_speech_prob": 0.007503920700401068}, {"id": 46, "seek": 27136, "start": 271.36, "end": 281.64, "text": " to map to time series databases like Prometheus.", "tokens": [50364, 281, 4471, 281, 565, 2638, 22380, 411, 2114, 649, 42209, 13, 50878], "temperature": 0.0, "avg_logprob": -0.16837812423706056, "compression_ratio": 1.4647887323943662, "no_speech_prob": 0.2616540193557739}, {"id": 47, "seek": 27136, "start": 281.64, "end": 288.56, "text": " The thing to understand is Postgres exposes these things through SQL.", "tokens": [50878, 440, 551, 281, 1223, 307, 10223, 45189, 1278, 4201, 613, 721, 807, 19200, 13, 51224], "temperature": 0.0, "avg_logprob": -0.16837812423706056, "compression_ratio": 1.4647887323943662, "no_speech_prob": 0.2616540193557739}, {"id": 48, "seek": 27136, "start": 288.56, "end": 294.92, "text": " The way you access these metrics is by logging into the database and running SQL queries.", "tokens": [51224, 440, 636, 291, 2105, 613, 16367, 307, 538, 27991, 666, 264, 8149, 293, 2614, 19200, 24109, 13, 51542], "temperature": 0.0, "avg_logprob": -0.16837812423706056, "compression_ratio": 1.4647887323943662, "no_speech_prob": 0.2616540193557739}, {"id": 49, "seek": 29492, "start": 294.92, "end": 306.72, "text": " So for example, this is pg.database, I realize you probably can't read it very well, but", "tokens": [50364, 407, 337, 1365, 11, 341, 307, 280, 70, 13, 20367, 455, 651, 11, 286, 4325, 291, 1391, 393, 380, 1401, 309, 588, 731, 11, 457, 50954], "temperature": 0.0, "avg_logprob": -0.2052887761315634, "compression_ratio": 1.708994708994709, "no_speech_prob": 0.3758752942085266}, {"id": 50, "seek": 29492, "start": 306.72, "end": 312.68, "text": " if you can, hopefully if you can see the general shape of it, I'll describe it, there's one", "tokens": [50954, 498, 291, 393, 11, 4696, 498, 291, 393, 536, 264, 2674, 3909, 295, 309, 11, 286, 603, 6786, 309, 11, 456, 311, 472, 51252], "temperature": 0.0, "avg_logprob": -0.2052887761315634, "compression_ratio": 1.708994708994709, "no_speech_prob": 0.3758752942085266}, {"id": 51, "seek": 29492, "start": 312.68, "end": 316.68, "text": " line for each database inside the Postgres cluster.", "tokens": [51252, 1622, 337, 1184, 8149, 1854, 264, 10223, 45189, 13630, 13, 51452], "temperature": 0.0, "avg_logprob": -0.2052887761315634, "compression_ratio": 1.708994708994709, "no_speech_prob": 0.3758752942085266}, {"id": 52, "seek": 29492, "start": 316.68, "end": 321.16, "text": " So there's a database called Postgres, there's a database called template one and database", "tokens": [51452, 407, 456, 311, 257, 8149, 1219, 10223, 45189, 11, 456, 311, 257, 8149, 1219, 12379, 472, 293, 8149, 51676], "temperature": 0.0, "avg_logprob": -0.2052887761315634, "compression_ratio": 1.708994708994709, "no_speech_prob": 0.3758752942085266}, {"id": 53, "seek": 32116, "start": 321.16, "end": 325.20000000000005, "text": " called template zero and another database with my username Stark.", "tokens": [50364, 1219, 12379, 4018, 293, 1071, 8149, 365, 452, 30351, 28967, 13, 50566], "temperature": 0.0, "avg_logprob": -0.18549704832189223, "compression_ratio": 1.6132075471698113, "no_speech_prob": 0.43215036392211914}, {"id": 54, "seek": 32116, "start": 325.20000000000005, "end": 331.6, "text": " And each row of this table, it's actually a view, there's no storage attached to it,", "tokens": [50566, 400, 1184, 5386, 295, 341, 3199, 11, 309, 311, 767, 257, 1910, 11, 456, 311, 572, 6725, 8570, 281, 309, 11, 50886], "temperature": 0.0, "avg_logprob": -0.18549704832189223, "compression_ratio": 1.6132075471698113, "no_speech_prob": 0.43215036392211914}, {"id": 55, "seek": 32116, "start": 331.6, "end": 337.36, "text": " it's a dynamically generated table, a virtual table, say.", "tokens": [50886, 309, 311, 257, 43492, 10833, 3199, 11, 257, 6374, 3199, 11, 584, 13, 51174], "temperature": 0.0, "avg_logprob": -0.18549704832189223, "compression_ratio": 1.6132075471698113, "no_speech_prob": 0.43215036392211914}, {"id": 56, "seek": 32116, "start": 337.36, "end": 341.44000000000005, "text": " Each row represents the metrics for that table.", "tokens": [51174, 6947, 5386, 8855, 264, 16367, 337, 300, 3199, 13, 51378], "temperature": 0.0, "avg_logprob": -0.18549704832189223, "compression_ratio": 1.6132075471698113, "no_speech_prob": 0.43215036392211914}, {"id": 57, "seek": 32116, "start": 341.44000000000005, "end": 347.32000000000005, "text": " So it shows you the number of backends that are connected to that database, I think I", "tokens": [51378, 407, 309, 3110, 291, 264, 1230, 295, 646, 2581, 300, 366, 4582, 281, 300, 8149, 11, 286, 519, 286, 51672], "temperature": 0.0, "avg_logprob": -0.18549704832189223, "compression_ratio": 1.6132075471698113, "no_speech_prob": 0.43215036392211914}, {"id": 58, "seek": 34732, "start": 347.4, "end": 351.32, "text": " said table before, I meant database, it shows you the number of backends connected to that", "tokens": [50368, 848, 3199, 949, 11, 286, 4140, 8149, 11, 309, 3110, 291, 264, 1230, 295, 646, 2581, 4582, 281, 300, 50564], "temperature": 0.0, "avg_logprob": -0.23008394789421696, "compression_ratio": 1.952127659574468, "no_speech_prob": 0.2294182926416397}, {"id": 59, "seek": 34732, "start": 351.32, "end": 359.6, "text": " database, that's a gauge in Prometheus parlance, you can go up and down, the number of transactions", "tokens": [50564, 8149, 11, 300, 311, 257, 17924, 294, 2114, 649, 42209, 13734, 719, 11, 291, 393, 352, 493, 293, 760, 11, 264, 1230, 295, 16856, 50978], "temperature": 0.0, "avg_logprob": -0.23008394789421696, "compression_ratio": 1.952127659574468, "no_speech_prob": 0.2294182926416397}, {"id": 60, "seek": 34732, "start": 359.6, "end": 371.28, "text": " that have committed on that database, I think that's since the database start up actually,", "tokens": [50978, 300, 362, 7784, 322, 300, 8149, 11, 286, 519, 300, 311, 1670, 264, 8149, 722, 493, 767, 11, 51562], "temperature": 0.0, "avg_logprob": -0.23008394789421696, "compression_ratio": 1.952127659574468, "no_speech_prob": 0.2294182926416397}, {"id": 61, "seek": 34732, "start": 371.28, "end": 374.12, "text": " the number of transactions that have rolled back, the number of blocks that have been", "tokens": [51562, 264, 1230, 295, 16856, 300, 362, 14306, 646, 11, 264, 1230, 295, 8474, 300, 362, 668, 51704], "temperature": 0.0, "avg_logprob": -0.23008394789421696, "compression_ratio": 1.952127659574468, "no_speech_prob": 0.2294182926416397}, {"id": 62, "seek": 37412, "start": 374.2, "end": 379.96, "text": " read on that database, the number of blocks that were hit in the shared memory cache,", "tokens": [50368, 1401, 322, 300, 8149, 11, 264, 1230, 295, 8474, 300, 645, 2045, 294, 264, 5507, 4675, 19459, 11, 50656], "temperature": 0.0, "avg_logprob": -0.14823074340820314, "compression_ratio": 1.9475806451612903, "no_speech_prob": 0.1322437971830368}, {"id": 63, "seek": 37412, "start": 379.96, "end": 384.68, "text": " these are all, and actually this is truncated, there are many, well, there's a good number", "tokens": [50656, 613, 366, 439, 11, 293, 767, 341, 307, 504, 409, 66, 770, 11, 456, 366, 867, 11, 731, 11, 456, 311, 257, 665, 1230, 50892], "temperature": 0.0, "avg_logprob": -0.14823074340820314, "compression_ratio": 1.9475806451612903, "no_speech_prob": 0.1322437971830368}, {"id": 64, "seek": 37412, "start": 384.68, "end": 389.88, "text": " of more columns as well, but the key point is there's a row for each database and there's", "tokens": [50892, 295, 544, 13766, 382, 731, 11, 457, 264, 2141, 935, 307, 456, 311, 257, 5386, 337, 1184, 8149, 293, 456, 311, 51152], "temperature": 0.0, "avg_logprob": -0.14823074340820314, "compression_ratio": 1.9475806451612903, "no_speech_prob": 0.1322437971830368}, {"id": 65, "seek": 37412, "start": 389.88, "end": 392.48, "text": " a bunch of metrics about that database.", "tokens": [51152, 257, 3840, 295, 16367, 466, 300, 8149, 13, 51282], "temperature": 0.0, "avg_logprob": -0.14823074340820314, "compression_ratio": 1.9475806451612903, "no_speech_prob": 0.1322437971830368}, {"id": 66, "seek": 37412, "start": 392.48, "end": 399.04, "text": " And then you can go into more detail, there's similar tables for, there's similar views", "tokens": [51282, 400, 550, 291, 393, 352, 666, 544, 2607, 11, 456, 311, 2531, 8020, 337, 11, 456, 311, 2531, 6809, 51610], "temperature": 0.0, "avg_logprob": -0.14823074340820314, "compression_ratio": 1.9475806451612903, "no_speech_prob": 0.1322437971830368}, {"id": 67, "seek": 37412, "start": 399.04, "end": 403.48, "text": " to show you metrics about your tables, the number of sequential scans that have occurred", "tokens": [51610, 281, 855, 291, 16367, 466, 428, 8020, 11, 264, 1230, 295, 42881, 35116, 300, 362, 11068, 51832], "temperature": 0.0, "avg_logprob": -0.14823074340820314, "compression_ratio": 1.9475806451612903, "no_speech_prob": 0.1322437971830368}, {"id": 68, "seek": 40348, "start": 403.48, "end": 410.68, "text": " on a table named PG bench branches in this case, and PG bench accounts, PG bench colors,", "tokens": [50364, 322, 257, 3199, 4926, 40975, 10638, 14770, 294, 341, 1389, 11, 293, 40975, 10638, 9402, 11, 40975, 10638, 4577, 11, 50724], "temperature": 0.0, "avg_logprob": -0.19254466465541295, "compression_ratio": 1.7031963470319635, "no_speech_prob": 0.005898778326809406}, {"id": 69, "seek": 40348, "start": 410.68, "end": 415.20000000000005, "text": " so the number of sequential scans on that, each row is a table and this is showing the", "tokens": [50724, 370, 264, 1230, 295, 42881, 35116, 322, 300, 11, 1184, 5386, 307, 257, 3199, 293, 341, 307, 4099, 264, 50950], "temperature": 0.0, "avg_logprob": -0.19254466465541295, "compression_ratio": 1.7031963470319635, "no_speech_prob": 0.005898778326809406}, {"id": 70, "seek": 40348, "start": 415.20000000000005, "end": 421.12, "text": " number of these various operations like sequential scans, tuples read, index scanned, for each", "tokens": [50950, 1230, 295, 613, 3683, 7705, 411, 42881, 35116, 11, 2604, 2622, 1401, 11, 8186, 45089, 11, 337, 1184, 51246], "temperature": 0.0, "avg_logprob": -0.19254466465541295, "compression_ratio": 1.7031963470319635, "no_speech_prob": 0.005898778326809406}, {"id": 71, "seek": 40348, "start": 421.12, "end": 425.04, "text": " of those tables.", "tokens": [51246, 295, 729, 8020, 13, 51442], "temperature": 0.0, "avg_logprob": -0.19254466465541295, "compression_ratio": 1.7031963470319635, "no_speech_prob": 0.005898778326809406}, {"id": 72, "seek": 40348, "start": 425.04, "end": 430.72, "text": " So in like Prometheus or other time series database world, you would probably want to", "tokens": [51442, 407, 294, 411, 2114, 649, 42209, 420, 661, 565, 2638, 8149, 1002, 11, 291, 576, 1391, 528, 281, 51726], "temperature": 0.0, "avg_logprob": -0.19254466465541295, "compression_ratio": 1.7031963470319635, "no_speech_prob": 0.005898778326809406}, {"id": 73, "seek": 43072, "start": 430.76000000000005, "end": 435.92, "text": " make the relation name, the table name here, a label on your metric, you probably also", "tokens": [50366, 652, 264, 9721, 1315, 11, 264, 3199, 1315, 510, 11, 257, 7645, 322, 428, 20678, 11, 291, 1391, 611, 50624], "temperature": 0.0, "avg_logprob": -0.14559975850213433, "compression_ratio": 1.83248730964467, "no_speech_prob": 0.031067855656147003}, {"id": 74, "seek": 43072, "start": 435.92, "end": 440.72, "text": " want the schema name as a label, you might want the ID number, which is that first column", "tokens": [50624, 528, 264, 34078, 1315, 382, 257, 7645, 11, 291, 1062, 528, 264, 7348, 1230, 11, 597, 307, 300, 700, 7738, 50864], "temperature": 0.0, "avg_logprob": -0.14559975850213433, "compression_ratio": 1.83248730964467, "no_speech_prob": 0.031067855656147003}, {"id": 75, "seek": 43072, "start": 440.72, "end": 445.48, "text": " as a label, you actually have a decision to make there, do you want the time series to", "tokens": [50864, 382, 257, 7645, 11, 291, 767, 362, 257, 3537, 281, 652, 456, 11, 360, 291, 528, 264, 565, 2638, 281, 51102], "temperature": 0.0, "avg_logprob": -0.14559975850213433, "compression_ratio": 1.83248730964467, "no_speech_prob": 0.031067855656147003}, {"id": 76, "seek": 43072, "start": 445.48, "end": 450.08000000000004, "text": " be tied to the ID number or the name, so if you rename a table, is that a new time series", "tokens": [51102, 312, 9601, 281, 264, 7348, 1230, 420, 264, 1315, 11, 370, 498, 291, 36741, 257, 3199, 11, 307, 300, 257, 777, 565, 2638, 51332], "temperature": 0.0, "avg_logprob": -0.14559975850213433, "compression_ratio": 1.83248730964467, "no_speech_prob": 0.031067855656147003}, {"id": 77, "seek": 43072, "start": 450.08000000000004, "end": 452.40000000000003, "text": " or not?", "tokens": [51332, 420, 406, 30, 51448], "temperature": 0.0, "avg_logprob": -0.14559975850213433, "compression_ratio": 1.83248730964467, "no_speech_prob": 0.031067855656147003}, {"id": 78, "seek": 45240, "start": 452.56, "end": 461.56, "text": " So the tool in Postgres world, like that mapping, those decisions are made somewhere, where", "tokens": [50372, 407, 264, 2290, 294, 10223, 45189, 1002, 11, 411, 300, 18350, 11, 729, 5327, 366, 1027, 4079, 11, 689, 50822], "temperature": 0.0, "avg_logprob": -0.22806443590106387, "compression_ratio": 1.572289156626506, "no_speech_prob": 0.08007870614528656}, {"id": 79, "seek": 45240, "start": 461.56, "end": 469.67999999999995, "text": " the mapping has to be made is in an agent that connects to the database, runs SQL and", "tokens": [50822, 264, 18350, 575, 281, 312, 1027, 307, 294, 364, 9461, 300, 16967, 281, 264, 8149, 11, 6676, 19200, 293, 51228], "temperature": 0.0, "avg_logprob": -0.22806443590106387, "compression_ratio": 1.572289156626506, "no_speech_prob": 0.08007870614528656}, {"id": 80, "seek": 45240, "start": 469.67999999999995, "end": 478.35999999999996, "text": " exposes the data in Prometheus exposition format or open metrics, so the agent, the", "tokens": [51228, 1278, 4201, 264, 1412, 294, 2114, 649, 42209, 1278, 5830, 7877, 420, 1269, 16367, 11, 370, 264, 9461, 11, 264, 51662], "temperature": 0.0, "avg_logprob": -0.22806443590106387, "compression_ratio": 1.572289156626506, "no_speech_prob": 0.08007870614528656}, {"id": 81, "seek": 47836, "start": 478.40000000000003, "end": 485.24, "text": " standard agent for Prometheus is called Postgres exporter and it has built in queries for", "tokens": [50366, 3832, 9461, 337, 2114, 649, 42209, 307, 1219, 10223, 45189, 1278, 6122, 293, 309, 575, 3094, 294, 24109, 337, 50708], "temperature": 0.0, "avg_logprob": -0.14518560682024276, "compression_ratio": 1.646788990825688, "no_speech_prob": 0.0019231413025408983}, {"id": 82, "seek": 47836, "start": 485.24, "end": 490.72, "text": " these things, it has built in ideas about what the right labels are for the metrics", "tokens": [50708, 613, 721, 11, 309, 575, 3094, 294, 3487, 466, 437, 264, 558, 16949, 366, 337, 264, 16367, 50982], "temperature": 0.0, "avg_logprob": -0.14518560682024276, "compression_ratio": 1.646788990825688, "no_speech_prob": 0.0019231413025408983}, {"id": 83, "seek": 47836, "start": 490.72, "end": 498.6, "text": " and how to map these data types, these are actually all 8 byte integers which need to", "tokens": [50982, 293, 577, 281, 4471, 613, 1412, 3467, 11, 613, 366, 767, 439, 1649, 40846, 41674, 597, 643, 281, 51376], "temperature": 0.0, "avg_logprob": -0.14518560682024276, "compression_ratio": 1.646788990825688, "no_speech_prob": 0.0019231413025408983}, {"id": 84, "seek": 47836, "start": 498.6, "end": 507.44, "text": " be mapped to floating point numbers for Prometheus, so like there's all kinds of hidden assumptions", "tokens": [51376, 312, 33318, 281, 12607, 935, 3547, 337, 2114, 649, 42209, 11, 370, 411, 456, 311, 439, 3685, 295, 7633, 17695, 51818], "temperature": 0.0, "avg_logprob": -0.14518560682024276, "compression_ratio": 1.646788990825688, "no_speech_prob": 0.0019231413025408983}, {"id": 85, "seek": 50744, "start": 507.71999999999997, "end": 514.96, "text": " that Postgres exporter has to be making to map this data to the monitoring data, the", "tokens": [50378, 300, 10223, 45189, 1278, 6122, 575, 281, 312, 1455, 281, 4471, 341, 1412, 281, 264, 11028, 1412, 11, 264, 50740], "temperature": 0.0, "avg_logprob": -0.18280190806235036, "compression_ratio": 1.4761904761904763, "no_speech_prob": 0.004968632943928242}, {"id": 86, "seek": 50744, "start": 514.96, "end": 522.32, "text": " data for Prometheus or M3 or whatever time series database you're using.", "tokens": [50740, 1412, 337, 2114, 649, 42209, 420, 376, 18, 420, 2035, 565, 2638, 8149, 291, 434, 1228, 13, 51108], "temperature": 0.0, "avg_logprob": -0.18280190806235036, "compression_ratio": 1.4761904761904763, "no_speech_prob": 0.004968632943928242}, {"id": 87, "seek": 50744, "start": 522.32, "end": 527.76, "text": " I don't have time to go into like how you would use these particular metrics to understand", "tokens": [51108, 286, 500, 380, 362, 565, 281, 352, 666, 411, 577, 291, 576, 764, 613, 1729, 16367, 281, 1223, 51380], "temperature": 0.0, "avg_logprob": -0.18280190806235036, "compression_ratio": 1.4761904761904763, "no_speech_prob": 0.004968632943928242}, {"id": 88, "seek": 52776, "start": 527.76, "end": 538.4, "text": " your, like how to tune your database, but one point is, the way Postgres, like these", "tokens": [50364, 428, 11, 411, 577, 281, 10864, 428, 8149, 11, 457, 472, 935, 307, 11, 264, 636, 10223, 45189, 11, 411, 613, 50896], "temperature": 0.0, "avg_logprob": -0.20345774992012683, "compression_ratio": 1.5777777777777777, "no_speech_prob": 0.261457622051239}, {"id": 89, "seek": 52776, "start": 538.4, "end": 544.24, "text": " metrics were originally designed, you were imagined to have a DBA logging into your database", "tokens": [50896, 16367, 645, 7993, 4761, 11, 291, 645, 16590, 281, 362, 257, 413, 9295, 27991, 666, 428, 8149, 51188], "temperature": 0.0, "avg_logprob": -0.20345774992012683, "compression_ratio": 1.5777777777777777, "no_speech_prob": 0.261457622051239}, {"id": 90, "seek": 52776, "start": 544.24, "end": 549.56, "text": " querying specific rows with a word clause, maybe doing calculations where you divide", "tokens": [51188, 7083, 1840, 2685, 13241, 365, 257, 1349, 25925, 11, 1310, 884, 20448, 689, 291, 9845, 51454], "temperature": 0.0, "avg_logprob": -0.20345774992012683, "compression_ratio": 1.5777777777777777, "no_speech_prob": 0.261457622051239}, {"id": 91, "seek": 52776, "start": 549.56, "end": 555.04, "text": " one by another to find out the number of tuples each sequential scan is returning and things", "tokens": [51454, 472, 538, 1071, 281, 915, 484, 264, 1230, 295, 2604, 2622, 1184, 42881, 11049, 307, 12678, 293, 721, 51728], "temperature": 0.0, "avg_logprob": -0.20345774992012683, "compression_ratio": 1.5777777777777777, "no_speech_prob": 0.261457622051239}, {"id": 92, "seek": 55504, "start": 555.04, "end": 561.36, "text": " like that and obviously in a modern observability world what you're actually going to do, what", "tokens": [50364, 411, 300, 293, 2745, 294, 257, 4363, 9951, 2310, 1002, 437, 291, 434, 767, 516, 281, 360, 11, 437, 50680], "temperature": 0.0, "avg_logprob": -0.17098330342492393, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.012795800343155861}, {"id": 93, "seek": 55504, "start": 561.36, "end": 566.8, "text": " Postgres exporter actually does is just do select star with no where clause, takes all", "tokens": [50680, 10223, 45189, 1278, 6122, 767, 775, 307, 445, 360, 3048, 3543, 365, 572, 689, 25925, 11, 2516, 439, 50952], "temperature": 0.0, "avg_logprob": -0.17098330342492393, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.012795800343155861}, {"id": 94, "seek": 55504, "start": 566.8, "end": 572.56, "text": " this data, dumps it into a time series database and then you do those same calculations but", "tokens": [50952, 341, 1412, 11, 11430, 82, 309, 666, 257, 565, 2638, 8149, 293, 550, 291, 360, 729, 912, 20448, 457, 51240], "temperature": 0.0, "avg_logprob": -0.17098330342492393, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.012795800343155861}, {"id": 95, "seek": 55504, "start": 572.56, "end": 580.3199999999999, "text": " you do them in from QL or whatever the equivalent is in your observability tool and that gives", "tokens": [51240, 291, 360, 552, 294, 490, 1249, 43, 420, 2035, 264, 10344, 307, 294, 428, 9951, 2310, 2290, 293, 300, 2709, 51628], "temperature": 0.0, "avg_logprob": -0.17098330342492393, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.012795800343155861}, {"id": 96, "seek": 58032, "start": 580.32, "end": 586.6400000000001, "text": " you the same kind of flexibility but now you can look at how those metrics relate to", "tokens": [50364, 291, 264, 912, 733, 295, 12635, 457, 586, 291, 393, 574, 412, 577, 729, 16367, 10961, 281, 50680], "temperature": 0.0, "avg_logprob": -0.12002086639404297, "compression_ratio": 1.733009708737864, "no_speech_prob": 0.04463860020041466}, {"id": 97, "seek": 58032, "start": 586.6400000000001, "end": 591.84, "text": " metrics that came from other sources so you get a more global view, you can aggregate", "tokens": [50680, 16367, 300, 1361, 490, 661, 7139, 370, 291, 483, 257, 544, 4338, 1910, 11, 291, 393, 26118, 50940], "temperature": 0.0, "avg_logprob": -0.12002086639404297, "compression_ratio": 1.733009708737864, "no_speech_prob": 0.04463860020041466}, {"id": 98, "seek": 58032, "start": 591.84, "end": 600.6400000000001, "text": " across multiples databases, you can aggregate across your Postgres databases and other systems.", "tokens": [50940, 2108, 46099, 22380, 11, 291, 393, 26118, 2108, 428, 10223, 45189, 22380, 293, 661, 3652, 13, 51380], "temperature": 0.0, "avg_logprob": -0.12002086639404297, "compression_ratio": 1.733009708737864, "no_speech_prob": 0.04463860020041466}, {"id": 99, "seek": 58032, "start": 600.6400000000001, "end": 608.6800000000001, "text": " So a lot of the flexibility here that these are designed to give you is no longer relevant", "tokens": [51380, 407, 257, 688, 295, 264, 12635, 510, 300, 613, 366, 4761, 281, 976, 291, 307, 572, 2854, 7340, 51782], "temperature": 0.0, "avg_logprob": -0.12002086639404297, "compression_ratio": 1.733009708737864, "no_speech_prob": 0.04463860020041466}, {"id": 100, "seek": 60868, "start": 608.68, "end": 614.1999999999999, "text": " when you're just doing a simple select star and dumping it all into Prometheus.", "tokens": [50364, 562, 291, 434, 445, 884, 257, 2199, 3048, 3543, 293, 42224, 309, 439, 666, 2114, 649, 42209, 13, 50640], "temperature": 0.0, "avg_logprob": -0.28330032546798906, "compression_ratio": 1.4894736842105263, "no_speech_prob": 0.0778251513838768}, {"id": 101, "seek": 60868, "start": 614.1999999999999, "end": 624.68, "text": " Sorry, there's more complicated metrics which don't really map well to tools like Prometheus", "tokens": [50640, 4919, 11, 456, 311, 544, 6179, 16367, 597, 500, 380, 534, 4471, 731, 281, 3873, 411, 2114, 649, 42209, 51164], "temperature": 0.0, "avg_logprob": -0.28330032546798906, "compression_ratio": 1.4894736842105263, "no_speech_prob": 0.0778251513838768}, {"id": 102, "seek": 60868, "start": 624.68, "end": 629.4799999999999, "text": " or M3, Datadog, whatever.", "tokens": [51164, 420, 376, 18, 11, 9315, 345, 664, 11, 2035, 13, 51404], "temperature": 0.0, "avg_logprob": -0.28330032546798906, "compression_ratio": 1.4894736842105263, "no_speech_prob": 0.0778251513838768}, {"id": 103, "seek": 60868, "start": 629.4799999999999, "end": 635.4799999999999, "text": " So this is PG stat activity, there's one row for each session, there's actually two,", "tokens": [51404, 407, 341, 307, 40975, 2219, 5191, 11, 456, 311, 472, 5386, 337, 1184, 5481, 11, 456, 311, 767, 732, 11, 51704], "temperature": 0.0, "avg_logprob": -0.28330032546798906, "compression_ratio": 1.4894736842105263, "no_speech_prob": 0.0778251513838768}, {"id": 104, "seek": 63548, "start": 635.48, "end": 643.6, "text": " there's the same, just to explain what you're looking at the first results that there are", "tokens": [50364, 456, 311, 264, 912, 11, 445, 281, 2903, 437, 291, 434, 1237, 412, 264, 700, 3542, 300, 456, 366, 50770], "temperature": 0.0, "avg_logprob": -0.16683032696063702, "compression_ratio": 1.610062893081761, "no_speech_prob": 0.20361723005771637}, {"id": 105, "seek": 63548, "start": 643.6, "end": 656.6800000000001, "text": " the first half dozen or dozen columns and then the second set there is, I've elided", "tokens": [50770, 264, 700, 1922, 16654, 420, 16654, 13766, 293, 550, 264, 1150, 992, 456, 307, 11, 286, 600, 806, 2112, 51424], "temperature": 0.0, "avg_logprob": -0.16683032696063702, "compression_ratio": 1.610062893081761, "no_speech_prob": 0.20361723005771637}, {"id": 106, "seek": 63548, "start": 656.6800000000001, "end": 661.96, "text": " after PID, I've elided those columns and showed you the next bunch of columns just", "tokens": [51424, 934, 430, 2777, 11, 286, 600, 806, 2112, 729, 13766, 293, 4712, 291, 264, 958, 3840, 295, 13766, 445, 51688], "temperature": 0.0, "avg_logprob": -0.16683032696063702, "compression_ratio": 1.610062893081761, "no_speech_prob": 0.20361723005771637}, {"id": 107, "seek": 66196, "start": 661.96, "end": 666.24, "text": " because I wanted to actually make a point about one of those columns that would be way", "tokens": [50364, 570, 286, 1415, 281, 767, 652, 257, 935, 466, 472, 295, 729, 13766, 300, 576, 312, 636, 50578], "temperature": 0.0, "avg_logprob": -0.1061274563824689, "compression_ratio": 1.5981735159817352, "no_speech_prob": 0.023959700018167496}, {"id": 108, "seek": 66196, "start": 666.24, "end": 668.32, "text": " past the edge of the screen.", "tokens": [50578, 1791, 264, 4691, 295, 264, 2568, 13, 50682], "temperature": 0.0, "avg_logprob": -0.1061274563824689, "compression_ratio": 1.5981735159817352, "no_speech_prob": 0.023959700018167496}, {"id": 109, "seek": 66196, "start": 668.32, "end": 674.72, "text": " So in PG stat activity you have one row per session on the database and obviously that", "tokens": [50682, 407, 294, 40975, 2219, 5191, 291, 362, 472, 5386, 680, 5481, 322, 264, 8149, 293, 2745, 300, 51002], "temperature": 0.0, "avg_logprob": -0.1061274563824689, "compression_ratio": 1.5981735159817352, "no_speech_prob": 0.023959700018167496}, {"id": 110, "seek": 66196, "start": 674.72, "end": 681.76, "text": " already is difficult to put into Prometheus because you would be having time series come", "tokens": [51002, 1217, 307, 2252, 281, 829, 666, 2114, 649, 42209, 570, 291, 576, 312, 1419, 565, 2638, 808, 51354], "temperature": 0.0, "avg_logprob": -0.1061274563824689, "compression_ratio": 1.5981735159817352, "no_speech_prob": 0.023959700018167496}, {"id": 111, "seek": 66196, "start": 681.76, "end": 686.84, "text": " and go every time an application connects and disconnects.", "tokens": [51354, 293, 352, 633, 565, 364, 3861, 16967, 293, 14299, 82, 13, 51608], "temperature": 0.0, "avg_logprob": -0.1061274563824689, "compression_ratio": 1.5981735159817352, "no_speech_prob": 0.023959700018167496}, {"id": 112, "seek": 68684, "start": 686.84, "end": 694.52, "text": " Probably what people actually, I think what Postgres exporter puts in the data is aggregates,", "tokens": [50364, 9210, 437, 561, 767, 11, 286, 519, 437, 10223, 45189, 1278, 6122, 8137, 294, 264, 1412, 307, 16743, 1024, 11, 50748], "temperature": 0.0, "avg_logprob": -0.2542937429327714, "compression_ratio": 1.6354166666666667, "no_speech_prob": 0.63850998878479}, {"id": 113, "seek": 68684, "start": 694.52, "end": 701.5600000000001, "text": " it just puts an account of how many rows are present and then maybe account of how many,", "tokens": [50748, 309, 445, 8137, 364, 2696, 295, 577, 867, 13241, 366, 1974, 293, 550, 1310, 2696, 295, 577, 867, 11, 51100], "temperature": 0.0, "avg_logprob": -0.2542937429327714, "compression_ratio": 1.6354166666666667, "no_speech_prob": 0.63850998878479}, {"id": 114, "seek": 68684, "start": 701.5600000000001, "end": 705.48, "text": " the minimum maximum of some of these columns.", "tokens": [51100, 264, 7285, 6674, 295, 512, 295, 613, 13766, 13, 51296], "temperature": 0.0, "avg_logprob": -0.2542937429327714, "compression_ratio": 1.6354166666666667, "no_speech_prob": 0.63850998878479}, {"id": 115, "seek": 68684, "start": 705.48, "end": 710.36, "text": " But there is data in here like the weight event type and weight event, those are text", "tokens": [51296, 583, 456, 307, 1412, 294, 510, 411, 264, 3364, 2280, 2010, 293, 3364, 2280, 11, 729, 366, 2487, 51540], "temperature": 0.0, "avg_logprob": -0.2542937429327714, "compression_ratio": 1.6354166666666667, "no_speech_prob": 0.63850998878479}, {"id": 116, "seek": 71036, "start": 710.36, "end": 717.08, "text": " strings, inside Postgres those are actually ID numbers but they get presented to the user", "tokens": [50364, 13985, 11, 1854, 10223, 45189, 729, 366, 767, 7348, 3547, 457, 436, 483, 8212, 281, 264, 4195, 50700], "temperature": 0.0, "avg_logprob": -0.14672991888863698, "compression_ratio": 1.5309278350515463, "no_speech_prob": 0.6277595162391663}, {"id": 117, "seek": 71036, "start": 717.08, "end": 727.44, "text": " in a nice readable format which then if you want to make metrics of you probably then", "tokens": [50700, 294, 257, 1481, 49857, 7877, 597, 550, 498, 291, 528, 281, 652, 16367, 295, 291, 1391, 550, 51218], "temperature": 0.0, "avg_logprob": -0.14672991888863698, "compression_ratio": 1.5309278350515463, "no_speech_prob": 0.6277595162391663}, {"id": 118, "seek": 71036, "start": 727.44, "end": 731.96, "text": " turn them back into numbers or you put them in labels, they're difficult to really make", "tokens": [51218, 1261, 552, 646, 666, 3547, 420, 291, 829, 552, 294, 16949, 11, 436, 434, 2252, 281, 534, 652, 51444], "temperature": 0.0, "avg_logprob": -0.14672991888863698, "compression_ratio": 1.5309278350515463, "no_speech_prob": 0.6277595162391663}, {"id": 119, "seek": 71036, "start": 731.96, "end": 737.88, "text": " use of in a time series database.", "tokens": [51444, 764, 295, 294, 257, 565, 2638, 8149, 13, 51740], "temperature": 0.0, "avg_logprob": -0.14672991888863698, "compression_ratio": 1.5309278350515463, "no_speech_prob": 0.6277595162391663}, {"id": 120, "seek": 73788, "start": 737.88, "end": 756.76, "text": " Some of them are quite important to have some idea, so there's information there that will", "tokens": [50364, 2188, 295, 552, 366, 1596, 1021, 281, 362, 512, 1558, 11, 370, 456, 311, 1589, 456, 300, 486, 51308], "temperature": 0.0, "avg_logprob": -0.25492804700678046, "compression_ratio": 1.4516129032258065, "no_speech_prob": 0.032419074326753616}, {"id": 121, "seek": 73788, "start": 756.76, "end": 762.64, "text": " show you in PG stat activity that will show you if a session is in a transaction, an idle", "tokens": [51308, 855, 291, 294, 40975, 2219, 5191, 300, 486, 855, 291, 498, 257, 5481, 307, 294, 257, 14425, 11, 364, 30650, 51602], "temperature": 0.0, "avg_logprob": -0.25492804700678046, "compression_ratio": 1.4516129032258065, "no_speech_prob": 0.032419074326753616}, {"id": 122, "seek": 76264, "start": 762.64, "end": 767.76, "text": " and you really do want to know if there's a session that's idle in transaction for a", "tokens": [50364, 293, 291, 534, 360, 528, 281, 458, 498, 456, 311, 257, 5481, 300, 311, 30650, 294, 14425, 337, 257, 50620], "temperature": 0.0, "avg_logprob": -0.17177203251765324, "compression_ratio": 1.60625, "no_speech_prob": 0.4859113395214081}, {"id": 123, "seek": 76264, "start": 767.76, "end": 769.88, "text": " long period of time.", "tokens": [50620, 938, 2896, 295, 565, 13, 50726], "temperature": 0.0, "avg_logprob": -0.17177203251765324, "compression_ratio": 1.60625, "no_speech_prob": 0.4859113395214081}, {"id": 124, "seek": 76264, "start": 769.88, "end": 777.6, "text": " So what most people do there is have an aggregate, they have one gauge for the maximum, the longest", "tokens": [50726, 407, 437, 881, 561, 360, 456, 307, 362, 364, 26118, 11, 436, 362, 472, 17924, 337, 264, 6674, 11, 264, 15438, 51112], "temperature": 0.0, "avg_logprob": -0.17177203251765324, "compression_ratio": 1.60625, "no_speech_prob": 0.4859113395214081}, {"id": 125, "seek": 76264, "start": 777.6, "end": 788.68, "text": " time that any session has been idle in transaction.", "tokens": [51112, 565, 300, 604, 5481, 575, 668, 30650, 294, 14425, 13, 51666], "temperature": 0.0, "avg_logprob": -0.17177203251765324, "compression_ratio": 1.60625, "no_speech_prob": 0.4859113395214081}, {"id": 126, "seek": 78868, "start": 788.68, "end": 795.52, "text": " So just to be clear what we're talking about here is Postgres exporter which is connecting", "tokens": [50364, 407, 445, 281, 312, 1850, 437, 321, 434, 1417, 466, 510, 307, 10223, 45189, 1278, 6122, 597, 307, 11015, 50706], "temperature": 0.0, "avg_logprob": -0.19517127672831217, "compression_ratio": 1.6272189349112427, "no_speech_prob": 0.11844229698181152}, {"id": 127, "seek": 78868, "start": 795.52, "end": 804.0, "text": " to Postgres QL and querying PG stat user tables, PG stat user indexes, PG stat activity,", "tokens": [50706, 281, 10223, 45189, 1249, 43, 293, 7083, 1840, 40975, 2219, 4195, 8020, 11, 40975, 2219, 4195, 8186, 279, 11, 40975, 2219, 5191, 11, 51130], "temperature": 0.0, "avg_logprob": -0.19517127672831217, "compression_ratio": 1.6272189349112427, "no_speech_prob": 0.11844229698181152}, {"id": 128, "seek": 78868, "start": 804.0, "end": 812.3599999999999, "text": " all the various views that start with PG stat, it can also, Postgres exporter is very flexible,", "tokens": [51130, 439, 264, 3683, 6809, 300, 722, 365, 40975, 2219, 11, 309, 393, 611, 11, 10223, 45189, 1278, 6122, 307, 588, 11358, 11, 51548], "temperature": 0.0, "avg_logprob": -0.19517127672831217, "compression_ratio": 1.6272189349112427, "no_speech_prob": 0.11844229698181152}, {"id": 129, "seek": 81236, "start": 812.36, "end": 820.92, "text": " you can configure customized queries to query other views that like some of the PG stat", "tokens": [50364, 291, 393, 22162, 30581, 24109, 281, 14581, 661, 6809, 300, 411, 512, 295, 264, 40975, 2219, 50792], "temperature": 0.0, "avg_logprob": -0.18712291350731483, "compression_ratio": 1.4846625766871167, "no_speech_prob": 0.4970545768737793}, {"id": 130, "seek": 81236, "start": 820.92, "end": 826.32, "text": " views you might want more detail than the default queries.", "tokens": [50792, 6809, 291, 1062, 528, 544, 2607, 813, 264, 7576, 24109, 13, 51062], "temperature": 0.0, "avg_logprob": -0.18712291350731483, "compression_ratio": 1.4846625766871167, "no_speech_prob": 0.4970545768737793}, {"id": 131, "seek": 81236, "start": 826.32, "end": 837.44, "text": " So it doesn't actually include all those table statistics by default if you have an application", "tokens": [51062, 407, 309, 1177, 380, 767, 4090, 439, 729, 3199, 12523, 538, 7576, 498, 291, 362, 364, 3861, 51618], "temperature": 0.0, "avg_logprob": -0.18712291350731483, "compression_ratio": 1.4846625766871167, "no_speech_prob": 0.4970545768737793}, {"id": 132, "seek": 83744, "start": 837.44, "end": 843.08, "text": " where your schema is fairly static and you have a reasonable number of tables to do that", "tokens": [50364, 689, 428, 34078, 307, 6457, 13437, 293, 291, 362, 257, 10585, 1230, 295, 8020, 281, 360, 300, 50646], "temperature": 0.0, "avg_logprob": -0.14504684799018946, "compression_ratio": 1.6203703703703705, "no_speech_prob": 0.8407794833183289}, {"id": 133, "seek": 83744, "start": 843.08, "end": 849.0, "text": " with, you can quite reasonably get all of those columns, put them in Prometheus and be able", "tokens": [50646, 365, 11, 291, 393, 1596, 23551, 483, 439, 295, 729, 13766, 11, 829, 552, 294, 2114, 649, 42209, 293, 312, 1075, 50942], "temperature": 0.0, "avg_logprob": -0.14504684799018946, "compression_ratio": 1.6203703703703705, "no_speech_prob": 0.8407794833183289}, {"id": 134, "seek": 83744, "start": 849.0, "end": 856.9200000000001, "text": " to do all kinds of nice graphs and visualizations, but that's not standard.", "tokens": [50942, 281, 360, 439, 3685, 295, 1481, 24877, 293, 5056, 14455, 11, 457, 300, 311, 406, 3832, 13, 51338], "temperature": 0.0, "avg_logprob": -0.14504684799018946, "compression_ratio": 1.6203703703703705, "no_speech_prob": 0.8407794833183289}, {"id": 135, "seek": 83744, "start": 856.9200000000001, "end": 860.96, "text": " And if you're, on the other hand, you're an ISP with hundreds of customers and your customers", "tokens": [51338, 400, 498, 291, 434, 11, 322, 264, 661, 1011, 11, 291, 434, 364, 6205, 47, 365, 6779, 295, 4581, 293, 428, 4581, 51540], "temperature": 0.0, "avg_logprob": -0.14504684799018946, "compression_ratio": 1.6203703703703705, "no_speech_prob": 0.8407794833183289}, {"id": 136, "seek": 86096, "start": 860.96, "end": 869.6, "text": " create and drop tables without your control, then you can't really be trying to gather", "tokens": [50364, 1884, 293, 3270, 8020, 1553, 428, 1969, 11, 550, 291, 393, 380, 534, 312, 1382, 281, 5448, 50796], "temperature": 0.0, "avg_logprob": -0.13507701765816166, "compression_ratio": 1.5135135135135136, "no_speech_prob": 0.8742261528968811}, {"id": 137, "seek": 86096, "start": 869.6, "end": 878.6800000000001, "text": " statistics like that because you're taking on an unbounded cardinality and time series", "tokens": [50796, 12523, 411, 300, 570, 291, 434, 1940, 322, 364, 517, 18767, 292, 2920, 259, 1860, 293, 565, 2638, 51250], "temperature": 0.0, "avg_logprob": -0.13507701765816166, "compression_ratio": 1.5135135135135136, "no_speech_prob": 0.8742261528968811}, {"id": 138, "seek": 86096, "start": 878.6800000000001, "end": 882.4000000000001, "text": " coming and going without being able to control it.", "tokens": [51250, 1348, 293, 516, 1553, 885, 1075, 281, 1969, 309, 13, 51436], "temperature": 0.0, "avg_logprob": -0.13507701765816166, "compression_ratio": 1.5135135135135136, "no_speech_prob": 0.8742261528968811}, {"id": 139, "seek": 88240, "start": 882.4, "end": 893.88, "text": " So the level of detail that you grab is very dependent on how you're using Postgres, whether", "tokens": [50364, 407, 264, 1496, 295, 2607, 300, 291, 4444, 307, 588, 12334, 322, 577, 291, 434, 1228, 10223, 45189, 11, 1968, 50938], "temperature": 0.0, "avg_logprob": -0.116101136283269, "compression_ratio": 1.612121212121212, "no_speech_prob": 0.5219590663909912}, {"id": 140, "seek": 88240, "start": 893.88, "end": 899.9599999999999, "text": " you're a site with one key database that you want to optimize or many, many databases", "tokens": [50938, 291, 434, 257, 3621, 365, 472, 2141, 8149, 300, 291, 528, 281, 19719, 420, 867, 11, 867, 22380, 51242], "temperature": 0.0, "avg_logprob": -0.116101136283269, "compression_ratio": 1.612121212121212, "no_speech_prob": 0.5219590663909912}, {"id": 141, "seek": 88240, "start": 899.9599999999999, "end": 906.56, "text": " that you just want to monitor at a high level or an application that you're controlling", "tokens": [51242, 300, 291, 445, 528, 281, 6002, 412, 257, 1090, 1496, 420, 364, 3861, 300, 291, 434, 14905, 51572], "temperature": 0.0, "avg_logprob": -0.116101136283269, "compression_ratio": 1.612121212121212, "no_speech_prob": 0.5219590663909912}, {"id": 142, "seek": 90656, "start": 906.56, "end": 911.68, "text": " versus applications that you're hosting for other people.", "tokens": [50364, 5717, 5821, 300, 291, 434, 16058, 337, 661, 561, 13, 50620], "temperature": 0.0, "avg_logprob": -0.18505435985523266, "compression_ratio": 1.6696428571428572, "no_speech_prob": 0.5902987122535706}, {"id": 143, "seek": 90656, "start": 911.68, "end": 917.4, "text": " It also means that many sites add queries in Postgres exported query, other data sources", "tokens": [50620, 467, 611, 1355, 300, 867, 7533, 909, 24109, 294, 10223, 45189, 42055, 14581, 11, 661, 1412, 7139, 50906], "temperature": 0.0, "avg_logprob": -0.18505435985523266, "compression_ratio": 1.6696428571428572, "no_speech_prob": 0.5902987122535706}, {"id": 144, "seek": 90656, "start": 917.4, "end": 921.68, "text": " like what I've put in this diagram here is PGSTAT statements, which is an extension in", "tokens": [50906, 411, 437, 286, 600, 829, 294, 341, 10686, 510, 307, 40975, 6840, 2218, 12363, 11, 597, 307, 364, 10320, 294, 51120], "temperature": 0.0, "avg_logprob": -0.18505435985523266, "compression_ratio": 1.6696428571428572, "no_speech_prob": 0.5902987122535706}, {"id": 145, "seek": 90656, "start": 921.68, "end": 927.1999999999999, "text": " Postgres, which gathers statistics for your queries.", "tokens": [51120, 10223, 45189, 11, 597, 290, 11850, 12523, 337, 428, 24109, 13, 51396], "temperature": 0.0, "avg_logprob": -0.18505435985523266, "compression_ratio": 1.6696428571428572, "no_speech_prob": 0.5902987122535706}, {"id": 146, "seek": 90656, "start": 927.1999999999999, "end": 934.5999999999999, "text": " So the key in there is a query ID, which is like a hash of the query with the constants", "tokens": [51396, 407, 264, 2141, 294, 456, 307, 257, 14581, 7348, 11, 597, 307, 411, 257, 22019, 295, 264, 14581, 365, 264, 35870, 51766], "temperature": 0.0, "avg_logprob": -0.18505435985523266, "compression_ratio": 1.6696428571428572, "no_speech_prob": 0.5902987122535706}, {"id": 147, "seek": 93460, "start": 934.64, "end": 941.4, "text": " removed, and you can get long-lived statistics about which queries are taking a lot of time", "tokens": [50366, 7261, 11, 293, 291, 393, 483, 938, 12, 46554, 12523, 466, 597, 24109, 366, 1940, 257, 688, 295, 565, 50704], "temperature": 0.0, "avg_logprob": -0.23738529947068956, "compression_ratio": 1.5303867403314917, "no_speech_prob": 0.18180681765079498}, {"id": 148, "seek": 93460, "start": 941.4, "end": 950.16, "text": " or doing a lot of ale, but that's, again, like a custom query that you would be adding.", "tokens": [50704, 420, 884, 257, 688, 295, 6775, 11, 457, 300, 311, 11, 797, 11, 411, 257, 2375, 14581, 300, 291, 576, 312, 5127, 13, 51142], "temperature": 0.0, "avg_logprob": -0.23738529947068956, "compression_ratio": 1.5303867403314917, "no_speech_prob": 0.18180681765079498}, {"id": 149, "seek": 93460, "start": 950.16, "end": 959.48, "text": " So I talked a bit about the map, like the difficulty mapping some of these metrics for me to use.", "tokens": [51142, 407, 286, 2825, 257, 857, 466, 264, 4471, 11, 411, 264, 10360, 18350, 512, 295, 613, 16367, 337, 385, 281, 764, 13, 51608], "temperature": 0.0, "avg_logprob": -0.23738529947068956, "compression_ratio": 1.5303867403314917, "no_speech_prob": 0.18180681765079498}, {"id": 150, "seek": 95948, "start": 959.48, "end": 966.0, "text": " There's other problems with, am I doing it for time?", "tokens": [50364, 821, 311, 661, 2740, 365, 11, 669, 286, 884, 309, 337, 565, 30, 50690], "temperature": 0.0, "avg_logprob": -0.33456425917776006, "compression_ratio": 1.5477707006369428, "no_speech_prob": 0.10748811811208725}, {"id": 151, "seek": 95948, "start": 966.0, "end": 968.0, "text": " Am I doing it for time?", "tokens": [50690, 2012, 286, 884, 309, 337, 565, 30, 50790], "temperature": 0.0, "avg_logprob": -0.33456425917776006, "compression_ratio": 1.5477707006369428, "no_speech_prob": 0.10748811811208725}, {"id": 152, "seek": 95948, "start": 968.0, "end": 977.84, "text": " There's, I don't, okay, there are, so I do want to talk a bit about the kinds of problems", "tokens": [50790, 821, 311, 11, 286, 500, 380, 11, 1392, 11, 456, 366, 11, 370, 286, 360, 528, 281, 751, 257, 857, 466, 264, 3685, 295, 2740, 51282], "temperature": 0.0, "avg_logprob": -0.33456425917776006, "compression_ratio": 1.5477707006369428, "no_speech_prob": 0.10748811811208725}, {"id": 153, "seek": 95948, "start": 977.84, "end": 980.88, "text": " that we have.", "tokens": [51282, 300, 321, 362, 13, 51434], "temperature": 0.0, "avg_logprob": -0.33456425917776006, "compression_ratio": 1.5477707006369428, "no_speech_prob": 0.10748811811208725}, {"id": 154, "seek": 95948, "start": 980.88, "end": 985.6, "text": " Some of the metrics don't map very well to Prometheus metrics.", "tokens": [51434, 2188, 295, 264, 16367, 500, 380, 4471, 588, 731, 281, 2114, 649, 42209, 16367, 13, 51670], "temperature": 0.0, "avg_logprob": -0.33456425917776006, "compression_ratio": 1.5477707006369428, "no_speech_prob": 0.10748811811208725}, {"id": 155, "seek": 98560, "start": 985.6, "end": 991.0, "text": " The fact that the metrics can be customized, and in fact kind of have to be customized", "tokens": [50364, 440, 1186, 300, 264, 16367, 393, 312, 30581, 11, 293, 294, 1186, 733, 295, 362, 281, 312, 30581, 50634], "temperature": 0.0, "avg_logprob": -0.17864805221557617, "compression_ratio": 1.7589285714285714, "no_speech_prob": 0.0937161073088646}, {"id": 156, "seek": 98560, "start": 991.0, "end": 996.4, "text": " because Postgres is used in different ways at different sites, means that there's no,", "tokens": [50634, 570, 10223, 45189, 307, 1143, 294, 819, 2098, 412, 819, 7533, 11, 1355, 300, 456, 311, 572, 11, 50904], "temperature": 0.0, "avg_logprob": -0.17864805221557617, "compression_ratio": 1.7589285714285714, "no_speech_prob": 0.0937161073088646}, {"id": 157, "seek": 98560, "start": 996.4, "end": 1001.32, "text": " there is a standard dashboard in Grafana for Postgres, but it's a very high-level dashboard.", "tokens": [50904, 456, 307, 257, 3832, 18342, 294, 8985, 69, 2095, 337, 10223, 45189, 11, 457, 309, 311, 257, 588, 1090, 12, 12418, 18342, 13, 51150], "temperature": 0.0, "avg_logprob": -0.17864805221557617, "compression_ratio": 1.7589285714285714, "no_speech_prob": 0.0937161073088646}, {"id": 158, "seek": 98560, "start": 1001.32, "end": 1005.44, "text": " I think I do have a screenshot there, yeah.", "tokens": [51150, 286, 519, 286, 360, 362, 257, 27712, 456, 11, 1338, 13, 51356], "temperature": 0.0, "avg_logprob": -0.17864805221557617, "compression_ratio": 1.7589285714285714, "no_speech_prob": 0.0937161073088646}, {"id": 159, "seek": 98560, "start": 1005.44, "end": 1013.84, "text": " There is a dashboard for Postgres, but it, this is not showing individual tables and", "tokens": [51356, 821, 307, 257, 18342, 337, 10223, 45189, 11, 457, 309, 11, 341, 307, 406, 4099, 2609, 8020, 293, 51776], "temperature": 0.0, "avg_logprob": -0.17864805221557617, "compression_ratio": 1.7589285714285714, "no_speech_prob": 0.0937161073088646}, {"id": 160, "seek": 101384, "start": 1013.84, "end": 1021.12, "text": " individual functions and so on, because on many sites that data wouldn't even be present.", "tokens": [50364, 2609, 6828, 293, 370, 322, 11, 570, 322, 867, 7533, 300, 1412, 2759, 380, 754, 312, 1974, 13, 50728], "temperature": 0.0, "avg_logprob": -0.15693270739387064, "compression_ratio": 1.7073170731707317, "no_speech_prob": 0.060808200389146805}, {"id": 161, "seek": 101384, "start": 1021.12, "end": 1026.4, "text": " You have to add custom queries for it.", "tokens": [50728, 509, 362, 281, 909, 2375, 24109, 337, 309, 13, 50992], "temperature": 0.0, "avg_logprob": -0.15693270739387064, "compression_ratio": 1.7073170731707317, "no_speech_prob": 0.060808200389146805}, {"id": 162, "seek": 101384, "start": 1026.4, "end": 1028.2, "text": " It also means you have to deploy the agent.", "tokens": [50992, 467, 611, 1355, 291, 362, 281, 7274, 264, 9461, 13, 51082], "temperature": 0.0, "avg_logprob": -0.15693270739387064, "compression_ratio": 1.7073170731707317, "no_speech_prob": 0.060808200389146805}, {"id": 163, "seek": 101384, "start": 1028.2, "end": 1034.24, "text": " You have to run this side, this Go program alongside your database everywhere you deploy", "tokens": [51082, 509, 362, 281, 1190, 341, 1252, 11, 341, 1037, 1461, 12385, 428, 8149, 5315, 291, 7274, 51384], "temperature": 0.0, "avg_logprob": -0.15693270739387064, "compression_ratio": 1.7073170731707317, "no_speech_prob": 0.060808200389146805}, {"id": 164, "seek": 101384, "start": 1034.24, "end": 1040.76, "text": " your database, or you could, depending on how you deploy it, you can deploy a single one", "tokens": [51384, 428, 8149, 11, 420, 291, 727, 11, 5413, 322, 577, 291, 7274, 309, 11, 291, 393, 7274, 257, 2167, 472, 51710], "temperature": 0.0, "avg_logprob": -0.15693270739387064, "compression_ratio": 1.7073170731707317, "no_speech_prob": 0.060808200389146805}, {"id": 165, "seek": 104076, "start": 1040.8799999999999, "end": 1047.48, "text": " for all your databases, or one for all the databases running on one host, so that mapping", "tokens": [50370, 337, 439, 428, 22380, 11, 420, 472, 337, 439, 264, 22380, 2614, 322, 472, 3975, 11, 370, 300, 18350, 50700], "temperature": 0.0, "avg_logprob": -0.189272076475854, "compression_ratio": 1.6102941176470589, "no_speech_prob": 0.13073112070560455}, {"id": 166, "seek": 104076, "start": 1047.48, "end": 1057.32, "text": " of which agent to, which agents metrics correspond to which actual database is entirely dependent", "tokens": [50700, 295, 597, 9461, 281, 11, 597, 12554, 16367, 6805, 281, 597, 3539, 8149, 307, 7696, 12334, 51192], "temperature": 0.0, "avg_logprob": -0.189272076475854, "compression_ratio": 1.6102941176470589, "no_speech_prob": 0.13073112070560455}, {"id": 167, "seek": 104076, "start": 1057.32, "end": 1062.12, "text": " on how you manage your deploys.", "tokens": [51192, 322, 577, 291, 3067, 428, 368, 49522, 13, 51432], "temperature": 0.0, "avg_logprob": -0.189272076475854, "compression_ratio": 1.6102941176470589, "no_speech_prob": 0.13073112070560455}, {"id": 168, "seek": 106212, "start": 1062.12, "end": 1072.04, "text": " The other problem that I've, the, I can't go into all of the problems, but the, the", "tokens": [50364, 440, 661, 1154, 300, 286, 600, 11, 264, 11, 286, 393, 380, 352, 666, 439, 295, 264, 2740, 11, 457, 264, 11, 264, 50860], "temperature": 0.0, "avg_logprob": -0.2940610598211419, "compression_ratio": 1.5987654320987654, "no_speech_prob": 0.32629337906837463}, {"id": 169, "seek": 106212, "start": 1072.04, "end": 1080.4799999999998, "text": " op, the Rezors contention, I gave names to each of these classes, but, so the Rezors", "tokens": [50860, 999, 11, 264, 1300, 89, 830, 660, 1251, 11, 286, 2729, 5288, 281, 1184, 295, 613, 5359, 11, 457, 11, 370, 264, 1300, 89, 830, 51282], "temperature": 0.0, "avg_logprob": -0.2940610598211419, "compression_ratio": 1.5987654320987654, "no_speech_prob": 0.32629337906837463}, {"id": 170, "seek": 106212, "start": 1080.4799999999998, "end": 1087.8799999999999, "text": " contention problems are that Postgres, because it's exposing this information through SQL,", "tokens": [51282, 660, 1251, 2740, 366, 300, 10223, 45189, 11, 570, 309, 311, 33178, 341, 1589, 807, 19200, 11, 51652], "temperature": 0.0, "avg_logprob": -0.2940610598211419, "compression_ratio": 1.5987654320987654, "no_speech_prob": 0.32629337906837463}, {"id": 171, "seek": 108788, "start": 1087.88, "end": 1093.48, "text": " means that you have to have a working SQL session in order to get the metrics.", "tokens": [50364, 1355, 300, 291, 362, 281, 362, 257, 1364, 19200, 5481, 294, 1668, 281, 483, 264, 16367, 13, 50644], "temperature": 0.0, "avg_logprob": -0.1840983715254007, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.1513109654188156}, {"id": 172, "seek": 108788, "start": 1093.48, "end": 1098.7600000000002, "text": " So when your system is not functioning correctly, you're very likely to also lose all your data,", "tokens": [50644, 407, 562, 428, 1185, 307, 406, 18483, 8944, 11, 291, 434, 588, 3700, 281, 611, 3624, 439, 428, 1412, 11, 50908], "temperature": 0.0, "avg_logprob": -0.1840983715254007, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.1513109654188156}, {"id": 173, "seek": 108788, "start": 1098.7600000000002, "end": 1103.1200000000001, "text": " which you need to debug the problem.", "tokens": [50908, 597, 291, 643, 281, 24083, 264, 1154, 13, 51126], "temperature": 0.0, "avg_logprob": -0.1840983715254007, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.1513109654188156}, {"id": 174, "seek": 108788, "start": 1103.1200000000001, "end": 1108.5200000000002, "text": " So if you're running low-end connections, or you're running into transaction wraparound,", "tokens": [51126, 407, 498, 291, 434, 2614, 2295, 12, 521, 9271, 11, 420, 291, 434, 2614, 666, 14425, 7843, 2181, 554, 11, 51396], "temperature": 0.0, "avg_logprob": -0.1840983715254007, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.1513109654188156}, {"id": 175, "seek": 108788, "start": 1108.5200000000002, "end": 1115.2800000000002, "text": " or the system is just out of memory, or getting disk errors, quite often you also lose all", "tokens": [51396, 420, 264, 1185, 307, 445, 484, 295, 4675, 11, 420, 1242, 12355, 13603, 11, 1596, 2049, 291, 611, 3624, 439, 51734], "temperature": 0.0, "avg_logprob": -0.1840983715254007, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.1513109654188156}, {"id": 176, "seek": 111528, "start": 1115.28, "end": 1120.36, "text": " your metrics that would allow you to figure out which application component is using all", "tokens": [50364, 428, 16367, 300, 576, 2089, 291, 281, 2573, 484, 597, 3861, 6542, 307, 1228, 439, 50618], "temperature": 0.0, "avg_logprob": -0.16061926579129868, "compression_ratio": 1.553191489361702, "no_speech_prob": 0.0029740778263658285}, {"id": 177, "seek": 111528, "start": 1120.36, "end": 1125.6399999999999, "text": " the connections, or which table is it that needs to be vacuumed to recover from the transaction", "tokens": [50618, 264, 9271, 11, 420, 597, 3199, 307, 309, 300, 2203, 281, 312, 14224, 292, 281, 8114, 490, 264, 14425, 50882], "temperature": 0.0, "avg_logprob": -0.16061926579129868, "compression_ratio": 1.553191489361702, "no_speech_prob": 0.0029740778263658285}, {"id": 178, "seek": 111528, "start": 1125.6399999999999, "end": 1129.28, "text": " wraparound issue.", "tokens": [50882, 7843, 2181, 554, 2734, 13, 51064], "temperature": 0.0, "avg_logprob": -0.16061926579129868, "compression_ratio": 1.553191489361702, "no_speech_prob": 0.0029740778263658285}, {"id": 179, "seek": 111528, "start": 1129.28, "end": 1137.3999999999999, "text": " I actually tried to, I've run into a problem where a table was locked by the application,", "tokens": [51064, 286, 767, 3031, 281, 11, 286, 600, 1190, 666, 257, 1154, 689, 257, 3199, 390, 9376, 538, 264, 3861, 11, 51470], "temperature": 0.0, "avg_logprob": -0.16061926579129868, "compression_ratio": 1.553191489361702, "no_speech_prob": 0.0029740778263658285}, {"id": 180, "seek": 113740, "start": 1137.4, "end": 1143.24, "text": " and the custom queries needed that same lock.", "tokens": [50364, 293, 264, 2375, 24109, 2978, 300, 912, 4017, 13, 50656], "temperature": 0.0, "avg_logprob": -0.14784423784277906, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.5457051992416382}, {"id": 181, "seek": 113740, "start": 1143.24, "end": 1149.76, "text": " So the queries all disappeared, the metrics all disappeared, because the Postgres exporter", "tokens": [50656, 407, 264, 24109, 439, 13954, 11, 264, 16367, 439, 13954, 11, 570, 264, 10223, 45189, 1278, 6122, 50982], "temperature": 0.0, "avg_logprob": -0.14784423784277906, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.5457051992416382}, {"id": 182, "seek": 113740, "start": 1149.76, "end": 1152.0, "text": " was getting blocked on that lock.", "tokens": [50982, 390, 1242, 15470, 322, 300, 4017, 13, 51094], "temperature": 0.0, "avg_logprob": -0.14784423784277906, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.5457051992416382}, {"id": 183, "seek": 113740, "start": 1152.0, "end": 1159.92, "text": " When I tried to recreate it for a demo, I actually found, oh, this is not a lock, this", "tokens": [51094, 1133, 286, 3031, 281, 25833, 309, 337, 257, 10723, 11, 286, 767, 1352, 11, 1954, 11, 341, 307, 406, 257, 4017, 11, 341, 51490], "temperature": 0.0, "avg_logprob": -0.14784423784277906, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.5457051992416382}, {"id": 184, "seek": 113740, "start": 1159.92, "end": 1166.0, "text": " is, I actually caused the regression test on Postgres to fail, because one of the regression", "tokens": [51490, 307, 11, 286, 767, 7008, 264, 24590, 1500, 322, 10223, 45189, 281, 3061, 11, 570, 472, 295, 264, 24590, 51794], "temperature": 0.0, "avg_logprob": -0.14784423784277906, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.5457051992416382}, {"id": 185, "seek": 116600, "start": 1166.0, "end": 1169.6, "text": " tests tries to drop a database.", "tokens": [50364, 6921, 9898, 281, 3270, 257, 8149, 13, 50544], "temperature": 0.0, "avg_logprob": -0.1410342534383138, "compression_ratio": 1.8677248677248677, "no_speech_prob": 0.008825129829347134}, {"id": 186, "seek": 116600, "start": 1169.6, "end": 1174.4, "text": " And the Postgres exporter keeps a connection to each database, because the metrics, like", "tokens": [50544, 400, 264, 10223, 45189, 1278, 6122, 5965, 257, 4984, 281, 1184, 8149, 11, 570, 264, 16367, 11, 411, 50784], "temperature": 0.0, "avg_logprob": -0.1410342534383138, "compression_ratio": 1.8677248677248677, "no_speech_prob": 0.008825129829347134}, {"id": 187, "seek": 116600, "start": 1174.4, "end": 1181.08, "text": " I said, you need a session, you need a connection to the database, so you need, in Postgres,", "tokens": [50784, 286, 848, 11, 291, 643, 257, 5481, 11, 291, 643, 257, 4984, 281, 264, 8149, 11, 370, 291, 643, 11, 294, 10223, 45189, 11, 51118], "temperature": 0.0, "avg_logprob": -0.1410342534383138, "compression_ratio": 1.8677248677248677, "no_speech_prob": 0.008825129829347134}, {"id": 188, "seek": 116600, "start": 1181.08, "end": 1184.28, "text": " each session is tied to a specific database.", "tokens": [51118, 1184, 5481, 307, 9601, 281, 257, 2685, 8149, 13, 51278], "temperature": 0.0, "avg_logprob": -0.1410342534383138, "compression_ratio": 1.8677248677248677, "no_speech_prob": 0.008825129829347134}, {"id": 189, "seek": 116600, "start": 1184.28, "end": 1192.8, "text": " So if you have a dozen databases, it uses a dozen connections, and it keeps those connections,", "tokens": [51278, 407, 498, 291, 362, 257, 16654, 22380, 11, 309, 4960, 257, 16654, 9271, 11, 293, 309, 5965, 729, 9271, 11, 51704], "temperature": 0.0, "avg_logprob": -0.1410342534383138, "compression_ratio": 1.8677248677248677, "no_speech_prob": 0.008825129829347134}, {"id": 190, "seek": 119280, "start": 1192.8, "end": 1198.76, "text": " it's optional, it's to work around the problem that it might not be able to connect if you", "tokens": [50364, 309, 311, 17312, 11, 309, 311, 281, 589, 926, 264, 1154, 300, 309, 1062, 406, 312, 1075, 281, 1745, 498, 291, 50662], "temperature": 0.0, "avg_logprob": -0.1434965880020805, "compression_ratio": 1.7640449438202248, "no_speech_prob": 0.04986841604113579}, {"id": 191, "seek": 119280, "start": 1198.76, "end": 1205.0, "text": " have a problem, but as a result, it has persistent connections to those databases, and the regression", "tokens": [50662, 362, 257, 1154, 11, 457, 382, 257, 1874, 11, 309, 575, 24315, 9271, 281, 729, 22380, 11, 293, 264, 24590, 50974], "temperature": 0.0, "avg_logprob": -0.1434965880020805, "compression_ratio": 1.7640449438202248, "no_speech_prob": 0.04986841604113579}, {"id": 192, "seek": 119280, "start": 1205.0, "end": 1208.04, "text": " test failed when they tried to drop that database.", "tokens": [50974, 1500, 7612, 562, 436, 3031, 281, 3270, 300, 8149, 13, 51126], "temperature": 0.0, "avg_logprob": -0.1434965880020805, "compression_ratio": 1.7640449438202248, "no_speech_prob": 0.04986841604113579}, {"id": 193, "seek": 119280, "start": 1208.04, "end": 1209.76, "text": " And that could actually happen in production.", "tokens": [51126, 400, 300, 727, 767, 1051, 294, 4265, 13, 51212], "temperature": 0.0, "avg_logprob": -0.1434965880020805, "compression_ratio": 1.7640449438202248, "no_speech_prob": 0.04986841604113579}, {"id": 194, "seek": 119280, "start": 1209.76, "end": 1214.8799999999999, "text": " If you try to do a deploy and roll out a new version of some data that drops a database", "tokens": [51212, 759, 291, 853, 281, 360, 257, 7274, 293, 3373, 484, 257, 777, 3037, 295, 512, 1412, 300, 11438, 257, 8149, 51468], "temperature": 0.0, "avg_logprob": -0.1434965880020805, "compression_ratio": 1.7640449438202248, "no_speech_prob": 0.04986841604113579}, {"id": 195, "seek": 119280, "start": 1214.8799999999999, "end": 1221.32, "text": " and recreates it from scratch, if you have Postgres exporter running and it has a connection,", "tokens": [51468, 293, 850, 620, 279, 309, 490, 8459, 11, 498, 291, 362, 10223, 45189, 1278, 6122, 2614, 293, 309, 575, 257, 4984, 11, 51790], "temperature": 0.0, "avg_logprob": -0.1434965880020805, "compression_ratio": 1.7640449438202248, "no_speech_prob": 0.04986841604113579}, {"id": 196, "seek": 122132, "start": 1221.32, "end": 1225.36, "text": " you could run into the same kind of issue.", "tokens": [50364, 291, 727, 1190, 666, 264, 912, 733, 295, 2734, 13, 50566], "temperature": 0.0, "avg_logprob": -0.12254287670185039, "compression_ratio": 1.5769230769230769, "no_speech_prob": 0.34337663650512695}, {"id": 197, "seek": 122132, "start": 1225.36, "end": 1237.52, "text": " So I'm hoping, I'm already working on something to replace Postgres exporter with a background", "tokens": [50566, 407, 286, 478, 7159, 11, 286, 478, 1217, 1364, 322, 746, 281, 7406, 10223, 45189, 1278, 6122, 365, 257, 3678, 51174], "temperature": 0.0, "avg_logprob": -0.12254287670185039, "compression_ratio": 1.5769230769230769, "no_speech_prob": 0.34337663650512695}, {"id": 198, "seek": 122132, "start": 1237.52, "end": 1242.36, "text": " worker inside Postgres, so you would be connecting directly to Postgres, you wouldn't have to", "tokens": [51174, 11346, 1854, 10223, 45189, 11, 370, 291, 576, 312, 11015, 3838, 281, 10223, 45189, 11, 291, 2759, 380, 362, 281, 51416], "temperature": 0.0, "avg_logprob": -0.12254287670185039, "compression_ratio": 1.5769230769230769, "no_speech_prob": 0.34337663650512695}, {"id": 199, "seek": 122132, "start": 1242.36, "end": 1249.6, "text": " deploy a separate program alongside it, and my goal is that that program would have standardized", "tokens": [51416, 7274, 257, 4994, 1461, 12385, 309, 11, 293, 452, 3387, 307, 300, 300, 1461, 576, 362, 31677, 51778], "temperature": 0.0, "avg_logprob": -0.12254287670185039, "compression_ratio": 1.5769230769230769, "no_speech_prob": 0.34337663650512695}, {"id": 200, "seek": 124960, "start": 1249.6, "end": 1253.84, "text": " metrics.", "tokens": [50364, 16367, 13, 50576], "temperature": 0.0, "avg_logprob": -0.19689501821994781, "compression_ratio": 1.7515151515151515, "no_speech_prob": 0.3756071627140045}, {"id": 201, "seek": 124960, "start": 1253.84, "end": 1259.9599999999998, "text": " That program would have standardized metrics that every dashboard or visualization or alerting,", "tokens": [50576, 663, 1461, 576, 362, 31677, 16367, 300, 633, 18342, 420, 25801, 420, 419, 27187, 11, 50882], "temperature": 0.0, "avg_logprob": -0.19689501821994781, "compression_ratio": 1.7515151515151515, "no_speech_prob": 0.3756071627140045}, {"id": 202, "seek": 124960, "start": 1259.9599999999998, "end": 1266.3999999999999, "text": " so we could have mix-ins that have alert rules and visualizations, and it would be able to", "tokens": [50882, 370, 321, 727, 362, 2890, 12, 1292, 300, 362, 9615, 4474, 293, 5056, 14455, 11, 293, 309, 576, 312, 1075, 281, 51204], "temperature": 0.0, "avg_logprob": -0.19689501821994781, "compression_ratio": 1.7515151515151515, "no_speech_prob": 0.3756071627140045}, {"id": 203, "seek": 124960, "start": 1266.3999999999999, "end": 1274.3999999999999, "text": " rely on standardized metrics that will always be present, and they would be exported directly", "tokens": [51204, 10687, 322, 31677, 16367, 300, 486, 1009, 312, 1974, 11, 293, 436, 576, 312, 42055, 3838, 51604], "temperature": 0.0, "avg_logprob": -0.19689501821994781, "compression_ratio": 1.7515151515151515, "no_speech_prob": 0.3756071627140045}, {"id": 204, "seek": 127440, "start": 1274.4, "end": 1281.8400000000001, "text": " from shared memory without going through the whole SQL infrastructure.", "tokens": [50364, 490, 5507, 4675, 1553, 516, 807, 264, 1379, 19200, 6896, 13, 50736], "temperature": 0.0, "avg_logprob": -0.1395974226400886, "compression_ratio": 1.5226130653266332, "no_speech_prob": 0.3124673068523407}, {"id": 205, "seek": 127440, "start": 1281.8400000000001, "end": 1289.24, "text": " So it would avoid depending on locks and transactions and all of the things that could interfere", "tokens": [50736, 407, 309, 576, 5042, 5413, 322, 20703, 293, 16856, 293, 439, 295, 264, 721, 300, 727, 23946, 51106], "temperature": 0.0, "avg_logprob": -0.1395974226400886, "compression_ratio": 1.5226130653266332, "no_speech_prob": 0.3124673068523407}, {"id": 206, "seek": 127440, "start": 1289.24, "end": 1293.96, "text": " with or be interfered with by the application.", "tokens": [51106, 365, 420, 312, 25799, 292, 365, 538, 264, 3861, 13, 51342], "temperature": 0.0, "avg_logprob": -0.1395974226400886, "compression_ratio": 1.5226130653266332, "no_speech_prob": 0.3124673068523407}, {"id": 207, "seek": 127440, "start": 1293.96, "end": 1300.24, "text": " It's still early days, I have a little proof of concept, but it's not going to be in the", "tokens": [51342, 467, 311, 920, 2440, 1708, 11, 286, 362, 257, 707, 8177, 295, 3410, 11, 457, 309, 311, 406, 516, 281, 312, 294, 264, 51656], "temperature": 0.0, "avg_logprob": -0.1395974226400886, "compression_ratio": 1.5226130653266332, "no_speech_prob": 0.3124673068523407}, {"id": 208, "seek": 130024, "start": 1300.24, "end": 1306.04, "text": " next version of Postgres, it's definitely experimental.", "tokens": [50364, 958, 3037, 295, 10223, 45189, 11, 309, 311, 2138, 17069, 13, 50654], "temperature": 0.0, "avg_logprob": -0.1740948204855317, "compression_ratio": 1.649402390438247, "no_speech_prob": 0.7015060186386108}, {"id": 209, "seek": 130024, "start": 1306.04, "end": 1312.6, "text": " The main difficulties are going to be sort of definitional problems of, for example,", "tokens": [50654, 440, 2135, 14399, 366, 516, 281, 312, 1333, 295, 1561, 2628, 2740, 295, 11, 337, 1365, 11, 50982], "temperature": 0.0, "avg_logprob": -0.1740948204855317, "compression_ratio": 1.649402390438247, "no_speech_prob": 0.7015060186386108}, {"id": 210, "seek": 130024, "start": 1312.6, "end": 1317.48, "text": " the table names, like I mentioned before, should a time series change when a table gets", "tokens": [50982, 264, 3199, 5288, 11, 411, 286, 2835, 949, 11, 820, 257, 565, 2638, 1319, 562, 257, 3199, 2170, 51226], "temperature": 0.0, "avg_logprob": -0.1740948204855317, "compression_ratio": 1.649402390438247, "no_speech_prob": 0.7015060186386108}, {"id": 211, "seek": 130024, "start": 1317.48, "end": 1318.88, "text": " renamed?", "tokens": [51226, 40949, 30, 51296], "temperature": 0.0, "avg_logprob": -0.1740948204855317, "compression_ratio": 1.649402390438247, "no_speech_prob": 0.7015060186386108}, {"id": 212, "seek": 130024, "start": 1318.88, "end": 1324.08, "text": " But in fact, I have a bigger problem because the table names are in the catalog, the schema", "tokens": [51296, 583, 294, 1186, 11, 286, 362, 257, 3801, 1154, 570, 264, 3199, 5288, 366, 294, 264, 19746, 11, 264, 34078, 51556], "temperature": 0.0, "avg_logprob": -0.1740948204855317, "compression_ratio": 1.649402390438247, "no_speech_prob": 0.7015060186386108}, {"id": 213, "seek": 130024, "start": 1324.08, "end": 1329.64, "text": " catalog, they're not in shared memory, and they're not, we don't really want them in", "tokens": [51556, 19746, 11, 436, 434, 406, 294, 5507, 4675, 11, 293, 436, 434, 406, 11, 321, 500, 380, 534, 528, 552, 294, 51834], "temperature": 0.0, "avg_logprob": -0.1740948204855317, "compression_ratio": 1.649402390438247, "no_speech_prob": 0.7015060186386108}, {"id": 214, "seek": 132964, "start": 1329.64, "end": 1341.6000000000001, "text": " shared memory, that brings in the whole risk of character encoding changes and collations.", "tokens": [50364, 5507, 4675, 11, 300, 5607, 294, 264, 1379, 3148, 295, 2517, 43430, 2962, 293, 1263, 763, 13, 50962], "temperature": 0.0, "avg_logprob": -0.21020140890347755, "compression_ratio": 1.4640883977900552, "no_speech_prob": 0.05895869806408882}, {"id": 215, "seek": 132964, "start": 1341.6000000000001, "end": 1352.64, "text": " So there's, it probably will only replace the core database metrics, and then you would", "tokens": [50962, 407, 456, 311, 11, 309, 1391, 486, 787, 7406, 264, 4965, 8149, 16367, 11, 293, 550, 291, 576, 51514], "temperature": 0.0, "avg_logprob": -0.21020140890347755, "compression_ratio": 1.4640883977900552, "no_speech_prob": 0.05895869806408882}, {"id": 216, "seek": 132964, "start": 1352.64, "end": 1357.6000000000001, "text": " still probably deploy a tool like Postgres Explorer only for your custom queries, only", "tokens": [51514, 920, 1391, 7274, 257, 2290, 411, 10223, 45189, 31895, 787, 337, 428, 2375, 24109, 11, 787, 51762], "temperature": 0.0, "avg_logprob": -0.21020140890347755, "compression_ratio": 1.4640883977900552, "no_speech_prob": 0.05895869806408882}, {"id": 217, "seek": 135760, "start": 1357.6, "end": 1369.1599999999999, "text": " for more application level metrics, not monitoring core Postgres metrics.", "tokens": [50364, 337, 544, 3861, 1496, 16367, 11, 406, 11028, 4965, 10223, 45189, 16367, 13, 50942], "temperature": 0.0, "avg_logprob": -0.2296600341796875, "compression_ratio": 1.3583333333333334, "no_speech_prob": 0.2674020230770111}, {"id": 218, "seek": 135760, "start": 1369.1599999999999, "end": 1374.52, "text": " So my hope is that when you deploy Postgres, you can add it to your targets in Prometheus", "tokens": [50942, 407, 452, 1454, 307, 300, 562, 291, 7274, 10223, 45189, 11, 291, 393, 909, 309, 281, 428, 12911, 294, 2114, 649, 42209, 51210], "temperature": 0.0, "avg_logprob": -0.2296600341796875, "compression_ratio": 1.3583333333333334, "no_speech_prob": 0.2674020230770111}, {"id": 219, "seek": 137452, "start": 1374.52, "end": 1391.2, "text": " and not have to do any further operational work to get dashboards and alerts.", "tokens": [50364, 293, 406, 362, 281, 360, 604, 3052, 16607, 589, 281, 483, 8240, 17228, 293, 28061, 13, 51198], "temperature": 0.0, "avg_logprob": -0.2889872127109104, "compression_ratio": 1.2242990654205608, "no_speech_prob": 0.49649402499198914}, {"id": 220, "seek": 137452, "start": 1391.2, "end": 1393.2, "text": " Two more minutes.", "tokens": [51198, 4453, 544, 2077, 13, 51298], "temperature": 0.0, "avg_logprob": -0.2889872127109104, "compression_ratio": 1.2242990654205608, "no_speech_prob": 0.49649402499198914}, {"id": 221, "seek": 137452, "start": 1393.2, "end": 1400.16, "text": " It feels like time is elastic here.", "tokens": [51298, 467, 3417, 411, 565, 307, 17115, 510, 13, 51646], "temperature": 0.0, "avg_logprob": -0.2889872127109104, "compression_ratio": 1.2242990654205608, "no_speech_prob": 0.49649402499198914}, {"id": 222, "seek": 140016, "start": 1400.16, "end": 1412.48, "text": " So I skipped over, I mean, so this is the proof of concept.", "tokens": [50364, 407, 286, 30193, 670, 11, 286, 914, 11, 370, 341, 307, 264, 8177, 295, 3410, 13, 50980], "temperature": 0.0, "avg_logprob": -0.15066258803657864, "compression_ratio": 1.4213483146067416, "no_speech_prob": 0.12507708370685577}, {"id": 223, "seek": 140016, "start": 1412.48, "end": 1417.1200000000001, "text": " The telemetry server in the first PS listing there is a single process.", "tokens": [50980, 440, 4304, 5537, 627, 7154, 294, 264, 700, 8168, 22161, 456, 307, 257, 2167, 1399, 13, 51212], "temperature": 0.0, "avg_logprob": -0.15066258803657864, "compression_ratio": 1.4213483146067416, "no_speech_prob": 0.12507708370685577}, {"id": 224, "seek": 140016, "start": 1417.1200000000001, "end": 1423.5600000000002, "text": " It's a Postgres background worker that can be, you can connect to it and get metrics", "tokens": [51212, 467, 311, 257, 10223, 45189, 3678, 11346, 300, 393, 312, 11, 291, 393, 1745, 281, 309, 293, 483, 16367, 51534], "temperature": 0.0, "avg_logprob": -0.15066258803657864, "compression_ratio": 1.4213483146067416, "no_speech_prob": 0.12507708370685577}, {"id": 225, "seek": 140016, "start": 1423.5600000000002, "end": 1427.44, "text": " with just ID numbers for the tables.", "tokens": [51534, 365, 445, 7348, 3547, 337, 264, 8020, 13, 51728], "temperature": 0.0, "avg_logprob": -0.15066258803657864, "compression_ratio": 1.4213483146067416, "no_speech_prob": 0.12507708370685577}, {"id": 226, "seek": 142744, "start": 1427.44, "end": 1432.2, "text": " And the second example is Postgres Exporter, and you can see there's a session, there's", "tokens": [50364, 400, 264, 1150, 1365, 307, 10223, 45189, 2111, 37356, 11, 293, 291, 393, 536, 456, 311, 257, 5481, 11, 456, 311, 50602], "temperature": 0.0, "avg_logprob": -0.15218669985547478, "compression_ratio": 1.786096256684492, "no_speech_prob": 0.03839688375592232}, {"id": 227, "seek": 142744, "start": 1432.2, "end": 1437.3600000000001, "text": " a database session, and with Postgres Exporter, there's a database session for each database,", "tokens": [50602, 257, 8149, 5481, 11, 293, 365, 10223, 45189, 2111, 37356, 11, 456, 311, 257, 8149, 5481, 337, 1184, 8149, 11, 50860], "temperature": 0.0, "avg_logprob": -0.15218669985547478, "compression_ratio": 1.786096256684492, "no_speech_prob": 0.03839688375592232}, {"id": 228, "seek": 142744, "start": 1437.3600000000001, "end": 1440.76, "text": " and they're all idle.", "tokens": [50860, 293, 436, 434, 439, 30650, 13, 51030], "temperature": 0.0, "avg_logprob": -0.15218669985547478, "compression_ratio": 1.786096256684492, "no_speech_prob": 0.03839688375592232}, {"id": 229, "seek": 142744, "start": 1440.76, "end": 1447.48, "text": " So even just reducing the number of sessions and reducing the number of processes involved", "tokens": [51030, 407, 754, 445, 12245, 264, 1230, 295, 11081, 293, 12245, 264, 1230, 295, 7555, 3288, 51366], "temperature": 0.0, "avg_logprob": -0.15218669985547478, "compression_ratio": 1.786096256684492, "no_speech_prob": 0.03839688375592232}, {"id": 230, "seek": 142744, "start": 1447.48, "end": 1456.44, "text": " is already quite a visible improvement.", "tokens": [51366, 307, 1217, 1596, 257, 8974, 10444, 13, 51814], "temperature": 0.0, "avg_logprob": -0.15218669985547478, "compression_ratio": 1.786096256684492, "no_speech_prob": 0.03839688375592232}, {"id": 231, "seek": 145644, "start": 1456.44, "end": 1463.1200000000001, "text": " I think I have more information if people have questions or want to see something specific,", "tokens": [50364, 286, 519, 286, 362, 544, 1589, 498, 561, 362, 1651, 420, 528, 281, 536, 746, 2685, 11, 50698], "temperature": 0.0, "avg_logprob": -0.15594051322158503, "compression_ratio": 1.3986486486486487, "no_speech_prob": 0.05617938190698624}, {"id": 232, "seek": 145644, "start": 1463.1200000000001, "end": 1470.6000000000001, "text": " but I tried to condense a much longer presentation to 25 minutes, so I've skipped over plenty", "tokens": [50698, 457, 286, 3031, 281, 2224, 1288, 257, 709, 2854, 5860, 281, 3552, 2077, 11, 370, 286, 600, 30193, 670, 7140, 51072], "temperature": 0.0, "avg_logprob": -0.15594051322158503, "compression_ratio": 1.3986486486486487, "no_speech_prob": 0.05617938190698624}, {"id": 233, "seek": 145644, "start": 1470.6000000000001, "end": 1471.6000000000001, "text": " of other information.", "tokens": [51072, 295, 661, 1589, 13, 51122], "temperature": 0.0, "avg_logprob": -0.15594051322158503, "compression_ratio": 1.3986486486486487, "no_speech_prob": 0.05617938190698624}, {"id": 234, "seek": 147160, "start": 1471.6, "end": 1477.1599999999999, "text": " If there's questions, that would be probably better than me just jumping around finding", "tokens": [50364, 759, 456, 311, 1651, 11, 300, 576, 312, 1391, 1101, 813, 385, 445, 11233, 926, 5006, 50642], "temperature": 0.0, "avg_logprob": -0.5224667739868164, "compression_ratio": 1.103448275862069, "no_speech_prob": 0.32325446605682373}, {"id": 235, "seek": 147160, "start": 1477.1599999999999, "end": 1489.6, "text": " a slide.", "tokens": [50642, 257, 4137, 13, 51264], "temperature": 0.0, "avg_logprob": -0.5224667739868164, "compression_ratio": 1.103448275862069, "no_speech_prob": 0.32325446605682373}, {"id": 236, "seek": 148960, "start": 1489.6, "end": 1499.9599999999998, "text": " Okay, so any questions, thanks a lot for the great talk, it was pretty interesting.", "tokens": [50364, 1033, 11, 370, 604, 1651, 11, 3231, 257, 688, 337, 264, 869, 751, 11, 309, 390, 1238, 1880, 13, 50882], "temperature": 0.0, "avg_logprob": -0.33480908075968424, "compression_ratio": 1.4496644295302012, "no_speech_prob": 0.2129819393157959}, {"id": 237, "seek": 148960, "start": 1499.9599999999998, "end": 1504.8, "text": " So any questions, anyone?", "tokens": [50882, 407, 604, 1651, 11, 2878, 30, 51124], "temperature": 0.0, "avg_logprob": -0.33480908075968424, "compression_ratio": 1.4496644295302012, "no_speech_prob": 0.2129819393157959}, {"id": 238, "seek": 148960, "start": 1504.8, "end": 1515.4399999999998, "text": " Hello, my name is Brian, you spoke about metrics, is there any traces or any talk of traces", "tokens": [51124, 2425, 11, 452, 1315, 307, 10765, 11, 291, 7179, 466, 16367, 11, 307, 456, 604, 26076, 420, 604, 751, 295, 26076, 51656], "temperature": 0.0, "avg_logprob": -0.33480908075968424, "compression_ratio": 1.4496644295302012, "no_speech_prob": 0.2129819393157959}, {"id": 239, "seek": 148960, "start": 1515.4399999999998, "end": 1517.9599999999998, "text": " in the future?", "tokens": [51656, 294, 264, 2027, 30, 51782], "temperature": 0.0, "avg_logprob": -0.33480908075968424, "compression_ratio": 1.4496644295302012, "no_speech_prob": 0.2129819393157959}, {"id": 240, "seek": 151796, "start": 1517.96, "end": 1525.76, "text": " I have ideas, I have plans, but they're all in my head, there's no code.", "tokens": [50364, 286, 362, 3487, 11, 286, 362, 5482, 11, 457, 436, 434, 439, 294, 452, 1378, 11, 456, 311, 572, 3089, 13, 50754], "temperature": 0.0, "avg_logprob": -0.14191717388986172, "compression_ratio": 1.7253886010362693, "no_speech_prob": 0.21217751502990723}, {"id": 241, "seek": 151796, "start": 1525.76, "end": 1531.4, "text": " Postgres does have explain plans, and explain plans are basically traces, but there's no", "tokens": [50754, 10223, 45189, 775, 362, 2903, 5482, 11, 293, 2903, 5482, 366, 1936, 26076, 11, 457, 456, 311, 572, 51036], "temperature": 0.0, "avg_logprob": -0.14191717388986172, "compression_ratio": 1.7253886010362693, "no_speech_prob": 0.21217751502990723}, {"id": 242, "seek": 151796, "start": 1531.4, "end": 1537.44, "text": " way to, what we have today is you run something on the terminal and you see the plan for your", "tokens": [51036, 636, 281, 11, 437, 321, 362, 965, 307, 291, 1190, 746, 322, 264, 14709, 293, 291, 536, 264, 1393, 337, 428, 51338], "temperature": 0.0, "avg_logprob": -0.14191717388986172, "compression_ratio": 1.7253886010362693, "no_speech_prob": 0.21217751502990723}, {"id": 243, "seek": 151796, "start": 1537.44, "end": 1544.44, "text": " query, and there's an extension that will dump the explain plans in the logs.", "tokens": [51338, 14581, 11, 293, 456, 311, 364, 10320, 300, 486, 11430, 264, 2903, 5482, 294, 264, 20820, 13, 51688], "temperature": 0.0, "avg_logprob": -0.14191717388986172, "compression_ratio": 1.7253886010362693, "no_speech_prob": 0.21217751502990723}, {"id": 244, "seek": 154444, "start": 1544.44, "end": 1550.88, "text": " So it wouldn't be much, it's a bit pie in the sky, but I don't see any reason we shouldn't", "tokens": [50364, 407, 309, 2759, 380, 312, 709, 11, 309, 311, 257, 857, 1730, 294, 264, 5443, 11, 457, 286, 500, 380, 536, 604, 1778, 321, 4659, 380, 50686], "temperature": 0.0, "avg_logprob": -0.13864493370056152, "compression_ratio": 1.5706214689265536, "no_speech_prob": 0.5864396095275879}, {"id": 245, "seek": 154444, "start": 1550.88, "end": 1560.16, "text": " be exporting that same information to a tracing server, and that basically just involves adding", "tokens": [50686, 312, 44686, 300, 912, 1589, 281, 257, 25262, 7154, 11, 293, 300, 1936, 445, 11626, 5127, 51150], "temperature": 0.0, "avg_logprob": -0.13864493370056152, "compression_ratio": 1.5706214689265536, "no_speech_prob": 0.5864396095275879}, {"id": 246, "seek": 154444, "start": 1560.16, "end": 1570.44, "text": " support for receiving the trace IDs, the spans, and creating spans for either plan nodes or", "tokens": [51150, 1406, 337, 10040, 264, 13508, 48212, 11, 264, 44086, 11, 293, 4084, 44086, 337, 2139, 1393, 13891, 420, 51664], "temperature": 0.0, "avg_logprob": -0.13864493370056152, "compression_ratio": 1.5706214689265536, "no_speech_prob": 0.5864396095275879}, {"id": 247, "seek": 157044, "start": 1570.44, "end": 1578.28, "text": " certain kinds of plan nodes, there's a lot of, it's not well thought out plans.", "tokens": [50364, 1629, 3685, 295, 1393, 13891, 11, 456, 311, 257, 688, 295, 11, 309, 311, 406, 731, 1194, 484, 5482, 13, 50756], "temperature": 0.0, "avg_logprob": -0.21779290712796726, "compression_ratio": 1.4628571428571429, "no_speech_prob": 0.3645971417427063}, {"id": 248, "seek": 157044, "start": 1578.28, "end": 1586.72, "text": " In my pie in the sky dream there is I want to be able to answer the question, which front", "tokens": [50756, 682, 452, 1730, 294, 264, 5443, 3055, 456, 307, 286, 528, 281, 312, 1075, 281, 1867, 264, 1168, 11, 597, 1868, 51178], "temperature": 0.0, "avg_logprob": -0.21779290712796726, "compression_ratio": 1.4628571428571429, "no_speech_prob": 0.3645971417427063}, {"id": 249, "seek": 157044, "start": 1586.72, "end": 1594.8400000000001, "text": " end web API endpoint is causing sequential scans on this table over here, skipping the", "tokens": [51178, 917, 3670, 9362, 35795, 307, 9853, 42881, 35116, 322, 341, 3199, 670, 510, 11, 31533, 264, 51584], "temperature": 0.0, "avg_logprob": -0.21779290712796726, "compression_ratio": 1.4628571428571429, "no_speech_prob": 0.3645971417427063}, {"id": 250, "seek": 159484, "start": 1594.84, "end": 1601.6799999999998, "text": " whole stack trace in the middle without having to dig all the way up.", "tokens": [50364, 1379, 8630, 13508, 294, 264, 2808, 1553, 1419, 281, 2528, 439, 264, 636, 493, 13, 50706], "temperature": 0.0, "avg_logprob": -0.2184610927806181, "compression_ratio": 1.5695652173913044, "no_speech_prob": 0.5307113528251648}, {"id": 251, "seek": 159484, "start": 1601.6799999999998, "end": 1609.48, "text": " So we have a architecture in which we have Postgres databases which are short lived running", "tokens": [50706, 407, 321, 362, 257, 9482, 294, 597, 321, 362, 10223, 45189, 22380, 597, 366, 2099, 5152, 2614, 51096], "temperature": 0.0, "avg_logprob": -0.2184610927806181, "compression_ratio": 1.5695652173913044, "no_speech_prob": 0.5307113528251648}, {"id": 252, "seek": 159484, "start": 1609.48, "end": 1616.28, "text": " in Docker containers, so the entire cluster basically will live and die for matters of", "tokens": [51096, 294, 33772, 17089, 11, 370, 264, 2302, 13630, 1936, 486, 1621, 293, 978, 337, 7001, 295, 51436], "temperature": 0.0, "avg_logprob": -0.2184610927806181, "compression_ratio": 1.5695652173913044, "no_speech_prob": 0.5307113528251648}, {"id": 253, "seek": 159484, "start": 1616.28, "end": 1619.8, "text": " possibly minutes or less.", "tokens": [51436, 6264, 2077, 420, 1570, 13, 51612], "temperature": 0.0, "avg_logprob": -0.2184610927806181, "compression_ratio": 1.5695652173913044, "no_speech_prob": 0.5307113528251648}, {"id": 254, "seek": 159484, "start": 1619.8, "end": 1623.0, "text": " And we would like to know what the hell is going on with them, have you got any bright", "tokens": [51612, 400, 321, 576, 411, 281, 458, 437, 264, 4921, 307, 516, 322, 365, 552, 11, 362, 291, 658, 604, 4730, 51772], "temperature": 0.0, "avg_logprob": -0.2184610927806181, "compression_ratio": 1.5695652173913044, "no_speech_prob": 0.5307113528251648}, {"id": 255, "seek": 162300, "start": 1623.0, "end": 1630.08, "text": " ideas?", "tokens": [50364, 3487, 30, 50718], "temperature": 0.0, "avg_logprob": -0.24780101776123048, "compression_ratio": 1.3359375, "no_speech_prob": 0.5474817752838135}, {"id": 256, "seek": 162300, "start": 1630.08, "end": 1638.24, "text": " I admit I don't think I've seen anybody trying to do that with Prometheus.", "tokens": [50718, 286, 9796, 286, 500, 380, 519, 286, 600, 1612, 4472, 1382, 281, 360, 300, 365, 2114, 649, 42209, 13, 51126], "temperature": 0.0, "avg_logprob": -0.24780101776123048, "compression_ratio": 1.3359375, "no_speech_prob": 0.5474817752838135}, {"id": 257, "seek": 162300, "start": 1638.24, "end": 1645.24, "text": " I mean it's not a best practice in Prometheus to have time series that keep changing, but", "tokens": [51126, 286, 914, 309, 311, 406, 257, 1151, 3124, 294, 2114, 649, 42209, 281, 362, 565, 2638, 300, 1066, 4473, 11, 457, 51476], "temperature": 0.0, "avg_logprob": -0.24780101776123048, "compression_ratio": 1.3359375, "no_speech_prob": 0.5474817752838135}, {"id": 258, "seek": 164524, "start": 1645.24, "end": 1654.56, "text": " you're kind of inevitably going to get a new bunch of time series with each database.", "tokens": [50364, 291, 434, 733, 295, 28171, 516, 281, 483, 257, 777, 3840, 295, 565, 2638, 365, 1184, 8149, 13, 50830], "temperature": 0.0, "avg_logprob": -0.2833114072500941, "compression_ratio": 1.5495049504950495, "no_speech_prob": 0.5381428599357605}, {"id": 259, "seek": 164524, "start": 1654.56, "end": 1660.0, "text": " I guess I need a better idea where you're looking.", "tokens": [50830, 286, 2041, 286, 643, 257, 1101, 1558, 689, 291, 434, 1237, 13, 51102], "temperature": 0.0, "avg_logprob": -0.2833114072500941, "compression_ratio": 1.5495049504950495, "no_speech_prob": 0.5381428599357605}, {"id": 260, "seek": 164524, "start": 1660.0, "end": 1664.88, "text": " I don't think I have anything off the top of my head that you wouldn't have already", "tokens": [51102, 286, 500, 380, 519, 286, 362, 1340, 766, 264, 1192, 295, 452, 1378, 300, 291, 2759, 380, 362, 1217, 51346], "temperature": 0.0, "avg_logprob": -0.2833114072500941, "compression_ratio": 1.5495049504950495, "no_speech_prob": 0.5381428599357605}, {"id": 261, "seek": 164524, "start": 1664.88, "end": 1666.6, "text": " thought about.", "tokens": [51346, 1194, 466, 13, 51432], "temperature": 0.0, "avg_logprob": -0.2833114072500941, "compression_ratio": 1.5495049504950495, "no_speech_prob": 0.5381428599357605}, {"id": 262, "seek": 164524, "start": 1666.6, "end": 1674.8, "text": " Hi, where can we get your proof concept from and fill it with it and test it?", "tokens": [51432, 2421, 11, 689, 393, 321, 483, 428, 8177, 3410, 490, 293, 2836, 309, 365, 309, 293, 1500, 309, 30, 51842], "temperature": 0.0, "avg_logprob": -0.2833114072500941, "compression_ratio": 1.5495049504950495, "no_speech_prob": 0.5381428599357605}, {"id": 263, "seek": 167480, "start": 1674.8, "end": 1676.84, "text": " I'm sorry, I didn't hear the question.", "tokens": [50364, 286, 478, 2597, 11, 286, 994, 380, 1568, 264, 1168, 13, 50466], "temperature": 0.0, "avg_logprob": -0.2156030469470554, "compression_ratio": 1.4943820224719102, "no_speech_prob": 0.0671892985701561}, {"id": 264, "seek": 167480, "start": 1676.84, "end": 1682.08, "text": " Where can you get your proof of concept from to test it and fill it with it?", "tokens": [50466, 2305, 393, 291, 483, 428, 8177, 295, 3410, 490, 281, 1500, 309, 293, 2836, 309, 365, 309, 30, 50728], "temperature": 0.0, "avg_logprob": -0.2156030469470554, "compression_ratio": 1.4943820224719102, "no_speech_prob": 0.0671892985701561}, {"id": 265, "seek": 167480, "start": 1682.08, "end": 1687.96, "text": " I posted a patch to the mailing list.", "tokens": [50728, 286, 9437, 257, 9972, 281, 264, 41612, 1329, 13, 51022], "temperature": 0.0, "avg_logprob": -0.2156030469470554, "compression_ratio": 1.4943820224719102, "no_speech_prob": 0.0671892985701561}, {"id": 266, "seek": 167480, "start": 1687.96, "end": 1696.72, "text": " Postgres follows a fairly old school patch review process where patches are mailed to", "tokens": [51022, 10223, 45189, 10002, 257, 6457, 1331, 1395, 9972, 3131, 1399, 689, 26531, 366, 463, 7292, 281, 51460], "temperature": 0.0, "avg_logprob": -0.2156030469470554, "compression_ratio": 1.4943820224719102, "no_speech_prob": 0.0671892985701561}, {"id": 267, "seek": 167480, "start": 1696.72, "end": 1699.0, "text": " the hacker's mailing list.", "tokens": [51460, 264, 38155, 311, 41612, 1329, 13, 51574], "temperature": 0.0, "avg_logprob": -0.2156030469470554, "compression_ratio": 1.4943820224719102, "no_speech_prob": 0.0671892985701561}, {"id": 268, "seek": 169900, "start": 1699.0, "end": 1721.64, "text": " So it's easy to lose sight of patches if they get posted and it was months ago.", "tokens": [50364, 407, 309, 311, 1858, 281, 3624, 7860, 295, 26531, 498, 436, 483, 9437, 293, 309, 390, 2493, 2057, 13, 51496], "temperature": 0.0, "avg_logprob": -0.1461876596723284, "compression_ratio": 1.202127659574468, "no_speech_prob": 0.0884619727730751}, {"id": 269, "seek": 169900, "start": 1721.64, "end": 1725.64, "text": " I can send it to you if you want.", "tokens": [51496, 286, 393, 2845, 309, 281, 291, 498, 291, 528, 13, 51696], "temperature": 0.0, "avg_logprob": -0.1461876596723284, "compression_ratio": 1.202127659574468, "no_speech_prob": 0.0884619727730751}, {"id": 270, "seek": 172564, "start": 1725.64, "end": 1729.3600000000001, "text": " You can probably find it on the mailing list if you search.", "tokens": [50364, 509, 393, 1391, 915, 309, 322, 264, 41612, 1329, 498, 291, 3164, 13, 50550], "temperature": 0.0, "avg_logprob": -0.23196460405985514, "compression_ratio": 1.4219653179190752, "no_speech_prob": 0.3425002694129944}, {"id": 271, "seek": 172564, "start": 1729.3600000000001, "end": 1730.96, "text": " It's pretty early days though.", "tokens": [50550, 467, 311, 1238, 2440, 1708, 1673, 13, 50630], "temperature": 0.0, "avg_logprob": -0.23196460405985514, "compression_ratio": 1.4219653179190752, "no_speech_prob": 0.3425002694129944}, {"id": 272, "seek": 172564, "start": 1730.96, "end": 1744.68, "text": " It's not really ready to use even for experimental production uses.", "tokens": [50630, 467, 311, 406, 534, 1919, 281, 764, 754, 337, 17069, 4265, 4960, 13, 51316], "temperature": 0.0, "avg_logprob": -0.23196460405985514, "compression_ratio": 1.4219653179190752, "no_speech_prob": 0.3425002694129944}, {"id": 273, "seek": 172564, "start": 1744.68, "end": 1752.16, "text": " With that integrated matrix, how do you expose the matrix to have an HTTP endpoint that", "tokens": [51316, 2022, 300, 10919, 8141, 11, 577, 360, 291, 19219, 264, 8141, 281, 362, 364, 33283, 35795, 300, 51690], "temperature": 0.0, "avg_logprob": -0.23196460405985514, "compression_ratio": 1.4219653179190752, "no_speech_prob": 0.3425002694129944}, {"id": 274, "seek": 175216, "start": 1752.16, "end": 1758.6000000000001, "text": " exposed directly from Postgres?", "tokens": [50364, 9495, 3838, 490, 10223, 45189, 30, 50686], "temperature": 0.0, "avg_logprob": -0.21385488510131836, "compression_ratio": 1.4885057471264367, "no_speech_prob": 0.4030401110649109}, {"id": 275, "seek": 175216, "start": 1758.6000000000001, "end": 1763.96, "text": " The current situation is it's a background worker and that background worker has a configuration", "tokens": [50686, 440, 2190, 2590, 307, 309, 311, 257, 3678, 11346, 293, 300, 3678, 11346, 575, 257, 11694, 50954], "temperature": 0.0, "avg_logprob": -0.21385488510131836, "compression_ratio": 1.4885057471264367, "no_speech_prob": 0.4030401110649109}, {"id": 276, "seek": 175216, "start": 1763.96, "end": 1775.0800000000002, "text": " option to specify a second port to listen on and it runs a very small embedded web server", "tokens": [50954, 3614, 281, 16500, 257, 1150, 2436, 281, 2140, 322, 293, 309, 6676, 257, 588, 1359, 16741, 3670, 7154, 51510], "temperature": 0.0, "avg_logprob": -0.21385488510131836, "compression_ratio": 1.4885057471264367, "no_speech_prob": 0.4030401110649109}, {"id": 277, "seek": 175216, "start": 1775.0800000000002, "end": 1780.92, "text": " so it responds to normal HTTPS requests.", "tokens": [51510, 370, 309, 27331, 281, 2710, 11751, 51, 6273, 12475, 13, 51802], "temperature": 0.0, "avg_logprob": -0.21385488510131836, "compression_ratio": 1.4885057471264367, "no_speech_prob": 0.4030401110649109}, {"id": 278, "seek": 178092, "start": 1781.52, "end": 1789.3200000000002, "text": " I would want the normal Postgres port to respond so that your label, your target is just the", "tokens": [50394, 286, 576, 528, 264, 2710, 10223, 45189, 2436, 281, 4196, 370, 300, 428, 7645, 11, 428, 3779, 307, 445, 264, 50784], "temperature": 0.0, "avg_logprob": -0.20734467304928203, "compression_ratio": 1.5337078651685394, "no_speech_prob": 0.47096070647239685}, {"id": 279, "seek": 178092, "start": 1789.3200000000002, "end": 1792.68, "text": " database port.", "tokens": [50784, 8149, 2436, 13, 50952], "temperature": 0.0, "avg_logprob": -0.20734467304928203, "compression_ratio": 1.5337078651685394, "no_speech_prob": 0.47096070647239685}, {"id": 280, "seek": 178092, "start": 1792.68, "end": 1799.64, "text": " I expect, well, I actually have already heard a lot of pushback on that idea.", "tokens": [50952, 286, 2066, 11, 731, 11, 286, 767, 362, 1217, 2198, 257, 688, 295, 2944, 3207, 322, 300, 1558, 13, 51300], "temperature": 0.0, "avg_logprob": -0.20734467304928203, "compression_ratio": 1.5337078651685394, "no_speech_prob": 0.47096070647239685}, {"id": 281, "seek": 178092, "start": 1799.64, "end": 1810.24, "text": " A lot of Postgres installs are sort of old school where you probably have it firewalled", "tokens": [51300, 316, 688, 295, 10223, 45189, 3625, 82, 366, 1333, 295, 1331, 1395, 689, 291, 1391, 362, 309, 36109, 292, 51830], "temperature": 0.0, "avg_logprob": -0.20734467304928203, "compression_ratio": 1.5337078651685394, "no_speech_prob": 0.47096070647239685}, {"id": 282, "seek": 181024, "start": 1810.36, "end": 1815.72, "text": " and you don't want to have two different, you don't want to have a new service running", "tokens": [50370, 293, 291, 500, 380, 528, 281, 362, 732, 819, 11, 291, 500, 380, 528, 281, 362, 257, 777, 2643, 2614, 50638], "temperature": 0.0, "avg_logprob": -0.15477556285291616, "compression_ratio": 1.8867924528301887, "no_speech_prob": 0.006482355762273073}, {"id": 283, "seek": 181024, "start": 1815.72, "end": 1821.72, "text": " on a port, the same port as the actual database, you want to have a port that you can firewall", "tokens": [50638, 322, 257, 2436, 11, 264, 912, 2436, 382, 264, 3539, 8149, 11, 291, 528, 281, 362, 257, 2436, 300, 291, 393, 36109, 50938], "temperature": 0.0, "avg_logprob": -0.15477556285291616, "compression_ratio": 1.8867924528301887, "no_speech_prob": 0.006482355762273073}, {"id": 284, "seek": 181024, "start": 1821.72, "end": 1824.8, "text": " separately for your admin stack.", "tokens": [50938, 14759, 337, 428, 24236, 8630, 13, 51092], "temperature": 0.0, "avg_logprob": -0.15477556285291616, "compression_ratio": 1.8867924528301887, "no_speech_prob": 0.006482355762273073}, {"id": 285, "seek": 181024, "start": 1824.8, "end": 1833.04, "text": " It makes Prometheus very difficult to manage when you have a different port to get metrics", "tokens": [51092, 467, 1669, 2114, 649, 42209, 588, 2252, 281, 3067, 562, 291, 362, 257, 819, 2436, 281, 483, 16367, 51504], "temperature": 0.0, "avg_logprob": -0.15477556285291616, "compression_ratio": 1.8867924528301887, "no_speech_prob": 0.006482355762273073}, {"id": 286, "seek": 181024, "start": 1833.04, "end": 1834.48, "text": " about.", "tokens": [51504, 466, 13, 51576], "temperature": 0.0, "avg_logprob": -0.15477556285291616, "compression_ratio": 1.8867924528301887, "no_speech_prob": 0.006482355762273073}, {"id": 287, "seek": 181024, "start": 1834.48, "end": 1839.2, "text": " So you have database running on port A and then you have metrics on port B and you have", "tokens": [51576, 407, 291, 362, 8149, 2614, 322, 2436, 316, 293, 550, 291, 362, 16367, 322, 2436, 363, 293, 291, 362, 51812], "temperature": 0.0, "avg_logprob": -0.15477556285291616, "compression_ratio": 1.8867924528301887, "no_speech_prob": 0.006482355762273073}, {"id": 288, "seek": 183920, "start": 1839.28, "end": 1846.8, "text": " to have your dashboards and the targets and so on all configured to understand that the", "tokens": [50368, 281, 362, 428, 8240, 17228, 293, 264, 12911, 293, 370, 322, 439, 30538, 281, 1223, 300, 264, 50744], "temperature": 0.0, "avg_logprob": -0.15439487828148735, "compression_ratio": 1.6830601092896176, "no_speech_prob": 0.011297334916889668}, {"id": 289, "seek": 183920, "start": 1846.8, "end": 1852.32, "text": " target with port B is actually the database on port A and you can add rewrite rules but", "tokens": [50744, 3779, 365, 2436, 363, 307, 767, 264, 8149, 322, 2436, 316, 293, 291, 393, 909, 28132, 4474, 457, 51020], "temperature": 0.0, "avg_logprob": -0.15439487828148735, "compression_ratio": 1.6830601092896176, "no_speech_prob": 0.011297334916889668}, {"id": 290, "seek": 183920, "start": 1852.32, "end": 1856.92, "text": " then you have to manage those rewrite rules.", "tokens": [51020, 550, 291, 362, 281, 3067, 729, 28132, 4474, 13, 51250], "temperature": 0.0, "avg_logprob": -0.15439487828148735, "compression_ratio": 1.6830601092896176, "no_speech_prob": 0.011297334916889668}, {"id": 291, "seek": 183920, "start": 1856.92, "end": 1866.52, "text": " But I don't really expect people to accept the idea of responding on the database port.", "tokens": [51250, 583, 286, 500, 380, 534, 2066, 561, 281, 3241, 264, 1558, 295, 16670, 322, 264, 8149, 2436, 13, 51730], "temperature": 0.0, "avg_logprob": -0.15439487828148735, "compression_ratio": 1.6830601092896176, "no_speech_prob": 0.011297334916889668}, {"id": 292, "seek": 186652, "start": 1866.52, "end": 1874.28, "text": " There's also a general security principle involved of, it's almost always a terrible", "tokens": [50364, 821, 311, 611, 257, 2674, 3825, 8665, 3288, 295, 11, 309, 311, 1920, 1009, 257, 6237, 50752], "temperature": 0.0, "avg_logprob": -0.16095923200065707, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.3974483013153076}, {"id": 293, "seek": 186652, "start": 1874.28, "end": 1879.52, "text": " idea for security reasons to respond to two different protocols on the same port because", "tokens": [50752, 1558, 337, 3825, 4112, 281, 4196, 281, 732, 819, 20618, 322, 264, 912, 2436, 570, 51014], "temperature": 0.0, "avg_logprob": -0.16095923200065707, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.3974483013153076}, {"id": 294, "seek": 186652, "start": 1879.52, "end": 1887.12, "text": " a lot of security vulnerabilities have come about from arranging, like finding bugs where", "tokens": [51014, 257, 688, 295, 3825, 37633, 362, 808, 466, 490, 5539, 9741, 11, 411, 5006, 15120, 689, 51394], "temperature": 0.0, "avg_logprob": -0.16095923200065707, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.3974483013153076}, {"id": 295, "seek": 186652, "start": 1887.12, "end": 1891.36, "text": " one side of a connection thinks you're talking protocol A and the other side thinks you're", "tokens": [51394, 472, 1252, 295, 257, 4984, 7309, 291, 434, 1417, 10336, 316, 293, 264, 661, 1252, 7309, 291, 434, 51606], "temperature": 0.0, "avg_logprob": -0.16095923200065707, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.3974483013153076}, {"id": 296, "seek": 186652, "start": 1891.36, "end": 1893.72, "text": " talking protocol B.", "tokens": [51606, 1417, 10336, 363, 13, 51724], "temperature": 0.0, "avg_logprob": -0.16095923200065707, "compression_ratio": 1.6846846846846846, "no_speech_prob": 0.3974483013153076}, {"id": 297, "seek": 189372, "start": 1893.72, "end": 1899.3600000000001, "text": " So it's probably, there's big trade-offs to doing that.", "tokens": [50364, 407, 309, 311, 1391, 11, 456, 311, 955, 4923, 12, 19231, 281, 884, 300, 13, 50646], "temperature": 0.0, "avg_logprob": -0.3730573875959529, "compression_ratio": 1.475770925110132, "no_speech_prob": 0.045161254703998566}, {"id": 298, "seek": 189372, "start": 1899.3600000000001, "end": 1906.28, "text": " First of all, thanks a lot for the amazing talk, very insightful.", "tokens": [50646, 2386, 295, 439, 11, 3231, 257, 688, 337, 264, 2243, 751, 11, 588, 46401, 13, 50992], "temperature": 0.0, "avg_logprob": -0.3730573875959529, "compression_ratio": 1.475770925110132, "no_speech_prob": 0.045161254703998566}, {"id": 299, "seek": 189372, "start": 1906.28, "end": 1909.3600000000001, "text": " Thanks for offering to modernize POSGRACE monitoring.", "tokens": [50992, 2561, 337, 8745, 281, 4363, 1125, 430, 4367, 38, 3750, 4969, 11028, 13, 51146], "temperature": 0.0, "avg_logprob": -0.3730573875959529, "compression_ratio": 1.475770925110132, "no_speech_prob": 0.045161254703998566}, {"id": 300, "seek": 189372, "start": 1909.3600000000001, "end": 1915.16, "text": " You had a very good point there about standardizing on the metrics.", "tokens": [51146, 509, 632, 257, 588, 665, 935, 456, 466, 3832, 3319, 322, 264, 16367, 13, 51436], "temperature": 0.0, "avg_logprob": -0.3730573875959529, "compression_ratio": 1.475770925110132, "no_speech_prob": 0.045161254703998566}, {"id": 301, "seek": 189372, "start": 1915.16, "end": 1919.8, "text": " I've been involved in the semantic conventions around open telemetry and other projects but", "tokens": [51436, 286, 600, 668, 3288, 294, 264, 47982, 33520, 926, 1269, 4304, 5537, 627, 293, 661, 4455, 457, 51668], "temperature": 0.0, "avg_logprob": -0.3730573875959529, "compression_ratio": 1.475770925110132, "no_speech_prob": 0.045161254703998566}, {"id": 302, "seek": 191980, "start": 1919.8, "end": 1926.08, "text": " in general, I'm curious to hear if you personally or Ivan or anyone else, what kind of effort", "tokens": [50364, 294, 2674, 11, 286, 478, 6369, 281, 1568, 498, 291, 5665, 420, 28893, 420, 2878, 1646, 11, 437, 733, 295, 4630, 50678], "temperature": 0.0, "avg_logprob": -0.16662084488641649, "compression_ratio": 1.4976525821596245, "no_speech_prob": 0.058712538331747055}, {"id": 303, "seek": 191980, "start": 1926.08, "end": 1933.04, "text": " is being done to standardize on database monitoring metrics, not specifically POSGRACE but databases", "tokens": [50678, 307, 885, 1096, 281, 3832, 1125, 322, 8149, 11028, 16367, 11, 406, 4682, 430, 4367, 38, 3750, 4969, 457, 22380, 51026], "temperature": 0.0, "avg_logprob": -0.16662084488641649, "compression_ratio": 1.4976525821596245, "no_speech_prob": 0.058712538331747055}, {"id": 304, "seek": 191980, "start": 1933.04, "end": 1937.8, "text": " in general, if you can share?", "tokens": [51026, 294, 2674, 11, 498, 291, 393, 2073, 30, 51264], "temperature": 0.0, "avg_logprob": -0.16662084488641649, "compression_ratio": 1.4976525821596245, "no_speech_prob": 0.058712538331747055}, {"id": 305, "seek": 191980, "start": 1937.8, "end": 1939.2, "text": " I would be interested in that.", "tokens": [51264, 286, 576, 312, 3102, 294, 300, 13, 51334], "temperature": 0.0, "avg_logprob": -0.16662084488641649, "compression_ratio": 1.4976525821596245, "no_speech_prob": 0.058712538331747055}, {"id": 306, "seek": 191980, "start": 1939.2, "end": 1946.04, "text": " I haven't heard anything on that front.", "tokens": [51334, 286, 2378, 380, 2198, 1340, 322, 300, 1868, 13, 51676], "temperature": 0.0, "avg_logprob": -0.16662084488641649, "compression_ratio": 1.4976525821596245, "no_speech_prob": 0.058712538331747055}, {"id": 307, "seek": 191980, "start": 1946.04, "end": 1947.04, "text": " That would be exciting.", "tokens": [51676, 663, 576, 312, 4670, 13, 51726], "temperature": 0.0, "avg_logprob": -0.16662084488641649, "compression_ratio": 1.4976525821596245, "no_speech_prob": 0.058712538331747055}, {"id": 308, "seek": 194704, "start": 1947.04, "end": 1949.6399999999999, "text": " That would be a lot of work.", "tokens": [50364, 663, 576, 312, 257, 688, 295, 589, 13, 50494], "temperature": 0.0, "avg_logprob": -0.2735668444165997, "compression_ratio": 1.401639344262295, "no_speech_prob": 0.27707335352897644}, {"id": 309, "seek": 194704, "start": 1949.6399999999999, "end": 1963.12, "text": " I think there's a lot of, a lot of the interesting metrics are very, that would be difficult.", "tokens": [50494, 286, 519, 456, 311, 257, 688, 295, 11, 257, 688, 295, 264, 1880, 16367, 366, 588, 11, 300, 576, 312, 2252, 13, 51168], "temperature": 0.0, "avg_logprob": -0.2735668444165997, "compression_ratio": 1.401639344262295, "no_speech_prob": 0.27707335352897644}, {"id": 310, "seek": 194704, "start": 1963.12, "end": 1970.12, "text": " I don't know, I haven't seen anything like that.", "tokens": [51168, 286, 500, 380, 458, 11, 286, 2378, 380, 1612, 1340, 411, 300, 13, 51518], "temperature": 0.0, "avg_logprob": -0.2735668444165997, "compression_ratio": 1.401639344262295, "no_speech_prob": 0.27707335352897644}, {"id": 311, "seek": 197012, "start": 1970.12, "end": 1979.28, "text": " Okay, so thanks a lot everyone.", "tokens": [50364, 1033, 11, 370, 3231, 257, 688, 1518, 13, 50822], "temperature": 0.0, "avg_logprob": -0.6747205474159934, "compression_ratio": 0.7948717948717948, "no_speech_prob": 0.27437227964401245}], "language": "en"}