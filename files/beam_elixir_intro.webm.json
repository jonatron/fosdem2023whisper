{"text": " All right, cool. So again, apologies for being this late. I really don't take it out on the people that are organizing this room. It's really my fault. So I hope still you have a nice day. And I'll try to keep it short, so we stay on schedule. So this is kind of an introductory talk for people that are new to Elixir and Alang. So Elixir is a language which now already exists for 10 years. And it's built on top of the Beam virtual machine, also called the Erlang VM. So it had some of the properties that the Beam runtime has as well. And the Beam runtime is actually created for telecom systems. So it's meant to be 24-7 on. And by doing that, it has to be full torrent, so if something goes wrong, it can still heal and keep on running. And because it has to be on all the time, it also means that any code changes should be done on the fly. All the system is running without interruptions, without bringing systems down, bringing systems up. But just keep things running on and changing the code under the hood. It also needed to be concurrent, because it needed to handle a lot of incoming telephone calls at the same time. And it also needs to be distributed, because you have to connect telephone switches together and make sure that everything runs smoothly. So those are kind of the properties that Erlang also inherited from Erlang as well. So when you look at other systems, multi-threaded, OK, programming can be hard. So in theory, it should all work like we have, you know, if you want to do something concurrently, we spawn a few threads and they do their work. But in practices, because threads can actually interfere with each other's work, it actually becomes a mess. So hence the second picture. The other property that Erlang has is full torrents. So in Erlang, you set up a supervision tree in which a supervisor is actually watching, monitoring, or worker. And if one of those processes dies, then the supervisor actually makes sure that a new process is spawned in its place. And the system as a whole keeps running, even though one of the parts actually fail. And so the mantra that's very often told in Erlang is, let it crash. Nice timing, OK. Because people feel safe by, you know, if there's an exception, if your code always goes for the happy path and something goes wrong, Erlang developers tend to not care that much about it because the system, like the supervisor, will restart that process again. So very exceptional edge cases are sometimes not covered because they feel comfortable having the system pick it up from there as well. Before Alexa came around, Erlang also existed for quite some while. So Alexa also inherited some of the experience of 20 years building telecom systems, which also makes it, for example, WhatsApp had only 57 engineers working for them when they were sold to Facebook. But only about 20 of them were Erlang developers. The rest were actually mobile developers supporting Android, Windows, iOS, et cetera. And they actually could handle a lot of users while having a small team. So then the question also becomes a little bit why does Alexa exist? And when people, like, innovate when they're building new things, there are approximately three things, three ways they can go around it. So they completely build something very new, which didn't exist before. Or they try to combine the ideas from previous, from other fields, for example. Or in some cases, people just put a new label on it and say, well, this is new. This is innovation. So hence the title of my talk is, is Alexa really something new? Or is it just a new label on the existing Erlang foundation? And some other languages, they, you know, they've tried to incrementally do some innovations. But after a while, the original sources picked up those changes. In this, like, CoffeeScript is a very famous example, in which the original language picked up those changes and nowadays a lot less people actually use CoffeeScript. So how we're doing on time, okay. So the question is then also, why did Jose, kind of the creator of Alexa, why did he write a new language? And he was at a time when he wrote, Alexa was working at the Rails team. And one of the things that he faced was trying to make Rails thread safe, so making sure that several threads that were running in the Rails program weren't interfering with each other. And by doing that, he was actually looking around, how did other, like folks, how there are other problems in languages, other frameworks, how did they solve that issue? And that's when he actually stumbled upon Erlang. And he liked it. It was, you know, just the thing he needed to use. But there were also some things that he was actually missing. So for starters, the syntax stems from Prolog. So it's unfamiliar for a lot of people. So that means that new people who come to Erlang have to, you know, have a high barrier to, okay, high barrier to actually get around because they feel unfamiliar with the syntax. So he did that first. And he also introduced other new syntax, for example, the pipe operator in which, like the result of the previous expression, is piped into the next function as a first parameter. So by doing that, you can avoid having a very nested function calls by having something that's more readable, more clear to other people. He also introduced more extensibility to the language by introducing macros and protocols. And one of my favorites is actually the bottom one. I'm not sure if everybody can read it, but it's an upcase function which takes a string and upcases every letter. And it does that under the hood via a macro. So the Unicode definition, like the library definitions of characters is downloaded and actually being translated to functions under the hood. So when you call this, you're actually using, you know, some data that is transformed into functions for the language. I'll skip over this part because we don't have judgment time. And you also actually see that those macros are used everywhere. So even like, you know, defining a module is a macro, defining a function, et cetera. Everything is actually implemented through macros. The other thing that he also introduced is the build tool to make it easier for people who are, for example, new to the language. If you want to have a package manager, like before, didn't really have package management, like in the sense that you could add packages to your project, but you had to download them by yourself, put them somewhere, define it in your config, like, okay, this is the path to my library that I'm using. And with Hex and with Mixed, Alex just made it easier, but, you know, by having a list of dependencies and go download it from a central place. Documentation was also made more prominent. For example, the doc tests, which are inspired by Python. So in this case, we have a function defined, and above it is a document, a comment in which there's an example. And this example doesn't serve only for documentation, but at the same time, it's also tests. So, you know, actually, you can, if you would change the implementation, you can directly see the effect of it because the test is just above it as documentation fails. So, and, yeah, the documentation is also accessible from Rappel, from other places. And this was built before the LSP. So nowadays, you can, you know, just hover over function in your editor, and you will see the documentation. But when Elixir was created, those functionalities weren't that common, like among other languages, and that's something that's really nice to work with. And the last thing that he kind of also introduced is a different culture, a culture which is a little bit more open to newcomers. So it's not like Erlang, you know, shed away from newcomers, but it also didn't, like, make it easier for new people who are new to the language to get started with it, et cetera. So that whole, you know, like, to come back to my question, like, is Elixir in kind of new flavor on top of Erlang? I think there are kind of projects stemming from Elixir which make it more interesting and which are really new. So, for example, NX numerical Elixir is an extension which makes machine learning easy, and that's something that, you know, before Elixir, nobody actually thought would be useful to do with the beam, with the Erlang VM, because it wasn't meant for that. It wasn't meant for numerical, for number crunching. But this library, this tooling actually makes it a lot easier to do, and that's very promising. Phoenix is actually a web framework which was inspired by Rails, and now study arounds. Phoenix is now an inspiration for Rails and other frameworks to work with. And NERVs is also kind of an interesting project which makes it possible to run on smaller devices like Raspberry Pis or something like this. So to answer the question, is Elixir really different from Erlang? Is it really, you know, an innovation or is it rehashing? I would say no. I think Elixir really adds something to the whole ecosystem, which wasn't that easy before that. So with that being said, thanks for listening. Thank you. Unfortunately, we don't have any time for Q&A, but you can find, don't you? Yes. Here. Again, I usually have the handle toxified, so on Twitter, if it still works or mastered on you, you can also find me. And I'll be around, I think, for today if you have any further questions. So thanks again for listening, and apologies for being this late. Thank you again. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 7.5200000000000005, "text": " All right, cool.", "tokens": [1057, 558, 11, 1627, 13], "temperature": 0.0, "avg_logprob": -0.2212099655814793, "compression_ratio": 1.5766129032258065, "no_speech_prob": 0.2816476821899414}, {"id": 1, "seek": 0, "start": 7.5200000000000005, "end": 9.68, "text": " So again, apologies for being this late.", "tokens": [407, 797, 11, 34929, 337, 885, 341, 3469, 13], "temperature": 0.0, "avg_logprob": -0.2212099655814793, "compression_ratio": 1.5766129032258065, "no_speech_prob": 0.2816476821899414}, {"id": 2, "seek": 0, "start": 9.68, "end": 12.88, "text": " I really don't take it out on the people that are organizing this room.", "tokens": [286, 534, 500, 380, 747, 309, 484, 322, 264, 561, 300, 366, 17608, 341, 1808, 13], "temperature": 0.0, "avg_logprob": -0.2212099655814793, "compression_ratio": 1.5766129032258065, "no_speech_prob": 0.2816476821899414}, {"id": 3, "seek": 0, "start": 12.88, "end": 14.6, "text": " It's really my fault.", "tokens": [467, 311, 534, 452, 7441, 13], "temperature": 0.0, "avg_logprob": -0.2212099655814793, "compression_ratio": 1.5766129032258065, "no_speech_prob": 0.2816476821899414}, {"id": 4, "seek": 0, "start": 14.6, "end": 17.04, "text": " So I hope still you have a nice day.", "tokens": [407, 286, 1454, 920, 291, 362, 257, 1481, 786, 13], "temperature": 0.0, "avg_logprob": -0.2212099655814793, "compression_ratio": 1.5766129032258065, "no_speech_prob": 0.2816476821899414}, {"id": 5, "seek": 0, "start": 17.04, "end": 20.76, "text": " And I'll try to keep it short, so we stay on schedule.", "tokens": [400, 286, 603, 853, 281, 1066, 309, 2099, 11, 370, 321, 1754, 322, 7567, 13], "temperature": 0.0, "avg_logprob": -0.2212099655814793, "compression_ratio": 1.5766129032258065, "no_speech_prob": 0.2816476821899414}, {"id": 6, "seek": 0, "start": 20.76, "end": 25.04, "text": " So this is kind of an introductory talk for people that are new to Elixir and Alang.", "tokens": [407, 341, 307, 733, 295, 364, 39048, 751, 337, 561, 300, 366, 777, 281, 2699, 970, 347, 293, 967, 656, 13], "temperature": 0.0, "avg_logprob": -0.2212099655814793, "compression_ratio": 1.5766129032258065, "no_speech_prob": 0.2816476821899414}, {"id": 7, "seek": 0, "start": 25.04, "end": 28.96, "text": " So Elixir is a language which now already exists for 10 years.", "tokens": [407, 2699, 970, 347, 307, 257, 2856, 597, 586, 1217, 8198, 337, 1266, 924, 13], "temperature": 0.0, "avg_logprob": -0.2212099655814793, "compression_ratio": 1.5766129032258065, "no_speech_prob": 0.2816476821899414}, {"id": 8, "seek": 2896, "start": 28.96, "end": 32.76, "text": " And it's built on top of the Beam virtual machine, also called the Erlang VM.", "tokens": [400, 309, 311, 3094, 322, 1192, 295, 264, 40916, 6374, 3479, 11, 611, 1219, 264, 3300, 25241, 18038, 13], "temperature": 0.0, "avg_logprob": -0.15351009368896484, "compression_ratio": 1.7067669172932332, "no_speech_prob": 0.0002519877743907273}, {"id": 9, "seek": 2896, "start": 32.76, "end": 37.96, "text": " So it had some of the properties that the Beam runtime has as well.", "tokens": [407, 309, 632, 512, 295, 264, 7221, 300, 264, 40916, 34474, 575, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.15351009368896484, "compression_ratio": 1.7067669172932332, "no_speech_prob": 0.0002519877743907273}, {"id": 10, "seek": 2896, "start": 37.96, "end": 42.120000000000005, "text": " And the Beam runtime is actually created for telecom systems.", "tokens": [400, 264, 40916, 34474, 307, 767, 2942, 337, 4304, 1112, 3652, 13], "temperature": 0.0, "avg_logprob": -0.15351009368896484, "compression_ratio": 1.7067669172932332, "no_speech_prob": 0.0002519877743907273}, {"id": 11, "seek": 2896, "start": 42.120000000000005, "end": 45.0, "text": " So it's meant to be 24-7 on.", "tokens": [407, 309, 311, 4140, 281, 312, 4022, 12, 22, 322, 13], "temperature": 0.0, "avg_logprob": -0.15351009368896484, "compression_ratio": 1.7067669172932332, "no_speech_prob": 0.0002519877743907273}, {"id": 12, "seek": 2896, "start": 45.0, "end": 49.64, "text": " And by doing that, it has to be full torrent, so if something goes wrong, it can still heal", "tokens": [400, 538, 884, 300, 11, 309, 575, 281, 312, 1577, 3930, 1753, 11, 370, 498, 746, 1709, 2085, 11, 309, 393, 920, 10526], "temperature": 0.0, "avg_logprob": -0.15351009368896484, "compression_ratio": 1.7067669172932332, "no_speech_prob": 0.0002519877743907273}, {"id": 13, "seek": 2896, "start": 49.64, "end": 52.64, "text": " and keep on running.", "tokens": [293, 1066, 322, 2614, 13], "temperature": 0.0, "avg_logprob": -0.15351009368896484, "compression_ratio": 1.7067669172932332, "no_speech_prob": 0.0002519877743907273}, {"id": 14, "seek": 2896, "start": 52.64, "end": 57.32, "text": " And because it has to be on all the time, it also means that any code changes should", "tokens": [400, 570, 309, 575, 281, 312, 322, 439, 264, 565, 11, 309, 611, 1355, 300, 604, 3089, 2962, 820], "temperature": 0.0, "avg_logprob": -0.15351009368896484, "compression_ratio": 1.7067669172932332, "no_speech_prob": 0.0002519877743907273}, {"id": 15, "seek": 2896, "start": 57.32, "end": 58.32, "text": " be done on the fly.", "tokens": [312, 1096, 322, 264, 3603, 13], "temperature": 0.0, "avg_logprob": -0.15351009368896484, "compression_ratio": 1.7067669172932332, "no_speech_prob": 0.0002519877743907273}, {"id": 16, "seek": 5832, "start": 58.32, "end": 61.8, "text": " All the system is running without interruptions, without bringing systems down, bringing systems", "tokens": [1057, 264, 1185, 307, 2614, 1553, 12729, 626, 11, 1553, 5062, 3652, 760, 11, 5062, 3652], "temperature": 0.0, "avg_logprob": -0.13243776622571443, "compression_ratio": 1.7838983050847457, "no_speech_prob": 0.00044767215149477124}, {"id": 17, "seek": 5832, "start": 61.8, "end": 62.8, "text": " up.", "tokens": [493, 13], "temperature": 0.0, "avg_logprob": -0.13243776622571443, "compression_ratio": 1.7838983050847457, "no_speech_prob": 0.00044767215149477124}, {"id": 18, "seek": 5832, "start": 62.8, "end": 67.8, "text": " But just keep things running on and changing the code under the hood.", "tokens": [583, 445, 1066, 721, 2614, 322, 293, 4473, 264, 3089, 833, 264, 13376, 13], "temperature": 0.0, "avg_logprob": -0.13243776622571443, "compression_ratio": 1.7838983050847457, "no_speech_prob": 0.00044767215149477124}, {"id": 19, "seek": 5832, "start": 67.8, "end": 71.8, "text": " It also needed to be concurrent, because it needed to handle a lot of incoming telephone", "tokens": [467, 611, 2978, 281, 312, 37702, 11, 570, 309, 2978, 281, 4813, 257, 688, 295, 22341, 19800], "temperature": 0.0, "avg_logprob": -0.13243776622571443, "compression_ratio": 1.7838983050847457, "no_speech_prob": 0.00044767215149477124}, {"id": 20, "seek": 5832, "start": 71.8, "end": 74.16, "text": " calls at the same time.", "tokens": [5498, 412, 264, 912, 565, 13], "temperature": 0.0, "avg_logprob": -0.13243776622571443, "compression_ratio": 1.7838983050847457, "no_speech_prob": 0.00044767215149477124}, {"id": 21, "seek": 5832, "start": 74.16, "end": 79.12, "text": " And it also needs to be distributed, because you have to connect telephone switches together", "tokens": [400, 309, 611, 2203, 281, 312, 12631, 11, 570, 291, 362, 281, 1745, 19800, 19458, 1214], "temperature": 0.0, "avg_logprob": -0.13243776622571443, "compression_ratio": 1.7838983050847457, "no_speech_prob": 0.00044767215149477124}, {"id": 22, "seek": 5832, "start": 79.12, "end": 83.32, "text": " and make sure that everything runs smoothly.", "tokens": [293, 652, 988, 300, 1203, 6676, 19565, 13], "temperature": 0.0, "avg_logprob": -0.13243776622571443, "compression_ratio": 1.7838983050847457, "no_speech_prob": 0.00044767215149477124}, {"id": 23, "seek": 8332, "start": 83.32, "end": 92.52, "text": " So those are kind of the properties that Erlang also inherited from Erlang as well.", "tokens": [407, 729, 366, 733, 295, 264, 7221, 300, 3300, 25241, 611, 27091, 490, 3300, 25241, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.16444382158297938, "compression_ratio": 1.5952380952380953, "no_speech_prob": 0.00012462702579796314}, {"id": 24, "seek": 8332, "start": 92.52, "end": 99.63999999999999, "text": " So when you look at other systems, multi-threaded, OK, programming can be hard.", "tokens": [407, 562, 291, 574, 412, 661, 3652, 11, 4825, 12, 392, 2538, 292, 11, 2264, 11, 9410, 393, 312, 1152, 13], "temperature": 0.0, "avg_logprob": -0.16444382158297938, "compression_ratio": 1.5952380952380953, "no_speech_prob": 0.00012462702579796314}, {"id": 25, "seek": 8332, "start": 99.63999999999999, "end": 104.19999999999999, "text": " So in theory, it should all work like we have, you know, if you want to do something concurrently,", "tokens": [407, 294, 5261, 11, 309, 820, 439, 589, 411, 321, 362, 11, 291, 458, 11, 498, 291, 528, 281, 360, 746, 37702, 356, 11], "temperature": 0.0, "avg_logprob": -0.16444382158297938, "compression_ratio": 1.5952380952380953, "no_speech_prob": 0.00012462702579796314}, {"id": 26, "seek": 8332, "start": 104.19999999999999, "end": 107.63999999999999, "text": " we spawn a few threads and they do their work.", "tokens": [321, 17088, 257, 1326, 19314, 293, 436, 360, 641, 589, 13], "temperature": 0.0, "avg_logprob": -0.16444382158297938, "compression_ratio": 1.5952380952380953, "no_speech_prob": 0.00012462702579796314}, {"id": 27, "seek": 8332, "start": 107.63999999999999, "end": 112.96, "text": " But in practices, because threads can actually interfere with each other's work, it actually", "tokens": [583, 294, 7525, 11, 570, 19314, 393, 767, 23946, 365, 1184, 661, 311, 589, 11, 309, 767], "temperature": 0.0, "avg_logprob": -0.16444382158297938, "compression_ratio": 1.5952380952380953, "no_speech_prob": 0.00012462702579796314}, {"id": 28, "seek": 11296, "start": 112.96, "end": 114.24, "text": " becomes a mess.", "tokens": [3643, 257, 2082, 13], "temperature": 0.0, "avg_logprob": -0.17940182156032985, "compression_ratio": 1.7136929460580912, "no_speech_prob": 8.074513607425615e-05}, {"id": 29, "seek": 11296, "start": 114.24, "end": 119.0, "text": " So hence the second picture.", "tokens": [407, 16678, 264, 1150, 3036, 13], "temperature": 0.0, "avg_logprob": -0.17940182156032985, "compression_ratio": 1.7136929460580912, "no_speech_prob": 8.074513607425615e-05}, {"id": 30, "seek": 11296, "start": 119.0, "end": 121.63999999999999, "text": " The other property that Erlang has is full torrents.", "tokens": [440, 661, 4707, 300, 3300, 25241, 575, 307, 1577, 3930, 1753, 82, 13], "temperature": 0.0, "avg_logprob": -0.17940182156032985, "compression_ratio": 1.7136929460580912, "no_speech_prob": 8.074513607425615e-05}, {"id": 31, "seek": 11296, "start": 121.63999999999999, "end": 128.0, "text": " So in Erlang, you set up a supervision tree in which a supervisor is actually watching,", "tokens": [407, 294, 3300, 25241, 11, 291, 992, 493, 257, 32675, 4230, 294, 597, 257, 24610, 307, 767, 1976, 11], "temperature": 0.0, "avg_logprob": -0.17940182156032985, "compression_ratio": 1.7136929460580912, "no_speech_prob": 8.074513607425615e-05}, {"id": 32, "seek": 11296, "start": 128.0, "end": 129.16, "text": " monitoring, or worker.", "tokens": [11028, 11, 420, 11346, 13], "temperature": 0.0, "avg_logprob": -0.17940182156032985, "compression_ratio": 1.7136929460580912, "no_speech_prob": 8.074513607425615e-05}, {"id": 33, "seek": 11296, "start": 129.16, "end": 133.44, "text": " And if one of those processes dies, then the supervisor actually makes sure that a new", "tokens": [400, 498, 472, 295, 729, 7555, 2714, 11, 550, 264, 24610, 767, 1669, 988, 300, 257, 777], "temperature": 0.0, "avg_logprob": -0.17940182156032985, "compression_ratio": 1.7136929460580912, "no_speech_prob": 8.074513607425615e-05}, {"id": 34, "seek": 11296, "start": 133.44, "end": 135.92, "text": " process is spawned in its place.", "tokens": [1399, 307, 17088, 292, 294, 1080, 1081, 13], "temperature": 0.0, "avg_logprob": -0.17940182156032985, "compression_ratio": 1.7136929460580912, "no_speech_prob": 8.074513607425615e-05}, {"id": 35, "seek": 11296, "start": 135.92, "end": 140.24, "text": " And the system as a whole keeps running, even though one of the parts actually fail.", "tokens": [400, 264, 1185, 382, 257, 1379, 5965, 2614, 11, 754, 1673, 472, 295, 264, 3166, 767, 3061, 13], "temperature": 0.0, "avg_logprob": -0.17940182156032985, "compression_ratio": 1.7136929460580912, "no_speech_prob": 8.074513607425615e-05}, {"id": 36, "seek": 14024, "start": 140.24, "end": 147.92000000000002, "text": " And so the mantra that's very often told in Erlang is, let it crash.", "tokens": [400, 370, 264, 32094, 300, 311, 588, 2049, 1907, 294, 3300, 25241, 307, 11, 718, 309, 8252, 13], "temperature": 0.0, "avg_logprob": -0.1730182878263704, "compression_ratio": 1.5219298245614035, "no_speech_prob": 3.216696859453805e-05}, {"id": 37, "seek": 14024, "start": 147.92000000000002, "end": 151.12, "text": " Nice timing, OK.", "tokens": [5490, 10822, 11, 2264, 13], "temperature": 0.0, "avg_logprob": -0.1730182878263704, "compression_ratio": 1.5219298245614035, "no_speech_prob": 3.216696859453805e-05}, {"id": 38, "seek": 14024, "start": 151.12, "end": 155.8, "text": " Because people feel safe by, you know, if there's an exception, if your code always", "tokens": [1436, 561, 841, 3273, 538, 11, 291, 458, 11, 498, 456, 311, 364, 11183, 11, 498, 428, 3089, 1009], "temperature": 0.0, "avg_logprob": -0.1730182878263704, "compression_ratio": 1.5219298245614035, "no_speech_prob": 3.216696859453805e-05}, {"id": 39, "seek": 14024, "start": 155.8, "end": 161.56, "text": " goes for the happy path and something goes wrong, Erlang developers tend to not care", "tokens": [1709, 337, 264, 2055, 3100, 293, 746, 1709, 2085, 11, 3300, 25241, 8849, 3928, 281, 406, 1127], "temperature": 0.0, "avg_logprob": -0.1730182878263704, "compression_ratio": 1.5219298245614035, "no_speech_prob": 3.216696859453805e-05}, {"id": 40, "seek": 14024, "start": 161.56, "end": 165.96, "text": " that much about it because the system, like the supervisor, will restart that process", "tokens": [300, 709, 466, 309, 570, 264, 1185, 11, 411, 264, 24610, 11, 486, 21022, 300, 1399], "temperature": 0.0, "avg_logprob": -0.1730182878263704, "compression_ratio": 1.5219298245614035, "no_speech_prob": 3.216696859453805e-05}, {"id": 41, "seek": 14024, "start": 165.96, "end": 167.12, "text": " again.", "tokens": [797, 13], "temperature": 0.0, "avg_logprob": -0.1730182878263704, "compression_ratio": 1.5219298245614035, "no_speech_prob": 3.216696859453805e-05}, {"id": 42, "seek": 16712, "start": 167.12, "end": 173.16, "text": " So very exceptional edge cases are sometimes not covered because they feel comfortable", "tokens": [407, 588, 19279, 4691, 3331, 366, 2171, 406, 5343, 570, 436, 841, 4619], "temperature": 0.0, "avg_logprob": -0.16120830036344982, "compression_ratio": 1.5384615384615385, "no_speech_prob": 8.988773333840072e-05}, {"id": 43, "seek": 16712, "start": 173.16, "end": 178.8, "text": " having the system pick it up from there as well.", "tokens": [1419, 264, 1185, 1888, 309, 493, 490, 456, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.16120830036344982, "compression_ratio": 1.5384615384615385, "no_speech_prob": 8.988773333840072e-05}, {"id": 44, "seek": 16712, "start": 178.8, "end": 182.96, "text": " Before Alexa came around, Erlang also existed for quite some while.", "tokens": [4546, 22595, 1361, 926, 11, 3300, 25241, 611, 13135, 337, 1596, 512, 1339, 13], "temperature": 0.0, "avg_logprob": -0.16120830036344982, "compression_ratio": 1.5384615384615385, "no_speech_prob": 8.988773333840072e-05}, {"id": 45, "seek": 16712, "start": 182.96, "end": 190.20000000000002, "text": " So Alexa also inherited some of the experience of 20 years building telecom systems, which", "tokens": [407, 22595, 611, 27091, 512, 295, 264, 1752, 295, 945, 924, 2390, 4304, 1112, 3652, 11, 597], "temperature": 0.0, "avg_logprob": -0.16120830036344982, "compression_ratio": 1.5384615384615385, "no_speech_prob": 8.988773333840072e-05}, {"id": 46, "seek": 16712, "start": 190.20000000000002, "end": 194.64000000000001, "text": " also makes it, for example, WhatsApp had only 57 engineers working for them when they", "tokens": [611, 1669, 309, 11, 337, 1365, 11, 30513, 632, 787, 21423, 11955, 1364, 337, 552, 562, 436], "temperature": 0.0, "avg_logprob": -0.16120830036344982, "compression_ratio": 1.5384615384615385, "no_speech_prob": 8.988773333840072e-05}, {"id": 47, "seek": 19464, "start": 194.64, "end": 197.64, "text": " were sold to Facebook.", "tokens": [645, 3718, 281, 4384, 13], "temperature": 0.0, "avg_logprob": -0.19395276774530826, "compression_ratio": 1.5294117647058822, "no_speech_prob": 8.207738574128598e-05}, {"id": 48, "seek": 19464, "start": 197.64, "end": 200.07999999999998, "text": " But only about 20 of them were Erlang developers.", "tokens": [583, 787, 466, 945, 295, 552, 645, 3300, 25241, 8849, 13], "temperature": 0.0, "avg_logprob": -0.19395276774530826, "compression_ratio": 1.5294117647058822, "no_speech_prob": 8.207738574128598e-05}, {"id": 49, "seek": 19464, "start": 200.07999999999998, "end": 206.55999999999997, "text": " The rest were actually mobile developers supporting Android, Windows, iOS, et cetera.", "tokens": [440, 1472, 645, 767, 6013, 8849, 7231, 8853, 11, 8591, 11, 17430, 11, 1030, 11458, 13], "temperature": 0.0, "avg_logprob": -0.19395276774530826, "compression_ratio": 1.5294117647058822, "no_speech_prob": 8.207738574128598e-05}, {"id": 50, "seek": 19464, "start": 206.55999999999997, "end": 213.95999999999998, "text": " And they actually could handle a lot of users while having a small team.", "tokens": [400, 436, 767, 727, 4813, 257, 688, 295, 5022, 1339, 1419, 257, 1359, 1469, 13], "temperature": 0.0, "avg_logprob": -0.19395276774530826, "compression_ratio": 1.5294117647058822, "no_speech_prob": 8.207738574128598e-05}, {"id": 51, "seek": 19464, "start": 213.95999999999998, "end": 219.23999999999998, "text": " So then the question also becomes a little bit why does Alexa exist?", "tokens": [407, 550, 264, 1168, 611, 3643, 257, 707, 857, 983, 775, 22595, 2514, 30], "temperature": 0.0, "avg_logprob": -0.19395276774530826, "compression_ratio": 1.5294117647058822, "no_speech_prob": 8.207738574128598e-05}, {"id": 52, "seek": 19464, "start": 219.23999999999998, "end": 222.88, "text": " And when people, like, innovate when they're building new things, there are approximately", "tokens": [400, 562, 561, 11, 411, 11, 33444, 562, 436, 434, 2390, 777, 721, 11, 456, 366, 10447], "temperature": 0.0, "avg_logprob": -0.19395276774530826, "compression_ratio": 1.5294117647058822, "no_speech_prob": 8.207738574128598e-05}, {"id": 53, "seek": 22288, "start": 222.88, "end": 226.92, "text": " three things, three ways they can go around it.", "tokens": [1045, 721, 11, 1045, 2098, 436, 393, 352, 926, 309, 13], "temperature": 0.0, "avg_logprob": -0.1546930529407619, "compression_ratio": 1.5689655172413792, "no_speech_prob": 0.0003645922406576574}, {"id": 54, "seek": 22288, "start": 226.92, "end": 232.2, "text": " So they completely build something very new, which didn't exist before.", "tokens": [407, 436, 2584, 1322, 746, 588, 777, 11, 597, 994, 380, 2514, 949, 13], "temperature": 0.0, "avg_logprob": -0.1546930529407619, "compression_ratio": 1.5689655172413792, "no_speech_prob": 0.0003645922406576574}, {"id": 55, "seek": 22288, "start": 232.2, "end": 238.28, "text": " Or they try to combine the ideas from previous, from other fields, for example.", "tokens": [1610, 436, 853, 281, 10432, 264, 3487, 490, 3894, 11, 490, 661, 7909, 11, 337, 1365, 13], "temperature": 0.0, "avg_logprob": -0.1546930529407619, "compression_ratio": 1.5689655172413792, "no_speech_prob": 0.0003645922406576574}, {"id": 56, "seek": 22288, "start": 238.28, "end": 242.68, "text": " Or in some cases, people just put a new label on it and say, well, this is new.", "tokens": [1610, 294, 512, 3331, 11, 561, 445, 829, 257, 777, 7645, 322, 309, 293, 584, 11, 731, 11, 341, 307, 777, 13], "temperature": 0.0, "avg_logprob": -0.1546930529407619, "compression_ratio": 1.5689655172413792, "no_speech_prob": 0.0003645922406576574}, {"id": 57, "seek": 22288, "start": 242.68, "end": 244.76, "text": " This is innovation.", "tokens": [639, 307, 8504, 13], "temperature": 0.0, "avg_logprob": -0.1546930529407619, "compression_ratio": 1.5689655172413792, "no_speech_prob": 0.0003645922406576574}, {"id": 58, "seek": 22288, "start": 244.76, "end": 249.64, "text": " So hence the title of my talk is, is Alexa really something new?", "tokens": [407, 16678, 264, 4876, 295, 452, 751, 307, 11, 307, 22595, 534, 746, 777, 30], "temperature": 0.0, "avg_logprob": -0.1546930529407619, "compression_ratio": 1.5689655172413792, "no_speech_prob": 0.0003645922406576574}, {"id": 59, "seek": 24964, "start": 249.64, "end": 256.8, "text": " Or is it just a new label on the existing Erlang foundation?", "tokens": [1610, 307, 309, 445, 257, 777, 7645, 322, 264, 6741, 3300, 25241, 7030, 30], "temperature": 0.0, "avg_logprob": -0.1907823587718763, "compression_ratio": 1.502415458937198, "no_speech_prob": 0.00018719177751336247}, {"id": 60, "seek": 24964, "start": 256.8, "end": 264.28, "text": " And some other languages, they, you know, they've tried to incrementally do some innovations.", "tokens": [400, 512, 661, 8650, 11, 436, 11, 291, 458, 11, 436, 600, 3031, 281, 26200, 379, 360, 512, 24283, 13], "temperature": 0.0, "avg_logprob": -0.1907823587718763, "compression_ratio": 1.502415458937198, "no_speech_prob": 0.00018719177751336247}, {"id": 61, "seek": 24964, "start": 264.28, "end": 268.32, "text": " But after a while, the original sources picked up those changes.", "tokens": [583, 934, 257, 1339, 11, 264, 3380, 7139, 6183, 493, 729, 2962, 13], "temperature": 0.0, "avg_logprob": -0.1907823587718763, "compression_ratio": 1.502415458937198, "no_speech_prob": 0.00018719177751336247}, {"id": 62, "seek": 24964, "start": 268.32, "end": 273.8, "text": " In this, like, CoffeeScript is a very famous example, in which the original language picked", "tokens": [682, 341, 11, 411, 11, 25481, 14237, 307, 257, 588, 4618, 1365, 11, 294, 597, 264, 3380, 2856, 6183], "temperature": 0.0, "avg_logprob": -0.1907823587718763, "compression_ratio": 1.502415458937198, "no_speech_prob": 0.00018719177751336247}, {"id": 63, "seek": 27380, "start": 273.8, "end": 280.68, "text": " up those changes and nowadays a lot less people actually use CoffeeScript.", "tokens": [493, 729, 2962, 293, 13434, 257, 688, 1570, 561, 767, 764, 25481, 14237, 13], "temperature": 0.0, "avg_logprob": -0.23868201982856976, "compression_ratio": 1.625, "no_speech_prob": 0.00012922215682920069}, {"id": 64, "seek": 27380, "start": 280.68, "end": 285.68, "text": " So how we're doing on time, okay.", "tokens": [407, 577, 321, 434, 884, 322, 565, 11, 1392, 13], "temperature": 0.0, "avg_logprob": -0.23868201982856976, "compression_ratio": 1.625, "no_speech_prob": 0.00012922215682920069}, {"id": 65, "seek": 27380, "start": 285.68, "end": 290.56, "text": " So the question is then also, why did Jose, kind of the creator of Alexa, why did he write", "tokens": [407, 264, 1168, 307, 550, 611, 11, 983, 630, 8635, 11, 733, 295, 264, 14181, 295, 22595, 11, 983, 630, 415, 2464], "temperature": 0.0, "avg_logprob": -0.23868201982856976, "compression_ratio": 1.625, "no_speech_prob": 0.00012922215682920069}, {"id": 66, "seek": 27380, "start": 290.56, "end": 292.48, "text": " a new language?", "tokens": [257, 777, 2856, 30], "temperature": 0.0, "avg_logprob": -0.23868201982856976, "compression_ratio": 1.625, "no_speech_prob": 0.00012922215682920069}, {"id": 67, "seek": 27380, "start": 292.48, "end": 296.44, "text": " And he was at a time when he wrote, Alexa was working at the Rails team.", "tokens": [400, 415, 390, 412, 257, 565, 562, 415, 4114, 11, 22595, 390, 1364, 412, 264, 48526, 1469, 13], "temperature": 0.0, "avg_logprob": -0.23868201982856976, "compression_ratio": 1.625, "no_speech_prob": 0.00012922215682920069}, {"id": 68, "seek": 27380, "start": 296.44, "end": 302.28000000000003, "text": " And one of the things that he faced was trying to make Rails thread safe, so making sure", "tokens": [400, 472, 295, 264, 721, 300, 415, 11446, 390, 1382, 281, 652, 48526, 7207, 3273, 11, 370, 1455, 988], "temperature": 0.0, "avg_logprob": -0.23868201982856976, "compression_ratio": 1.625, "no_speech_prob": 0.00012922215682920069}, {"id": 69, "seek": 30228, "start": 302.28, "end": 307.08, "text": " that several threads that were running in the Rails program weren't interfering with", "tokens": [300, 2940, 19314, 300, 645, 2614, 294, 264, 48526, 1461, 4999, 380, 48721, 365], "temperature": 0.0, "avg_logprob": -0.18264569645434353, "compression_ratio": 1.702290076335878, "no_speech_prob": 7.823729538358748e-05}, {"id": 70, "seek": 30228, "start": 307.08, "end": 308.08, "text": " each other.", "tokens": [1184, 661, 13], "temperature": 0.0, "avg_logprob": -0.18264569645434353, "compression_ratio": 1.702290076335878, "no_speech_prob": 7.823729538358748e-05}, {"id": 71, "seek": 30228, "start": 308.08, "end": 311.91999999999996, "text": " And by doing that, he was actually looking around, how did other, like folks, how there", "tokens": [400, 538, 884, 300, 11, 415, 390, 767, 1237, 926, 11, 577, 630, 661, 11, 411, 4024, 11, 577, 456], "temperature": 0.0, "avg_logprob": -0.18264569645434353, "compression_ratio": 1.702290076335878, "no_speech_prob": 7.823729538358748e-05}, {"id": 72, "seek": 30228, "start": 311.91999999999996, "end": 316.4, "text": " are other problems in languages, other frameworks, how did they solve that issue?", "tokens": [366, 661, 2740, 294, 8650, 11, 661, 29834, 11, 577, 630, 436, 5039, 300, 2734, 30], "temperature": 0.0, "avg_logprob": -0.18264569645434353, "compression_ratio": 1.702290076335878, "no_speech_prob": 7.823729538358748e-05}, {"id": 73, "seek": 30228, "start": 316.4, "end": 319.08, "text": " And that's when he actually stumbled upon Erlang.", "tokens": [400, 300, 311, 562, 415, 767, 36668, 3564, 3300, 25241, 13], "temperature": 0.0, "avg_logprob": -0.18264569645434353, "compression_ratio": 1.702290076335878, "no_speech_prob": 7.823729538358748e-05}, {"id": 74, "seek": 30228, "start": 319.08, "end": 320.08, "text": " And he liked it.", "tokens": [400, 415, 4501, 309, 13], "temperature": 0.0, "avg_logprob": -0.18264569645434353, "compression_ratio": 1.702290076335878, "no_speech_prob": 7.823729538358748e-05}, {"id": 75, "seek": 30228, "start": 320.08, "end": 325.4, "text": " It was, you know, just the thing he needed to use.", "tokens": [467, 390, 11, 291, 458, 11, 445, 264, 551, 415, 2978, 281, 764, 13], "temperature": 0.0, "avg_logprob": -0.18264569645434353, "compression_ratio": 1.702290076335878, "no_speech_prob": 7.823729538358748e-05}, {"id": 76, "seek": 30228, "start": 325.4, "end": 330.0, "text": " But there were also some things that he was actually missing.", "tokens": [583, 456, 645, 611, 512, 721, 300, 415, 390, 767, 5361, 13], "temperature": 0.0, "avg_logprob": -0.18264569645434353, "compression_ratio": 1.702290076335878, "no_speech_prob": 7.823729538358748e-05}, {"id": 77, "seek": 33000, "start": 330.0, "end": 335.32, "text": " So for starters, the syntax stems from Prolog.", "tokens": [407, 337, 35131, 11, 264, 28431, 27600, 490, 1705, 4987, 13], "temperature": 0.0, "avg_logprob": -0.13967706719223333, "compression_ratio": 1.6592920353982301, "no_speech_prob": 5.384640462580137e-05}, {"id": 78, "seek": 33000, "start": 335.32, "end": 337.96, "text": " So it's unfamiliar for a lot of people.", "tokens": [407, 309, 311, 29415, 337, 257, 688, 295, 561, 13], "temperature": 0.0, "avg_logprob": -0.13967706719223333, "compression_ratio": 1.6592920353982301, "no_speech_prob": 5.384640462580137e-05}, {"id": 79, "seek": 33000, "start": 337.96, "end": 342.92, "text": " So that means that new people who come to Erlang have to, you know, have a high barrier", "tokens": [407, 300, 1355, 300, 777, 561, 567, 808, 281, 3300, 25241, 362, 281, 11, 291, 458, 11, 362, 257, 1090, 13357], "temperature": 0.0, "avg_logprob": -0.13967706719223333, "compression_ratio": 1.6592920353982301, "no_speech_prob": 5.384640462580137e-05}, {"id": 80, "seek": 33000, "start": 342.92, "end": 351.28, "text": " to, okay, high barrier to actually get around because they feel unfamiliar with the syntax.", "tokens": [281, 11, 1392, 11, 1090, 13357, 281, 767, 483, 926, 570, 436, 841, 29415, 365, 264, 28431, 13], "temperature": 0.0, "avg_logprob": -0.13967706719223333, "compression_ratio": 1.6592920353982301, "no_speech_prob": 5.384640462580137e-05}, {"id": 81, "seek": 33000, "start": 351.28, "end": 353.56, "text": " So he did that first.", "tokens": [407, 415, 630, 300, 700, 13], "temperature": 0.0, "avg_logprob": -0.13967706719223333, "compression_ratio": 1.6592920353982301, "no_speech_prob": 5.384640462580137e-05}, {"id": 82, "seek": 33000, "start": 353.56, "end": 358.12, "text": " And he also introduced other new syntax, for example, the pipe operator in which, like", "tokens": [400, 415, 611, 7268, 661, 777, 28431, 11, 337, 1365, 11, 264, 11240, 12973, 294, 597, 11, 411], "temperature": 0.0, "avg_logprob": -0.13967706719223333, "compression_ratio": 1.6592920353982301, "no_speech_prob": 5.384640462580137e-05}, {"id": 83, "seek": 35812, "start": 358.12, "end": 364.76, "text": " the result of the previous expression, is piped into the next function as a first parameter.", "tokens": [264, 1874, 295, 264, 3894, 6114, 11, 307, 8489, 292, 666, 264, 958, 2445, 382, 257, 700, 13075, 13], "temperature": 0.0, "avg_logprob": -0.11186182498931885, "compression_ratio": 1.6217391304347826, "no_speech_prob": 6.808475882280618e-05}, {"id": 84, "seek": 35812, "start": 364.76, "end": 369.76, "text": " So by doing that, you can avoid having a very nested function calls by having something", "tokens": [407, 538, 884, 300, 11, 291, 393, 5042, 1419, 257, 588, 15646, 292, 2445, 5498, 538, 1419, 746], "temperature": 0.0, "avg_logprob": -0.11186182498931885, "compression_ratio": 1.6217391304347826, "no_speech_prob": 6.808475882280618e-05}, {"id": 85, "seek": 35812, "start": 369.76, "end": 374.32, "text": " that's more readable, more clear to other people.", "tokens": [300, 311, 544, 49857, 11, 544, 1850, 281, 661, 561, 13], "temperature": 0.0, "avg_logprob": -0.11186182498931885, "compression_ratio": 1.6217391304347826, "no_speech_prob": 6.808475882280618e-05}, {"id": 86, "seek": 35812, "start": 374.32, "end": 382.56, "text": " He also introduced more extensibility to the language by introducing macros and protocols.", "tokens": [634, 611, 7268, 544, 1279, 694, 2841, 281, 264, 2856, 538, 15424, 7912, 2635, 293, 20618, 13], "temperature": 0.0, "avg_logprob": -0.11186182498931885, "compression_ratio": 1.6217391304347826, "no_speech_prob": 6.808475882280618e-05}, {"id": 87, "seek": 35812, "start": 382.56, "end": 384.88, "text": " And one of my favorites is actually the bottom one.", "tokens": [400, 472, 295, 452, 16907, 307, 767, 264, 2767, 472, 13], "temperature": 0.0, "avg_logprob": -0.11186182498931885, "compression_ratio": 1.6217391304347826, "no_speech_prob": 6.808475882280618e-05}, {"id": 88, "seek": 38488, "start": 384.88, "end": 389.71999999999997, "text": " I'm not sure if everybody can read it, but it's an upcase function which takes a string", "tokens": [286, 478, 406, 988, 498, 2201, 393, 1401, 309, 11, 457, 309, 311, 364, 493, 9765, 2445, 597, 2516, 257, 6798], "temperature": 0.0, "avg_logprob": -0.16083132303678072, "compression_ratio": 1.7073170731707317, "no_speech_prob": 0.00019668346794787794}, {"id": 89, "seek": 38488, "start": 389.71999999999997, "end": 391.96, "text": " and upcases every letter.", "tokens": [293, 493, 46505, 633, 5063, 13], "temperature": 0.0, "avg_logprob": -0.16083132303678072, "compression_ratio": 1.7073170731707317, "no_speech_prob": 0.00019668346794787794}, {"id": 90, "seek": 38488, "start": 391.96, "end": 394.6, "text": " And it does that under the hood via a macro.", "tokens": [400, 309, 775, 300, 833, 264, 13376, 5766, 257, 18887, 13], "temperature": 0.0, "avg_logprob": -0.16083132303678072, "compression_ratio": 1.7073170731707317, "no_speech_prob": 0.00019668346794787794}, {"id": 91, "seek": 38488, "start": 394.6, "end": 402.12, "text": " So the Unicode definition, like the library definitions of characters is downloaded and", "tokens": [407, 264, 1156, 299, 1429, 7123, 11, 411, 264, 6405, 21988, 295, 4342, 307, 21748, 293], "temperature": 0.0, "avg_logprob": -0.16083132303678072, "compression_ratio": 1.7073170731707317, "no_speech_prob": 0.00019668346794787794}, {"id": 92, "seek": 38488, "start": 402.12, "end": 405.71999999999997, "text": " actually being translated to functions under the hood.", "tokens": [767, 885, 16805, 281, 6828, 833, 264, 13376, 13], "temperature": 0.0, "avg_logprob": -0.16083132303678072, "compression_ratio": 1.7073170731707317, "no_speech_prob": 0.00019668346794787794}, {"id": 93, "seek": 38488, "start": 405.71999999999997, "end": 411.4, "text": " So when you call this, you're actually using, you know, some data that is transformed into", "tokens": [407, 562, 291, 818, 341, 11, 291, 434, 767, 1228, 11, 291, 458, 11, 512, 1412, 300, 307, 16894, 666], "temperature": 0.0, "avg_logprob": -0.16083132303678072, "compression_ratio": 1.7073170731707317, "no_speech_prob": 0.00019668346794787794}, {"id": 94, "seek": 38488, "start": 411.4, "end": 414.84, "text": " functions for the language.", "tokens": [6828, 337, 264, 2856, 13], "temperature": 0.0, "avg_logprob": -0.16083132303678072, "compression_ratio": 1.7073170731707317, "no_speech_prob": 0.00019668346794787794}, {"id": 95, "seek": 41484, "start": 414.84, "end": 418.2, "text": " I'll skip over this part because we don't have judgment time.", "tokens": [286, 603, 10023, 670, 341, 644, 570, 321, 500, 380, 362, 12216, 565, 13], "temperature": 0.0, "avg_logprob": -0.16128155649924764, "compression_ratio": 1.5846774193548387, "no_speech_prob": 8.344170782947913e-05}, {"id": 96, "seek": 41484, "start": 418.2, "end": 421.44, "text": " And you also actually see that those macros are used everywhere.", "tokens": [400, 291, 611, 767, 536, 300, 729, 7912, 2635, 366, 1143, 5315, 13], "temperature": 0.0, "avg_logprob": -0.16128155649924764, "compression_ratio": 1.5846774193548387, "no_speech_prob": 8.344170782947913e-05}, {"id": 97, "seek": 41484, "start": 421.44, "end": 428.03999999999996, "text": " So even like, you know, defining a module is a macro, defining a function, et cetera.", "tokens": [407, 754, 411, 11, 291, 458, 11, 17827, 257, 10088, 307, 257, 18887, 11, 17827, 257, 2445, 11, 1030, 11458, 13], "temperature": 0.0, "avg_logprob": -0.16128155649924764, "compression_ratio": 1.5846774193548387, "no_speech_prob": 8.344170782947913e-05}, {"id": 98, "seek": 41484, "start": 428.03999999999996, "end": 433.35999999999996, "text": " Everything is actually implemented through macros.", "tokens": [5471, 307, 767, 12270, 807, 7912, 2635, 13], "temperature": 0.0, "avg_logprob": -0.16128155649924764, "compression_ratio": 1.5846774193548387, "no_speech_prob": 8.344170782947913e-05}, {"id": 99, "seek": 41484, "start": 433.35999999999996, "end": 437.2, "text": " The other thing that he also introduced is the build tool to make it easier for people", "tokens": [440, 661, 551, 300, 415, 611, 7268, 307, 264, 1322, 2290, 281, 652, 309, 3571, 337, 561], "temperature": 0.0, "avg_logprob": -0.16128155649924764, "compression_ratio": 1.5846774193548387, "no_speech_prob": 8.344170782947913e-05}, {"id": 100, "seek": 41484, "start": 437.2, "end": 440.88, "text": " who are, for example, new to the language.", "tokens": [567, 366, 11, 337, 1365, 11, 777, 281, 264, 2856, 13], "temperature": 0.0, "avg_logprob": -0.16128155649924764, "compression_ratio": 1.5846774193548387, "no_speech_prob": 8.344170782947913e-05}, {"id": 101, "seek": 44088, "start": 440.88, "end": 445.36, "text": " If you want to have a package manager, like before, didn't really have package management,", "tokens": [759, 291, 528, 281, 362, 257, 7372, 6598, 11, 411, 949, 11, 994, 380, 534, 362, 7372, 4592, 11], "temperature": 0.0, "avg_logprob": -0.21671685894716133, "compression_ratio": 1.6329113924050633, "no_speech_prob": 9.017501724883914e-05}, {"id": 102, "seek": 44088, "start": 445.36, "end": 452.0, "text": " like in the sense that you could add packages to your project, but you had to download them", "tokens": [411, 294, 264, 2020, 300, 291, 727, 909, 17401, 281, 428, 1716, 11, 457, 291, 632, 281, 5484, 552], "temperature": 0.0, "avg_logprob": -0.21671685894716133, "compression_ratio": 1.6329113924050633, "no_speech_prob": 9.017501724883914e-05}, {"id": 103, "seek": 44088, "start": 452.0, "end": 456.56, "text": " by yourself, put them somewhere, define it in your config, like, okay, this is the path", "tokens": [538, 1803, 11, 829, 552, 4079, 11, 6964, 309, 294, 428, 6662, 11, 411, 11, 1392, 11, 341, 307, 264, 3100], "temperature": 0.0, "avg_logprob": -0.21671685894716133, "compression_ratio": 1.6329113924050633, "no_speech_prob": 9.017501724883914e-05}, {"id": 104, "seek": 44088, "start": 456.56, "end": 459.6, "text": " to my library that I'm using.", "tokens": [281, 452, 6405, 300, 286, 478, 1228, 13], "temperature": 0.0, "avg_logprob": -0.21671685894716133, "compression_ratio": 1.6329113924050633, "no_speech_prob": 9.017501724883914e-05}, {"id": 105, "seek": 44088, "start": 459.6, "end": 466.04, "text": " And with Hex and with Mixed, Alex just made it easier, but, you know, by having a list", "tokens": [400, 365, 634, 87, 293, 365, 12769, 292, 11, 5202, 445, 1027, 309, 3571, 11, 457, 11, 291, 458, 11, 538, 1419, 257, 1329], "temperature": 0.0, "avg_logprob": -0.21671685894716133, "compression_ratio": 1.6329113924050633, "no_speech_prob": 9.017501724883914e-05}, {"id": 106, "seek": 46604, "start": 466.04, "end": 471.52000000000004, "text": " of dependencies and go download it from a central place.", "tokens": [295, 36606, 293, 352, 5484, 309, 490, 257, 5777, 1081, 13], "temperature": 0.0, "avg_logprob": -0.1600459484343833, "compression_ratio": 1.5895196506550218, "no_speech_prob": 6.918868166394532e-05}, {"id": 107, "seek": 46604, "start": 471.52000000000004, "end": 474.32, "text": " Documentation was also made more prominent.", "tokens": [37684, 399, 390, 611, 1027, 544, 17034, 13], "temperature": 0.0, "avg_logprob": -0.1600459484343833, "compression_ratio": 1.5895196506550218, "no_speech_prob": 6.918868166394532e-05}, {"id": 108, "seek": 46604, "start": 474.32, "end": 477.72, "text": " For example, the doc tests, which are inspired by Python.", "tokens": [1171, 1365, 11, 264, 3211, 6921, 11, 597, 366, 7547, 538, 15329, 13], "temperature": 0.0, "avg_logprob": -0.1600459484343833, "compression_ratio": 1.5895196506550218, "no_speech_prob": 6.918868166394532e-05}, {"id": 109, "seek": 46604, "start": 477.72, "end": 484.68, "text": " So in this case, we have a function defined, and above it is a document, a comment in which", "tokens": [407, 294, 341, 1389, 11, 321, 362, 257, 2445, 7642, 11, 293, 3673, 309, 307, 257, 4166, 11, 257, 2871, 294, 597], "temperature": 0.0, "avg_logprob": -0.1600459484343833, "compression_ratio": 1.5895196506550218, "no_speech_prob": 6.918868166394532e-05}, {"id": 110, "seek": 46604, "start": 484.68, "end": 486.40000000000003, "text": " there's an example.", "tokens": [456, 311, 364, 1365, 13], "temperature": 0.0, "avg_logprob": -0.1600459484343833, "compression_ratio": 1.5895196506550218, "no_speech_prob": 6.918868166394532e-05}, {"id": 111, "seek": 46604, "start": 486.40000000000003, "end": 492.8, "text": " And this example doesn't serve only for documentation, but at the same time, it's also tests.", "tokens": [400, 341, 1365, 1177, 380, 4596, 787, 337, 14333, 11, 457, 412, 264, 912, 565, 11, 309, 311, 611, 6921, 13], "temperature": 0.0, "avg_logprob": -0.1600459484343833, "compression_ratio": 1.5895196506550218, "no_speech_prob": 6.918868166394532e-05}, {"id": 112, "seek": 49280, "start": 492.8, "end": 497.24, "text": " So, you know, actually, you can, if you would change the implementation, you can directly", "tokens": [407, 11, 291, 458, 11, 767, 11, 291, 393, 11, 498, 291, 576, 1319, 264, 11420, 11, 291, 393, 3838], "temperature": 0.0, "avg_logprob": -0.2262065850415276, "compression_ratio": 1.752212389380531, "no_speech_prob": 9.432420483790338e-05}, {"id": 113, "seek": 49280, "start": 497.24, "end": 504.08, "text": " see the effect of it because the test is just above it as documentation fails.", "tokens": [536, 264, 1802, 295, 309, 570, 264, 1500, 307, 445, 3673, 309, 382, 14333, 18199, 13], "temperature": 0.0, "avg_logprob": -0.2262065850415276, "compression_ratio": 1.752212389380531, "no_speech_prob": 9.432420483790338e-05}, {"id": 114, "seek": 49280, "start": 504.08, "end": 512.32, "text": " So, and, yeah, the documentation is also accessible from Rappel, from other places.", "tokens": [407, 11, 293, 11, 1338, 11, 264, 14333, 307, 611, 9515, 490, 497, 1746, 338, 11, 490, 661, 3190, 13], "temperature": 0.0, "avg_logprob": -0.2262065850415276, "compression_ratio": 1.752212389380531, "no_speech_prob": 9.432420483790338e-05}, {"id": 115, "seek": 49280, "start": 512.32, "end": 514.36, "text": " And this was built before the LSP.", "tokens": [400, 341, 390, 3094, 949, 264, 441, 27921, 13], "temperature": 0.0, "avg_logprob": -0.2262065850415276, "compression_ratio": 1.752212389380531, "no_speech_prob": 9.432420483790338e-05}, {"id": 116, "seek": 49280, "start": 514.36, "end": 518.64, "text": " So nowadays, you can, you know, just hover over function in your editor, and you will", "tokens": [407, 13434, 11, 291, 393, 11, 291, 458, 11, 445, 20076, 670, 2445, 294, 428, 9839, 11, 293, 291, 486], "temperature": 0.0, "avg_logprob": -0.2262065850415276, "compression_ratio": 1.752212389380531, "no_speech_prob": 9.432420483790338e-05}, {"id": 117, "seek": 49280, "start": 518.64, "end": 520.48, "text": " see the documentation.", "tokens": [536, 264, 14333, 13], "temperature": 0.0, "avg_logprob": -0.2262065850415276, "compression_ratio": 1.752212389380531, "no_speech_prob": 9.432420483790338e-05}, {"id": 118, "seek": 52048, "start": 520.48, "end": 526.84, "text": " But when Elixir was created, those functionalities weren't that common, like among other languages,", "tokens": [583, 562, 2699, 970, 347, 390, 2942, 11, 729, 11745, 1088, 4999, 380, 300, 2689, 11, 411, 3654, 661, 8650, 11], "temperature": 0.0, "avg_logprob": -0.136239226983518, "compression_ratio": 1.592274678111588, "no_speech_prob": 0.0002597588172648102}, {"id": 119, "seek": 52048, "start": 526.84, "end": 530.08, "text": " and that's something that's really nice to work with.", "tokens": [293, 300, 311, 746, 300, 311, 534, 1481, 281, 589, 365, 13], "temperature": 0.0, "avg_logprob": -0.136239226983518, "compression_ratio": 1.592274678111588, "no_speech_prob": 0.0002597588172648102}, {"id": 120, "seek": 52048, "start": 530.08, "end": 535.96, "text": " And the last thing that he kind of also introduced is a different culture, a culture which is", "tokens": [400, 264, 1036, 551, 300, 415, 733, 295, 611, 7268, 307, 257, 819, 3713, 11, 257, 3713, 597, 307], "temperature": 0.0, "avg_logprob": -0.136239226983518, "compression_ratio": 1.592274678111588, "no_speech_prob": 0.0002597588172648102}, {"id": 121, "seek": 52048, "start": 535.96, "end": 538.52, "text": " a little bit more open to newcomers.", "tokens": [257, 707, 857, 544, 1269, 281, 40014, 433, 13], "temperature": 0.0, "avg_logprob": -0.136239226983518, "compression_ratio": 1.592274678111588, "no_speech_prob": 0.0002597588172648102}, {"id": 122, "seek": 52048, "start": 538.52, "end": 544.2, "text": " So it's not like Erlang, you know, shed away from newcomers, but it also didn't, like,", "tokens": [407, 309, 311, 406, 411, 3300, 25241, 11, 291, 458, 11, 14951, 1314, 490, 40014, 433, 11, 457, 309, 611, 994, 380, 11, 411, 11], "temperature": 0.0, "avg_logprob": -0.136239226983518, "compression_ratio": 1.592274678111588, "no_speech_prob": 0.0002597588172648102}, {"id": 123, "seek": 54420, "start": 544.2, "end": 555.0, "text": " make it easier for new people who are new to the language to get started with it, et cetera.", "tokens": [652, 309, 3571, 337, 777, 561, 567, 366, 777, 281, 264, 2856, 281, 483, 1409, 365, 309, 11, 1030, 11458, 13], "temperature": 0.0, "avg_logprob": -0.17635296715630425, "compression_ratio": 1.5658536585365854, "no_speech_prob": 0.00010514436144148931}, {"id": 124, "seek": 54420, "start": 555.0, "end": 561.36, "text": " So that whole, you know, like, to come back to my question, like, is Elixir in kind of", "tokens": [407, 300, 1379, 11, 291, 458, 11, 411, 11, 281, 808, 646, 281, 452, 1168, 11, 411, 11, 307, 2699, 970, 347, 294, 733, 295], "temperature": 0.0, "avg_logprob": -0.17635296715630425, "compression_ratio": 1.5658536585365854, "no_speech_prob": 0.00010514436144148931}, {"id": 125, "seek": 54420, "start": 561.36, "end": 564.0400000000001, "text": " new flavor on top of Erlang?", "tokens": [777, 6813, 322, 1192, 295, 3300, 25241, 30], "temperature": 0.0, "avg_logprob": -0.17635296715630425, "compression_ratio": 1.5658536585365854, "no_speech_prob": 0.00010514436144148931}, {"id": 126, "seek": 54420, "start": 564.0400000000001, "end": 568.96, "text": " I think there are kind of projects stemming from Elixir which make it more interesting", "tokens": [286, 519, 456, 366, 733, 295, 4455, 12312, 2810, 490, 2699, 970, 347, 597, 652, 309, 544, 1880], "temperature": 0.0, "avg_logprob": -0.17635296715630425, "compression_ratio": 1.5658536585365854, "no_speech_prob": 0.00010514436144148931}, {"id": 127, "seek": 54420, "start": 568.96, "end": 570.1600000000001, "text": " and which are really new.", "tokens": [293, 597, 366, 534, 777, 13], "temperature": 0.0, "avg_logprob": -0.17635296715630425, "compression_ratio": 1.5658536585365854, "no_speech_prob": 0.00010514436144148931}, {"id": 128, "seek": 57016, "start": 570.16, "end": 578.88, "text": " So, for example, NX numerical Elixir is an extension which makes machine learning easy,", "tokens": [407, 11, 337, 1365, 11, 426, 55, 29054, 2699, 970, 347, 307, 364, 10320, 597, 1669, 3479, 2539, 1858, 11], "temperature": 0.0, "avg_logprob": -0.15950931367420015, "compression_ratio": 1.651639344262295, "no_speech_prob": 6.915365520399064e-05}, {"id": 129, "seek": 57016, "start": 578.88, "end": 582.8, "text": " and that's something that, you know, before Elixir, nobody actually thought would be useful", "tokens": [293, 300, 311, 746, 300, 11, 291, 458, 11, 949, 2699, 970, 347, 11, 5079, 767, 1194, 576, 312, 4420], "temperature": 0.0, "avg_logprob": -0.15950931367420015, "compression_ratio": 1.651639344262295, "no_speech_prob": 6.915365520399064e-05}, {"id": 130, "seek": 57016, "start": 582.8, "end": 587.76, "text": " to do with the beam, with the Erlang VM, because it wasn't meant for that.", "tokens": [281, 360, 365, 264, 14269, 11, 365, 264, 3300, 25241, 18038, 11, 570, 309, 2067, 380, 4140, 337, 300, 13], "temperature": 0.0, "avg_logprob": -0.15950931367420015, "compression_ratio": 1.651639344262295, "no_speech_prob": 6.915365520399064e-05}, {"id": 131, "seek": 57016, "start": 587.76, "end": 592.04, "text": " It wasn't meant for numerical, for number crunching.", "tokens": [467, 2067, 380, 4140, 337, 29054, 11, 337, 1230, 13386, 278, 13], "temperature": 0.0, "avg_logprob": -0.15950931367420015, "compression_ratio": 1.651639344262295, "no_speech_prob": 6.915365520399064e-05}, {"id": 132, "seek": 57016, "start": 592.04, "end": 598.24, "text": " But this library, this tooling actually makes it a lot easier to do, and that's very promising.", "tokens": [583, 341, 6405, 11, 341, 46593, 767, 1669, 309, 257, 688, 3571, 281, 360, 11, 293, 300, 311, 588, 20257, 13], "temperature": 0.0, "avg_logprob": -0.15950931367420015, "compression_ratio": 1.651639344262295, "no_speech_prob": 6.915365520399064e-05}, {"id": 133, "seek": 59824, "start": 598.24, "end": 603.84, "text": " Phoenix is actually a web framework which was inspired by Rails, and now study arounds.", "tokens": [18383, 307, 767, 257, 3670, 8388, 597, 390, 7547, 538, 48526, 11, 293, 586, 2979, 926, 82, 13], "temperature": 0.0, "avg_logprob": -0.18787803290025243, "compression_ratio": 1.618867924528302, "no_speech_prob": 0.0002440781390760094}, {"id": 134, "seek": 59824, "start": 603.84, "end": 608.84, "text": " Phoenix is now an inspiration for Rails and other frameworks to work with.", "tokens": [18383, 307, 586, 364, 10249, 337, 48526, 293, 661, 29834, 281, 589, 365, 13], "temperature": 0.0, "avg_logprob": -0.18787803290025243, "compression_ratio": 1.618867924528302, "no_speech_prob": 0.0002440781390760094}, {"id": 135, "seek": 59824, "start": 608.84, "end": 614.88, "text": " And NERVs is also kind of an interesting project which makes it possible to run on smaller", "tokens": [400, 426, 1598, 53, 82, 307, 611, 733, 295, 364, 1880, 1716, 597, 1669, 309, 1944, 281, 1190, 322, 4356], "temperature": 0.0, "avg_logprob": -0.18787803290025243, "compression_ratio": 1.618867924528302, "no_speech_prob": 0.0002440781390760094}, {"id": 136, "seek": 59824, "start": 614.88, "end": 619.16, "text": " devices like Raspberry Pis or something like this.", "tokens": [5759, 411, 41154, 43263, 420, 746, 411, 341, 13], "temperature": 0.0, "avg_logprob": -0.18787803290025243, "compression_ratio": 1.618867924528302, "no_speech_prob": 0.0002440781390760094}, {"id": 137, "seek": 59824, "start": 619.16, "end": 622.64, "text": " So to answer the question, is Elixir really different from Erlang?", "tokens": [407, 281, 1867, 264, 1168, 11, 307, 2699, 970, 347, 534, 819, 490, 3300, 25241, 30], "temperature": 0.0, "avg_logprob": -0.18787803290025243, "compression_ratio": 1.618867924528302, "no_speech_prob": 0.0002440781390760094}, {"id": 138, "seek": 59824, "start": 622.64, "end": 627.04, "text": " Is it really, you know, an innovation or is it rehashing?", "tokens": [1119, 309, 534, 11, 291, 458, 11, 364, 8504, 420, 307, 309, 22355, 11077, 30], "temperature": 0.0, "avg_logprob": -0.18787803290025243, "compression_ratio": 1.618867924528302, "no_speech_prob": 0.0002440781390760094}, {"id": 139, "seek": 62704, "start": 627.04, "end": 628.36, "text": " I would say no.", "tokens": [286, 576, 584, 572, 13], "temperature": 0.0, "avg_logprob": -0.20968903435601127, "compression_ratio": 1.4120879120879122, "no_speech_prob": 0.0006589661934413016}, {"id": 140, "seek": 62704, "start": 628.36, "end": 638.48, "text": " I think Elixir really adds something to the whole ecosystem, which wasn't that easy before that.", "tokens": [286, 519, 2699, 970, 347, 534, 10860, 746, 281, 264, 1379, 11311, 11, 597, 2067, 380, 300, 1858, 949, 300, 13], "temperature": 0.0, "avg_logprob": -0.20968903435601127, "compression_ratio": 1.4120879120879122, "no_speech_prob": 0.0006589661934413016}, {"id": 141, "seek": 62704, "start": 638.48, "end": 648.92, "text": " So with that being said, thanks for listening.", "tokens": [407, 365, 300, 885, 848, 11, 3231, 337, 4764, 13], "temperature": 0.0, "avg_logprob": -0.20968903435601127, "compression_ratio": 1.4120879120879122, "no_speech_prob": 0.0006589661934413016}, {"id": 142, "seek": 62704, "start": 648.92, "end": 649.92, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.20968903435601127, "compression_ratio": 1.4120879120879122, "no_speech_prob": 0.0006589661934413016}, {"id": 143, "seek": 62704, "start": 649.92, "end": 654.24, "text": " Unfortunately, we don't have any time for Q&A, but you can find, don't you?", "tokens": [8590, 11, 321, 500, 380, 362, 604, 565, 337, 1249, 5, 32, 11, 457, 291, 393, 915, 11, 500, 380, 291, 30], "temperature": 0.0, "avg_logprob": -0.20968903435601127, "compression_ratio": 1.4120879120879122, "no_speech_prob": 0.0006589661934413016}, {"id": 144, "seek": 62704, "start": 654.24, "end": 655.24, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.20968903435601127, "compression_ratio": 1.4120879120879122, "no_speech_prob": 0.0006589661934413016}, {"id": 145, "seek": 62704, "start": 655.24, "end": 656.24, "text": " Here.", "tokens": [1692, 13], "temperature": 0.0, "avg_logprob": -0.20968903435601127, "compression_ratio": 1.4120879120879122, "no_speech_prob": 0.0006589661934413016}, {"id": 146, "seek": 65624, "start": 656.24, "end": 661.32, "text": " Again, I usually have the handle toxified, so on Twitter, if it still works or mastered", "tokens": [3764, 11, 286, 2673, 362, 264, 4813, 10357, 2587, 11, 370, 322, 5794, 11, 498, 309, 920, 1985, 420, 38686], "temperature": 0.0, "avg_logprob": -0.22221753368638966, "compression_ratio": 2.2176165803108807, "no_speech_prob": 0.0005838510114699602}, {"id": 147, "seek": 65624, "start": 661.32, "end": 664.12, "text": " on you, you can also find me.", "tokens": [322, 291, 11, 291, 393, 611, 915, 385, 13], "temperature": 0.0, "avg_logprob": -0.22221753368638966, "compression_ratio": 2.2176165803108807, "no_speech_prob": 0.0005838510114699602}, {"id": 148, "seek": 65624, "start": 664.12, "end": 667.6800000000001, "text": " And I'll be around, I think, for today if you have any further questions.", "tokens": [400, 286, 603, 312, 926, 11, 286, 519, 11, 337, 965, 498, 291, 362, 604, 3052, 1651, 13], "temperature": 0.0, "avg_logprob": -0.22221753368638966, "compression_ratio": 2.2176165803108807, "no_speech_prob": 0.0005838510114699602}, {"id": 149, "seek": 65624, "start": 667.6800000000001, "end": 671.16, "text": " So thanks again for listening, and apologies for being this late.", "tokens": [407, 3231, 797, 337, 4764, 11, 293, 34929, 337, 885, 341, 3469, 13], "temperature": 0.0, "avg_logprob": -0.22221753368638966, "compression_ratio": 2.2176165803108807, "no_speech_prob": 0.0005838510114699602}, {"id": 150, "seek": 65624, "start": 671.16, "end": 672.16, "text": " Thank you again.", "tokens": [1044, 291, 797, 13], "temperature": 0.0, "avg_logprob": -0.22221753368638966, "compression_ratio": 2.2176165803108807, "no_speech_prob": 0.0005838510114699602}, {"id": 151, "seek": 65624, "start": 672.16, "end": 673.16, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.22221753368638966, "compression_ratio": 2.2176165803108807, "no_speech_prob": 0.0005838510114699602}, {"id": 152, "seek": 65624, "start": 673.16, "end": 674.16, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.22221753368638966, "compression_ratio": 2.2176165803108807, "no_speech_prob": 0.0005838510114699602}, {"id": 153, "seek": 65624, "start": 674.16, "end": 675.16, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.22221753368638966, "compression_ratio": 2.2176165803108807, "no_speech_prob": 0.0005838510114699602}, {"id": 154, "seek": 65624, "start": 675.16, "end": 676.16, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.22221753368638966, "compression_ratio": 2.2176165803108807, "no_speech_prob": 0.0005838510114699602}, {"id": 155, "seek": 65624, "start": 676.16, "end": 677.16, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.22221753368638966, "compression_ratio": 2.2176165803108807, "no_speech_prob": 0.0005838510114699602}, {"id": 156, "seek": 65624, "start": 677.16, "end": 678.16, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.22221753368638966, "compression_ratio": 2.2176165803108807, "no_speech_prob": 0.0005838510114699602}, {"id": 157, "seek": 65624, "start": 678.16, "end": 679.16, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.22221753368638966, "compression_ratio": 2.2176165803108807, "no_speech_prob": 0.0005838510114699602}, {"id": 158, "seek": 65624, "start": 679.16, "end": 680.16, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.22221753368638966, "compression_ratio": 2.2176165803108807, "no_speech_prob": 0.0005838510114699602}, {"id": 159, "seek": 65624, "start": 680.16, "end": 681.16, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.22221753368638966, "compression_ratio": 2.2176165803108807, "no_speech_prob": 0.0005838510114699602}, {"id": 160, "seek": 65624, "start": 681.16, "end": 682.16, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.22221753368638966, "compression_ratio": 2.2176165803108807, "no_speech_prob": 0.0005838510114699602}, {"id": 161, "seek": 65624, "start": 682.16, "end": 683.16, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.22221753368638966, "compression_ratio": 2.2176165803108807, "no_speech_prob": 0.0005838510114699602}, {"id": 162, "seek": 65624, "start": 683.16, "end": 684.16, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.22221753368638966, "compression_ratio": 2.2176165803108807, "no_speech_prob": 0.0005838510114699602}, {"id": 163, "seek": 65624, "start": 684.16, "end": 685.16, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.22221753368638966, "compression_ratio": 2.2176165803108807, "no_speech_prob": 0.0005838510114699602}, {"id": 164, "seek": 65624, "start": 685.16, "end": 686.16, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.22221753368638966, "compression_ratio": 2.2176165803108807, "no_speech_prob": 0.0005838510114699602}], "language": "en"}