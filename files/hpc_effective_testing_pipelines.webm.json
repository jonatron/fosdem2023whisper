{"text": " Okay, now we come to it. Alright. So last talk. Alright, testing, testing. Okay, so I started here. My talk is about developing effective testing pipelines for HPC applications. Just to give a short introduction about who I am, relatively new here. So, you know, I first started in the HPC industry while I was in college. I joined my university's HPC Institute as a software consultant, so largely in that role. I was kind of more focused on support. So in that case, I was working on, like, singularity deployments, you know, helping debug Fortran. Not very good at writing Fortran, you know, helping build custom kernels for Jupyter, all that good stuff. And then I left for a bit to go work at another university to do some adversarial machine learning workflow orchestration framework. And then, eventually, I came back to my university's HPC site then as an engineer, instead of a kind of support role. So more in that case, what I worked on was, like, building, you know, a suite of singularity containers that clients could consume, and then also working on, like, debugging tools that interfaced with, like, Moab and Torque and PBS and all that. And then after I graduated university, I joined Canonical. So that was probably, like, nine months ago now. So, you know, kind of the start then, you know, what sent me down this path of wanting to develop effective testing pipelines for HPC applications? Well, first, when I started at Canonical, to be frank, I wasn't very good at Debian packaging. I had mostly deployed most of my software using bash scripts, compiling from source. And so part of that is I had to write provisioning scripts, so I mostly work in cloud orchestration, like, nodes and whatnot, onto clouds. And so I had to, you know, develop dangerous code, you know. So it's installing packages, making configurations, kind of setting pre-seeds in, what is it, Debian, Ubuntu. And so basically, I kind of had this, you know, dilemma of where, okay, I want an easy way to test these provisioning scripts without kind of having to go through all this manual effort. So originally, you know, I just, you know, typed in vagrant virtual box or any real kind of virtual machine or a supervisor, bring it up, install the script, and then once I was done with it, blow it out. And then kind of also have this issue of where I had a desire for reproducible tests, because even though, like, you know, I know how to bring up, like, a virtual machine on my system, you know, I might be working with someone who's off of Windows or Mac, and so they don't have the same setup that I do, or they're using a different distribution, in fact. So this gave me the idea of, you know, kind of, if I'm on my personal workstation here, so my laptop, unfortunately, my current laptop's X server isn't working, so the HDMI cable gets all screwed up, so thank you, EasyBuild folks, for lending me your computer. But basically, I had the idea that what if I take a test that's written on my system and then have the ability to run it using any hypervisor I want on any operating system that I need to test that code on without any extra hassle of having to really go through supporting or teaching someone else how to bring up that instance. And basically the case of, like, oh, I have to write code, or run or anything else that needs to run, like Ubuntu, CentOS, Alma, or Rocky. And then kind of after working for that a bit, you know, I had kind of an initial prototype that would bring up, you know, basic operating system image, and then kind of as I, you know, got more into my HBC work at Canonical, I kind of realized, like, oh, okay, you know, maybe don't want to rack up the cloud bill trying to test and deploy to AWS or, you know, Azure, or, you know, even our own private internal public cloud or private cloud using OpenStack for, you know, just trying to provision HBC nodes. So, for example, have, like, identity management, open LDAP, shared file system using NFS, you know, have other options. And then also working in the case of just setting up and configuring a Slurm cluster, all kind of headless without any kind of manual user intervention. And so I kind of had this revelation where I'm like, why waste precious compute time on your HBC cluster because the fact is it's expensive, you know, you're kind of paying for that tenancy. And what if you could test your simulations, jobs or applications and whatnot on a mini HBC cluster that's kind of similar to the target platform that you're deploying, but it's more of a mock so that you can kind of get the general feel for the platform before moving on to the more expensive resources. So in this case, you know, I started working on a custom testing framework called CleanTest, which is basically a fancy Python testing library that allows you to bring up many HBC clusters on your local system and, you know, just kind of in general usage for developers who are in a hurry. So kind of then breaking into a question, you know, what exactly is a CleanTest? Because, you know, originally I named it SimpleTest because I just wanted it to be really dead simple, but for some reason PyPI wouldn't let me register that name. So CleanTest it is. So basically it comes in three parts. There's kind of a different breakdown. First, you have the bootstrap and configuration stage. So for that, it's kind of where you can register hooks and whatnot for configuring the instances that you're bringing up or do some more advanced bootstrapping. So the example I had shown in the previous slide of where you're able to bring up NFS, open LDAP, slurm services and whatnot, and then be able to inject scriptlets into that. And so kind of that's when we get to the second part here, which is a Tesla. Kind of interesting little word that I came up with, joking with some of my colleagues, but basically a Tesla is an entire Python program that's wrapped into a regular function, and kind of the idea is that they contain the full body of the test that you want to be able to run inside this virtual machine container or, you know, test mini-cluster. And then kind of the last part here is the evaluation reporting aspect. And then kind of with that, you know, I took a test, you know, subtest framework, you know, agnostic approach where I know that everyone kind of has their own taste that they like. Some people like pie tests, some like unit tests, you know. I don't want to sit here and make opinions for you, so, you know, I want you to be able to write tests in the format that you're most comfortable with. Oh, that came out small, but that's okay. So kind of the first part here is the going more advanced into, like, what exactly is the bootstrap in configuration is that you're able to bring up example nodes, you're able to provision them. What is it? You can also register hooks, so it's kind of similar to anyone who's done any Debian packaging. Listening to Todd, I don't think he's still here. Yeah, you seem to have some experience with Debian developers. So, but... How do you, like, circuit 2,000? Yeah, circuit 2,000, yeah, it's cool. But, yeah, so if anyone's ever, like, worked with P-Builder before, kind of one of the features that I really like about P-Builder for building Debian packages is that you can have different hooks that you can ingest, or you can create that run at certain parts of the package build. So I kind of wanted to replicate that same functionality. And then kind of the general process is instantiating a configure instance, so that's, like, a Python singleton class object that basically takes in all that info, shares it across, you know, the whole test suite. They can bring up nodes that you need, and then you define your hooks, so that's kind of, like, what do I want to run when I start the environment and then register them so that, you know, when you run the test, the program knows about it. And then kind of the next part here is the testlets. So that part kind of uses some little bit more tricky programming. So in this case, I use Python decorators and metaprogramming, so kind of reading class descriptors and whatnot, assessing the current state of the program. And what the decorators do in this case with the metaprogramming is that rather than having that function run locally, instead it kind of takes out the body of that function that you defined. And then it injects it inside of the container instance and runs it there, so the idea is that, like, oh, you could be working off of a new bunch of machine, but you're developing for a cluster that's running Rocky Linux. So in that case, you can just easily bring it up, inject it in there, get the results back. And then finally, kind of the last part, evaluation slash reporting. It's like each testlet kind of returns this results object, so that kind of contains an exit code, standard out, standard error. And from there, you can evaluate the results locally instead of having to kind of instead do it inside of the container, so you could say, like, oh, in this case, if you're, like, doing a spread test, so kind of if you have, like, oh, you know, I need to test this on Ubuntu 22.04 or 20.04 and 18.04, it returns a generator object of a name and a result. So, you know, let's say that your code works on 22.04 and 20.04, but the version of Python on 18.04 is too old for what you're trying to do, so report back is an error. So kind of then, you know, breaking into how does it exactly work. So the idea is that you kind of start on your local host, so that's kind of your computer there. So you have the host operating system, and then you have the clean test package installed as, you know, I'm part of your Python interpreter, which is a regular Python package. The idea is that then, as you see that dotted line in the middle there, it then makes the request of the hypervisor of your choice and tells it, like, hey, so, you know, the user who wrote this test told me that I need to bring up a certain instance, you know, says that they need, like, a centOS image, so bring up a centOS image for me, and then once that's done, you know, what clean test does is that it takes that test body function and it kind of creates a simple JSON packet, which is a checksum to verify the authenticity of the testlet, the data, which is basically the testlet encoded, and then, or any data necessary for the testlet, and then the injectable, which is basically, like, hey, you know, when you get this data packet, here's what you need to do with it. And then once that happens then, you know, clean test, what it does is that it copies itself onto the container image and then from there it ingests that data packet, does the evaluation that you requested, and then it returns that result object back to the clean test that's on local host. So kind of two different ways that it works. Then for, like, how do you control the hypervisor? The first way is kind of Archon, which is a fancy word for director, you know. I kind of wanted to have a buzzword in there somewhere. But the idea is that what the Archon does is that it's kind of more declarative approach to doing clean tests, so rather than, you know, saying, like, oh, you know, automatically do this, wrap it, you know, you can kind of direct the deployment of said mini-HBC cluster, and then what Harness does is that instead of, you know, having to explicitly declare, like, this is the infrastructure that I want for my deployment, it just brings up an instance based on the function that it's been wrapped around. So this is a short demo video. Let's see if I can choose better quality here. Oh, don't tell me. Came as a PDF, but let's see here. All right, YouTube, sweet. They go full-spring. There we go. Oh, settings, playback. 180p. There we go. It's a little interesting. But yeah, so basically what happens here is that just using, like, simple talks, in that case, I use talks as kind of the test administrator. I started a test, which is called LSD Archon, which basically says bring up a test environment instance. So first it starts with LDAP, so it's provisioning an LDAP node on top of LSD hypervisor. That's what I'm using here. So first it starts with LDAP, and then after a few minutes, for it to boot, crappy hotel Wi-Fi was when I was doing this. And then see there? Now you have the NFS image. That starts provisioning, and then somewhere in here. Now you have the Slurm CTLD node that comes up. And now you have the Slurm, three Slurm compute nodes that come up, and the idea is that then what the framework does is that it injects a testlet inside of Slurm CTLD, and then from there it uses SBatch to submit the job off to the test cluster. Takes a bit. Ooh. A little too far ahead. Give it a few seconds. Yep, and then it cleans up the cluster so that it doesn't linger on afterwards. Oh, goodbye. Oh, God. What happened here? All right. Okay. That's not fun. Okay. Yeah, I want to go back to the video. I don't know why I jumped into the other video. I just had an auto play moment. Wow. I feel like a school teacher. This is right for the end. Okay. All right, thank you. Yeah. All right, okay. Ooh, no auto play. All right, so basically what happens here, I'm going to full screen it so it's a little bit bigger. What? Come on. I'm an engineer, not a YouTube video player on a projector kind of guy, but what is it? Yeah. So what I've seen here is that the test starts, brings up the nodes that you need to use. So in that case, it was just LDAP for basic identity management, manifest for shared file system, and then just like Slurm for kind of resource management services. And then from there, it just like injects like a little test script to run. And then, yeah, what's if the job succeeds, it kind of copies back to the results. And then, yeah, and then it says like, okay, we get the result that we expect, so in the case of the test that I wrote, it just prints out basically like, I love doing research, and then it says like, I love doing research in the log file for standard out. So, yeah, pretty low fidelity right now is mostly a lot of work, went into just getting it to work and all that. Okay, now I want to go back to the slides. There we go. Hey, so now you saw that video, you know, kind of overgoing some of the current limitations. The first is that I'm kind of bad at playing YouTube videos and presentations, but the next part here is that kind of, right now, big issue is that there's kind of a lack of robust multi-distribution support. So currently, I mostly developed it to work on Ubuntu and work with Ubuntu, I wonder why. But you can't launch Alma, Rocky, CentOS, Arch instances, et cetera, but kind of the macros, hooks, and like utilities that I built into the framework aren't really fully there yet for supporting it. And then public documentation is behind because, you know, usually I write code before I write documentation. Unfortunately, it just seems to be how it always goes. Yeah, so I need to update that. And then kind of big issue right now is lack of package manager integration. So a lot of the support has been added ad hoc. So currently, I support like charm libraries, which is something that Canonically uses, and then snap packages, which are kind of controversial, depending on your opinions. And then also just pips because I do a lot of Python development. But in the future, I hope to add support for like Debian packages, RPMs, you know, Arch installs, it's back in EasyBuild. So, yeah, and then lastly, I'm the only developer currently. So, you know, code developed in isolation isn't reviewed as thoroughly as it could be. So, you know, yeah, I make design choices based on what I think is appropriate. So, yeah, so last thing too is that, you know, testing framework I think is a lot cooler than the video that I kind of struggled to play here. So if you want to scan the QR code, if you're interested, feel free. Slides are also online as well. So if you're not available right now, you can check it out. And then lastly, you know, this is kind of a, you know, call for involvement. So, you know, really, at Canonical, we're trying to start getting Ubuntu kind of geared better for HPC, you know, we kind of know that we're a little bit behind Red Hat in the case of like network driver support and whatnot. So, you know, just if you're interested in using Ubuntu for your workflows and whatnot, we have a public Mattermost channel so you can scan that QR code or you can, you know, check it out later. But, yeah, we have a public channel for HPC online. So, yeah, if there's something that's missing or, you know, there's kind of some reason why you're being held back on using Ubuntu for HPC, we'd really love to hear that feedback. So, yeah, that's it. Thank you. Any questions for Jason? Last chance for today. So, you're just doing, this is all Python code that does this system for you. Yes, yes. So, how are you spinning up the LXD containers? So, the idea is that, in the case of LXD, it has a public API socket that uses, I think it's like open API standard or something. But, yeah, so you can make, like, HTTP requests out to that API that basically say, like, oh, you know, I need this instance or tear this down or set this configuration so I can install, like, AppTanner or some other container hypervisor inside of LXD and whatnot. So, yeah, so I'm just using the API. Any other questions? So, yeah, I'm interested in this. So, the, like, you had an NFS server and some other stuff. Are you, how are you, are those preassembled images that you're just using? Are you building up with some kind of configuration management to use Ansible to build them or how do you do that? Yeah, so currently what I have is, like, the way that I provision, I'm using, like, base Ubuntu images for configuration right now, but you do have the ability to register your own custom instances and pull them in as well. But basically, I have a little mechanism built into the framework where you can write, like, provisioning scripts using, like, the clean test utilities. So, there's some stuff for, like, installing apps, running commands on, like, sub-processes on the unit and then also, like, you can reach out to the network, download anything you need. So, yeah, I'm just using custom Python scripts, the provision that are... Yes, yes. Anyone else? Last chance there? All right. It's for the stream and the recording. We've been doing well all day. Let's keep it up. Thank you very much. Would you mind please to move to the previous slide so I can scan my QR code correctly? Okay, thank you very much. You're welcome. That was a good last question. The other one? Which one are you looking for? This one or...? Yeah, this one. Okay. That's all good. All right. If there's no more questions, we can wrap up here. Thanks a lot, everyone. That was a wrap for today. The 9th HPC Dev Room at FOSDEM, that means if FOSDEM likes us, we can have a 10th one next year. That would be really nice. Some practical stuff. If you're leaving the room, if you see any trash, please take it with you and dump it in an appropriate place outside. And the FOSDEM team has asked us to ask you to leave the building as soon as possible so they can lock up the whole building. There's another talk going on in Janssen, in the really big room. I would recommend going there. It's a really nice way to wrap up FOSDEM, and there will be places there to get one or maybe two or three more beers and have some more chats with people. Thanks a lot, and hopefully see you next year. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 7.0, "text": " Okay, now we come to it.", "tokens": [1033, 11, 586, 321, 808, 281, 309, 13], "temperature": 0.0, "avg_logprob": -0.3608524322509766, "compression_ratio": 1.467455621301775, "no_speech_prob": 0.027485882863402367}, {"id": 1, "seek": 0, "start": 7.0, "end": 8.0, "text": " Alright.", "tokens": [2798, 13], "temperature": 0.0, "avg_logprob": -0.3608524322509766, "compression_ratio": 1.467455621301775, "no_speech_prob": 0.027485882863402367}, {"id": 2, "seek": 0, "start": 8.0, "end": 10.0, "text": " So last talk.", "tokens": [407, 1036, 751, 13], "temperature": 0.0, "avg_logprob": -0.3608524322509766, "compression_ratio": 1.467455621301775, "no_speech_prob": 0.027485882863402367}, {"id": 3, "seek": 0, "start": 10.0, "end": 13.0, "text": " Alright, testing, testing.", "tokens": [2798, 11, 4997, 11, 4997, 13], "temperature": 0.0, "avg_logprob": -0.3608524322509766, "compression_ratio": 1.467455621301775, "no_speech_prob": 0.027485882863402367}, {"id": 4, "seek": 0, "start": 13.0, "end": 16.0, "text": " Okay, so I started here.", "tokens": [1033, 11, 370, 286, 1409, 510, 13], "temperature": 0.0, "avg_logprob": -0.3608524322509766, "compression_ratio": 1.467455621301775, "no_speech_prob": 0.027485882863402367}, {"id": 5, "seek": 0, "start": 16.0, "end": 19.0, "text": " My talk is about developing effective testing pipelines", "tokens": [1222, 751, 307, 466, 6416, 4942, 4997, 40168], "temperature": 0.0, "avg_logprob": -0.3608524322509766, "compression_ratio": 1.467455621301775, "no_speech_prob": 0.027485882863402367}, {"id": 6, "seek": 0, "start": 19.0, "end": 21.0, "text": " for HPC applications.", "tokens": [337, 12557, 34, 5821, 13], "temperature": 0.0, "avg_logprob": -0.3608524322509766, "compression_ratio": 1.467455621301775, "no_speech_prob": 0.027485882863402367}, {"id": 7, "seek": 0, "start": 21.0, "end": 25.0, "text": " Just to give a short introduction about who I am,", "tokens": [1449, 281, 976, 257, 2099, 9339, 466, 567, 286, 669, 11], "temperature": 0.0, "avg_logprob": -0.3608524322509766, "compression_ratio": 1.467455621301775, "no_speech_prob": 0.027485882863402367}, {"id": 8, "seek": 0, "start": 25.0, "end": 27.0, "text": " relatively new here.", "tokens": [7226, 777, 510, 13], "temperature": 0.0, "avg_logprob": -0.3608524322509766, "compression_ratio": 1.467455621301775, "no_speech_prob": 0.027485882863402367}, {"id": 9, "seek": 2700, "start": 27.0, "end": 31.0, "text": " So, you know, I first started in the HPC industry while I was in college.", "tokens": [407, 11, 291, 458, 11, 286, 700, 1409, 294, 264, 12557, 34, 3518, 1339, 286, 390, 294, 3859, 13], "temperature": 0.0, "avg_logprob": -0.10838041960738087, "compression_ratio": 1.6619217081850535, "no_speech_prob": 2.795697764668148e-05}, {"id": 10, "seek": 2700, "start": 31.0, "end": 37.0, "text": " I joined my university's HPC Institute as a software consultant,", "tokens": [286, 6869, 452, 5454, 311, 12557, 34, 9446, 382, 257, 4722, 24676, 11], "temperature": 0.0, "avg_logprob": -0.10838041960738087, "compression_ratio": 1.6619217081850535, "no_speech_prob": 2.795697764668148e-05}, {"id": 11, "seek": 2700, "start": 37.0, "end": 39.0, "text": " so largely in that role.", "tokens": [370, 11611, 294, 300, 3090, 13], "temperature": 0.0, "avg_logprob": -0.10838041960738087, "compression_ratio": 1.6619217081850535, "no_speech_prob": 2.795697764668148e-05}, {"id": 12, "seek": 2700, "start": 39.0, "end": 41.0, "text": " I was kind of more focused on support.", "tokens": [286, 390, 733, 295, 544, 5178, 322, 1406, 13], "temperature": 0.0, "avg_logprob": -0.10838041960738087, "compression_ratio": 1.6619217081850535, "no_speech_prob": 2.795697764668148e-05}, {"id": 13, "seek": 2700, "start": 41.0, "end": 44.0, "text": " So in that case, I was working on, like, singularity deployments,", "tokens": [407, 294, 300, 1389, 11, 286, 390, 1364, 322, 11, 411, 11, 20010, 507, 7274, 1117, 11], "temperature": 0.0, "avg_logprob": -0.10838041960738087, "compression_ratio": 1.6619217081850535, "no_speech_prob": 2.795697764668148e-05}, {"id": 14, "seek": 2700, "start": 44.0, "end": 46.0, "text": " you know, helping debug Fortran.", "tokens": [291, 458, 11, 4315, 24083, 11002, 4257, 13], "temperature": 0.0, "avg_logprob": -0.10838041960738087, "compression_ratio": 1.6619217081850535, "no_speech_prob": 2.795697764668148e-05}, {"id": 15, "seek": 2700, "start": 46.0, "end": 48.0, "text": " Not very good at writing Fortran, you know,", "tokens": [1726, 588, 665, 412, 3579, 11002, 4257, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.10838041960738087, "compression_ratio": 1.6619217081850535, "no_speech_prob": 2.795697764668148e-05}, {"id": 16, "seek": 2700, "start": 48.0, "end": 51.0, "text": " helping build custom kernels for Jupyter, all that good stuff.", "tokens": [4315, 1322, 2375, 23434, 1625, 337, 22125, 88, 391, 11, 439, 300, 665, 1507, 13], "temperature": 0.0, "avg_logprob": -0.10838041960738087, "compression_ratio": 1.6619217081850535, "no_speech_prob": 2.795697764668148e-05}, {"id": 17, "seek": 2700, "start": 51.0, "end": 54.0, "text": " And then I left for a bit to go work at another university", "tokens": [400, 550, 286, 1411, 337, 257, 857, 281, 352, 589, 412, 1071, 5454], "temperature": 0.0, "avg_logprob": -0.10838041960738087, "compression_ratio": 1.6619217081850535, "no_speech_prob": 2.795697764668148e-05}, {"id": 18, "seek": 5400, "start": 54.0, "end": 58.0, "text": " to do some adversarial machine learning workflow orchestration framework.", "tokens": [281, 360, 512, 17641, 44745, 3479, 2539, 20993, 14161, 2405, 8388, 13], "temperature": 0.0, "avg_logprob": -0.10417308410008748, "compression_ratio": 1.676923076923077, "no_speech_prob": 6.338117600535043e-06}, {"id": 19, "seek": 5400, "start": 58.0, "end": 62.0, "text": " And then, eventually, I came back to my university's HPC site", "tokens": [400, 550, 11, 4728, 11, 286, 1361, 646, 281, 452, 5454, 311, 12557, 34, 3621], "temperature": 0.0, "avg_logprob": -0.10417308410008748, "compression_ratio": 1.676923076923077, "no_speech_prob": 6.338117600535043e-06}, {"id": 20, "seek": 5400, "start": 62.0, "end": 65.0, "text": " then as an engineer, instead of a kind of support role.", "tokens": [550, 382, 364, 11403, 11, 2602, 295, 257, 733, 295, 1406, 3090, 13], "temperature": 0.0, "avg_logprob": -0.10417308410008748, "compression_ratio": 1.676923076923077, "no_speech_prob": 6.338117600535043e-06}, {"id": 21, "seek": 5400, "start": 65.0, "end": 67.0, "text": " So more in that case, what I worked on was, like,", "tokens": [407, 544, 294, 300, 1389, 11, 437, 286, 2732, 322, 390, 11, 411, 11], "temperature": 0.0, "avg_logprob": -0.10417308410008748, "compression_ratio": 1.676923076923077, "no_speech_prob": 6.338117600535043e-06}, {"id": 22, "seek": 5400, "start": 67.0, "end": 69.0, "text": " building, you know, a suite of singularity containers", "tokens": [2390, 11, 291, 458, 11, 257, 14205, 295, 20010, 507, 17089], "temperature": 0.0, "avg_logprob": -0.10417308410008748, "compression_ratio": 1.676923076923077, "no_speech_prob": 6.338117600535043e-06}, {"id": 23, "seek": 5400, "start": 69.0, "end": 71.0, "text": " that clients could consume,", "tokens": [300, 6982, 727, 14732, 11], "temperature": 0.0, "avg_logprob": -0.10417308410008748, "compression_ratio": 1.676923076923077, "no_speech_prob": 6.338117600535043e-06}, {"id": 24, "seek": 5400, "start": 71.0, "end": 73.0, "text": " and then also working on, like, debugging tools", "tokens": [293, 550, 611, 1364, 322, 11, 411, 11, 45592, 3873], "temperature": 0.0, "avg_logprob": -0.10417308410008748, "compression_ratio": 1.676923076923077, "no_speech_prob": 6.338117600535043e-06}, {"id": 25, "seek": 5400, "start": 73.0, "end": 77.0, "text": " that interfaced with, like, Moab and Torque and PBS and all that.", "tokens": [300, 14510, 3839, 365, 11, 411, 11, 3335, 455, 293, 7160, 1077, 293, 33517, 293, 439, 300, 13], "temperature": 0.0, "avg_logprob": -0.10417308410008748, "compression_ratio": 1.676923076923077, "no_speech_prob": 6.338117600535043e-06}, {"id": 26, "seek": 5400, "start": 77.0, "end": 80.0, "text": " And then after I graduated university, I joined Canonical.", "tokens": [400, 550, 934, 286, 13693, 5454, 11, 286, 6869, 27666, 804, 13], "temperature": 0.0, "avg_logprob": -0.10417308410008748, "compression_ratio": 1.676923076923077, "no_speech_prob": 6.338117600535043e-06}, {"id": 27, "seek": 5400, "start": 80.0, "end": 83.0, "text": " So that was probably, like, nine months ago now.", "tokens": [407, 300, 390, 1391, 11, 411, 11, 4949, 2493, 2057, 586, 13], "temperature": 0.0, "avg_logprob": -0.10417308410008748, "compression_ratio": 1.676923076923077, "no_speech_prob": 6.338117600535043e-06}, {"id": 28, "seek": 8300, "start": 83.0, "end": 87.0, "text": " So, you know, kind of the start then, you know,", "tokens": [407, 11, 291, 458, 11, 733, 295, 264, 722, 550, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.08993183038173577, "compression_ratio": 1.5677655677655677, "no_speech_prob": 1.0127941095561255e-05}, {"id": 29, "seek": 8300, "start": 87.0, "end": 90.0, "text": " what sent me down this path of wanting to develop", "tokens": [437, 2279, 385, 760, 341, 3100, 295, 7935, 281, 1499], "temperature": 0.0, "avg_logprob": -0.08993183038173577, "compression_ratio": 1.5677655677655677, "no_speech_prob": 1.0127941095561255e-05}, {"id": 30, "seek": 8300, "start": 90.0, "end": 94.0, "text": " effective testing pipelines for HPC applications?", "tokens": [4942, 4997, 40168, 337, 12557, 34, 5821, 30], "temperature": 0.0, "avg_logprob": -0.08993183038173577, "compression_ratio": 1.5677655677655677, "no_speech_prob": 1.0127941095561255e-05}, {"id": 31, "seek": 8300, "start": 94.0, "end": 97.0, "text": " Well, first, when I started at Canonical, to be frank,", "tokens": [1042, 11, 700, 11, 562, 286, 1409, 412, 27666, 804, 11, 281, 312, 10455, 11], "temperature": 0.0, "avg_logprob": -0.08993183038173577, "compression_ratio": 1.5677655677655677, "no_speech_prob": 1.0127941095561255e-05}, {"id": 32, "seek": 8300, "start": 97.0, "end": 99.0, "text": " I wasn't very good at Debian packaging.", "tokens": [286, 2067, 380, 588, 665, 412, 1346, 20196, 16836, 13], "temperature": 0.0, "avg_logprob": -0.08993183038173577, "compression_ratio": 1.5677655677655677, "no_speech_prob": 1.0127941095561255e-05}, {"id": 33, "seek": 8300, "start": 99.0, "end": 102.0, "text": " I had mostly deployed most of my software using bash scripts,", "tokens": [286, 632, 5240, 17826, 881, 295, 452, 4722, 1228, 46183, 23294, 11], "temperature": 0.0, "avg_logprob": -0.08993183038173577, "compression_ratio": 1.5677655677655677, "no_speech_prob": 1.0127941095561255e-05}, {"id": 34, "seek": 8300, "start": 102.0, "end": 104.0, "text": " compiling from source.", "tokens": [715, 4883, 490, 4009, 13], "temperature": 0.0, "avg_logprob": -0.08993183038173577, "compression_ratio": 1.5677655677655677, "no_speech_prob": 1.0127941095561255e-05}, {"id": 35, "seek": 8300, "start": 104.0, "end": 107.0, "text": " And so part of that is I had to write provisioning scripts,", "tokens": [400, 370, 644, 295, 300, 307, 286, 632, 281, 2464, 17225, 278, 23294, 11], "temperature": 0.0, "avg_logprob": -0.08993183038173577, "compression_ratio": 1.5677655677655677, "no_speech_prob": 1.0127941095561255e-05}, {"id": 36, "seek": 8300, "start": 107.0, "end": 110.0, "text": " so I mostly work in cloud orchestration,", "tokens": [370, 286, 5240, 589, 294, 4588, 14161, 2405, 11], "temperature": 0.0, "avg_logprob": -0.08993183038173577, "compression_ratio": 1.5677655677655677, "no_speech_prob": 1.0127941095561255e-05}, {"id": 37, "seek": 11000, "start": 110.0, "end": 113.0, "text": " like, nodes and whatnot, onto clouds.", "tokens": [411, 11, 13891, 293, 25882, 11, 3911, 12193, 13], "temperature": 0.0, "avg_logprob": -0.11563858304704938, "compression_ratio": 1.7285223367697595, "no_speech_prob": 8.662678737891838e-06}, {"id": 38, "seek": 11000, "start": 113.0, "end": 116.0, "text": " And so I had to, you know, develop dangerous code, you know.", "tokens": [400, 370, 286, 632, 281, 11, 291, 458, 11, 1499, 5795, 3089, 11, 291, 458, 13], "temperature": 0.0, "avg_logprob": -0.11563858304704938, "compression_ratio": 1.7285223367697595, "no_speech_prob": 8.662678737891838e-06}, {"id": 39, "seek": 11000, "start": 116.0, "end": 118.0, "text": " So it's installing packages, making configurations,", "tokens": [407, 309, 311, 20762, 17401, 11, 1455, 31493, 11], "temperature": 0.0, "avg_logprob": -0.11563858304704938, "compression_ratio": 1.7285223367697595, "no_speech_prob": 8.662678737891838e-06}, {"id": 40, "seek": 11000, "start": 118.0, "end": 123.0, "text": " kind of setting pre-seeds in, what is it, Debian, Ubuntu.", "tokens": [733, 295, 3287, 659, 12, 405, 5147, 294, 11, 437, 307, 309, 11, 1346, 20196, 11, 30230, 45605, 13], "temperature": 0.0, "avg_logprob": -0.11563858304704938, "compression_ratio": 1.7285223367697595, "no_speech_prob": 8.662678737891838e-06}, {"id": 41, "seek": 11000, "start": 123.0, "end": 126.0, "text": " And so basically, I kind of had this, you know, dilemma of where,", "tokens": [400, 370, 1936, 11, 286, 733, 295, 632, 341, 11, 291, 458, 11, 34312, 295, 689, 11], "temperature": 0.0, "avg_logprob": -0.11563858304704938, "compression_ratio": 1.7285223367697595, "no_speech_prob": 8.662678737891838e-06}, {"id": 42, "seek": 11000, "start": 126.0, "end": 130.0, "text": " okay, I want an easy way to test these provisioning scripts", "tokens": [1392, 11, 286, 528, 364, 1858, 636, 281, 1500, 613, 17225, 278, 23294], "temperature": 0.0, "avg_logprob": -0.11563858304704938, "compression_ratio": 1.7285223367697595, "no_speech_prob": 8.662678737891838e-06}, {"id": 43, "seek": 11000, "start": 130.0, "end": 133.0, "text": " without kind of having to go through all this manual effort.", "tokens": [1553, 733, 295, 1419, 281, 352, 807, 439, 341, 9688, 4630, 13], "temperature": 0.0, "avg_logprob": -0.11563858304704938, "compression_ratio": 1.7285223367697595, "no_speech_prob": 8.662678737891838e-06}, {"id": 44, "seek": 11000, "start": 133.0, "end": 135.0, "text": " So originally, you know, I just, you know,", "tokens": [407, 7993, 11, 291, 458, 11, 286, 445, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.11563858304704938, "compression_ratio": 1.7285223367697595, "no_speech_prob": 8.662678737891838e-06}, {"id": 45, "seek": 11000, "start": 135.0, "end": 139.0, "text": " typed in vagrant virtual box or any real kind of virtual machine", "tokens": [33941, 294, 13501, 7541, 6374, 2424, 420, 604, 957, 733, 295, 6374, 3479], "temperature": 0.0, "avg_logprob": -0.11563858304704938, "compression_ratio": 1.7285223367697595, "no_speech_prob": 8.662678737891838e-06}, {"id": 46, "seek": 13900, "start": 139.0, "end": 141.0, "text": " or a supervisor, bring it up, install the script,", "tokens": [420, 257, 24610, 11, 1565, 309, 493, 11, 3625, 264, 5755, 11], "temperature": 0.0, "avg_logprob": -0.10535088777542115, "compression_ratio": 1.7024539877300613, "no_speech_prob": 5.6817025324562564e-06}, {"id": 47, "seek": 13900, "start": 141.0, "end": 144.0, "text": " and then once I was done with it, blow it out.", "tokens": [293, 550, 1564, 286, 390, 1096, 365, 309, 11, 6327, 309, 484, 13], "temperature": 0.0, "avg_logprob": -0.10535088777542115, "compression_ratio": 1.7024539877300613, "no_speech_prob": 5.6817025324562564e-06}, {"id": 48, "seek": 13900, "start": 144.0, "end": 146.0, "text": " And then kind of also have this issue of where I had a desire", "tokens": [400, 550, 733, 295, 611, 362, 341, 2734, 295, 689, 286, 632, 257, 7516], "temperature": 0.0, "avg_logprob": -0.10535088777542115, "compression_ratio": 1.7024539877300613, "no_speech_prob": 5.6817025324562564e-06}, {"id": 49, "seek": 13900, "start": 146.0, "end": 149.0, "text": " for reproducible tests, because even though, like, you know,", "tokens": [337, 11408, 32128, 6921, 11, 570, 754, 1673, 11, 411, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.10535088777542115, "compression_ratio": 1.7024539877300613, "no_speech_prob": 5.6817025324562564e-06}, {"id": 50, "seek": 13900, "start": 149.0, "end": 152.0, "text": " I know how to bring up, like, a virtual machine on my system,", "tokens": [286, 458, 577, 281, 1565, 493, 11, 411, 11, 257, 6374, 3479, 322, 452, 1185, 11], "temperature": 0.0, "avg_logprob": -0.10535088777542115, "compression_ratio": 1.7024539877300613, "no_speech_prob": 5.6817025324562564e-06}, {"id": 51, "seek": 13900, "start": 152.0, "end": 155.0, "text": " you know, I might be working with someone who's off of Windows", "tokens": [291, 458, 11, 286, 1062, 312, 1364, 365, 1580, 567, 311, 766, 295, 8591], "temperature": 0.0, "avg_logprob": -0.10535088777542115, "compression_ratio": 1.7024539877300613, "no_speech_prob": 5.6817025324562564e-06}, {"id": 52, "seek": 13900, "start": 155.0, "end": 158.0, "text": " or Mac, and so they don't have the same setup that I do,", "tokens": [420, 5707, 11, 293, 370, 436, 500, 380, 362, 264, 912, 8657, 300, 286, 360, 11], "temperature": 0.0, "avg_logprob": -0.10535088777542115, "compression_ratio": 1.7024539877300613, "no_speech_prob": 5.6817025324562564e-06}, {"id": 53, "seek": 13900, "start": 158.0, "end": 162.0, "text": " or they're using a different distribution, in fact.", "tokens": [420, 436, 434, 1228, 257, 819, 7316, 11, 294, 1186, 13], "temperature": 0.0, "avg_logprob": -0.10535088777542115, "compression_ratio": 1.7024539877300613, "no_speech_prob": 5.6817025324562564e-06}, {"id": 54, "seek": 13900, "start": 162.0, "end": 165.0, "text": " So this gave me the idea of, you know, kind of,", "tokens": [407, 341, 2729, 385, 264, 1558, 295, 11, 291, 458, 11, 733, 295, 11], "temperature": 0.0, "avg_logprob": -0.10535088777542115, "compression_ratio": 1.7024539877300613, "no_speech_prob": 5.6817025324562564e-06}, {"id": 55, "seek": 13900, "start": 165.0, "end": 168.0, "text": " if I'm on my personal workstation here, so my laptop,", "tokens": [498, 286, 478, 322, 452, 2973, 589, 19159, 510, 11, 370, 452, 10732, 11], "temperature": 0.0, "avg_logprob": -0.10535088777542115, "compression_ratio": 1.7024539877300613, "no_speech_prob": 5.6817025324562564e-06}, {"id": 56, "seek": 16800, "start": 168.0, "end": 171.0, "text": " unfortunately, my current laptop's X server isn't working,", "tokens": [7015, 11, 452, 2190, 10732, 311, 1783, 7154, 1943, 380, 1364, 11], "temperature": 0.0, "avg_logprob": -0.0902509823651381, "compression_ratio": 1.6595744680851063, "no_speech_prob": 1.1299232937744819e-05}, {"id": 57, "seek": 16800, "start": 171.0, "end": 173.0, "text": " so the HDMI cable gets all screwed up,", "tokens": [370, 264, 30811, 8220, 2170, 439, 20331, 493, 11], "temperature": 0.0, "avg_logprob": -0.0902509823651381, "compression_ratio": 1.6595744680851063, "no_speech_prob": 1.1299232937744819e-05}, {"id": 58, "seek": 16800, "start": 173.0, "end": 176.0, "text": " so thank you, EasyBuild folks, for lending me your computer.", "tokens": [370, 1309, 291, 11, 16002, 28110, 793, 4024, 11, 337, 29823, 385, 428, 3820, 13], "temperature": 0.0, "avg_logprob": -0.0902509823651381, "compression_ratio": 1.6595744680851063, "no_speech_prob": 1.1299232937744819e-05}, {"id": 59, "seek": 16800, "start": 176.0, "end": 179.0, "text": " But basically, I had the idea that what if I take a test", "tokens": [583, 1936, 11, 286, 632, 264, 1558, 300, 437, 498, 286, 747, 257, 1500], "temperature": 0.0, "avg_logprob": -0.0902509823651381, "compression_ratio": 1.6595744680851063, "no_speech_prob": 1.1299232937744819e-05}, {"id": 60, "seek": 16800, "start": 179.0, "end": 183.0, "text": " that's written on my system and then have the ability to run it", "tokens": [300, 311, 3720, 322, 452, 1185, 293, 550, 362, 264, 3485, 281, 1190, 309], "temperature": 0.0, "avg_logprob": -0.0902509823651381, "compression_ratio": 1.6595744680851063, "no_speech_prob": 1.1299232937744819e-05}, {"id": 61, "seek": 16800, "start": 183.0, "end": 186.0, "text": " using any hypervisor I want on any operating system", "tokens": [1228, 604, 9848, 16457, 286, 528, 322, 604, 7447, 1185], "temperature": 0.0, "avg_logprob": -0.0902509823651381, "compression_ratio": 1.6595744680851063, "no_speech_prob": 1.1299232937744819e-05}, {"id": 62, "seek": 16800, "start": 186.0, "end": 188.0, "text": " that I need to test that code on without any extra hassle", "tokens": [300, 286, 643, 281, 1500, 300, 3089, 322, 1553, 604, 2857, 39526], "temperature": 0.0, "avg_logprob": -0.0902509823651381, "compression_ratio": 1.6595744680851063, "no_speech_prob": 1.1299232937744819e-05}, {"id": 63, "seek": 16800, "start": 188.0, "end": 191.0, "text": " of having to really go through supporting", "tokens": [295, 1419, 281, 534, 352, 807, 7231], "temperature": 0.0, "avg_logprob": -0.0902509823651381, "compression_ratio": 1.6595744680851063, "no_speech_prob": 1.1299232937744819e-05}, {"id": 64, "seek": 16800, "start": 191.0, "end": 194.0, "text": " or teaching someone else how to bring up that instance.", "tokens": [420, 4571, 1580, 1646, 577, 281, 1565, 493, 300, 5197, 13], "temperature": 0.0, "avg_logprob": -0.0902509823651381, "compression_ratio": 1.6595744680851063, "no_speech_prob": 1.1299232937744819e-05}, {"id": 65, "seek": 16800, "start": 194.0, "end": 197.0, "text": " And basically the case of, like, oh, I have to write code,", "tokens": [400, 1936, 264, 1389, 295, 11, 411, 11, 1954, 11, 286, 362, 281, 2464, 3089, 11], "temperature": 0.0, "avg_logprob": -0.0902509823651381, "compression_ratio": 1.6595744680851063, "no_speech_prob": 1.1299232937744819e-05}, {"id": 66, "seek": 19700, "start": 197.0, "end": 199.0, "text": " or run or anything else that needs to run,", "tokens": [420, 1190, 420, 1340, 1646, 300, 2203, 281, 1190, 11], "temperature": 0.0, "avg_logprob": -0.15039190509975356, "compression_ratio": 1.7294520547945205, "no_speech_prob": 1.3005465007154271e-05}, {"id": 67, "seek": 19700, "start": 199.0, "end": 203.0, "text": " like Ubuntu, CentOS, Alma, or Rocky.", "tokens": [411, 30230, 45605, 11, 3408, 4367, 11, 42439, 11, 420, 26916, 13], "temperature": 0.0, "avg_logprob": -0.15039190509975356, "compression_ratio": 1.7294520547945205, "no_speech_prob": 1.3005465007154271e-05}, {"id": 68, "seek": 19700, "start": 203.0, "end": 205.0, "text": " And then kind of after working for that a bit,", "tokens": [400, 550, 733, 295, 934, 1364, 337, 300, 257, 857, 11], "temperature": 0.0, "avg_logprob": -0.15039190509975356, "compression_ratio": 1.7294520547945205, "no_speech_prob": 1.3005465007154271e-05}, {"id": 69, "seek": 19700, "start": 205.0, "end": 207.0, "text": " you know, I had kind of an initial prototype", "tokens": [291, 458, 11, 286, 632, 733, 295, 364, 5883, 19475], "temperature": 0.0, "avg_logprob": -0.15039190509975356, "compression_ratio": 1.7294520547945205, "no_speech_prob": 1.3005465007154271e-05}, {"id": 70, "seek": 19700, "start": 207.0, "end": 210.0, "text": " that would bring up, you know, basic operating system image,", "tokens": [300, 576, 1565, 493, 11, 291, 458, 11, 3875, 7447, 1185, 3256, 11], "temperature": 0.0, "avg_logprob": -0.15039190509975356, "compression_ratio": 1.7294520547945205, "no_speech_prob": 1.3005465007154271e-05}, {"id": 71, "seek": 19700, "start": 210.0, "end": 214.0, "text": " and then kind of as I, you know, got more into my HBC work at Canonical,", "tokens": [293, 550, 733, 295, 382, 286, 11, 291, 458, 11, 658, 544, 666, 452, 389, 7869, 589, 412, 27666, 804, 11], "temperature": 0.0, "avg_logprob": -0.15039190509975356, "compression_ratio": 1.7294520547945205, "no_speech_prob": 1.3005465007154271e-05}, {"id": 72, "seek": 19700, "start": 214.0, "end": 218.0, "text": " I kind of realized, like, oh, okay, you know,", "tokens": [286, 733, 295, 5334, 11, 411, 11, 1954, 11, 1392, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.15039190509975356, "compression_ratio": 1.7294520547945205, "no_speech_prob": 1.3005465007154271e-05}, {"id": 73, "seek": 19700, "start": 218.0, "end": 221.0, "text": " maybe don't want to rack up the cloud bill trying to test", "tokens": [1310, 500, 380, 528, 281, 14788, 493, 264, 4588, 2961, 1382, 281, 1500], "temperature": 0.0, "avg_logprob": -0.15039190509975356, "compression_ratio": 1.7294520547945205, "no_speech_prob": 1.3005465007154271e-05}, {"id": 74, "seek": 19700, "start": 221.0, "end": 223.0, "text": " and deploy to AWS or, you know, Azure,", "tokens": [293, 7274, 281, 17650, 420, 11, 291, 458, 11, 11969, 11], "temperature": 0.0, "avg_logprob": -0.15039190509975356, "compression_ratio": 1.7294520547945205, "no_speech_prob": 1.3005465007154271e-05}, {"id": 75, "seek": 19700, "start": 223.0, "end": 226.0, "text": " or, you know, even our own private internal public cloud", "tokens": [420, 11, 291, 458, 11, 754, 527, 1065, 4551, 6920, 1908, 4588], "temperature": 0.0, "avg_logprob": -0.15039190509975356, "compression_ratio": 1.7294520547945205, "no_speech_prob": 1.3005465007154271e-05}, {"id": 76, "seek": 22600, "start": 226.0, "end": 228.0, "text": " or private cloud using OpenStack", "tokens": [420, 4551, 4588, 1228, 7238, 4520, 501], "temperature": 0.0, "avg_logprob": -0.08977832794189453, "compression_ratio": 1.623003194888179, "no_speech_prob": 1.7775295418687165e-05}, {"id": 77, "seek": 22600, "start": 228.0, "end": 231.0, "text": " for, you know, just trying to provision HBC nodes.", "tokens": [337, 11, 291, 458, 11, 445, 1382, 281, 17225, 389, 7869, 13891, 13], "temperature": 0.0, "avg_logprob": -0.08977832794189453, "compression_ratio": 1.623003194888179, "no_speech_prob": 1.7775295418687165e-05}, {"id": 78, "seek": 22600, "start": 231.0, "end": 233.0, "text": " So, for example, have, like, identity management,", "tokens": [407, 11, 337, 1365, 11, 362, 11, 411, 11, 6575, 4592, 11], "temperature": 0.0, "avg_logprob": -0.08977832794189453, "compression_ratio": 1.623003194888179, "no_speech_prob": 1.7775295418687165e-05}, {"id": 79, "seek": 22600, "start": 233.0, "end": 236.0, "text": " open LDAP, shared file system using NFS,", "tokens": [1269, 33936, 4715, 11, 5507, 3991, 1185, 1228, 13576, 50, 11], "temperature": 0.0, "avg_logprob": -0.08977832794189453, "compression_ratio": 1.623003194888179, "no_speech_prob": 1.7775295418687165e-05}, {"id": 80, "seek": 22600, "start": 236.0, "end": 238.0, "text": " you know, have other options.", "tokens": [291, 458, 11, 362, 661, 3956, 13], "temperature": 0.0, "avg_logprob": -0.08977832794189453, "compression_ratio": 1.623003194888179, "no_speech_prob": 1.7775295418687165e-05}, {"id": 81, "seek": 22600, "start": 238.0, "end": 241.0, "text": " And then also working in the case of just setting up", "tokens": [400, 550, 611, 1364, 294, 264, 1389, 295, 445, 3287, 493], "temperature": 0.0, "avg_logprob": -0.08977832794189453, "compression_ratio": 1.623003194888179, "no_speech_prob": 1.7775295418687165e-05}, {"id": 82, "seek": 22600, "start": 241.0, "end": 243.0, "text": " and configuring a Slurm cluster, all kind of headless", "tokens": [293, 6662, 1345, 257, 6187, 26717, 13630, 11, 439, 733, 295, 1378, 1832], "temperature": 0.0, "avg_logprob": -0.08977832794189453, "compression_ratio": 1.623003194888179, "no_speech_prob": 1.7775295418687165e-05}, {"id": 83, "seek": 22600, "start": 243.0, "end": 246.0, "text": " without any kind of manual user intervention.", "tokens": [1553, 604, 733, 295, 9688, 4195, 13176, 13], "temperature": 0.0, "avg_logprob": -0.08977832794189453, "compression_ratio": 1.623003194888179, "no_speech_prob": 1.7775295418687165e-05}, {"id": 84, "seek": 22600, "start": 246.0, "end": 249.0, "text": " And so I kind of had this revelation where I'm like,", "tokens": [400, 370, 286, 733, 295, 632, 341, 23456, 689, 286, 478, 411, 11], "temperature": 0.0, "avg_logprob": -0.08977832794189453, "compression_ratio": 1.623003194888179, "no_speech_prob": 1.7775295418687165e-05}, {"id": 85, "seek": 22600, "start": 249.0, "end": 252.0, "text": " why waste precious compute time on your HBC cluster", "tokens": [983, 5964, 12406, 14722, 565, 322, 428, 389, 7869, 13630], "temperature": 0.0, "avg_logprob": -0.08977832794189453, "compression_ratio": 1.623003194888179, "no_speech_prob": 1.7775295418687165e-05}, {"id": 86, "seek": 22600, "start": 252.0, "end": 254.0, "text": " because the fact is it's expensive, you know,", "tokens": [570, 264, 1186, 307, 309, 311, 5124, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.08977832794189453, "compression_ratio": 1.623003194888179, "no_speech_prob": 1.7775295418687165e-05}, {"id": 87, "seek": 25400, "start": 254.0, "end": 256.0, "text": " you're kind of paying for that tenancy.", "tokens": [291, 434, 733, 295, 6229, 337, 300, 2064, 6717, 13], "temperature": 0.0, "avg_logprob": -0.11029931037656722, "compression_ratio": 1.7027972027972027, "no_speech_prob": 6.960928203625372e-06}, {"id": 88, "seek": 25400, "start": 256.0, "end": 258.0, "text": " And what if you could test your simulations,", "tokens": [400, 437, 498, 291, 727, 1500, 428, 35138, 11], "temperature": 0.0, "avg_logprob": -0.11029931037656722, "compression_ratio": 1.7027972027972027, "no_speech_prob": 6.960928203625372e-06}, {"id": 89, "seek": 25400, "start": 258.0, "end": 262.0, "text": " jobs or applications and whatnot on a mini HBC cluster", "tokens": [4782, 420, 5821, 293, 25882, 322, 257, 8382, 389, 7869, 13630], "temperature": 0.0, "avg_logprob": -0.11029931037656722, "compression_ratio": 1.7027972027972027, "no_speech_prob": 6.960928203625372e-06}, {"id": 90, "seek": 25400, "start": 262.0, "end": 265.0, "text": " that's kind of similar to the target platform", "tokens": [300, 311, 733, 295, 2531, 281, 264, 3779, 3663], "temperature": 0.0, "avg_logprob": -0.11029931037656722, "compression_ratio": 1.7027972027972027, "no_speech_prob": 6.960928203625372e-06}, {"id": 91, "seek": 25400, "start": 265.0, "end": 267.0, "text": " that you're deploying, but it's more of a mock", "tokens": [300, 291, 434, 34198, 11, 457, 309, 311, 544, 295, 257, 17362], "temperature": 0.0, "avg_logprob": -0.11029931037656722, "compression_ratio": 1.7027972027972027, "no_speech_prob": 6.960928203625372e-06}, {"id": 92, "seek": 25400, "start": 267.0, "end": 269.0, "text": " so that you can kind of get the general feel for the platform", "tokens": [370, 300, 291, 393, 733, 295, 483, 264, 2674, 841, 337, 264, 3663], "temperature": 0.0, "avg_logprob": -0.11029931037656722, "compression_ratio": 1.7027972027972027, "no_speech_prob": 6.960928203625372e-06}, {"id": 93, "seek": 25400, "start": 269.0, "end": 272.0, "text": " before moving on to the more expensive resources.", "tokens": [949, 2684, 322, 281, 264, 544, 5124, 3593, 13], "temperature": 0.0, "avg_logprob": -0.11029931037656722, "compression_ratio": 1.7027972027972027, "no_speech_prob": 6.960928203625372e-06}, {"id": 94, "seek": 25400, "start": 272.0, "end": 275.0, "text": " So in this case, you know,", "tokens": [407, 294, 341, 1389, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.11029931037656722, "compression_ratio": 1.7027972027972027, "no_speech_prob": 6.960928203625372e-06}, {"id": 95, "seek": 25400, "start": 275.0, "end": 278.0, "text": " I started working on a custom testing framework", "tokens": [286, 1409, 1364, 322, 257, 2375, 4997, 8388], "temperature": 0.0, "avg_logprob": -0.11029931037656722, "compression_ratio": 1.7027972027972027, "no_speech_prob": 6.960928203625372e-06}, {"id": 96, "seek": 25400, "start": 278.0, "end": 283.0, "text": " called CleanTest, which is basically a fancy Python testing library", "tokens": [1219, 18463, 51, 377, 11, 597, 307, 1936, 257, 10247, 15329, 4997, 6405], "temperature": 0.0, "avg_logprob": -0.11029931037656722, "compression_ratio": 1.7027972027972027, "no_speech_prob": 6.960928203625372e-06}, {"id": 97, "seek": 28300, "start": 283.0, "end": 286.0, "text": " that allows you to bring up many HBC clusters", "tokens": [300, 4045, 291, 281, 1565, 493, 867, 389, 7869, 23313], "temperature": 0.0, "avg_logprob": -0.07249649651616598, "compression_ratio": 1.6827586206896552, "no_speech_prob": 6.642618700425373e-06}, {"id": 98, "seek": 28300, "start": 286.0, "end": 288.0, "text": " on your local system and, you know,", "tokens": [322, 428, 2654, 1185, 293, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.07249649651616598, "compression_ratio": 1.6827586206896552, "no_speech_prob": 6.642618700425373e-06}, {"id": 99, "seek": 28300, "start": 288.0, "end": 290.0, "text": " just kind of in general usage for developers", "tokens": [445, 733, 295, 294, 2674, 14924, 337, 8849], "temperature": 0.0, "avg_logprob": -0.07249649651616598, "compression_ratio": 1.6827586206896552, "no_speech_prob": 6.642618700425373e-06}, {"id": 100, "seek": 28300, "start": 290.0, "end": 292.0, "text": " who are in a hurry.", "tokens": [567, 366, 294, 257, 11025, 13], "temperature": 0.0, "avg_logprob": -0.07249649651616598, "compression_ratio": 1.6827586206896552, "no_speech_prob": 6.642618700425373e-06}, {"id": 101, "seek": 28300, "start": 292.0, "end": 295.0, "text": " So kind of then breaking into a question, you know,", "tokens": [407, 733, 295, 550, 7697, 666, 257, 1168, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.07249649651616598, "compression_ratio": 1.6827586206896552, "no_speech_prob": 6.642618700425373e-06}, {"id": 102, "seek": 28300, "start": 295.0, "end": 297.0, "text": " what exactly is a CleanTest?", "tokens": [437, 2293, 307, 257, 18463, 51, 377, 30], "temperature": 0.0, "avg_logprob": -0.07249649651616598, "compression_ratio": 1.6827586206896552, "no_speech_prob": 6.642618700425373e-06}, {"id": 103, "seek": 28300, "start": 297.0, "end": 300.0, "text": " Because, you know, originally I named it SimpleTest", "tokens": [1436, 11, 291, 458, 11, 7993, 286, 4926, 309, 21532, 51, 377], "temperature": 0.0, "avg_logprob": -0.07249649651616598, "compression_ratio": 1.6827586206896552, "no_speech_prob": 6.642618700425373e-06}, {"id": 104, "seek": 28300, "start": 300.0, "end": 302.0, "text": " because I just wanted it to be really dead simple,", "tokens": [570, 286, 445, 1415, 309, 281, 312, 534, 3116, 2199, 11], "temperature": 0.0, "avg_logprob": -0.07249649651616598, "compression_ratio": 1.6827586206896552, "no_speech_prob": 6.642618700425373e-06}, {"id": 105, "seek": 28300, "start": 302.0, "end": 305.0, "text": " but for some reason PyPI wouldn't let me register that name.", "tokens": [457, 337, 512, 1778, 9953, 31701, 2759, 380, 718, 385, 7280, 300, 1315, 13], "temperature": 0.0, "avg_logprob": -0.07249649651616598, "compression_ratio": 1.6827586206896552, "no_speech_prob": 6.642618700425373e-06}, {"id": 106, "seek": 28300, "start": 305.0, "end": 307.0, "text": " So CleanTest it is.", "tokens": [407, 18463, 51, 377, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.07249649651616598, "compression_ratio": 1.6827586206896552, "no_speech_prob": 6.642618700425373e-06}, {"id": 107, "seek": 28300, "start": 307.0, "end": 310.0, "text": " So basically it comes in three parts.", "tokens": [407, 1936, 309, 1487, 294, 1045, 3166, 13], "temperature": 0.0, "avg_logprob": -0.07249649651616598, "compression_ratio": 1.6827586206896552, "no_speech_prob": 6.642618700425373e-06}, {"id": 108, "seek": 28300, "start": 310.0, "end": 312.0, "text": " There's kind of a different breakdown.", "tokens": [821, 311, 733, 295, 257, 819, 18188, 13], "temperature": 0.0, "avg_logprob": -0.07249649651616598, "compression_ratio": 1.6827586206896552, "no_speech_prob": 6.642618700425373e-06}, {"id": 109, "seek": 31200, "start": 312.0, "end": 315.0, "text": " First, you have the bootstrap and configuration stage.", "tokens": [2386, 11, 291, 362, 264, 11450, 372, 4007, 293, 11694, 3233, 13], "temperature": 0.0, "avg_logprob": -0.10527235311228078, "compression_ratio": 1.7105263157894737, "no_speech_prob": 2.177468195441179e-05}, {"id": 110, "seek": 31200, "start": 315.0, "end": 318.0, "text": " So for that, it's kind of where you can register hooks and whatnot", "tokens": [407, 337, 300, 11, 309, 311, 733, 295, 689, 291, 393, 7280, 26485, 293, 25882], "temperature": 0.0, "avg_logprob": -0.10527235311228078, "compression_ratio": 1.7105263157894737, "no_speech_prob": 2.177468195441179e-05}, {"id": 111, "seek": 31200, "start": 318.0, "end": 321.0, "text": " for configuring the instances that you're bringing up", "tokens": [337, 6662, 1345, 264, 14519, 300, 291, 434, 5062, 493], "temperature": 0.0, "avg_logprob": -0.10527235311228078, "compression_ratio": 1.7105263157894737, "no_speech_prob": 2.177468195441179e-05}, {"id": 112, "seek": 31200, "start": 321.0, "end": 323.0, "text": " or do some more advanced bootstrapping.", "tokens": [420, 360, 512, 544, 7339, 11450, 19639, 3759, 13], "temperature": 0.0, "avg_logprob": -0.10527235311228078, "compression_ratio": 1.7105263157894737, "no_speech_prob": 2.177468195441179e-05}, {"id": 113, "seek": 31200, "start": 323.0, "end": 325.0, "text": " So the example I had shown in the previous slide", "tokens": [407, 264, 1365, 286, 632, 4898, 294, 264, 3894, 4137], "temperature": 0.0, "avg_logprob": -0.10527235311228078, "compression_ratio": 1.7105263157894737, "no_speech_prob": 2.177468195441179e-05}, {"id": 114, "seek": 31200, "start": 325.0, "end": 327.0, "text": " of where you're able to bring up NFS,", "tokens": [295, 689, 291, 434, 1075, 281, 1565, 493, 13576, 50, 11], "temperature": 0.0, "avg_logprob": -0.10527235311228078, "compression_ratio": 1.7105263157894737, "no_speech_prob": 2.177468195441179e-05}, {"id": 115, "seek": 31200, "start": 327.0, "end": 329.0, "text": " open LDAP, slurm services and whatnot,", "tokens": [1269, 33936, 4715, 11, 1061, 26717, 3328, 293, 25882, 11], "temperature": 0.0, "avg_logprob": -0.10527235311228078, "compression_ratio": 1.7105263157894737, "no_speech_prob": 2.177468195441179e-05}, {"id": 116, "seek": 31200, "start": 329.0, "end": 333.0, "text": " and then be able to inject scriptlets into that.", "tokens": [293, 550, 312, 1075, 281, 10711, 5755, 12541, 666, 300, 13], "temperature": 0.0, "avg_logprob": -0.10527235311228078, "compression_ratio": 1.7105263157894737, "no_speech_prob": 2.177468195441179e-05}, {"id": 117, "seek": 31200, "start": 333.0, "end": 336.0, "text": " And so kind of that's when we get to the second part here,", "tokens": [400, 370, 733, 295, 300, 311, 562, 321, 483, 281, 264, 1150, 644, 510, 11], "temperature": 0.0, "avg_logprob": -0.10527235311228078, "compression_ratio": 1.7105263157894737, "no_speech_prob": 2.177468195441179e-05}, {"id": 118, "seek": 31200, "start": 336.0, "end": 338.0, "text": " which is a Tesla.", "tokens": [597, 307, 257, 13666, 13], "temperature": 0.0, "avg_logprob": -0.10527235311228078, "compression_ratio": 1.7105263157894737, "no_speech_prob": 2.177468195441179e-05}, {"id": 119, "seek": 31200, "start": 338.0, "end": 341.0, "text": " Kind of interesting little word that I came up with,", "tokens": [9242, 295, 1880, 707, 1349, 300, 286, 1361, 493, 365, 11], "temperature": 0.0, "avg_logprob": -0.10527235311228078, "compression_ratio": 1.7105263157894737, "no_speech_prob": 2.177468195441179e-05}, {"id": 120, "seek": 34100, "start": 341.0, "end": 343.0, "text": " joking with some of my colleagues,", "tokens": [17396, 365, 512, 295, 452, 7734, 11], "temperature": 0.0, "avg_logprob": -0.08228003403236125, "compression_ratio": 1.8026315789473684, "no_speech_prob": 1.4736006960447412e-05}, {"id": 121, "seek": 34100, "start": 343.0, "end": 345.0, "text": " but basically a Tesla is an entire Python program", "tokens": [457, 1936, 257, 13666, 307, 364, 2302, 15329, 1461], "temperature": 0.0, "avg_logprob": -0.08228003403236125, "compression_ratio": 1.8026315789473684, "no_speech_prob": 1.4736006960447412e-05}, {"id": 122, "seek": 34100, "start": 345.0, "end": 347.0, "text": " that's wrapped into a regular function,", "tokens": [300, 311, 14226, 666, 257, 3890, 2445, 11], "temperature": 0.0, "avg_logprob": -0.08228003403236125, "compression_ratio": 1.8026315789473684, "no_speech_prob": 1.4736006960447412e-05}, {"id": 123, "seek": 34100, "start": 347.0, "end": 350.0, "text": " and kind of the idea is that they contain the full body of the test", "tokens": [293, 733, 295, 264, 1558, 307, 300, 436, 5304, 264, 1577, 1772, 295, 264, 1500], "temperature": 0.0, "avg_logprob": -0.08228003403236125, "compression_ratio": 1.8026315789473684, "no_speech_prob": 1.4736006960447412e-05}, {"id": 124, "seek": 34100, "start": 350.0, "end": 354.0, "text": " that you want to be able to run inside this virtual machine container", "tokens": [300, 291, 528, 281, 312, 1075, 281, 1190, 1854, 341, 6374, 3479, 10129], "temperature": 0.0, "avg_logprob": -0.08228003403236125, "compression_ratio": 1.8026315789473684, "no_speech_prob": 1.4736006960447412e-05}, {"id": 125, "seek": 34100, "start": 354.0, "end": 356.0, "text": " or, you know, test mini-cluster.", "tokens": [420, 11, 291, 458, 11, 1500, 8382, 12, 3474, 8393, 13], "temperature": 0.0, "avg_logprob": -0.08228003403236125, "compression_ratio": 1.8026315789473684, "no_speech_prob": 1.4736006960447412e-05}, {"id": 126, "seek": 34100, "start": 356.0, "end": 358.0, "text": " And then kind of the last part here", "tokens": [400, 550, 733, 295, 264, 1036, 644, 510], "temperature": 0.0, "avg_logprob": -0.08228003403236125, "compression_ratio": 1.8026315789473684, "no_speech_prob": 1.4736006960447412e-05}, {"id": 127, "seek": 34100, "start": 358.0, "end": 361.0, "text": " is the evaluation reporting aspect.", "tokens": [307, 264, 13344, 10031, 4171, 13], "temperature": 0.0, "avg_logprob": -0.08228003403236125, "compression_ratio": 1.8026315789473684, "no_speech_prob": 1.4736006960447412e-05}, {"id": 128, "seek": 34100, "start": 361.0, "end": 364.0, "text": " And then kind of with that, you know, I took a test, you know,", "tokens": [400, 550, 733, 295, 365, 300, 11, 291, 458, 11, 286, 1890, 257, 1500, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.08228003403236125, "compression_ratio": 1.8026315789473684, "no_speech_prob": 1.4736006960447412e-05}, {"id": 129, "seek": 34100, "start": 364.0, "end": 366.0, "text": " subtest framework, you know, agnostic approach", "tokens": [7257, 377, 8388, 11, 291, 458, 11, 623, 77, 19634, 3109], "temperature": 0.0, "avg_logprob": -0.08228003403236125, "compression_ratio": 1.8026315789473684, "no_speech_prob": 1.4736006960447412e-05}, {"id": 130, "seek": 34100, "start": 366.0, "end": 369.0, "text": " where I know that everyone kind of has their own taste that they like.", "tokens": [689, 286, 458, 300, 1518, 733, 295, 575, 641, 1065, 3939, 300, 436, 411, 13], "temperature": 0.0, "avg_logprob": -0.08228003403236125, "compression_ratio": 1.8026315789473684, "no_speech_prob": 1.4736006960447412e-05}, {"id": 131, "seek": 36900, "start": 369.0, "end": 372.0, "text": " Some people like pie tests, some like unit tests, you know.", "tokens": [2188, 561, 411, 1730, 6921, 11, 512, 411, 4985, 6921, 11, 291, 458, 13], "temperature": 0.0, "avg_logprob": -0.10021701540265765, "compression_ratio": 1.7402135231316727, "no_speech_prob": 8.396931661991403e-06}, {"id": 132, "seek": 36900, "start": 372.0, "end": 374.0, "text": " I don't want to sit here and make opinions for you,", "tokens": [286, 500, 380, 528, 281, 1394, 510, 293, 652, 11819, 337, 291, 11], "temperature": 0.0, "avg_logprob": -0.10021701540265765, "compression_ratio": 1.7402135231316727, "no_speech_prob": 8.396931661991403e-06}, {"id": 133, "seek": 36900, "start": 374.0, "end": 377.0, "text": " so, you know, I want you to be able to write tests", "tokens": [370, 11, 291, 458, 11, 286, 528, 291, 281, 312, 1075, 281, 2464, 6921], "temperature": 0.0, "avg_logprob": -0.10021701540265765, "compression_ratio": 1.7402135231316727, "no_speech_prob": 8.396931661991403e-06}, {"id": 134, "seek": 36900, "start": 377.0, "end": 380.0, "text": " in the format that you're most comfortable with.", "tokens": [294, 264, 7877, 300, 291, 434, 881, 4619, 365, 13], "temperature": 0.0, "avg_logprob": -0.10021701540265765, "compression_ratio": 1.7402135231316727, "no_speech_prob": 8.396931661991403e-06}, {"id": 135, "seek": 36900, "start": 380.0, "end": 383.0, "text": " Oh, that came out small, but that's okay.", "tokens": [876, 11, 300, 1361, 484, 1359, 11, 457, 300, 311, 1392, 13], "temperature": 0.0, "avg_logprob": -0.10021701540265765, "compression_ratio": 1.7402135231316727, "no_speech_prob": 8.396931661991403e-06}, {"id": 136, "seek": 36900, "start": 383.0, "end": 385.0, "text": " So kind of the first part here", "tokens": [407, 733, 295, 264, 700, 644, 510], "temperature": 0.0, "avg_logprob": -0.10021701540265765, "compression_ratio": 1.7402135231316727, "no_speech_prob": 8.396931661991403e-06}, {"id": 137, "seek": 36900, "start": 385.0, "end": 387.0, "text": " is the going more advanced into, like,", "tokens": [307, 264, 516, 544, 7339, 666, 11, 411, 11], "temperature": 0.0, "avg_logprob": -0.10021701540265765, "compression_ratio": 1.7402135231316727, "no_speech_prob": 8.396931661991403e-06}, {"id": 138, "seek": 36900, "start": 387.0, "end": 389.0, "text": " what exactly is the bootstrap in configuration", "tokens": [437, 2293, 307, 264, 11450, 372, 4007, 294, 11694], "temperature": 0.0, "avg_logprob": -0.10021701540265765, "compression_ratio": 1.7402135231316727, "no_speech_prob": 8.396931661991403e-06}, {"id": 139, "seek": 36900, "start": 389.0, "end": 392.0, "text": " is that you're able to bring up example nodes,", "tokens": [307, 300, 291, 434, 1075, 281, 1565, 493, 1365, 13891, 11], "temperature": 0.0, "avg_logprob": -0.10021701540265765, "compression_ratio": 1.7402135231316727, "no_speech_prob": 8.396931661991403e-06}, {"id": 140, "seek": 36900, "start": 392.0, "end": 396.0, "text": " you're able to provision them.", "tokens": [291, 434, 1075, 281, 17225, 552, 13], "temperature": 0.0, "avg_logprob": -0.10021701540265765, "compression_ratio": 1.7402135231316727, "no_speech_prob": 8.396931661991403e-06}, {"id": 141, "seek": 36900, "start": 396.0, "end": 398.0, "text": " What is it? You can also register hooks,", "tokens": [708, 307, 309, 30, 509, 393, 611, 7280, 26485, 11], "temperature": 0.0, "avg_logprob": -0.10021701540265765, "compression_ratio": 1.7402135231316727, "no_speech_prob": 8.396931661991403e-06}, {"id": 142, "seek": 39800, "start": 398.0, "end": 401.0, "text": " so it's kind of similar to anyone who's done any Debian packaging.", "tokens": [370, 309, 311, 733, 295, 2531, 281, 2878, 567, 311, 1096, 604, 1346, 20196, 16836, 13], "temperature": 0.0, "avg_logprob": -0.16449540963202167, "compression_ratio": 1.7694805194805194, "no_speech_prob": 2.391997622908093e-05}, {"id": 143, "seek": 39800, "start": 401.0, "end": 404.0, "text": " Listening to Todd, I don't think he's still here.", "tokens": [49321, 281, 21488, 11, 286, 500, 380, 519, 415, 311, 920, 510, 13], "temperature": 0.0, "avg_logprob": -0.16449540963202167, "compression_ratio": 1.7694805194805194, "no_speech_prob": 2.391997622908093e-05}, {"id": 144, "seek": 39800, "start": 404.0, "end": 407.0, "text": " Yeah, you seem to have some experience with Debian developers.", "tokens": [865, 11, 291, 1643, 281, 362, 512, 1752, 365, 1346, 20196, 8849, 13], "temperature": 0.0, "avg_logprob": -0.16449540963202167, "compression_ratio": 1.7694805194805194, "no_speech_prob": 2.391997622908093e-05}, {"id": 145, "seek": 39800, "start": 407.0, "end": 409.0, "text": " So, but...", "tokens": [407, 11, 457, 485], "temperature": 0.0, "avg_logprob": -0.16449540963202167, "compression_ratio": 1.7694805194805194, "no_speech_prob": 2.391997622908093e-05}, {"id": 146, "seek": 39800, "start": 409.0, "end": 411.0, "text": " How do you, like, circuit 2,000?", "tokens": [1012, 360, 291, 11, 411, 11, 9048, 568, 11, 1360, 30], "temperature": 0.0, "avg_logprob": -0.16449540963202167, "compression_ratio": 1.7694805194805194, "no_speech_prob": 2.391997622908093e-05}, {"id": 147, "seek": 39800, "start": 411.0, "end": 413.0, "text": " Yeah, circuit 2,000, yeah, it's cool.", "tokens": [865, 11, 9048, 568, 11, 1360, 11, 1338, 11, 309, 311, 1627, 13], "temperature": 0.0, "avg_logprob": -0.16449540963202167, "compression_ratio": 1.7694805194805194, "no_speech_prob": 2.391997622908093e-05}, {"id": 148, "seek": 39800, "start": 413.0, "end": 416.0, "text": " But, yeah, so if anyone's ever, like, worked with P-Builder before,", "tokens": [583, 11, 1338, 11, 370, 498, 2878, 311, 1562, 11, 411, 11, 2732, 365, 430, 12, 28110, 793, 260, 949, 11], "temperature": 0.0, "avg_logprob": -0.16449540963202167, "compression_ratio": 1.7694805194805194, "no_speech_prob": 2.391997622908093e-05}, {"id": 149, "seek": 39800, "start": 416.0, "end": 418.0, "text": " kind of one of the features that I really like about P-Builder", "tokens": [733, 295, 472, 295, 264, 4122, 300, 286, 534, 411, 466, 430, 12, 28110, 793, 260], "temperature": 0.0, "avg_logprob": -0.16449540963202167, "compression_ratio": 1.7694805194805194, "no_speech_prob": 2.391997622908093e-05}, {"id": 150, "seek": 39800, "start": 418.0, "end": 422.0, "text": " for building Debian packages is that you can have different hooks", "tokens": [337, 2390, 1346, 20196, 17401, 307, 300, 291, 393, 362, 819, 26485], "temperature": 0.0, "avg_logprob": -0.16449540963202167, "compression_ratio": 1.7694805194805194, "no_speech_prob": 2.391997622908093e-05}, {"id": 151, "seek": 39800, "start": 422.0, "end": 425.0, "text": " that you can ingest, or you can create that run at certain parts", "tokens": [300, 291, 393, 3957, 377, 11, 420, 291, 393, 1884, 300, 1190, 412, 1629, 3166], "temperature": 0.0, "avg_logprob": -0.16449540963202167, "compression_ratio": 1.7694805194805194, "no_speech_prob": 2.391997622908093e-05}, {"id": 152, "seek": 39800, "start": 425.0, "end": 427.0, "text": " of the package build.", "tokens": [295, 264, 7372, 1322, 13], "temperature": 0.0, "avg_logprob": -0.16449540963202167, "compression_ratio": 1.7694805194805194, "no_speech_prob": 2.391997622908093e-05}, {"id": 153, "seek": 42700, "start": 427.0, "end": 430.0, "text": " So I kind of wanted to replicate that same functionality.", "tokens": [407, 286, 733, 295, 1415, 281, 25356, 300, 912, 14980, 13], "temperature": 0.0, "avg_logprob": -0.09314900932582558, "compression_ratio": 1.7560137457044673, "no_speech_prob": 1.6960071661742404e-05}, {"id": 154, "seek": 42700, "start": 430.0, "end": 432.0, "text": " And then kind of the general process", "tokens": [400, 550, 733, 295, 264, 2674, 1399], "temperature": 0.0, "avg_logprob": -0.09314900932582558, "compression_ratio": 1.7560137457044673, "no_speech_prob": 1.6960071661742404e-05}, {"id": 155, "seek": 42700, "start": 432.0, "end": 434.0, "text": " is instantiating a configure instance,", "tokens": [307, 9836, 72, 990, 257, 22162, 5197, 11], "temperature": 0.0, "avg_logprob": -0.09314900932582558, "compression_ratio": 1.7560137457044673, "no_speech_prob": 1.6960071661742404e-05}, {"id": 156, "seek": 42700, "start": 434.0, "end": 437.0, "text": " so that's, like, a Python singleton class object", "tokens": [370, 300, 311, 11, 411, 11, 257, 15329, 1522, 14806, 1508, 2657], "temperature": 0.0, "avg_logprob": -0.09314900932582558, "compression_ratio": 1.7560137457044673, "no_speech_prob": 1.6960071661742404e-05}, {"id": 157, "seek": 42700, "start": 437.0, "end": 440.0, "text": " that basically takes in all that info, shares it across,", "tokens": [300, 1936, 2516, 294, 439, 300, 13614, 11, 12182, 309, 2108, 11], "temperature": 0.0, "avg_logprob": -0.09314900932582558, "compression_ratio": 1.7560137457044673, "no_speech_prob": 1.6960071661742404e-05}, {"id": 158, "seek": 42700, "start": 440.0, "end": 442.0, "text": " you know, the whole test suite.", "tokens": [291, 458, 11, 264, 1379, 1500, 14205, 13], "temperature": 0.0, "avg_logprob": -0.09314900932582558, "compression_ratio": 1.7560137457044673, "no_speech_prob": 1.6960071661742404e-05}, {"id": 159, "seek": 42700, "start": 442.0, "end": 444.0, "text": " They can bring up nodes that you need,", "tokens": [814, 393, 1565, 493, 13891, 300, 291, 643, 11], "temperature": 0.0, "avg_logprob": -0.09314900932582558, "compression_ratio": 1.7560137457044673, "no_speech_prob": 1.6960071661742404e-05}, {"id": 160, "seek": 42700, "start": 444.0, "end": 446.0, "text": " and then you define your hooks,", "tokens": [293, 550, 291, 6964, 428, 26485, 11], "temperature": 0.0, "avg_logprob": -0.09314900932582558, "compression_ratio": 1.7560137457044673, "no_speech_prob": 1.6960071661742404e-05}, {"id": 161, "seek": 42700, "start": 446.0, "end": 448.0, "text": " so that's kind of, like, what do I want to run", "tokens": [370, 300, 311, 733, 295, 11, 411, 11, 437, 360, 286, 528, 281, 1190], "temperature": 0.0, "avg_logprob": -0.09314900932582558, "compression_ratio": 1.7560137457044673, "no_speech_prob": 1.6960071661742404e-05}, {"id": 162, "seek": 42700, "start": 448.0, "end": 451.0, "text": " when I start the environment and then register them", "tokens": [562, 286, 722, 264, 2823, 293, 550, 7280, 552], "temperature": 0.0, "avg_logprob": -0.09314900932582558, "compression_ratio": 1.7560137457044673, "no_speech_prob": 1.6960071661742404e-05}, {"id": 163, "seek": 42700, "start": 451.0, "end": 453.0, "text": " so that, you know, when you run the test,", "tokens": [370, 300, 11, 291, 458, 11, 562, 291, 1190, 264, 1500, 11], "temperature": 0.0, "avg_logprob": -0.09314900932582558, "compression_ratio": 1.7560137457044673, "no_speech_prob": 1.6960071661742404e-05}, {"id": 164, "seek": 42700, "start": 453.0, "end": 456.0, "text": " the program knows about it.", "tokens": [264, 1461, 3255, 466, 309, 13], "temperature": 0.0, "avg_logprob": -0.09314900932582558, "compression_ratio": 1.7560137457044673, "no_speech_prob": 1.6960071661742404e-05}, {"id": 165, "seek": 45600, "start": 456.0, "end": 459.0, "text": " And then kind of the next part here is the testlets.", "tokens": [400, 550, 733, 295, 264, 958, 644, 510, 307, 264, 1500, 12541, 13], "temperature": 0.0, "avg_logprob": -0.09924150685795018, "compression_ratio": 1.8830645161290323, "no_speech_prob": 2.2818450815975666e-05}, {"id": 166, "seek": 45600, "start": 459.0, "end": 463.0, "text": " So that part kind of uses some little bit more tricky programming.", "tokens": [407, 300, 644, 733, 295, 4960, 512, 707, 857, 544, 12414, 9410, 13], "temperature": 0.0, "avg_logprob": -0.09924150685795018, "compression_ratio": 1.8830645161290323, "no_speech_prob": 2.2818450815975666e-05}, {"id": 167, "seek": 45600, "start": 463.0, "end": 466.0, "text": " So in this case, I use Python decorators and metaprogramming,", "tokens": [407, 294, 341, 1389, 11, 286, 764, 15329, 7919, 3391, 293, 1131, 569, 340, 1342, 2810, 11], "temperature": 0.0, "avg_logprob": -0.09924150685795018, "compression_ratio": 1.8830645161290323, "no_speech_prob": 2.2818450815975666e-05}, {"id": 168, "seek": 45600, "start": 466.0, "end": 469.0, "text": " so kind of reading class descriptors and whatnot,", "tokens": [370, 733, 295, 3760, 1508, 31280, 830, 293, 25882, 11], "temperature": 0.0, "avg_logprob": -0.09924150685795018, "compression_ratio": 1.8830645161290323, "no_speech_prob": 2.2818450815975666e-05}, {"id": 169, "seek": 45600, "start": 469.0, "end": 472.0, "text": " assessing the current state of the program.", "tokens": [34348, 264, 2190, 1785, 295, 264, 1461, 13], "temperature": 0.0, "avg_logprob": -0.09924150685795018, "compression_ratio": 1.8830645161290323, "no_speech_prob": 2.2818450815975666e-05}, {"id": 170, "seek": 45600, "start": 472.0, "end": 475.0, "text": " And what the decorators do in this case with the metaprogramming", "tokens": [400, 437, 264, 7919, 3391, 360, 294, 341, 1389, 365, 264, 1131, 569, 340, 1342, 2810], "temperature": 0.0, "avg_logprob": -0.09924150685795018, "compression_ratio": 1.8830645161290323, "no_speech_prob": 2.2818450815975666e-05}, {"id": 171, "seek": 45600, "start": 475.0, "end": 478.0, "text": " is that rather than having that function run locally,", "tokens": [307, 300, 2831, 813, 1419, 300, 2445, 1190, 16143, 11], "temperature": 0.0, "avg_logprob": -0.09924150685795018, "compression_ratio": 1.8830645161290323, "no_speech_prob": 2.2818450815975666e-05}, {"id": 172, "seek": 45600, "start": 478.0, "end": 481.0, "text": " instead it kind of takes out the body of that function", "tokens": [2602, 309, 733, 295, 2516, 484, 264, 1772, 295, 300, 2445], "temperature": 0.0, "avg_logprob": -0.09924150685795018, "compression_ratio": 1.8830645161290323, "no_speech_prob": 2.2818450815975666e-05}, {"id": 173, "seek": 45600, "start": 481.0, "end": 483.0, "text": " that you defined.", "tokens": [300, 291, 7642, 13], "temperature": 0.0, "avg_logprob": -0.09924150685795018, "compression_ratio": 1.8830645161290323, "no_speech_prob": 2.2818450815975666e-05}, {"id": 174, "seek": 48300, "start": 483.0, "end": 488.0, "text": " And then it injects it inside of the container instance", "tokens": [400, 550, 309, 10711, 82, 309, 1854, 295, 264, 10129, 5197], "temperature": 0.0, "avg_logprob": -0.10578430562779523, "compression_ratio": 1.7440273037542662, "no_speech_prob": 5.254505140328547e-06}, {"id": 175, "seek": 48300, "start": 488.0, "end": 490.0, "text": " and runs it there, so the idea is that, like,", "tokens": [293, 6676, 309, 456, 11, 370, 264, 1558, 307, 300, 11, 411, 11], "temperature": 0.0, "avg_logprob": -0.10578430562779523, "compression_ratio": 1.7440273037542662, "no_speech_prob": 5.254505140328547e-06}, {"id": 176, "seek": 48300, "start": 490.0, "end": 492.0, "text": " oh, you could be working off of a new bunch of machine,", "tokens": [1954, 11, 291, 727, 312, 1364, 766, 295, 257, 777, 3840, 295, 3479, 11], "temperature": 0.0, "avg_logprob": -0.10578430562779523, "compression_ratio": 1.7440273037542662, "no_speech_prob": 5.254505140328547e-06}, {"id": 177, "seek": 48300, "start": 492.0, "end": 495.0, "text": " but you're developing for a cluster that's running Rocky Linux.", "tokens": [457, 291, 434, 6416, 337, 257, 13630, 300, 311, 2614, 26916, 18734, 13], "temperature": 0.0, "avg_logprob": -0.10578430562779523, "compression_ratio": 1.7440273037542662, "no_speech_prob": 5.254505140328547e-06}, {"id": 178, "seek": 48300, "start": 495.0, "end": 497.0, "text": " So in that case, you can just easily bring it up,", "tokens": [407, 294, 300, 1389, 11, 291, 393, 445, 3612, 1565, 309, 493, 11], "temperature": 0.0, "avg_logprob": -0.10578430562779523, "compression_ratio": 1.7440273037542662, "no_speech_prob": 5.254505140328547e-06}, {"id": 179, "seek": 48300, "start": 497.0, "end": 500.0, "text": " inject it in there, get the results back.", "tokens": [10711, 309, 294, 456, 11, 483, 264, 3542, 646, 13], "temperature": 0.0, "avg_logprob": -0.10578430562779523, "compression_ratio": 1.7440273037542662, "no_speech_prob": 5.254505140328547e-06}, {"id": 180, "seek": 48300, "start": 500.0, "end": 502.0, "text": " And then finally, kind of the last part,", "tokens": [400, 550, 2721, 11, 733, 295, 264, 1036, 644, 11], "temperature": 0.0, "avg_logprob": -0.10578430562779523, "compression_ratio": 1.7440273037542662, "no_speech_prob": 5.254505140328547e-06}, {"id": 181, "seek": 48300, "start": 502.0, "end": 504.0, "text": " evaluation slash reporting.", "tokens": [13344, 17330, 10031, 13], "temperature": 0.0, "avg_logprob": -0.10578430562779523, "compression_ratio": 1.7440273037542662, "no_speech_prob": 5.254505140328547e-06}, {"id": 182, "seek": 48300, "start": 504.0, "end": 507.0, "text": " It's like each testlet kind of returns this results object,", "tokens": [467, 311, 411, 1184, 1500, 2631, 733, 295, 11247, 341, 3542, 2657, 11], "temperature": 0.0, "avg_logprob": -0.10578430562779523, "compression_ratio": 1.7440273037542662, "no_speech_prob": 5.254505140328547e-06}, {"id": 183, "seek": 48300, "start": 507.0, "end": 510.0, "text": " so that kind of contains an exit code, standard out, standard error.", "tokens": [370, 300, 733, 295, 8306, 364, 11043, 3089, 11, 3832, 484, 11, 3832, 6713, 13], "temperature": 0.0, "avg_logprob": -0.10578430562779523, "compression_ratio": 1.7440273037542662, "no_speech_prob": 5.254505140328547e-06}, {"id": 184, "seek": 51000, "start": 510.0, "end": 514.0, "text": " And from there, you can evaluate the results locally", "tokens": [400, 490, 456, 11, 291, 393, 13059, 264, 3542, 16143], "temperature": 0.0, "avg_logprob": -0.09820095578530677, "compression_ratio": 1.6963562753036436, "no_speech_prob": 6.747131010342855e-06}, {"id": 185, "seek": 51000, "start": 514.0, "end": 517.0, "text": " instead of having to kind of instead do it inside of the container,", "tokens": [2602, 295, 1419, 281, 733, 295, 2602, 360, 309, 1854, 295, 264, 10129, 11], "temperature": 0.0, "avg_logprob": -0.09820095578530677, "compression_ratio": 1.6963562753036436, "no_speech_prob": 6.747131010342855e-06}, {"id": 186, "seek": 51000, "start": 517.0, "end": 520.0, "text": " so you could say, like, oh, in this case,", "tokens": [370, 291, 727, 584, 11, 411, 11, 1954, 11, 294, 341, 1389, 11], "temperature": 0.0, "avg_logprob": -0.09820095578530677, "compression_ratio": 1.6963562753036436, "no_speech_prob": 6.747131010342855e-06}, {"id": 187, "seek": 51000, "start": 520.0, "end": 522.0, "text": " if you're, like, doing a spread test,", "tokens": [498, 291, 434, 11, 411, 11, 884, 257, 3974, 1500, 11], "temperature": 0.0, "avg_logprob": -0.09820095578530677, "compression_ratio": 1.6963562753036436, "no_speech_prob": 6.747131010342855e-06}, {"id": 188, "seek": 51000, "start": 522.0, "end": 525.0, "text": " so kind of if you have, like, oh, you know,", "tokens": [370, 733, 295, 498, 291, 362, 11, 411, 11, 1954, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.09820095578530677, "compression_ratio": 1.6963562753036436, "no_speech_prob": 6.747131010342855e-06}, {"id": 189, "seek": 51000, "start": 525.0, "end": 530.0, "text": " I need to test this on Ubuntu 22.04 or 20.04 and 18.04,", "tokens": [286, 643, 281, 1500, 341, 322, 30230, 45605, 5853, 13, 14565, 420, 945, 13, 14565, 293, 2443, 13, 14565, 11], "temperature": 0.0, "avg_logprob": -0.09820095578530677, "compression_ratio": 1.6963562753036436, "no_speech_prob": 6.747131010342855e-06}, {"id": 190, "seek": 51000, "start": 530.0, "end": 533.0, "text": " it returns a generator object of a name and a result.", "tokens": [309, 11247, 257, 19265, 2657, 295, 257, 1315, 293, 257, 1874, 13], "temperature": 0.0, "avg_logprob": -0.09820095578530677, "compression_ratio": 1.6963562753036436, "no_speech_prob": 6.747131010342855e-06}, {"id": 191, "seek": 51000, "start": 533.0, "end": 537.0, "text": " So, you know, let's say that your code works on 22.04 and 20.04,", "tokens": [407, 11, 291, 458, 11, 718, 311, 584, 300, 428, 3089, 1985, 322, 5853, 13, 14565, 293, 945, 13, 14565, 11], "temperature": 0.0, "avg_logprob": -0.09820095578530677, "compression_ratio": 1.6963562753036436, "no_speech_prob": 6.747131010342855e-06}, {"id": 192, "seek": 53700, "start": 537.0, "end": 541.0, "text": " but the version of Python on 18.04 is too old for what you're trying to do,", "tokens": [457, 264, 3037, 295, 15329, 322, 2443, 13, 14565, 307, 886, 1331, 337, 437, 291, 434, 1382, 281, 360, 11], "temperature": 0.0, "avg_logprob": -0.07722762604834328, "compression_ratio": 1.782006920415225, "no_speech_prob": 1.0287983968737535e-05}, {"id": 193, "seek": 53700, "start": 541.0, "end": 544.0, "text": " so report back is an error.", "tokens": [370, 2275, 646, 307, 364, 6713, 13], "temperature": 0.0, "avg_logprob": -0.07722762604834328, "compression_ratio": 1.782006920415225, "no_speech_prob": 1.0287983968737535e-05}, {"id": 194, "seek": 53700, "start": 544.0, "end": 548.0, "text": " So kind of then, you know, breaking into how does it exactly work.", "tokens": [407, 733, 295, 550, 11, 291, 458, 11, 7697, 666, 577, 775, 309, 2293, 589, 13], "temperature": 0.0, "avg_logprob": -0.07722762604834328, "compression_ratio": 1.782006920415225, "no_speech_prob": 1.0287983968737535e-05}, {"id": 195, "seek": 53700, "start": 548.0, "end": 551.0, "text": " So the idea is that you kind of start on your local host,", "tokens": [407, 264, 1558, 307, 300, 291, 733, 295, 722, 322, 428, 2654, 3975, 11], "temperature": 0.0, "avg_logprob": -0.07722762604834328, "compression_ratio": 1.782006920415225, "no_speech_prob": 1.0287983968737535e-05}, {"id": 196, "seek": 53700, "start": 551.0, "end": 553.0, "text": " so that's kind of your computer there.", "tokens": [370, 300, 311, 733, 295, 428, 3820, 456, 13], "temperature": 0.0, "avg_logprob": -0.07722762604834328, "compression_ratio": 1.782006920415225, "no_speech_prob": 1.0287983968737535e-05}, {"id": 197, "seek": 53700, "start": 553.0, "end": 555.0, "text": " So you have the host operating system,", "tokens": [407, 291, 362, 264, 3975, 7447, 1185, 11], "temperature": 0.0, "avg_logprob": -0.07722762604834328, "compression_ratio": 1.782006920415225, "no_speech_prob": 1.0287983968737535e-05}, {"id": 198, "seek": 53700, "start": 555.0, "end": 557.0, "text": " and then you have the clean test package installed", "tokens": [293, 550, 291, 362, 264, 2541, 1500, 7372, 8899], "temperature": 0.0, "avg_logprob": -0.07722762604834328, "compression_ratio": 1.782006920415225, "no_speech_prob": 1.0287983968737535e-05}, {"id": 199, "seek": 53700, "start": 557.0, "end": 560.0, "text": " as, you know, I'm part of your Python interpreter,", "tokens": [382, 11, 291, 458, 11, 286, 478, 644, 295, 428, 15329, 34132, 11], "temperature": 0.0, "avg_logprob": -0.07722762604834328, "compression_ratio": 1.782006920415225, "no_speech_prob": 1.0287983968737535e-05}, {"id": 200, "seek": 53700, "start": 560.0, "end": 562.0, "text": " which is a regular Python package.", "tokens": [597, 307, 257, 3890, 15329, 7372, 13], "temperature": 0.0, "avg_logprob": -0.07722762604834328, "compression_ratio": 1.782006920415225, "no_speech_prob": 1.0287983968737535e-05}, {"id": 201, "seek": 53700, "start": 562.0, "end": 565.0, "text": " The idea is that then, as you see that dotted line in the middle there,", "tokens": [440, 1558, 307, 300, 550, 11, 382, 291, 536, 300, 37459, 1622, 294, 264, 2808, 456, 11], "temperature": 0.0, "avg_logprob": -0.07722762604834328, "compression_ratio": 1.782006920415225, "no_speech_prob": 1.0287983968737535e-05}, {"id": 202, "seek": 56500, "start": 565.0, "end": 568.0, "text": " it then makes the request of the hypervisor of your choice", "tokens": [309, 550, 1669, 264, 5308, 295, 264, 9848, 16457, 295, 428, 3922], "temperature": 0.0, "avg_logprob": -0.10624551773071289, "compression_ratio": 1.7715355805243447, "no_speech_prob": 2.9298678782652132e-05}, {"id": 203, "seek": 56500, "start": 568.0, "end": 572.0, "text": " and tells it, like, hey, so, you know, the user who wrote this test", "tokens": [293, 5112, 309, 11, 411, 11, 4177, 11, 370, 11, 291, 458, 11, 264, 4195, 567, 4114, 341, 1500], "temperature": 0.0, "avg_logprob": -0.10624551773071289, "compression_ratio": 1.7715355805243447, "no_speech_prob": 2.9298678782652132e-05}, {"id": 204, "seek": 56500, "start": 572.0, "end": 576.0, "text": " told me that I need to bring up a certain instance,", "tokens": [1907, 385, 300, 286, 643, 281, 1565, 493, 257, 1629, 5197, 11], "temperature": 0.0, "avg_logprob": -0.10624551773071289, "compression_ratio": 1.7715355805243447, "no_speech_prob": 2.9298678782652132e-05}, {"id": 205, "seek": 56500, "start": 576.0, "end": 579.0, "text": " you know, says that they need, like, a centOS image,", "tokens": [291, 458, 11, 1619, 300, 436, 643, 11, 411, 11, 257, 1489, 4367, 3256, 11], "temperature": 0.0, "avg_logprob": -0.10624551773071289, "compression_ratio": 1.7715355805243447, "no_speech_prob": 2.9298678782652132e-05}, {"id": 206, "seek": 56500, "start": 579.0, "end": 581.0, "text": " so bring up a centOS image for me,", "tokens": [370, 1565, 493, 257, 1489, 4367, 3256, 337, 385, 11], "temperature": 0.0, "avg_logprob": -0.10624551773071289, "compression_ratio": 1.7715355805243447, "no_speech_prob": 2.9298678782652132e-05}, {"id": 207, "seek": 56500, "start": 581.0, "end": 584.0, "text": " and then once that's done, you know, what clean test does", "tokens": [293, 550, 1564, 300, 311, 1096, 11, 291, 458, 11, 437, 2541, 1500, 775], "temperature": 0.0, "avg_logprob": -0.10624551773071289, "compression_ratio": 1.7715355805243447, "no_speech_prob": 2.9298678782652132e-05}, {"id": 208, "seek": 56500, "start": 584.0, "end": 586.0, "text": " is that it takes that test body function", "tokens": [307, 300, 309, 2516, 300, 1500, 1772, 2445], "temperature": 0.0, "avg_logprob": -0.10624551773071289, "compression_ratio": 1.7715355805243447, "no_speech_prob": 2.9298678782652132e-05}, {"id": 209, "seek": 56500, "start": 586.0, "end": 589.0, "text": " and it kind of creates a simple JSON packet,", "tokens": [293, 309, 733, 295, 7829, 257, 2199, 31828, 20300, 11], "temperature": 0.0, "avg_logprob": -0.10624551773071289, "compression_ratio": 1.7715355805243447, "no_speech_prob": 2.9298678782652132e-05}, {"id": 210, "seek": 56500, "start": 589.0, "end": 592.0, "text": " which is a checksum to verify the authenticity of the testlet,", "tokens": [597, 307, 257, 13834, 449, 281, 16888, 264, 34215, 295, 264, 1500, 2631, 11], "temperature": 0.0, "avg_logprob": -0.10624551773071289, "compression_ratio": 1.7715355805243447, "no_speech_prob": 2.9298678782652132e-05}, {"id": 211, "seek": 59200, "start": 592.0, "end": 595.0, "text": " the data, which is basically the testlet encoded,", "tokens": [264, 1412, 11, 597, 307, 1936, 264, 1500, 2631, 2058, 12340, 11], "temperature": 0.0, "avg_logprob": -0.062363004350995684, "compression_ratio": 1.9550561797752808, "no_speech_prob": 1.184051507152617e-05}, {"id": 212, "seek": 59200, "start": 595.0, "end": 599.0, "text": " and then, or any data necessary for the testlet,", "tokens": [293, 550, 11, 420, 604, 1412, 4818, 337, 264, 1500, 2631, 11], "temperature": 0.0, "avg_logprob": -0.062363004350995684, "compression_ratio": 1.9550561797752808, "no_speech_prob": 1.184051507152617e-05}, {"id": 213, "seek": 59200, "start": 599.0, "end": 601.0, "text": " and then the injectable, which is basically, like, hey,", "tokens": [293, 550, 264, 10711, 712, 11, 597, 307, 1936, 11, 411, 11, 4177, 11], "temperature": 0.0, "avg_logprob": -0.062363004350995684, "compression_ratio": 1.9550561797752808, "no_speech_prob": 1.184051507152617e-05}, {"id": 214, "seek": 59200, "start": 601.0, "end": 603.0, "text": " you know, when you get this data packet,", "tokens": [291, 458, 11, 562, 291, 483, 341, 1412, 20300, 11], "temperature": 0.0, "avg_logprob": -0.062363004350995684, "compression_ratio": 1.9550561797752808, "no_speech_prob": 1.184051507152617e-05}, {"id": 215, "seek": 59200, "start": 603.0, "end": 605.0, "text": " here's what you need to do with it.", "tokens": [510, 311, 437, 291, 643, 281, 360, 365, 309, 13], "temperature": 0.0, "avg_logprob": -0.062363004350995684, "compression_ratio": 1.9550561797752808, "no_speech_prob": 1.184051507152617e-05}, {"id": 216, "seek": 59200, "start": 605.0, "end": 607.0, "text": " And then once that happens then, you know, clean test,", "tokens": [400, 550, 1564, 300, 2314, 550, 11, 291, 458, 11, 2541, 1500, 11], "temperature": 0.0, "avg_logprob": -0.062363004350995684, "compression_ratio": 1.9550561797752808, "no_speech_prob": 1.184051507152617e-05}, {"id": 217, "seek": 59200, "start": 607.0, "end": 611.0, "text": " what it does is that it copies itself onto the container image", "tokens": [437, 309, 775, 307, 300, 309, 14341, 2564, 3911, 264, 10129, 3256], "temperature": 0.0, "avg_logprob": -0.062363004350995684, "compression_ratio": 1.9550561797752808, "no_speech_prob": 1.184051507152617e-05}, {"id": 218, "seek": 59200, "start": 611.0, "end": 614.0, "text": " and then from there it ingests that data packet,", "tokens": [293, 550, 490, 456, 309, 3957, 4409, 300, 1412, 20300, 11], "temperature": 0.0, "avg_logprob": -0.062363004350995684, "compression_ratio": 1.9550561797752808, "no_speech_prob": 1.184051507152617e-05}, {"id": 219, "seek": 59200, "start": 614.0, "end": 616.0, "text": " does the evaluation that you requested,", "tokens": [775, 264, 13344, 300, 291, 16436, 11], "temperature": 0.0, "avg_logprob": -0.062363004350995684, "compression_ratio": 1.9550561797752808, "no_speech_prob": 1.184051507152617e-05}, {"id": 220, "seek": 59200, "start": 616.0, "end": 619.0, "text": " and then it returns that result object back to the clean test", "tokens": [293, 550, 309, 11247, 300, 1874, 2657, 646, 281, 264, 2541, 1500], "temperature": 0.0, "avg_logprob": -0.062363004350995684, "compression_ratio": 1.9550561797752808, "no_speech_prob": 1.184051507152617e-05}, {"id": 221, "seek": 59200, "start": 619.0, "end": 621.0, "text": " that's on local host.", "tokens": [300, 311, 322, 2654, 3975, 13], "temperature": 0.0, "avg_logprob": -0.062363004350995684, "compression_ratio": 1.9550561797752808, "no_speech_prob": 1.184051507152617e-05}, {"id": 222, "seek": 62100, "start": 621.0, "end": 624.0, "text": " So kind of two different ways that it works.", "tokens": [407, 733, 295, 732, 819, 2098, 300, 309, 1985, 13], "temperature": 0.0, "avg_logprob": -0.11470327879253187, "compression_ratio": 1.7483443708609272, "no_speech_prob": 8.798863746051211e-06}, {"id": 223, "seek": 62100, "start": 624.0, "end": 627.0, "text": " Then for, like, how do you control the hypervisor?", "tokens": [1396, 337, 11, 411, 11, 577, 360, 291, 1969, 264, 9848, 16457, 30], "temperature": 0.0, "avg_logprob": -0.11470327879253187, "compression_ratio": 1.7483443708609272, "no_speech_prob": 8.798863746051211e-06}, {"id": 224, "seek": 62100, "start": 627.0, "end": 629.0, "text": " The first way is kind of Archon,", "tokens": [440, 700, 636, 307, 733, 295, 10984, 266, 11], "temperature": 0.0, "avg_logprob": -0.11470327879253187, "compression_ratio": 1.7483443708609272, "no_speech_prob": 8.798863746051211e-06}, {"id": 225, "seek": 62100, "start": 629.0, "end": 631.0, "text": " which is a fancy word for director, you know.", "tokens": [597, 307, 257, 10247, 1349, 337, 5391, 11, 291, 458, 13], "temperature": 0.0, "avg_logprob": -0.11470327879253187, "compression_ratio": 1.7483443708609272, "no_speech_prob": 8.798863746051211e-06}, {"id": 226, "seek": 62100, "start": 631.0, "end": 633.0, "text": " I kind of wanted to have a buzzword in there somewhere.", "tokens": [286, 733, 295, 1415, 281, 362, 257, 13036, 7462, 294, 456, 4079, 13], "temperature": 0.0, "avg_logprob": -0.11470327879253187, "compression_ratio": 1.7483443708609272, "no_speech_prob": 8.798863746051211e-06}, {"id": 227, "seek": 62100, "start": 633.0, "end": 636.0, "text": " But the idea is that what the Archon does", "tokens": [583, 264, 1558, 307, 300, 437, 264, 10984, 266, 775], "temperature": 0.0, "avg_logprob": -0.11470327879253187, "compression_ratio": 1.7483443708609272, "no_speech_prob": 8.798863746051211e-06}, {"id": 228, "seek": 62100, "start": 636.0, "end": 638.0, "text": " is that it's kind of more declarative approach", "tokens": [307, 300, 309, 311, 733, 295, 544, 16694, 1166, 3109], "temperature": 0.0, "avg_logprob": -0.11470327879253187, "compression_ratio": 1.7483443708609272, "no_speech_prob": 8.798863746051211e-06}, {"id": 229, "seek": 62100, "start": 638.0, "end": 640.0, "text": " to doing clean tests, so rather than, you know,", "tokens": [281, 884, 2541, 6921, 11, 370, 2831, 813, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.11470327879253187, "compression_ratio": 1.7483443708609272, "no_speech_prob": 8.798863746051211e-06}, {"id": 230, "seek": 62100, "start": 640.0, "end": 642.0, "text": " saying, like, oh, you know, automatically do this, wrap it,", "tokens": [1566, 11, 411, 11, 1954, 11, 291, 458, 11, 6772, 360, 341, 11, 7019, 309, 11], "temperature": 0.0, "avg_logprob": -0.11470327879253187, "compression_ratio": 1.7483443708609272, "no_speech_prob": 8.798863746051211e-06}, {"id": 231, "seek": 62100, "start": 642.0, "end": 645.0, "text": " you know, you can kind of direct the deployment of said", "tokens": [291, 458, 11, 291, 393, 733, 295, 2047, 264, 19317, 295, 848], "temperature": 0.0, "avg_logprob": -0.11470327879253187, "compression_ratio": 1.7483443708609272, "no_speech_prob": 8.798863746051211e-06}, {"id": 232, "seek": 62100, "start": 645.0, "end": 648.0, "text": " mini-HBC cluster, and then what Harness does", "tokens": [8382, 12, 39, 7869, 13630, 11, 293, 550, 437, 389, 16937, 775], "temperature": 0.0, "avg_logprob": -0.11470327879253187, "compression_ratio": 1.7483443708609272, "no_speech_prob": 8.798863746051211e-06}, {"id": 233, "seek": 64800, "start": 648.0, "end": 651.0, "text": " is that instead of, you know, having to explicitly declare,", "tokens": [307, 300, 2602, 295, 11, 291, 458, 11, 1419, 281, 20803, 19710, 11], "temperature": 0.0, "avg_logprob": -0.10604390376756172, "compression_ratio": 1.4943820224719102, "no_speech_prob": 1.0615172868710943e-05}, {"id": 234, "seek": 64800, "start": 651.0, "end": 654.0, "text": " like, this is the infrastructure that I want for my deployment,", "tokens": [411, 11, 341, 307, 264, 6896, 300, 286, 528, 337, 452, 19317, 11], "temperature": 0.0, "avg_logprob": -0.10604390376756172, "compression_ratio": 1.4943820224719102, "no_speech_prob": 1.0615172868710943e-05}, {"id": 235, "seek": 64800, "start": 654.0, "end": 657.0, "text": " it just brings up an instance based on the function", "tokens": [309, 445, 5607, 493, 364, 5197, 2361, 322, 264, 2445], "temperature": 0.0, "avg_logprob": -0.10604390376756172, "compression_ratio": 1.4943820224719102, "no_speech_prob": 1.0615172868710943e-05}, {"id": 236, "seek": 64800, "start": 657.0, "end": 659.0, "text": " that it's been wrapped around.", "tokens": [300, 309, 311, 668, 14226, 926, 13], "temperature": 0.0, "avg_logprob": -0.10604390376756172, "compression_ratio": 1.4943820224719102, "no_speech_prob": 1.0615172868710943e-05}, {"id": 237, "seek": 64800, "start": 659.0, "end": 662.0, "text": " So this is a short demo video.", "tokens": [407, 341, 307, 257, 2099, 10723, 960, 13], "temperature": 0.0, "avg_logprob": -0.10604390376756172, "compression_ratio": 1.4943820224719102, "no_speech_prob": 1.0615172868710943e-05}, {"id": 238, "seek": 64800, "start": 662.0, "end": 665.0, "text": " Let's see if I can choose better quality here.", "tokens": [961, 311, 536, 498, 286, 393, 2826, 1101, 3125, 510, 13], "temperature": 0.0, "avg_logprob": -0.10604390376756172, "compression_ratio": 1.4943820224719102, "no_speech_prob": 1.0615172868710943e-05}, {"id": 239, "seek": 64800, "start": 665.0, "end": 667.0, "text": " Oh, don't tell me.", "tokens": [876, 11, 500, 380, 980, 385, 13], "temperature": 0.0, "avg_logprob": -0.10604390376756172, "compression_ratio": 1.4943820224719102, "no_speech_prob": 1.0615172868710943e-05}, {"id": 240, "seek": 64800, "start": 667.0, "end": 669.0, "text": " Came as a PDF, but let's see here.", "tokens": [36042, 382, 257, 17752, 11, 457, 718, 311, 536, 510, 13], "temperature": 0.0, "avg_logprob": -0.10604390376756172, "compression_ratio": 1.4943820224719102, "no_speech_prob": 1.0615172868710943e-05}, {"id": 241, "seek": 64800, "start": 669.0, "end": 671.0, "text": " All right, YouTube, sweet.", "tokens": [1057, 558, 11, 3088, 11, 3844, 13], "temperature": 0.0, "avg_logprob": -0.10604390376756172, "compression_ratio": 1.4943820224719102, "no_speech_prob": 1.0615172868710943e-05}, {"id": 242, "seek": 64800, "start": 674.0, "end": 676.0, "text": " They go full-spring. There we go.", "tokens": [814, 352, 1577, 12, 30757, 13, 821, 321, 352, 13], "temperature": 0.0, "avg_logprob": -0.10604390376756172, "compression_ratio": 1.4943820224719102, "no_speech_prob": 1.0615172868710943e-05}, {"id": 243, "seek": 67600, "start": 676.0, "end": 679.0, "text": " Oh, settings, playback.", "tokens": [876, 11, 6257, 11, 37223, 13], "temperature": 0.0, "avg_logprob": -0.14614570463025892, "compression_ratio": 1.6689189189189189, "no_speech_prob": 1.3845006833435036e-05}, {"id": 244, "seek": 67600, "start": 679.0, "end": 682.0, "text": " 180p. There we go.", "tokens": [11971, 79, 13, 821, 321, 352, 13], "temperature": 0.0, "avg_logprob": -0.14614570463025892, "compression_ratio": 1.6689189189189189, "no_speech_prob": 1.3845006833435036e-05}, {"id": 245, "seek": 67600, "start": 682.0, "end": 683.0, "text": " It's a little interesting.", "tokens": [467, 311, 257, 707, 1880, 13], "temperature": 0.0, "avg_logprob": -0.14614570463025892, "compression_ratio": 1.6689189189189189, "no_speech_prob": 1.3845006833435036e-05}, {"id": 246, "seek": 67600, "start": 683.0, "end": 685.0, "text": " But yeah, so basically what happens here is that", "tokens": [583, 1338, 11, 370, 1936, 437, 2314, 510, 307, 300], "temperature": 0.0, "avg_logprob": -0.14614570463025892, "compression_ratio": 1.6689189189189189, "no_speech_prob": 1.3845006833435036e-05}, {"id": 247, "seek": 67600, "start": 685.0, "end": 687.0, "text": " just using, like, simple talks, in that case,", "tokens": [445, 1228, 11, 411, 11, 2199, 6686, 11, 294, 300, 1389, 11], "temperature": 0.0, "avg_logprob": -0.14614570463025892, "compression_ratio": 1.6689189189189189, "no_speech_prob": 1.3845006833435036e-05}, {"id": 248, "seek": 67600, "start": 687.0, "end": 690.0, "text": " I use talks as kind of the test administrator.", "tokens": [286, 764, 6686, 382, 733, 295, 264, 1500, 25529, 13], "temperature": 0.0, "avg_logprob": -0.14614570463025892, "compression_ratio": 1.6689189189189189, "no_speech_prob": 1.3845006833435036e-05}, {"id": 249, "seek": 67600, "start": 690.0, "end": 693.0, "text": " I started a test, which is called LSD Archon,", "tokens": [286, 1409, 257, 1500, 11, 597, 307, 1219, 441, 23969, 10984, 266, 11], "temperature": 0.0, "avg_logprob": -0.14614570463025892, "compression_ratio": 1.6689189189189189, "no_speech_prob": 1.3845006833435036e-05}, {"id": 250, "seek": 67600, "start": 693.0, "end": 695.0, "text": " which basically says bring up a test environment instance.", "tokens": [597, 1936, 1619, 1565, 493, 257, 1500, 2823, 5197, 13], "temperature": 0.0, "avg_logprob": -0.14614570463025892, "compression_ratio": 1.6689189189189189, "no_speech_prob": 1.3845006833435036e-05}, {"id": 251, "seek": 67600, "start": 695.0, "end": 697.0, "text": " So first it starts with LDAP,", "tokens": [407, 700, 309, 3719, 365, 33936, 4715, 11], "temperature": 0.0, "avg_logprob": -0.14614570463025892, "compression_ratio": 1.6689189189189189, "no_speech_prob": 1.3845006833435036e-05}, {"id": 252, "seek": 67600, "start": 697.0, "end": 700.0, "text": " so it's provisioning an LDAP node on top of LSD hypervisor.", "tokens": [370, 309, 311, 17225, 278, 364, 33936, 4715, 9984, 322, 1192, 295, 441, 23969, 9848, 16457, 13], "temperature": 0.0, "avg_logprob": -0.14614570463025892, "compression_ratio": 1.6689189189189189, "no_speech_prob": 1.3845006833435036e-05}, {"id": 253, "seek": 67600, "start": 700.0, "end": 702.0, "text": " That's what I'm using here.", "tokens": [663, 311, 437, 286, 478, 1228, 510, 13], "temperature": 0.0, "avg_logprob": -0.14614570463025892, "compression_ratio": 1.6689189189189189, "no_speech_prob": 1.3845006833435036e-05}, {"id": 254, "seek": 67600, "start": 702.0, "end": 705.0, "text": " So first it starts with LDAP, and then after a few minutes,", "tokens": [407, 700, 309, 3719, 365, 33936, 4715, 11, 293, 550, 934, 257, 1326, 2077, 11], "temperature": 0.0, "avg_logprob": -0.14614570463025892, "compression_ratio": 1.6689189189189189, "no_speech_prob": 1.3845006833435036e-05}, {"id": 255, "seek": 70500, "start": 705.0, "end": 710.0, "text": " for it to boot, crappy hotel Wi-Fi was when I was doing this.", "tokens": [337, 309, 281, 11450, 11, 36531, 7622, 14035, 12, 13229, 390, 562, 286, 390, 884, 341, 13], "temperature": 0.0, "avg_logprob": -0.16021994388464725, "compression_ratio": 1.6871794871794872, "no_speech_prob": 1.3417309673968703e-05}, {"id": 256, "seek": 70500, "start": 710.0, "end": 712.0, "text": " And then see there?", "tokens": [400, 550, 536, 456, 30], "temperature": 0.0, "avg_logprob": -0.16021994388464725, "compression_ratio": 1.6871794871794872, "no_speech_prob": 1.3417309673968703e-05}, {"id": 257, "seek": 70500, "start": 712.0, "end": 715.0, "text": " Now you have the NFS image.", "tokens": [823, 291, 362, 264, 13576, 50, 3256, 13], "temperature": 0.0, "avg_logprob": -0.16021994388464725, "compression_ratio": 1.6871794871794872, "no_speech_prob": 1.3417309673968703e-05}, {"id": 258, "seek": 70500, "start": 715.0, "end": 718.0, "text": " That starts provisioning, and then somewhere in here.", "tokens": [663, 3719, 17225, 278, 11, 293, 550, 4079, 294, 510, 13], "temperature": 0.0, "avg_logprob": -0.16021994388464725, "compression_ratio": 1.6871794871794872, "no_speech_prob": 1.3417309673968703e-05}, {"id": 259, "seek": 70500, "start": 718.0, "end": 722.0, "text": " Now you have the Slurm CTLD node that comes up.", "tokens": [823, 291, 362, 264, 6187, 26717, 19529, 23704, 9984, 300, 1487, 493, 13], "temperature": 0.0, "avg_logprob": -0.16021994388464725, "compression_ratio": 1.6871794871794872, "no_speech_prob": 1.3417309673968703e-05}, {"id": 260, "seek": 70500, "start": 726.0, "end": 728.0, "text": " And now you have the Slurm,", "tokens": [400, 586, 291, 362, 264, 6187, 26717, 11], "temperature": 0.0, "avg_logprob": -0.16021994388464725, "compression_ratio": 1.6871794871794872, "no_speech_prob": 1.3417309673968703e-05}, {"id": 261, "seek": 70500, "start": 728.0, "end": 731.0, "text": " three Slurm compute nodes that come up,", "tokens": [1045, 6187, 26717, 14722, 13891, 300, 808, 493, 11], "temperature": 0.0, "avg_logprob": -0.16021994388464725, "compression_ratio": 1.6871794871794872, "no_speech_prob": 1.3417309673968703e-05}, {"id": 262, "seek": 70500, "start": 731.0, "end": 733.0, "text": " and the idea is that then what the framework does", "tokens": [293, 264, 1558, 307, 300, 550, 437, 264, 8388, 775], "temperature": 0.0, "avg_logprob": -0.16021994388464725, "compression_ratio": 1.6871794871794872, "no_speech_prob": 1.3417309673968703e-05}, {"id": 263, "seek": 73300, "start": 733.0, "end": 736.0, "text": " is that it injects a testlet inside of Slurm CTLD,", "tokens": [307, 300, 309, 10711, 82, 257, 1500, 2631, 1854, 295, 6187, 26717, 19529, 23704, 11], "temperature": 0.0, "avg_logprob": -0.13594233989715576, "compression_ratio": 1.452127659574468, "no_speech_prob": 1.1842245839943644e-05}, {"id": 264, "seek": 73300, "start": 736.0, "end": 738.0, "text": " and then from there it uses SBatch", "tokens": [293, 550, 490, 456, 309, 4960, 26944, 852], "temperature": 0.0, "avg_logprob": -0.13594233989715576, "compression_ratio": 1.452127659574468, "no_speech_prob": 1.1842245839943644e-05}, {"id": 265, "seek": 73300, "start": 738.0, "end": 741.0, "text": " to submit the job off to the test cluster.", "tokens": [281, 10315, 264, 1691, 766, 281, 264, 1500, 13630, 13], "temperature": 0.0, "avg_logprob": -0.13594233989715576, "compression_ratio": 1.452127659574468, "no_speech_prob": 1.1842245839943644e-05}, {"id": 266, "seek": 73300, "start": 743.0, "end": 745.0, "text": " Takes a bit.", "tokens": [44347, 257, 857, 13], "temperature": 0.0, "avg_logprob": -0.13594233989715576, "compression_ratio": 1.452127659574468, "no_speech_prob": 1.1842245839943644e-05}, {"id": 267, "seek": 73300, "start": 749.0, "end": 751.0, "text": " Ooh.", "tokens": [7951, 13], "temperature": 0.0, "avg_logprob": -0.13594233989715576, "compression_ratio": 1.452127659574468, "no_speech_prob": 1.1842245839943644e-05}, {"id": 268, "seek": 73300, "start": 751.0, "end": 753.0, "text": " A little too far ahead.", "tokens": [316, 707, 886, 1400, 2286, 13], "temperature": 0.0, "avg_logprob": -0.13594233989715576, "compression_ratio": 1.452127659574468, "no_speech_prob": 1.1842245839943644e-05}, {"id": 269, "seek": 73300, "start": 753.0, "end": 755.0, "text": " Give it a few seconds.", "tokens": [5303, 309, 257, 1326, 3949, 13], "temperature": 0.0, "avg_logprob": -0.13594233989715576, "compression_ratio": 1.452127659574468, "no_speech_prob": 1.1842245839943644e-05}, {"id": 270, "seek": 73300, "start": 756.0, "end": 758.0, "text": " Yep, and then it cleans up the cluster", "tokens": [7010, 11, 293, 550, 309, 16912, 493, 264, 13630], "temperature": 0.0, "avg_logprob": -0.13594233989715576, "compression_ratio": 1.452127659574468, "no_speech_prob": 1.1842245839943644e-05}, {"id": 271, "seek": 75800, "start": 758.0, "end": 764.0, "text": " so that it doesn't linger on afterwards.", "tokens": [370, 300, 309, 1177, 380, 45657, 322, 10543, 13], "temperature": 0.0, "avg_logprob": -0.17769180238246918, "compression_ratio": 1.2325581395348837, "no_speech_prob": 2.9299537345650606e-05}, {"id": 272, "seek": 75800, "start": 764.0, "end": 766.0, "text": " Oh, goodbye.", "tokens": [876, 11, 12084, 13], "temperature": 0.0, "avg_logprob": -0.17769180238246918, "compression_ratio": 1.2325581395348837, "no_speech_prob": 2.9299537345650606e-05}, {"id": 273, "seek": 75800, "start": 769.0, "end": 771.0, "text": " Oh, God.", "tokens": [876, 11, 1265, 13], "temperature": 0.0, "avg_logprob": -0.17769180238246918, "compression_ratio": 1.2325581395348837, "no_speech_prob": 2.9299537345650606e-05}, {"id": 274, "seek": 75800, "start": 771.0, "end": 773.0, "text": " What happened here?", "tokens": [708, 2011, 510, 30], "temperature": 0.0, "avg_logprob": -0.17769180238246918, "compression_ratio": 1.2325581395348837, "no_speech_prob": 2.9299537345650606e-05}, {"id": 275, "seek": 75800, "start": 777.0, "end": 778.0, "text": " All right.", "tokens": [1057, 558, 13], "temperature": 0.0, "avg_logprob": -0.17769180238246918, "compression_ratio": 1.2325581395348837, "no_speech_prob": 2.9299537345650606e-05}, {"id": 276, "seek": 75800, "start": 778.0, "end": 779.0, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.17769180238246918, "compression_ratio": 1.2325581395348837, "no_speech_prob": 2.9299537345650606e-05}, {"id": 277, "seek": 75800, "start": 779.0, "end": 781.0, "text": " That's not fun.", "tokens": [663, 311, 406, 1019, 13], "temperature": 0.0, "avg_logprob": -0.17769180238246918, "compression_ratio": 1.2325581395348837, "no_speech_prob": 2.9299537345650606e-05}, {"id": 278, "seek": 75800, "start": 783.0, "end": 785.0, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.17769180238246918, "compression_ratio": 1.2325581395348837, "no_speech_prob": 2.9299537345650606e-05}, {"id": 279, "seek": 75800, "start": 785.0, "end": 787.0, "text": " Yeah, I want to go back to the video.", "tokens": [865, 11, 286, 528, 281, 352, 646, 281, 264, 960, 13], "temperature": 0.0, "avg_logprob": -0.17769180238246918, "compression_ratio": 1.2325581395348837, "no_speech_prob": 2.9299537345650606e-05}, {"id": 280, "seek": 78700, "start": 787.0, "end": 790.0, "text": " I don't know why I jumped into the other video.", "tokens": [286, 500, 380, 458, 983, 286, 13864, 666, 264, 661, 960, 13], "temperature": 0.0, "avg_logprob": -0.1874655707407806, "compression_ratio": 1.2706766917293233, "no_speech_prob": 2.3182610675576143e-05}, {"id": 281, "seek": 78700, "start": 795.0, "end": 797.0, "text": " I just had an auto play moment.", "tokens": [286, 445, 632, 364, 8399, 862, 1623, 13], "temperature": 0.0, "avg_logprob": -0.1874655707407806, "compression_ratio": 1.2706766917293233, "no_speech_prob": 2.3182610675576143e-05}, {"id": 282, "seek": 78700, "start": 797.0, "end": 798.0, "text": " Wow.", "tokens": [3153, 13], "temperature": 0.0, "avg_logprob": -0.1874655707407806, "compression_ratio": 1.2706766917293233, "no_speech_prob": 2.3182610675576143e-05}, {"id": 283, "seek": 78700, "start": 798.0, "end": 800.0, "text": " I feel like a school teacher.", "tokens": [286, 841, 411, 257, 1395, 5027, 13], "temperature": 0.0, "avg_logprob": -0.1874655707407806, "compression_ratio": 1.2706766917293233, "no_speech_prob": 2.3182610675576143e-05}, {"id": 284, "seek": 78700, "start": 808.0, "end": 810.0, "text": " This is right for the end.", "tokens": [639, 307, 558, 337, 264, 917, 13], "temperature": 0.0, "avg_logprob": -0.1874655707407806, "compression_ratio": 1.2706766917293233, "no_speech_prob": 2.3182610675576143e-05}, {"id": 285, "seek": 78700, "start": 810.0, "end": 811.0, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.1874655707407806, "compression_ratio": 1.2706766917293233, "no_speech_prob": 2.3182610675576143e-05}, {"id": 286, "seek": 81100, "start": 811.0, "end": 818.0, "text": " All right, thank you.", "tokens": [1057, 558, 11, 1309, 291, 13], "temperature": 0.0, "avg_logprob": -0.121942271788915, "compression_ratio": 1.439153439153439, "no_speech_prob": 1.3210805263952352e-05}, {"id": 287, "seek": 81100, "start": 818.0, "end": 819.0, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.121942271788915, "compression_ratio": 1.439153439153439, "no_speech_prob": 1.3210805263952352e-05}, {"id": 288, "seek": 81100, "start": 819.0, "end": 820.0, "text": " All right, okay.", "tokens": [1057, 558, 11, 1392, 13], "temperature": 0.0, "avg_logprob": -0.121942271788915, "compression_ratio": 1.439153439153439, "no_speech_prob": 1.3210805263952352e-05}, {"id": 289, "seek": 81100, "start": 820.0, "end": 821.0, "text": " Ooh, no auto play.", "tokens": [7951, 11, 572, 8399, 862, 13], "temperature": 0.0, "avg_logprob": -0.121942271788915, "compression_ratio": 1.439153439153439, "no_speech_prob": 1.3210805263952352e-05}, {"id": 290, "seek": 81100, "start": 821.0, "end": 823.0, "text": " All right, so basically what happens here,", "tokens": [1057, 558, 11, 370, 1936, 437, 2314, 510, 11], "temperature": 0.0, "avg_logprob": -0.121942271788915, "compression_ratio": 1.439153439153439, "no_speech_prob": 1.3210805263952352e-05}, {"id": 291, "seek": 81100, "start": 823.0, "end": 829.0, "text": " I'm going to full screen it so it's a little bit bigger.", "tokens": [286, 478, 516, 281, 1577, 2568, 309, 370, 309, 311, 257, 707, 857, 3801, 13], "temperature": 0.0, "avg_logprob": -0.121942271788915, "compression_ratio": 1.439153439153439, "no_speech_prob": 1.3210805263952352e-05}, {"id": 292, "seek": 81100, "start": 829.0, "end": 830.0, "text": " What?", "tokens": [708, 30], "temperature": 0.0, "avg_logprob": -0.121942271788915, "compression_ratio": 1.439153439153439, "no_speech_prob": 1.3210805263952352e-05}, {"id": 293, "seek": 81100, "start": 830.0, "end": 832.0, "text": " Come on.", "tokens": [2492, 322, 13], "temperature": 0.0, "avg_logprob": -0.121942271788915, "compression_ratio": 1.439153439153439, "no_speech_prob": 1.3210805263952352e-05}, {"id": 294, "seek": 81100, "start": 832.0, "end": 835.0, "text": " I'm an engineer, not a YouTube video player", "tokens": [286, 478, 364, 11403, 11, 406, 257, 3088, 960, 4256], "temperature": 0.0, "avg_logprob": -0.121942271788915, "compression_ratio": 1.439153439153439, "no_speech_prob": 1.3210805263952352e-05}, {"id": 295, "seek": 81100, "start": 835.0, "end": 838.0, "text": " on a projector kind of guy, but what is it?", "tokens": [322, 257, 39792, 733, 295, 2146, 11, 457, 437, 307, 309, 30], "temperature": 0.0, "avg_logprob": -0.121942271788915, "compression_ratio": 1.439153439153439, "no_speech_prob": 1.3210805263952352e-05}, {"id": 296, "seek": 81100, "start": 838.0, "end": 839.0, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.121942271788915, "compression_ratio": 1.439153439153439, "no_speech_prob": 1.3210805263952352e-05}, {"id": 297, "seek": 83900, "start": 839.0, "end": 843.0, "text": " So what I've seen here is that the test starts,", "tokens": [407, 437, 286, 600, 1612, 510, 307, 300, 264, 1500, 3719, 11], "temperature": 0.0, "avg_logprob": -0.17382392883300782, "compression_ratio": 1.741444866920152, "no_speech_prob": 5.645918645313941e-05}, {"id": 298, "seek": 83900, "start": 843.0, "end": 845.0, "text": " brings up the nodes that you need to use.", "tokens": [5607, 493, 264, 13891, 300, 291, 643, 281, 764, 13], "temperature": 0.0, "avg_logprob": -0.17382392883300782, "compression_ratio": 1.741444866920152, "no_speech_prob": 5.645918645313941e-05}, {"id": 299, "seek": 83900, "start": 845.0, "end": 848.0, "text": " So in that case, it was just LDAP for basic identity management,", "tokens": [407, 294, 300, 1389, 11, 309, 390, 445, 33936, 4715, 337, 3875, 6575, 4592, 11], "temperature": 0.0, "avg_logprob": -0.17382392883300782, "compression_ratio": 1.741444866920152, "no_speech_prob": 5.645918645313941e-05}, {"id": 300, "seek": 83900, "start": 848.0, "end": 851.0, "text": " manifest for shared file system,", "tokens": [10067, 337, 5507, 3991, 1185, 11], "temperature": 0.0, "avg_logprob": -0.17382392883300782, "compression_ratio": 1.741444866920152, "no_speech_prob": 5.645918645313941e-05}, {"id": 301, "seek": 83900, "start": 851.0, "end": 854.0, "text": " and then just like Slurm for kind of resource management services.", "tokens": [293, 550, 445, 411, 6187, 26717, 337, 733, 295, 7684, 4592, 3328, 13], "temperature": 0.0, "avg_logprob": -0.17382392883300782, "compression_ratio": 1.741444866920152, "no_speech_prob": 5.645918645313941e-05}, {"id": 302, "seek": 83900, "start": 854.0, "end": 857.0, "text": " And then from there, it just like injects like a little test script", "tokens": [400, 550, 490, 456, 11, 309, 445, 411, 10711, 82, 411, 257, 707, 1500, 5755], "temperature": 0.0, "avg_logprob": -0.17382392883300782, "compression_ratio": 1.741444866920152, "no_speech_prob": 5.645918645313941e-05}, {"id": 303, "seek": 83900, "start": 857.0, "end": 858.0, "text": " to run.", "tokens": [281, 1190, 13], "temperature": 0.0, "avg_logprob": -0.17382392883300782, "compression_ratio": 1.741444866920152, "no_speech_prob": 5.645918645313941e-05}, {"id": 304, "seek": 83900, "start": 858.0, "end": 861.0, "text": " And then, yeah, what's if the job succeeds,", "tokens": [400, 550, 11, 1338, 11, 437, 311, 498, 264, 1691, 49263, 11], "temperature": 0.0, "avg_logprob": -0.17382392883300782, "compression_ratio": 1.741444866920152, "no_speech_prob": 5.645918645313941e-05}, {"id": 305, "seek": 83900, "start": 861.0, "end": 863.0, "text": " it kind of copies back to the results.", "tokens": [309, 733, 295, 14341, 646, 281, 264, 3542, 13], "temperature": 0.0, "avg_logprob": -0.17382392883300782, "compression_ratio": 1.741444866920152, "no_speech_prob": 5.645918645313941e-05}, {"id": 306, "seek": 83900, "start": 863.0, "end": 866.0, "text": " And then, yeah, and then it says like, okay,", "tokens": [400, 550, 11, 1338, 11, 293, 550, 309, 1619, 411, 11, 1392, 11], "temperature": 0.0, "avg_logprob": -0.17382392883300782, "compression_ratio": 1.741444866920152, "no_speech_prob": 5.645918645313941e-05}, {"id": 307, "seek": 86600, "start": 866.0, "end": 870.0, "text": " we get the result that we expect, so in the case of the test", "tokens": [321, 483, 264, 1874, 300, 321, 2066, 11, 370, 294, 264, 1389, 295, 264, 1500], "temperature": 0.0, "avg_logprob": -0.11042294194621424, "compression_ratio": 1.7224489795918367, "no_speech_prob": 8.66299797053216e-06}, {"id": 308, "seek": 86600, "start": 870.0, "end": 873.0, "text": " that I wrote, it just prints out basically like,", "tokens": [300, 286, 4114, 11, 309, 445, 22305, 484, 1936, 411, 11], "temperature": 0.0, "avg_logprob": -0.11042294194621424, "compression_ratio": 1.7224489795918367, "no_speech_prob": 8.66299797053216e-06}, {"id": 309, "seek": 86600, "start": 873.0, "end": 875.0, "text": " I love doing research, and then it says like,", "tokens": [286, 959, 884, 2132, 11, 293, 550, 309, 1619, 411, 11], "temperature": 0.0, "avg_logprob": -0.11042294194621424, "compression_ratio": 1.7224489795918367, "no_speech_prob": 8.66299797053216e-06}, {"id": 310, "seek": 86600, "start": 875.0, "end": 878.0, "text": " I love doing research in the log file for standard out.", "tokens": [286, 959, 884, 2132, 294, 264, 3565, 3991, 337, 3832, 484, 13], "temperature": 0.0, "avg_logprob": -0.11042294194621424, "compression_ratio": 1.7224489795918367, "no_speech_prob": 8.66299797053216e-06}, {"id": 311, "seek": 86600, "start": 878.0, "end": 882.0, "text": " So, yeah, pretty low fidelity right now is mostly a lot of work,", "tokens": [407, 11, 1338, 11, 1238, 2295, 46404, 558, 586, 307, 5240, 257, 688, 295, 589, 11], "temperature": 0.0, "avg_logprob": -0.11042294194621424, "compression_ratio": 1.7224489795918367, "no_speech_prob": 8.66299797053216e-06}, {"id": 312, "seek": 86600, "start": 882.0, "end": 885.0, "text": " went into just getting it to work and all that.", "tokens": [1437, 666, 445, 1242, 309, 281, 589, 293, 439, 300, 13], "temperature": 0.0, "avg_logprob": -0.11042294194621424, "compression_ratio": 1.7224489795918367, "no_speech_prob": 8.66299797053216e-06}, {"id": 313, "seek": 86600, "start": 885.0, "end": 888.0, "text": " Okay, now I want to go back to the slides.", "tokens": [1033, 11, 586, 286, 528, 281, 352, 646, 281, 264, 9788, 13], "temperature": 0.0, "avg_logprob": -0.11042294194621424, "compression_ratio": 1.7224489795918367, "no_speech_prob": 8.66299797053216e-06}, {"id": 314, "seek": 86600, "start": 888.0, "end": 890.0, "text": " There we go.", "tokens": [821, 321, 352, 13], "temperature": 0.0, "avg_logprob": -0.11042294194621424, "compression_ratio": 1.7224489795918367, "no_speech_prob": 8.66299797053216e-06}, {"id": 315, "seek": 86600, "start": 890.0, "end": 894.0, "text": " Hey, so now you saw that video, you know,", "tokens": [1911, 11, 370, 586, 291, 1866, 300, 960, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.11042294194621424, "compression_ratio": 1.7224489795918367, "no_speech_prob": 8.66299797053216e-06}, {"id": 316, "seek": 89400, "start": 894.0, "end": 896.0, "text": " kind of overgoing some of the current limitations.", "tokens": [733, 295, 670, 8102, 512, 295, 264, 2190, 15705, 13], "temperature": 0.0, "avg_logprob": -0.12724281524444794, "compression_ratio": 1.65625, "no_speech_prob": 3.372997889528051e-05}, {"id": 317, "seek": 89400, "start": 896.0, "end": 899.0, "text": " The first is that I'm kind of bad at playing YouTube videos", "tokens": [440, 700, 307, 300, 286, 478, 733, 295, 1578, 412, 2433, 3088, 2145], "temperature": 0.0, "avg_logprob": -0.12724281524444794, "compression_ratio": 1.65625, "no_speech_prob": 3.372997889528051e-05}, {"id": 318, "seek": 89400, "start": 899.0, "end": 903.0, "text": " and presentations, but the next part here is that kind of,", "tokens": [293, 18964, 11, 457, 264, 958, 644, 510, 307, 300, 733, 295, 11], "temperature": 0.0, "avg_logprob": -0.12724281524444794, "compression_ratio": 1.65625, "no_speech_prob": 3.372997889528051e-05}, {"id": 319, "seek": 89400, "start": 903.0, "end": 906.0, "text": " right now, big issue is that there's kind of a lack of", "tokens": [558, 586, 11, 955, 2734, 307, 300, 456, 311, 733, 295, 257, 5011, 295], "temperature": 0.0, "avg_logprob": -0.12724281524444794, "compression_ratio": 1.65625, "no_speech_prob": 3.372997889528051e-05}, {"id": 320, "seek": 89400, "start": 906.0, "end": 908.0, "text": " robust multi-distribution support.", "tokens": [13956, 4825, 12, 42649, 30783, 1406, 13], "temperature": 0.0, "avg_logprob": -0.12724281524444794, "compression_ratio": 1.65625, "no_speech_prob": 3.372997889528051e-05}, {"id": 321, "seek": 89400, "start": 908.0, "end": 911.0, "text": " So currently, I mostly developed it to work on Ubuntu", "tokens": [407, 4362, 11, 286, 5240, 4743, 309, 281, 589, 322, 30230, 45605], "temperature": 0.0, "avg_logprob": -0.12724281524444794, "compression_ratio": 1.65625, "no_speech_prob": 3.372997889528051e-05}, {"id": 322, "seek": 89400, "start": 911.0, "end": 914.0, "text": " and work with Ubuntu, I wonder why.", "tokens": [293, 589, 365, 30230, 45605, 11, 286, 2441, 983, 13], "temperature": 0.0, "avg_logprob": -0.12724281524444794, "compression_ratio": 1.65625, "no_speech_prob": 3.372997889528051e-05}, {"id": 323, "seek": 89400, "start": 914.0, "end": 918.0, "text": " But you can't launch Alma, Rocky, CentOS, Arch instances, et cetera,", "tokens": [583, 291, 393, 380, 4025, 42439, 11, 26916, 11, 3408, 4367, 11, 10984, 14519, 11, 1030, 11458, 11], "temperature": 0.0, "avg_logprob": -0.12724281524444794, "compression_ratio": 1.65625, "no_speech_prob": 3.372997889528051e-05}, {"id": 324, "seek": 89400, "start": 918.0, "end": 921.0, "text": " but kind of the macros, hooks, and like utilities that I built", "tokens": [457, 733, 295, 264, 7912, 2635, 11, 26485, 11, 293, 411, 30482, 300, 286, 3094], "temperature": 0.0, "avg_logprob": -0.12724281524444794, "compression_ratio": 1.65625, "no_speech_prob": 3.372997889528051e-05}, {"id": 325, "seek": 89400, "start": 921.0, "end": 923.0, "text": " into the framework aren't really fully there yet", "tokens": [666, 264, 8388, 3212, 380, 534, 4498, 456, 1939], "temperature": 0.0, "avg_logprob": -0.12724281524444794, "compression_ratio": 1.65625, "no_speech_prob": 3.372997889528051e-05}, {"id": 326, "seek": 92300, "start": 923.0, "end": 925.0, "text": " for supporting it.", "tokens": [337, 7231, 309, 13], "temperature": 0.0, "avg_logprob": -0.11931570156200512, "compression_ratio": 1.756838905775076, "no_speech_prob": 1.240962137671886e-05}, {"id": 327, "seek": 92300, "start": 925.0, "end": 927.0, "text": " And then public documentation is behind because, you know,", "tokens": [400, 550, 1908, 14333, 307, 2261, 570, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.11931570156200512, "compression_ratio": 1.756838905775076, "no_speech_prob": 1.240962137671886e-05}, {"id": 328, "seek": 92300, "start": 927.0, "end": 929.0, "text": " usually I write code before I write documentation.", "tokens": [2673, 286, 2464, 3089, 949, 286, 2464, 14333, 13], "temperature": 0.0, "avg_logprob": -0.11931570156200512, "compression_ratio": 1.756838905775076, "no_speech_prob": 1.240962137671886e-05}, {"id": 329, "seek": 92300, "start": 929.0, "end": 932.0, "text": " Unfortunately, it just seems to be how it always goes.", "tokens": [8590, 11, 309, 445, 2544, 281, 312, 577, 309, 1009, 1709, 13], "temperature": 0.0, "avg_logprob": -0.11931570156200512, "compression_ratio": 1.756838905775076, "no_speech_prob": 1.240962137671886e-05}, {"id": 330, "seek": 92300, "start": 932.0, "end": 934.0, "text": " Yeah, so I need to update that.", "tokens": [865, 11, 370, 286, 643, 281, 5623, 300, 13], "temperature": 0.0, "avg_logprob": -0.11931570156200512, "compression_ratio": 1.756838905775076, "no_speech_prob": 1.240962137671886e-05}, {"id": 331, "seek": 92300, "start": 934.0, "end": 937.0, "text": " And then kind of big issue right now", "tokens": [400, 550, 733, 295, 955, 2734, 558, 586], "temperature": 0.0, "avg_logprob": -0.11931570156200512, "compression_ratio": 1.756838905775076, "no_speech_prob": 1.240962137671886e-05}, {"id": 332, "seek": 92300, "start": 937.0, "end": 939.0, "text": " is lack of package manager integration.", "tokens": [307, 5011, 295, 7372, 6598, 10980, 13], "temperature": 0.0, "avg_logprob": -0.11931570156200512, "compression_ratio": 1.756838905775076, "no_speech_prob": 1.240962137671886e-05}, {"id": 333, "seek": 92300, "start": 939.0, "end": 941.0, "text": " So a lot of the support has been added ad hoc.", "tokens": [407, 257, 688, 295, 264, 1406, 575, 668, 3869, 614, 16708, 13], "temperature": 0.0, "avg_logprob": -0.11931570156200512, "compression_ratio": 1.756838905775076, "no_speech_prob": 1.240962137671886e-05}, {"id": 334, "seek": 92300, "start": 941.0, "end": 943.0, "text": " So currently, I support like charm libraries,", "tokens": [407, 4362, 11, 286, 1406, 411, 18904, 15148, 11], "temperature": 0.0, "avg_logprob": -0.11931570156200512, "compression_ratio": 1.756838905775076, "no_speech_prob": 1.240962137671886e-05}, {"id": 335, "seek": 92300, "start": 943.0, "end": 945.0, "text": " which is something that Canonically uses,", "tokens": [597, 307, 746, 300, 27666, 984, 4960, 11], "temperature": 0.0, "avg_logprob": -0.11931570156200512, "compression_ratio": 1.756838905775076, "no_speech_prob": 1.240962137671886e-05}, {"id": 336, "seek": 92300, "start": 945.0, "end": 947.0, "text": " and then snap packages, which are kind of controversial,", "tokens": [293, 550, 13650, 17401, 11, 597, 366, 733, 295, 17323, 11], "temperature": 0.0, "avg_logprob": -0.11931570156200512, "compression_ratio": 1.756838905775076, "no_speech_prob": 1.240962137671886e-05}, {"id": 337, "seek": 92300, "start": 947.0, "end": 949.0, "text": " depending on your opinions.", "tokens": [5413, 322, 428, 11819, 13], "temperature": 0.0, "avg_logprob": -0.11931570156200512, "compression_ratio": 1.756838905775076, "no_speech_prob": 1.240962137671886e-05}, {"id": 338, "seek": 92300, "start": 949.0, "end": 952.0, "text": " And then also just pips because I do a lot of Python development.", "tokens": [400, 550, 611, 445, 280, 2600, 570, 286, 360, 257, 688, 295, 15329, 3250, 13], "temperature": 0.0, "avg_logprob": -0.11931570156200512, "compression_ratio": 1.756838905775076, "no_speech_prob": 1.240962137671886e-05}, {"id": 339, "seek": 95200, "start": 952.0, "end": 954.0, "text": " But in the future, I hope to add support", "tokens": [583, 294, 264, 2027, 11, 286, 1454, 281, 909, 1406], "temperature": 0.0, "avg_logprob": -0.13046434999422263, "compression_ratio": 1.6653992395437263, "no_speech_prob": 2.2820404410595074e-05}, {"id": 340, "seek": 95200, "start": 954.0, "end": 957.0, "text": " for like Debian packages, RPMs, you know, Arch installs,", "tokens": [337, 411, 1346, 20196, 17401, 11, 14105, 26386, 11, 291, 458, 11, 10984, 3625, 82, 11], "temperature": 0.0, "avg_logprob": -0.13046434999422263, "compression_ratio": 1.6653992395437263, "no_speech_prob": 2.2820404410595074e-05}, {"id": 341, "seek": 95200, "start": 957.0, "end": 959.0, "text": " it's back in EasyBuild.", "tokens": [309, 311, 646, 294, 16002, 28110, 793, 13], "temperature": 0.0, "avg_logprob": -0.13046434999422263, "compression_ratio": 1.6653992395437263, "no_speech_prob": 2.2820404410595074e-05}, {"id": 342, "seek": 95200, "start": 959.0, "end": 962.0, "text": " So, yeah, and then lastly, I'm the only developer currently.", "tokens": [407, 11, 1338, 11, 293, 550, 16386, 11, 286, 478, 264, 787, 10754, 4362, 13], "temperature": 0.0, "avg_logprob": -0.13046434999422263, "compression_ratio": 1.6653992395437263, "no_speech_prob": 2.2820404410595074e-05}, {"id": 343, "seek": 95200, "start": 962.0, "end": 965.0, "text": " So, you know, code developed in isolation isn't reviewed", "tokens": [407, 11, 291, 458, 11, 3089, 4743, 294, 16001, 1943, 380, 18429], "temperature": 0.0, "avg_logprob": -0.13046434999422263, "compression_ratio": 1.6653992395437263, "no_speech_prob": 2.2820404410595074e-05}, {"id": 344, "seek": 95200, "start": 965.0, "end": 967.0, "text": " as thoroughly as it could be.", "tokens": [382, 17987, 382, 309, 727, 312, 13], "temperature": 0.0, "avg_logprob": -0.13046434999422263, "compression_ratio": 1.6653992395437263, "no_speech_prob": 2.2820404410595074e-05}, {"id": 345, "seek": 95200, "start": 967.0, "end": 971.0, "text": " So, you know, yeah, I make design choices", "tokens": [407, 11, 291, 458, 11, 1338, 11, 286, 652, 1715, 7994], "temperature": 0.0, "avg_logprob": -0.13046434999422263, "compression_ratio": 1.6653992395437263, "no_speech_prob": 2.2820404410595074e-05}, {"id": 346, "seek": 95200, "start": 971.0, "end": 973.0, "text": " based on what I think is appropriate.", "tokens": [2361, 322, 437, 286, 519, 307, 6854, 13], "temperature": 0.0, "avg_logprob": -0.13046434999422263, "compression_ratio": 1.6653992395437263, "no_speech_prob": 2.2820404410595074e-05}, {"id": 347, "seek": 95200, "start": 973.0, "end": 978.0, "text": " So, yeah, so last thing too is that, you know,", "tokens": [407, 11, 1338, 11, 370, 1036, 551, 886, 307, 300, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.13046434999422263, "compression_ratio": 1.6653992395437263, "no_speech_prob": 2.2820404410595074e-05}, {"id": 348, "seek": 95200, "start": 978.0, "end": 980.0, "text": " testing framework I think is a lot cooler", "tokens": [4997, 8388, 286, 519, 307, 257, 688, 15566], "temperature": 0.0, "avg_logprob": -0.13046434999422263, "compression_ratio": 1.6653992395437263, "no_speech_prob": 2.2820404410595074e-05}, {"id": 349, "seek": 98000, "start": 980.0, "end": 983.0, "text": " than the video that I kind of struggled to play here.", "tokens": [813, 264, 960, 300, 286, 733, 295, 19023, 281, 862, 510, 13], "temperature": 0.0, "avg_logprob": -0.07444045746248532, "compression_ratio": 1.7466216216216217, "no_speech_prob": 1.9828779841191135e-05}, {"id": 350, "seek": 98000, "start": 983.0, "end": 985.0, "text": " So if you want to scan the QR code,", "tokens": [407, 498, 291, 528, 281, 11049, 264, 32784, 3089, 11], "temperature": 0.0, "avg_logprob": -0.07444045746248532, "compression_ratio": 1.7466216216216217, "no_speech_prob": 1.9828779841191135e-05}, {"id": 351, "seek": 98000, "start": 985.0, "end": 987.0, "text": " if you're interested, feel free.", "tokens": [498, 291, 434, 3102, 11, 841, 1737, 13], "temperature": 0.0, "avg_logprob": -0.07444045746248532, "compression_ratio": 1.7466216216216217, "no_speech_prob": 1.9828779841191135e-05}, {"id": 352, "seek": 98000, "start": 987.0, "end": 989.0, "text": " Slides are also online as well.", "tokens": [6187, 1875, 366, 611, 2950, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.07444045746248532, "compression_ratio": 1.7466216216216217, "no_speech_prob": 1.9828779841191135e-05}, {"id": 353, "seek": 98000, "start": 989.0, "end": 991.0, "text": " So if you're not available right now, you can check it out.", "tokens": [407, 498, 291, 434, 406, 2435, 558, 586, 11, 291, 393, 1520, 309, 484, 13], "temperature": 0.0, "avg_logprob": -0.07444045746248532, "compression_ratio": 1.7466216216216217, "no_speech_prob": 1.9828779841191135e-05}, {"id": 354, "seek": 98000, "start": 991.0, "end": 996.0, "text": " And then lastly, you know, this is kind of a, you know,", "tokens": [400, 550, 16386, 11, 291, 458, 11, 341, 307, 733, 295, 257, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.07444045746248532, "compression_ratio": 1.7466216216216217, "no_speech_prob": 1.9828779841191135e-05}, {"id": 355, "seek": 98000, "start": 996.0, "end": 998.0, "text": " call for involvement.", "tokens": [818, 337, 17447, 13], "temperature": 0.0, "avg_logprob": -0.07444045746248532, "compression_ratio": 1.7466216216216217, "no_speech_prob": 1.9828779841191135e-05}, {"id": 356, "seek": 98000, "start": 998.0, "end": 1000.0, "text": " So, you know, really, at Canonical,", "tokens": [407, 11, 291, 458, 11, 534, 11, 412, 27666, 804, 11], "temperature": 0.0, "avg_logprob": -0.07444045746248532, "compression_ratio": 1.7466216216216217, "no_speech_prob": 1.9828779841191135e-05}, {"id": 357, "seek": 98000, "start": 1000.0, "end": 1002.0, "text": " we're trying to start getting Ubuntu kind of geared better", "tokens": [321, 434, 1382, 281, 722, 1242, 30230, 45605, 733, 295, 35924, 1101], "temperature": 0.0, "avg_logprob": -0.07444045746248532, "compression_ratio": 1.7466216216216217, "no_speech_prob": 1.9828779841191135e-05}, {"id": 358, "seek": 98000, "start": 1002.0, "end": 1004.0, "text": " for HPC, you know, we kind of know", "tokens": [337, 12557, 34, 11, 291, 458, 11, 321, 733, 295, 458], "temperature": 0.0, "avg_logprob": -0.07444045746248532, "compression_ratio": 1.7466216216216217, "no_speech_prob": 1.9828779841191135e-05}, {"id": 359, "seek": 98000, "start": 1004.0, "end": 1006.0, "text": " that we're a little bit behind Red Hat", "tokens": [300, 321, 434, 257, 707, 857, 2261, 4477, 15867], "temperature": 0.0, "avg_logprob": -0.07444045746248532, "compression_ratio": 1.7466216216216217, "no_speech_prob": 1.9828779841191135e-05}, {"id": 360, "seek": 98000, "start": 1006.0, "end": 1008.0, "text": " in the case of like network driver support and whatnot.", "tokens": [294, 264, 1389, 295, 411, 3209, 6787, 1406, 293, 25882, 13], "temperature": 0.0, "avg_logprob": -0.07444045746248532, "compression_ratio": 1.7466216216216217, "no_speech_prob": 1.9828779841191135e-05}, {"id": 361, "seek": 100800, "start": 1008.0, "end": 1010.0, "text": " So, you know, just if you're interested", "tokens": [407, 11, 291, 458, 11, 445, 498, 291, 434, 3102], "temperature": 0.0, "avg_logprob": -0.06301290971519304, "compression_ratio": 1.788, "no_speech_prob": 1.028600672725588e-05}, {"id": 362, "seek": 100800, "start": 1010.0, "end": 1012.0, "text": " in using Ubuntu for your workflows and whatnot,", "tokens": [294, 1228, 30230, 45605, 337, 428, 43461, 293, 25882, 11], "temperature": 0.0, "avg_logprob": -0.06301290971519304, "compression_ratio": 1.788, "no_speech_prob": 1.028600672725588e-05}, {"id": 363, "seek": 100800, "start": 1012.0, "end": 1014.0, "text": " we have a public Mattermost channel", "tokens": [321, 362, 257, 1908, 20285, 1761, 2269], "temperature": 0.0, "avg_logprob": -0.06301290971519304, "compression_ratio": 1.788, "no_speech_prob": 1.028600672725588e-05}, {"id": 364, "seek": 100800, "start": 1014.0, "end": 1016.0, "text": " so you can scan that QR code or you can, you know,", "tokens": [370, 291, 393, 11049, 300, 32784, 3089, 420, 291, 393, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.06301290971519304, "compression_ratio": 1.788, "no_speech_prob": 1.028600672725588e-05}, {"id": 365, "seek": 100800, "start": 1016.0, "end": 1017.0, "text": " check it out later.", "tokens": [1520, 309, 484, 1780, 13], "temperature": 0.0, "avg_logprob": -0.06301290971519304, "compression_ratio": 1.788, "no_speech_prob": 1.028600672725588e-05}, {"id": 366, "seek": 100800, "start": 1017.0, "end": 1022.0, "text": " But, yeah, we have a public channel for HPC online.", "tokens": [583, 11, 1338, 11, 321, 362, 257, 1908, 2269, 337, 12557, 34, 2950, 13], "temperature": 0.0, "avg_logprob": -0.06301290971519304, "compression_ratio": 1.788, "no_speech_prob": 1.028600672725588e-05}, {"id": 367, "seek": 100800, "start": 1022.0, "end": 1024.0, "text": " So, yeah, if there's something that's missing", "tokens": [407, 11, 1338, 11, 498, 456, 311, 746, 300, 311, 5361], "temperature": 0.0, "avg_logprob": -0.06301290971519304, "compression_ratio": 1.788, "no_speech_prob": 1.028600672725588e-05}, {"id": 368, "seek": 100800, "start": 1024.0, "end": 1026.0, "text": " or, you know, there's kind of some reason", "tokens": [420, 11, 291, 458, 11, 456, 311, 733, 295, 512, 1778], "temperature": 0.0, "avg_logprob": -0.06301290971519304, "compression_ratio": 1.788, "no_speech_prob": 1.028600672725588e-05}, {"id": 369, "seek": 100800, "start": 1026.0, "end": 1029.0, "text": " why you're being held back on using Ubuntu for HPC,", "tokens": [983, 291, 434, 885, 5167, 646, 322, 1228, 30230, 45605, 337, 12557, 34, 11], "temperature": 0.0, "avg_logprob": -0.06301290971519304, "compression_ratio": 1.788, "no_speech_prob": 1.028600672725588e-05}, {"id": 370, "seek": 100800, "start": 1029.0, "end": 1031.0, "text": " we'd really love to hear that feedback.", "tokens": [321, 1116, 534, 959, 281, 1568, 300, 5824, 13], "temperature": 0.0, "avg_logprob": -0.06301290971519304, "compression_ratio": 1.788, "no_speech_prob": 1.028600672725588e-05}, {"id": 371, "seek": 100800, "start": 1031.0, "end": 1034.0, "text": " So, yeah, that's it.", "tokens": [407, 11, 1338, 11, 300, 311, 309, 13], "temperature": 0.0, "avg_logprob": -0.06301290971519304, "compression_ratio": 1.788, "no_speech_prob": 1.028600672725588e-05}, {"id": 372, "seek": 103400, "start": 1034.0, "end": 1042.0, "text": " Thank you.", "tokens": [1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.1659845741846228, "compression_ratio": 1.4421052631578948, "no_speech_prob": 1.6944713934208266e-05}, {"id": 373, "seek": 103400, "start": 1042.0, "end": 1044.0, "text": " Any questions for Jason?", "tokens": [2639, 1651, 337, 11181, 30], "temperature": 0.0, "avg_logprob": -0.1659845741846228, "compression_ratio": 1.4421052631578948, "no_speech_prob": 1.6944713934208266e-05}, {"id": 374, "seek": 103400, "start": 1044.0, "end": 1047.0, "text": " Last chance for today.", "tokens": [5264, 2931, 337, 965, 13], "temperature": 0.0, "avg_logprob": -0.1659845741846228, "compression_ratio": 1.4421052631578948, "no_speech_prob": 1.6944713934208266e-05}, {"id": 375, "seek": 103400, "start": 1047.0, "end": 1050.0, "text": " So, you're just doing, this is all Python code", "tokens": [407, 11, 291, 434, 445, 884, 11, 341, 307, 439, 15329, 3089], "temperature": 0.0, "avg_logprob": -0.1659845741846228, "compression_ratio": 1.4421052631578948, "no_speech_prob": 1.6944713934208266e-05}, {"id": 376, "seek": 103400, "start": 1050.0, "end": 1052.0, "text": " that does this system for you.", "tokens": [300, 775, 341, 1185, 337, 291, 13], "temperature": 0.0, "avg_logprob": -0.1659845741846228, "compression_ratio": 1.4421052631578948, "no_speech_prob": 1.6944713934208266e-05}, {"id": 377, "seek": 103400, "start": 1052.0, "end": 1053.0, "text": " Yes, yes.", "tokens": [1079, 11, 2086, 13], "temperature": 0.0, "avg_logprob": -0.1659845741846228, "compression_ratio": 1.4421052631578948, "no_speech_prob": 1.6944713934208266e-05}, {"id": 378, "seek": 103400, "start": 1053.0, "end": 1055.0, "text": " So, how are you spinning up the LXD containers?", "tokens": [407, 11, 577, 366, 291, 15640, 493, 264, 441, 55, 35, 17089, 30], "temperature": 0.0, "avg_logprob": -0.1659845741846228, "compression_ratio": 1.4421052631578948, "no_speech_prob": 1.6944713934208266e-05}, {"id": 379, "seek": 103400, "start": 1055.0, "end": 1059.0, "text": " So, the idea is that, in the case of LXD,", "tokens": [407, 11, 264, 1558, 307, 300, 11, 294, 264, 1389, 295, 441, 55, 35, 11], "temperature": 0.0, "avg_logprob": -0.1659845741846228, "compression_ratio": 1.4421052631578948, "no_speech_prob": 1.6944713934208266e-05}, {"id": 380, "seek": 103400, "start": 1059.0, "end": 1062.0, "text": " it has a public API socket that uses,", "tokens": [309, 575, 257, 1908, 9362, 19741, 300, 4960, 11], "temperature": 0.0, "avg_logprob": -0.1659845741846228, "compression_ratio": 1.4421052631578948, "no_speech_prob": 1.6944713934208266e-05}, {"id": 381, "seek": 106200, "start": 1062.0, "end": 1064.0, "text": " I think it's like open API standard or something.", "tokens": [286, 519, 309, 311, 411, 1269, 9362, 3832, 420, 746, 13], "temperature": 0.0, "avg_logprob": -0.1276751661722639, "compression_ratio": 1.5564853556485356, "no_speech_prob": 1.9810542653431185e-05}, {"id": 382, "seek": 106200, "start": 1064.0, "end": 1066.0, "text": " But, yeah, so you can make, like,", "tokens": [583, 11, 1338, 11, 370, 291, 393, 652, 11, 411, 11], "temperature": 0.0, "avg_logprob": -0.1276751661722639, "compression_ratio": 1.5564853556485356, "no_speech_prob": 1.9810542653431185e-05}, {"id": 383, "seek": 106200, "start": 1066.0, "end": 1068.0, "text": " HTTP requests out to that API", "tokens": [33283, 12475, 484, 281, 300, 9362], "temperature": 0.0, "avg_logprob": -0.1276751661722639, "compression_ratio": 1.5564853556485356, "no_speech_prob": 1.9810542653431185e-05}, {"id": 384, "seek": 106200, "start": 1068.0, "end": 1070.0, "text": " that basically say, like, oh, you know,", "tokens": [300, 1936, 584, 11, 411, 11, 1954, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.1276751661722639, "compression_ratio": 1.5564853556485356, "no_speech_prob": 1.9810542653431185e-05}, {"id": 385, "seek": 106200, "start": 1070.0, "end": 1072.0, "text": " I need this instance or tear this down", "tokens": [286, 643, 341, 5197, 420, 12556, 341, 760], "temperature": 0.0, "avg_logprob": -0.1276751661722639, "compression_ratio": 1.5564853556485356, "no_speech_prob": 1.9810542653431185e-05}, {"id": 386, "seek": 106200, "start": 1072.0, "end": 1074.0, "text": " or set this configuration so I can install, like,", "tokens": [420, 992, 341, 11694, 370, 286, 393, 3625, 11, 411, 11], "temperature": 0.0, "avg_logprob": -0.1276751661722639, "compression_ratio": 1.5564853556485356, "no_speech_prob": 1.9810542653431185e-05}, {"id": 387, "seek": 106200, "start": 1074.0, "end": 1076.0, "text": " AppTanner or some other container hypervisor", "tokens": [3132, 51, 9805, 420, 512, 661, 10129, 9848, 16457], "temperature": 0.0, "avg_logprob": -0.1276751661722639, "compression_ratio": 1.5564853556485356, "no_speech_prob": 1.9810542653431185e-05}, {"id": 388, "seek": 106200, "start": 1076.0, "end": 1078.0, "text": " inside of LXD and whatnot.", "tokens": [1854, 295, 441, 55, 35, 293, 25882, 13], "temperature": 0.0, "avg_logprob": -0.1276751661722639, "compression_ratio": 1.5564853556485356, "no_speech_prob": 1.9810542653431185e-05}, {"id": 389, "seek": 106200, "start": 1078.0, "end": 1083.0, "text": " So, yeah, so I'm just using the API.", "tokens": [407, 11, 1338, 11, 370, 286, 478, 445, 1228, 264, 9362, 13], "temperature": 0.0, "avg_logprob": -0.1276751661722639, "compression_ratio": 1.5564853556485356, "no_speech_prob": 1.9810542653431185e-05}, {"id": 390, "seek": 106200, "start": 1083.0, "end": 1091.0, "text": " Any other questions?", "tokens": [2639, 661, 1651, 30], "temperature": 0.0, "avg_logprob": -0.1276751661722639, "compression_ratio": 1.5564853556485356, "no_speech_prob": 1.9810542653431185e-05}, {"id": 391, "seek": 109100, "start": 1091.0, "end": 1093.0, "text": " So, yeah, I'm interested in this.", "tokens": [407, 11, 1338, 11, 286, 478, 3102, 294, 341, 13], "temperature": 0.0, "avg_logprob": -0.13480543409075055, "compression_ratio": 1.67595818815331, "no_speech_prob": 2.2810179871157743e-05}, {"id": 392, "seek": 109100, "start": 1093.0, "end": 1098.0, "text": " So, the, like, you had an NFS server", "tokens": [407, 11, 264, 11, 411, 11, 291, 632, 364, 13576, 50, 7154], "temperature": 0.0, "avg_logprob": -0.13480543409075055, "compression_ratio": 1.67595818815331, "no_speech_prob": 2.2810179871157743e-05}, {"id": 393, "seek": 109100, "start": 1098.0, "end": 1099.0, "text": " and some other stuff.", "tokens": [293, 512, 661, 1507, 13], "temperature": 0.0, "avg_logprob": -0.13480543409075055, "compression_ratio": 1.67595818815331, "no_speech_prob": 2.2810179871157743e-05}, {"id": 394, "seek": 109100, "start": 1099.0, "end": 1101.0, "text": " Are you, how are you, are those preassembled images", "tokens": [2014, 291, 11, 577, 366, 291, 11, 366, 729, 659, 29386, 1493, 5267], "temperature": 0.0, "avg_logprob": -0.13480543409075055, "compression_ratio": 1.67595818815331, "no_speech_prob": 2.2810179871157743e-05}, {"id": 395, "seek": 109100, "start": 1101.0, "end": 1102.0, "text": " that you're just using?", "tokens": [300, 291, 434, 445, 1228, 30], "temperature": 0.0, "avg_logprob": -0.13480543409075055, "compression_ratio": 1.67595818815331, "no_speech_prob": 2.2810179871157743e-05}, {"id": 396, "seek": 109100, "start": 1102.0, "end": 1105.0, "text": " Are you building up with some kind of configuration management", "tokens": [2014, 291, 2390, 493, 365, 512, 733, 295, 11694, 4592], "temperature": 0.0, "avg_logprob": -0.13480543409075055, "compression_ratio": 1.67595818815331, "no_speech_prob": 2.2810179871157743e-05}, {"id": 397, "seek": 109100, "start": 1105.0, "end": 1107.0, "text": " to use Ansible to build them or how do you do that?", "tokens": [281, 764, 14590, 964, 281, 1322, 552, 420, 577, 360, 291, 360, 300, 30], "temperature": 0.0, "avg_logprob": -0.13480543409075055, "compression_ratio": 1.67595818815331, "no_speech_prob": 2.2810179871157743e-05}, {"id": 398, "seek": 109100, "start": 1107.0, "end": 1110.0, "text": " Yeah, so currently what I have is,", "tokens": [865, 11, 370, 4362, 437, 286, 362, 307, 11], "temperature": 0.0, "avg_logprob": -0.13480543409075055, "compression_ratio": 1.67595818815331, "no_speech_prob": 2.2810179871157743e-05}, {"id": 399, "seek": 109100, "start": 1110.0, "end": 1112.0, "text": " like, the way that I provision,", "tokens": [411, 11, 264, 636, 300, 286, 17225, 11], "temperature": 0.0, "avg_logprob": -0.13480543409075055, "compression_ratio": 1.67595818815331, "no_speech_prob": 2.2810179871157743e-05}, {"id": 400, "seek": 109100, "start": 1112.0, "end": 1116.0, "text": " I'm using, like, base Ubuntu images", "tokens": [286, 478, 1228, 11, 411, 11, 3096, 30230, 45605, 5267], "temperature": 0.0, "avg_logprob": -0.13480543409075055, "compression_ratio": 1.67595818815331, "no_speech_prob": 2.2810179871157743e-05}, {"id": 401, "seek": 109100, "start": 1116.0, "end": 1117.0, "text": " for configuration right now,", "tokens": [337, 11694, 558, 586, 11], "temperature": 0.0, "avg_logprob": -0.13480543409075055, "compression_ratio": 1.67595818815331, "no_speech_prob": 2.2810179871157743e-05}, {"id": 402, "seek": 109100, "start": 1117.0, "end": 1120.0, "text": " but you do have the ability to register your own custom instances", "tokens": [457, 291, 360, 362, 264, 3485, 281, 7280, 428, 1065, 2375, 14519], "temperature": 0.0, "avg_logprob": -0.13480543409075055, "compression_ratio": 1.67595818815331, "no_speech_prob": 2.2810179871157743e-05}, {"id": 403, "seek": 112000, "start": 1120.0, "end": 1121.0, "text": " and pull them in as well.", "tokens": [293, 2235, 552, 294, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.11706880422738883, "compression_ratio": 1.6816479400749065, "no_speech_prob": 2.795731052174233e-05}, {"id": 404, "seek": 112000, "start": 1121.0, "end": 1124.0, "text": " But basically, I have a little mechanism", "tokens": [583, 1936, 11, 286, 362, 257, 707, 7513], "temperature": 0.0, "avg_logprob": -0.11706880422738883, "compression_ratio": 1.6816479400749065, "no_speech_prob": 2.795731052174233e-05}, {"id": 405, "seek": 112000, "start": 1124.0, "end": 1126.0, "text": " built into the framework where you can write,", "tokens": [3094, 666, 264, 8388, 689, 291, 393, 2464, 11], "temperature": 0.0, "avg_logprob": -0.11706880422738883, "compression_ratio": 1.6816479400749065, "no_speech_prob": 2.795731052174233e-05}, {"id": 406, "seek": 112000, "start": 1126.0, "end": 1128.0, "text": " like, provisioning scripts using, like,", "tokens": [411, 11, 17225, 278, 23294, 1228, 11, 411, 11], "temperature": 0.0, "avg_logprob": -0.11706880422738883, "compression_ratio": 1.6816479400749065, "no_speech_prob": 2.795731052174233e-05}, {"id": 407, "seek": 112000, "start": 1128.0, "end": 1129.0, "text": " the clean test utilities.", "tokens": [264, 2541, 1500, 30482, 13], "temperature": 0.0, "avg_logprob": -0.11706880422738883, "compression_ratio": 1.6816479400749065, "no_speech_prob": 2.795731052174233e-05}, {"id": 408, "seek": 112000, "start": 1129.0, "end": 1131.0, "text": " So, there's some stuff for, like, installing apps,", "tokens": [407, 11, 456, 311, 512, 1507, 337, 11, 411, 11, 20762, 7733, 11], "temperature": 0.0, "avg_logprob": -0.11706880422738883, "compression_ratio": 1.6816479400749065, "no_speech_prob": 2.795731052174233e-05}, {"id": 409, "seek": 112000, "start": 1131.0, "end": 1135.0, "text": " running commands on, like, sub-processes on the unit", "tokens": [2614, 16901, 322, 11, 411, 11, 1422, 12, 41075, 279, 322, 264, 4985], "temperature": 0.0, "avg_logprob": -0.11706880422738883, "compression_ratio": 1.6816479400749065, "no_speech_prob": 2.795731052174233e-05}, {"id": 410, "seek": 112000, "start": 1135.0, "end": 1137.0, "text": " and then also, like, you can reach out to the network,", "tokens": [293, 550, 611, 11, 411, 11, 291, 393, 2524, 484, 281, 264, 3209, 11], "temperature": 0.0, "avg_logprob": -0.11706880422738883, "compression_ratio": 1.6816479400749065, "no_speech_prob": 2.795731052174233e-05}, {"id": 411, "seek": 112000, "start": 1137.0, "end": 1138.0, "text": " download anything you need.", "tokens": [5484, 1340, 291, 643, 13], "temperature": 0.0, "avg_logprob": -0.11706880422738883, "compression_ratio": 1.6816479400749065, "no_speech_prob": 2.795731052174233e-05}, {"id": 412, "seek": 112000, "start": 1138.0, "end": 1140.0, "text": " So, yeah, I'm just using custom Python scripts,", "tokens": [407, 11, 1338, 11, 286, 478, 445, 1228, 2375, 15329, 23294, 11], "temperature": 0.0, "avg_logprob": -0.11706880422738883, "compression_ratio": 1.6816479400749065, "no_speech_prob": 2.795731052174233e-05}, {"id": 413, "seek": 112000, "start": 1140.0, "end": 1142.0, "text": " the provision that are...", "tokens": [264, 17225, 300, 366, 485], "temperature": 0.0, "avg_logprob": -0.11706880422738883, "compression_ratio": 1.6816479400749065, "no_speech_prob": 2.795731052174233e-05}, {"id": 414, "seek": 112000, "start": 1142.0, "end": 1149.0, "text": " Yes, yes.", "tokens": [1079, 11, 2086, 13], "temperature": 0.0, "avg_logprob": -0.11706880422738883, "compression_ratio": 1.6816479400749065, "no_speech_prob": 2.795731052174233e-05}, {"id": 415, "seek": 114900, "start": 1149.0, "end": 1151.0, "text": " Anyone else?", "tokens": [14643, 1646, 30], "temperature": 0.0, "avg_logprob": -0.14309073831433447, "compression_ratio": 1.490909090909091, "no_speech_prob": 0.0009023931343108416}, {"id": 416, "seek": 114900, "start": 1151.0, "end": 1152.0, "text": " Last chance there?", "tokens": [5264, 2931, 456, 30], "temperature": 0.0, "avg_logprob": -0.14309073831433447, "compression_ratio": 1.490909090909091, "no_speech_prob": 0.0009023931343108416}, {"id": 417, "seek": 114900, "start": 1152.0, "end": 1155.0, "text": " All right.", "tokens": [1057, 558, 13], "temperature": 0.0, "avg_logprob": -0.14309073831433447, "compression_ratio": 1.490909090909091, "no_speech_prob": 0.0009023931343108416}, {"id": 418, "seek": 114900, "start": 1155.0, "end": 1158.0, "text": " It's for the stream and the recording.", "tokens": [467, 311, 337, 264, 4309, 293, 264, 6613, 13], "temperature": 0.0, "avg_logprob": -0.14309073831433447, "compression_ratio": 1.490909090909091, "no_speech_prob": 0.0009023931343108416}, {"id": 419, "seek": 114900, "start": 1158.0, "end": 1160.0, "text": " We've been doing well all day.", "tokens": [492, 600, 668, 884, 731, 439, 786, 13], "temperature": 0.0, "avg_logprob": -0.14309073831433447, "compression_ratio": 1.490909090909091, "no_speech_prob": 0.0009023931343108416}, {"id": 420, "seek": 114900, "start": 1160.0, "end": 1161.0, "text": " Let's keep it up.", "tokens": [961, 311, 1066, 309, 493, 13], "temperature": 0.0, "avg_logprob": -0.14309073831433447, "compression_ratio": 1.490909090909091, "no_speech_prob": 0.0009023931343108416}, {"id": 421, "seek": 114900, "start": 1161.0, "end": 1163.0, "text": " Thank you very much.", "tokens": [1044, 291, 588, 709, 13], "temperature": 0.0, "avg_logprob": -0.14309073831433447, "compression_ratio": 1.490909090909091, "no_speech_prob": 0.0009023931343108416}, {"id": 422, "seek": 114900, "start": 1163.0, "end": 1167.0, "text": " Would you mind please to move to the previous slide", "tokens": [6068, 291, 1575, 1767, 281, 1286, 281, 264, 3894, 4137], "temperature": 0.0, "avg_logprob": -0.14309073831433447, "compression_ratio": 1.490909090909091, "no_speech_prob": 0.0009023931343108416}, {"id": 423, "seek": 114900, "start": 1167.0, "end": 1170.0, "text": " so I can scan my QR code correctly?", "tokens": [370, 286, 393, 11049, 452, 32784, 3089, 8944, 30], "temperature": 0.0, "avg_logprob": -0.14309073831433447, "compression_ratio": 1.490909090909091, "no_speech_prob": 0.0009023931343108416}, {"id": 424, "seek": 114900, "start": 1170.0, "end": 1172.0, "text": " Okay, thank you very much.", "tokens": [1033, 11, 1309, 291, 588, 709, 13], "temperature": 0.0, "avg_logprob": -0.14309073831433447, "compression_ratio": 1.490909090909091, "no_speech_prob": 0.0009023931343108416}, {"id": 425, "seek": 114900, "start": 1172.0, "end": 1174.0, "text": " You're welcome.", "tokens": [509, 434, 2928, 13], "temperature": 0.0, "avg_logprob": -0.14309073831433447, "compression_ratio": 1.490909090909091, "no_speech_prob": 0.0009023931343108416}, {"id": 426, "seek": 114900, "start": 1174.0, "end": 1175.0, "text": " That was a good last question.", "tokens": [663, 390, 257, 665, 1036, 1168, 13], "temperature": 0.0, "avg_logprob": -0.14309073831433447, "compression_ratio": 1.490909090909091, "no_speech_prob": 0.0009023931343108416}, {"id": 427, "seek": 114900, "start": 1175.0, "end": 1177.0, "text": " The other one?", "tokens": [440, 661, 472, 30], "temperature": 0.0, "avg_logprob": -0.14309073831433447, "compression_ratio": 1.490909090909091, "no_speech_prob": 0.0009023931343108416}, {"id": 428, "seek": 117700, "start": 1177.0, "end": 1179.0, "text": " Which one are you looking for?", "tokens": [3013, 472, 366, 291, 1237, 337, 30], "temperature": 0.0, "avg_logprob": -0.10695712174041362, "compression_ratio": 1.528052805280528, "no_speech_prob": 0.0009153857827186584}, {"id": 429, "seek": 117700, "start": 1179.0, "end": 1180.0, "text": " This one or...?", "tokens": [639, 472, 420, 8964], "temperature": 0.0, "avg_logprob": -0.10695712174041362, "compression_ratio": 1.528052805280528, "no_speech_prob": 0.0009153857827186584}, {"id": 430, "seek": 117700, "start": 1180.0, "end": 1181.0, "text": " Yeah, this one.", "tokens": [865, 11, 341, 472, 13], "temperature": 0.0, "avg_logprob": -0.10695712174041362, "compression_ratio": 1.528052805280528, "no_speech_prob": 0.0009153857827186584}, {"id": 431, "seek": 117700, "start": 1181.0, "end": 1182.0, "text": " Okay.", "tokens": [1033, 13], "temperature": 0.0, "avg_logprob": -0.10695712174041362, "compression_ratio": 1.528052805280528, "no_speech_prob": 0.0009153857827186584}, {"id": 432, "seek": 117700, "start": 1182.0, "end": 1184.0, "text": " That's all good.", "tokens": [663, 311, 439, 665, 13], "temperature": 0.0, "avg_logprob": -0.10695712174041362, "compression_ratio": 1.528052805280528, "no_speech_prob": 0.0009153857827186584}, {"id": 433, "seek": 117700, "start": 1184.0, "end": 1185.0, "text": " All right.", "tokens": [1057, 558, 13], "temperature": 0.0, "avg_logprob": -0.10695712174041362, "compression_ratio": 1.528052805280528, "no_speech_prob": 0.0009153857827186584}, {"id": 434, "seek": 117700, "start": 1185.0, "end": 1187.0, "text": " If there's no more questions, we can wrap up here.", "tokens": [759, 456, 311, 572, 544, 1651, 11, 321, 393, 7019, 493, 510, 13], "temperature": 0.0, "avg_logprob": -0.10695712174041362, "compression_ratio": 1.528052805280528, "no_speech_prob": 0.0009153857827186584}, {"id": 435, "seek": 117700, "start": 1187.0, "end": 1189.0, "text": " Thanks a lot, everyone.", "tokens": [2561, 257, 688, 11, 1518, 13], "temperature": 0.0, "avg_logprob": -0.10695712174041362, "compression_ratio": 1.528052805280528, "no_speech_prob": 0.0009153857827186584}, {"id": 436, "seek": 117700, "start": 1189.0, "end": 1191.0, "text": " That was a wrap for today.", "tokens": [663, 390, 257, 7019, 337, 965, 13], "temperature": 0.0, "avg_logprob": -0.10695712174041362, "compression_ratio": 1.528052805280528, "no_speech_prob": 0.0009153857827186584}, {"id": 437, "seek": 117700, "start": 1191.0, "end": 1193.0, "text": " The 9th HPC Dev Room at FOSDEM,", "tokens": [440, 1722, 392, 12557, 34, 9096, 19190, 412, 479, 4367, 35, 6683, 11], "temperature": 0.0, "avg_logprob": -0.10695712174041362, "compression_ratio": 1.528052805280528, "no_speech_prob": 0.0009153857827186584}, {"id": 438, "seek": 117700, "start": 1193.0, "end": 1195.0, "text": " that means if FOSDEM likes us,", "tokens": [300, 1355, 498, 479, 4367, 35, 6683, 5902, 505, 11], "temperature": 0.0, "avg_logprob": -0.10695712174041362, "compression_ratio": 1.528052805280528, "no_speech_prob": 0.0009153857827186584}, {"id": 439, "seek": 117700, "start": 1195.0, "end": 1197.0, "text": " we can have a 10th one next year.", "tokens": [321, 393, 362, 257, 1266, 392, 472, 958, 1064, 13], "temperature": 0.0, "avg_logprob": -0.10695712174041362, "compression_ratio": 1.528052805280528, "no_speech_prob": 0.0009153857827186584}, {"id": 440, "seek": 117700, "start": 1197.0, "end": 1199.0, "text": " That would be really nice.", "tokens": [663, 576, 312, 534, 1481, 13], "temperature": 0.0, "avg_logprob": -0.10695712174041362, "compression_ratio": 1.528052805280528, "no_speech_prob": 0.0009153857827186584}, {"id": 441, "seek": 117700, "start": 1199.0, "end": 1200.0, "text": " Some practical stuff.", "tokens": [2188, 8496, 1507, 13], "temperature": 0.0, "avg_logprob": -0.10695712174041362, "compression_ratio": 1.528052805280528, "no_speech_prob": 0.0009153857827186584}, {"id": 442, "seek": 117700, "start": 1200.0, "end": 1202.0, "text": " If you're leaving the room, if you see any trash,", "tokens": [759, 291, 434, 5012, 264, 1808, 11, 498, 291, 536, 604, 11321, 11], "temperature": 0.0, "avg_logprob": -0.10695712174041362, "compression_ratio": 1.528052805280528, "no_speech_prob": 0.0009153857827186584}, {"id": 443, "seek": 117700, "start": 1202.0, "end": 1204.0, "text": " please take it with you and dump it", "tokens": [1767, 747, 309, 365, 291, 293, 11430, 309], "temperature": 0.0, "avg_logprob": -0.10695712174041362, "compression_ratio": 1.528052805280528, "no_speech_prob": 0.0009153857827186584}, {"id": 444, "seek": 117700, "start": 1204.0, "end": 1206.0, "text": " in an appropriate place outside.", "tokens": [294, 364, 6854, 1081, 2380, 13], "temperature": 0.0, "avg_logprob": -0.10695712174041362, "compression_ratio": 1.528052805280528, "no_speech_prob": 0.0009153857827186584}, {"id": 445, "seek": 120600, "start": 1206.0, "end": 1209.0, "text": " And the FOSDEM team has asked us to ask you", "tokens": [400, 264, 479, 4367, 35, 6683, 1469, 575, 2351, 505, 281, 1029, 291], "temperature": 0.0, "avg_logprob": -0.06584492940751333, "compression_ratio": 1.6307692307692307, "no_speech_prob": 0.002788945334032178}, {"id": 446, "seek": 120600, "start": 1209.0, "end": 1211.0, "text": " to leave the building as soon as possible", "tokens": [281, 1856, 264, 2390, 382, 2321, 382, 1944], "temperature": 0.0, "avg_logprob": -0.06584492940751333, "compression_ratio": 1.6307692307692307, "no_speech_prob": 0.002788945334032178}, {"id": 447, "seek": 120600, "start": 1211.0, "end": 1213.0, "text": " so they can lock up the whole building.", "tokens": [370, 436, 393, 4017, 493, 264, 1379, 2390, 13], "temperature": 0.0, "avg_logprob": -0.06584492940751333, "compression_ratio": 1.6307692307692307, "no_speech_prob": 0.002788945334032178}, {"id": 448, "seek": 120600, "start": 1213.0, "end": 1215.0, "text": " There's another talk going on in Janssen,", "tokens": [821, 311, 1071, 751, 516, 322, 294, 508, 599, 6748, 11], "temperature": 0.0, "avg_logprob": -0.06584492940751333, "compression_ratio": 1.6307692307692307, "no_speech_prob": 0.002788945334032178}, {"id": 449, "seek": 120600, "start": 1215.0, "end": 1217.0, "text": " in the really big room.", "tokens": [294, 264, 534, 955, 1808, 13], "temperature": 0.0, "avg_logprob": -0.06584492940751333, "compression_ratio": 1.6307692307692307, "no_speech_prob": 0.002788945334032178}, {"id": 450, "seek": 120600, "start": 1217.0, "end": 1219.0, "text": " I would recommend going there.", "tokens": [286, 576, 2748, 516, 456, 13], "temperature": 0.0, "avg_logprob": -0.06584492940751333, "compression_ratio": 1.6307692307692307, "no_speech_prob": 0.002788945334032178}, {"id": 451, "seek": 120600, "start": 1219.0, "end": 1221.0, "text": " It's a really nice way to wrap up FOSDEM,", "tokens": [467, 311, 257, 534, 1481, 636, 281, 7019, 493, 479, 4367, 35, 6683, 11], "temperature": 0.0, "avg_logprob": -0.06584492940751333, "compression_ratio": 1.6307692307692307, "no_speech_prob": 0.002788945334032178}, {"id": 452, "seek": 120600, "start": 1221.0, "end": 1223.0, "text": " and there will be places there to get one", "tokens": [293, 456, 486, 312, 3190, 456, 281, 483, 472], "temperature": 0.0, "avg_logprob": -0.06584492940751333, "compression_ratio": 1.6307692307692307, "no_speech_prob": 0.002788945334032178}, {"id": 453, "seek": 120600, "start": 1223.0, "end": 1225.0, "text": " or maybe two or three more beers", "tokens": [420, 1310, 732, 420, 1045, 544, 34159], "temperature": 0.0, "avg_logprob": -0.06584492940751333, "compression_ratio": 1.6307692307692307, "no_speech_prob": 0.002788945334032178}, {"id": 454, "seek": 120600, "start": 1225.0, "end": 1227.0, "text": " and have some more chats with people.", "tokens": [293, 362, 512, 544, 38057, 365, 561, 13], "temperature": 0.0, "avg_logprob": -0.06584492940751333, "compression_ratio": 1.6307692307692307, "no_speech_prob": 0.002788945334032178}, {"id": 455, "seek": 120600, "start": 1227.0, "end": 1230.0, "text": " Thanks a lot, and hopefully see you next year.", "tokens": [2561, 257, 688, 11, 293, 4696, 536, 291, 958, 1064, 13], "temperature": 0.0, "avg_logprob": -0.06584492940751333, "compression_ratio": 1.6307692307692307, "no_speech_prob": 0.002788945334032178}, {"id": 456, "seek": 123000, "start": 1230.0, "end": 1237.0, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 50714], "temperature": 0.0, "avg_logprob": -0.3550623257954915, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.004991031251847744}], "language": "en"}