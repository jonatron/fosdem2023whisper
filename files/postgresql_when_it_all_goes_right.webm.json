{"text": " We are starting, please be quiet. Couple of things, first of all, welcome. Here I am to introduce our next speaker, Pablo, who is going to talk about to go. Just a few practical things. When you exit, please exit from the back. And if you want to go out in between the talk, please be quiet. Because this diaphragm is very loud and these chairs are very squeaky. So, yes. That being said, enjoy. Hello people. How are you today? It's very fun. Because first two talks were not really crowded. But mine is good already. My name is Pablo Golub. I'm working for Cybertech. So, I'm a senior consultant in the body of a young developer. So, today, a couple of words about my company. Cybertech is purely PostgreSQL company. We work with clients only if they have PostgreSQL. If they don't, we install it and they can work with us from that point. We are having several branches all over, not all over, but the world. Some of them in South America, most of them are in Europe. Not now. I wanted to restart. So, some of our customers, so choose your fighter. Some of our products. So, we are not only consulting people, but we do products. Yeah. Why PostgreSQL? You know why. It's cool. Absolutely. So, what I'm talking about today. So, first of all, I want to introduce you to the Go language. How many of you have an idea of what the Go language is? Okay. So, I don't need to start from the beginning explaining what the compiler is. So, yeah. Okay. Then, I will say a couple of words about IDEs and editors we are using. Then, I will describe drivers for PostgreSQL specifically. Some useful extensions. How we do testing, how we do releases, how we do continuous integration, development, etc. And then, probably, I hope, we will have a question session. Okay. So, why Go? First of all, when I start my first project, I like that Go produces the native one binary for every platform. I said, wow. Wow. I just can build everything from the same command line for every operating system and architecture I want to. And I don't need virtual machines and other crap. Just like Go. It's simple enough. It has a good community. It now has already very comprehensive tools support by GitHub, GitLab, etc., etc. Yeah. So, cross-platform is somehow connected with the native binaries for every architecture. So, this is the last developer survey for Go asking how people are using Go language for what kind of. So, speaking about PostgreSQL, I would say that data processing is somehow connected. Before that, we had, like, these answers where you can see that databases is like a half of the projects people were using. Probably, you know, if not, so the top products written Go are Kubernetes and Docker, OpenShift, then Hugo, the fastest framework for building statistical sites, etc., etc. Postgres-related Go products which are written in Go are the CockroachDB, both Postgres operators from Zalando and from Crunchy, WallG, PgCenter, PgWatch, PgTimeTable, so on and so on. So, if you want to find more projects, more applications written in Go, please go to this site, to this repo. There are a lot of them. A lot of them, yeah. Okay, so what about tooling? Because when I was started, I used sublime text. There was no proper IDE to work with, no debugger, no these kind of things. Right now, according to the last year developer Sari, the most used IDE is VS Code, then GoLand by JetBrains, and then Vim, and sublime text is 1%. I was saying at the conference that they talked that I will try GoLand and will tell you about how it is different from VS Code. No, still didn't try it, but I think it's good. So these are the answers from the previous years. So as you can see, the intention is the same. So, VS Code on top, and GoLanguage, et cetera, et cetera. GoLand, sorry. What I'm using, I'm using VS Code with the official plugin installed. Then I'm using the tipwars command line utility to make these fancy tables out of test output. Linter, of course, tip nine. I tried GitLab co-pilot. It's not bad, but I don't want to spend my money on this. I have my own head, you know. GoReleaser to produce the packages and binaries like in one go. Then PostgreSQL, of course. And the last, but not least, the Gitpod.io, which is pretty much the same thing as a Git Hub workspace, but it's free for open source developers. So it's good if you want to try something new and you don't want to install everything on your machine or to set up the virtual machine. You can go there, run it in your browser, drink a beer on the beach, and try something new. It's okay. If you're done, you just close your browser, close your tab, and it's gone. Now, about drivers, about the PostgreSQL part of this talk. The whole idea of this talk started after I tried to find good tutorials about how to start to work with PostgreSQL. A lot of them, not all of them, but a lot of them say, okay, just use ORM and you're fine. Well, why? If I need to create utility to use three commands, why should I use ORM? And yeah, don't get me wrong. ORMs are fine if you know what you are doing. They solve the problems, but you don't need to put it everywhere and you don't need to start from it because otherwise you will be learning ORM but not learning PostgreSQL itself, right? Yeah. We have SQL for that. So, during this talk, I will not be explaining ORMs on how to work with that. I will explain the basic drivers. Anyway, ORMs are using drivers on the low level to speak to the PostgreSQL, right? So, we should know how to use them. So, the thing is, in Go, that we have these databases QL interfaces. Interfaces is just like an agreement on what methods are available from, I don't know, from object, from structure, or whatever. And for each database, there should be a special driver, an implementation for these interface, right? So, the first official implementation for the PostgreSQL in the Go world was Leap2Q. It's good. It's proven. It's a long time on the market, but it is in maintenance mode right now for two years, probably. It's not bad. It's okay. You can be sure that this functionality is solid, but if you want more, and if you start a new project, JXC-PGX is the way to go, because you can use it with whatever you want. I will show you later. So, yeah, we are scientists, and we do graphs. So, unlike of Python, or not in Python, but NPM, JavaScript work, we don't have this statistic for how many times a particular package was downloaded, used, whatever. So, the most funny way is to use GitHub stars and, yeah, to build this stuff. So, as you can see, the PGX started one year later, but now it's going to be very popular. So, in 2019-20, there was an announcement that the LPQ is going to maintain smart, and the PGX started to grow. So, what if your project is using already databases QL, or you want to follow tutorials or techniques and to use these databases QL, standard de facto interfaces? For that purpose, PGX has a special wrapper. So, you can still use databases QL interface, but you can, underneath, on the low level, you will use the PGX package. So, you should use PGX solely if you are starting a new project, and your project is aiming only POSQS QL. Then you don't need databases QL, but if you are dependent on Orm, or you are dependent on other package which wants you to use databases QL, you go for wrapper. In that case, the dependency will use this wrapper to speak to databases QL, and you will use the power of PGX. So, there are a lot of unique features that are not implemented in the standard library, and they cannot be implemented because this interface is the same for every possible database. So, for example, you cannot add methods with a copy support because only POSQS QL do copy support, right? So, the most cool feature is that PGX supports binary transfer protocol, and it supports natively all built-in POSQS types. And if you create user types, it will support them out of the box unless they are very complicated. But even in that case, you can create a special interface or a special object structure that will tell PGX how to encode, decode the developers of your types. So, as I said, yeah, copy protocol, logging, yeah, and for connection pooling, you have this after connect hook. So, the idea in girl language is that the database object that you have is pooled by default. So, it can create additional connections, and you never know how many active... Well, you can know, but you can never tell how many connections you have right now. And this, for example, after connect hook helps you to prepare your session, prepare your new open connection for something, like add some identifier, login, or whatever. Yeah, listen.notify is implemented natively. What else? Yeah, different JSON, HStore, large objects. So, everything you need is already there. Nice thing about PGX is in December, probably the new major version 5 release was... And it was a huge step forward, especially in the term of dependencies. v4, version 4, was good, but it has so many external dependencies that, for example, Magnus Agander said, no, we will not rewrite our internal tool into PGX because it's too much dependencies. It's not the thing anymore, and it's very cool. So, yeah, hello world. You probably all know how to write it in the database SQL interface, so you're just using that import package, but instead of using libpq, you are specifying PGX as the libp, which is a wrapper for the standard library. And then all things are the same. No difference. So, if you want to update your project, you just change the import part, the import of libpq to the PGX standard lib, and you are fine. If you want to use PGX directly, you are fine to do that. The thing is here that the PGX return the connect method return the one connection only. So, if you don't need a pool of connections, or if you want to be sure that only one connection is live, one connection is used, you are going with PGX connect, right? But please remember that you cannot use this structure, this connection in parallel, so you need to know that at one point in time, only one thread or one go routine can talk to the database. Otherwise, you're good. But if you want a pool of connections, you are going with PGX pool. And I don't know what can I add here. It's obvious. You can pass it to the go routines, and it will create additional connections as you go, and you can limit up a number of connections, etc., etc. It's very, very, very flexible. Okay, about useful extensions. For my first project, I started with the libpq as well. It's way to go. That's how we grow. And later, I understand that I want this copy functionality badly. I need that. So I started to look to the PGX, how to switch it, and I didn't want to lose these SQL things when you're encoding, decoding your structures, slices, arrays, whatever, right from rows or two rows, right? That's what most people think the ORM do. It just translates the rows into the structures. But, yeah, it's very useful. So, like, if you are working with an old database SQL or libpq, you are importing this SQL thing, and you can have a lot of new methods, like you can struct the row into the structure, or you can scan the scalar into the variable, or you can create a slice from your rows, etc., etc. It's very cool. PGX, at that time, didn't provide that. But with the latest version 5, everything is already there. Better is included. Probably you can find cases where you want more control over decoding and coding, but after this guy was introduced, wrote to struct by name, written by me, by the way, yeah, everything became very easy. So, before that, we had only row to struct by position, right? So, if your structure fields are in the same position as your field in your row result set, you're fine. You're just, like, doing the back and forth. But if you want to skip some fields, or, for example, if you have some non-public fields in the structure, but still want to use this functionality to decode and code from the result set, this is the way to go. Yeah. Now about testing. We all know it's very essential, right? And I heard a lot this statement that you need to write your tests first, and only then implementation. I never did. Maybe one of us tried it. Oh, go, go, go. I'm too lazy, because I never know where at the end I will go with my code. I'm starting like, okay, I will implement this thing that will return this integer, and then I'm like, oh, no, let's do this. CTE with a lot of things, yeah. And if I write a test before I need to follow it, right? No, it's not funny. How we do testing? So I would say there are three main approaches. The first one, obviously, is to start a real PostgreSQL server. You can have your local installation on the test environment, or you can download it during the test running, install it, initialize, et cetera, then cache, but it's still the same. It's a real PostgreSQL server. The second approach would be Mockin libraries. For database SQL, that would be Datadog, go SQL Mock. And for PGX, I created this PGX Mock, which is the brother of the SQL Mock, but, yeah, works with PGX. I hope you know what is Mockin and how these things are working, right? We are pretending that we are a PostgreSQL server, and our application, our tests, are thinking that they are speaking to the real server, but in fact, we just throw the needed answers to the application. So, do we need rows? Okay, this is row, this is the answer. Oh, no, that one is a row. Let's see how you will react with that, et cetera, et cetera. But if you want to test on the protocol level, there is also some very low libraries, like PG Mock, which is just like the real low-level Mockin protocol. KacrosDB has its own test server, which is just like an import KacrosDB test server and use it in your tests. And another library is copied. Let's try to maybe... It's not very useful. No, let's get back. Can it work? Okay, so how to create a test, how to use this PGX Mock thing. So, if you read me on the repository, you will see that now change is required to your application. That's a lie. You need to provide an interface because the PGX return structures is a connection or a pool. We cannot mock structures. We can mock interfaces. So, I am defining PGX interface here and say to my method, to my function, that I will use this interface. Please use that. And for my function, it doesn't care whether it be a real connection or whether it be Mockin or anything. It just knows that this object has this method and it's enough for that, okay? So, yeah, we write a code, kind of shit even, okay? We are trying to call me, we are trying to roll back, et cetera, et cetera, et cetera, how to test it. So, I will always start with a successful test cases. I am a very positive person. First thing, first though, I am creating the Mockin object. PGX mock new pool. Then I will tell my Mockin object how should my session looks like, right? So, I am saying I am expecting that we will start a transaction. I am expecting to begin. Then I am expecting that the code will try to execute update statement, right? And when this happens, please return to this code the new result that update was successful and we updated one row, right? After that, I expect that the code will try to insert something. And I expect that the arguments for this statement would be two and three. If that is the case, please tell that everything is good. We insert one row. And after all that, I expect that the code will commit the transaction, right? That is what I am expecting from the code. Then I am calling my function record starts and instead of the PGX, I am passing the Mockin object, Mock. And two and three arguments, right? And if anything goes wrong, the taste case is failed, right? But another thing I want to check is every expectation I set were met. For example, after the commit, my code might want to write a log to the database or do other things. I don't expect that thing from it and these expectations were met will fail if something else happens inside this function which is not being expected, right? So for fail, for failure is pretty much the same. We are telling that we expect to start transaction, we expect to start update statement, but let's pretend we want to test how our code will behave if the insert statement will fail. So we are telling, when insert statement is coming with the arguments two and three, let's pretend that error happened. Return error to our code and the error with some error text. Very beautiful. We are starting our function, but in that case, we know that it should fail. That's why we are checking our error to be not new. We are waiting error, right? And the same for expectations were met. So for example, if we failed and our code tries to do more than we are expecting, we say, no, please don't. Please don't. Yeah, so then you are just using go test with the t-parts thingy. I just love how the tables look after this output. So like for this case, we have like one package and we have two test cases, right? But in real application, you might have hundreds, hundreds of test cases and dozens of packages. They all be listed and you can see a coverage for every package and you can see probably coverage for every test case, how many passes, how many fails, et cetera, et cetera. Also, you want to probably investigate what is the coverage. For that, you are using the built-in go to cover two test cases that will produce temporary HTML files and will open them in your browser. So you see a combo box with the list of files in your application and you just go through all your code. The red one is not covered by our test cases. The green one covered by our test cases. For example, in this case, our main function is to test it all because it's tricky to test the main function. That's why you should put it outside of everything and make it like two, three lines and only use your packages inside. Okay, so time for continuous integration and continuous delivery. As a company, we are working in GitHub, but I'm pretty sure that the same functionality is available on GitLab and BigBucket and everywhere. So for every my project, I want to have at least five actions, GitHub actions. First one is a dependent bot. I want my repository is constantly being checked if any package I'm dependent on is updated. So it will update, okay, we have a new minor or whatever version of this package. It will automatically create the pull request. I will check the output. I will check if tests are fine, if everything is okay. Okay, very good. I like this because you can do three pull requests per day and you are super productive. Then what I want to also always have is a code QL which will build your sources and will instigate the possible security vulnerabilities. Building tests, I'm using that for pull requests only because if you have fired them on every push and the test is heavy, it's not fine. Release will produce the binaries and packages when the new release is created. And the docker is the same like for release, it will produce a special tag and an image and push it. But for every commit, it will produce a special docker image which you can just try immediately, right? Like a night build or whatever. Dependable is very simple. For example, for almost all my repositories, I first want to check the Go code itself, so package ecosystem Go mode. And I want to use the latest GitHub actions as well. That's important. So I check them daily and that's usually enough. For code QL, nothing special. When you create these actions from the GitHub interface, it will fill all the fields for you. I never changed the important thing there, only removed some comments and we are fine. Building tests, I hope you can see what is going on there. No. Sorry, I don't want to switch to the editor because I cannot work like that. Yeah, so I will tell you. So I usually run all my tests on three different platforms, Windows, MacOS and Linux. The good thing is all the workers already have PostgreSQL installed on them, but the thing is that it's not started. So for you, essentially it's to start PostgreSQL and then run your tests and you are fine. Usually the version of Postgres is behind two or three minor versions, but it's okay. If you want just like the latest one, you can go with the Docker images instead of that one. Yeah. So there in the build action we have Linter, so no, without Linter we cannot accept any changes or pull requests, pull requests. And yeah, and then we are using, we are generating the coverage report to put them everywhere. See, 99% of code is covered. Yeah, let's lie. Okay, so release is a little bit simpler. As I said, we are using Go Releaser. It's absolutely fabulous piece of software that may produce everything for everything. So the GitHub action code is simple because everything is stored in the YAML configuration file where you set up the name, the architecture, the OSIS, everything. And then you just like, okay, let's check out our code and let's release it. And the cool thing about it, this is the Go Releaser, will create a change lock automatically for you based on your pull requests. So when I'm releasing, it's just like, I copy paste it, just sort it by the, like, what's added, what's fixed, and whatever. And I'm done. The release is very simple for me. Absolutely. Before that I may spend two days on each release to produce all these binders, et cetera, et cetera. Okay, Docker. Go Releaser can produce Docker images. I'm too lazy to rewrite this. And yeah, I'm using like another special, special GitHub actions to build a Docker. You can build them for every possible platforms. And this Apple M1, M2 silicon thing is whatever, it's just working. Okay, takeaways. The Go is popular. Devrim doesn't like Go. Yes? So maybe this is the last time you see this talk, like when everything goes right, he said that I need to switch to Rust. So maybe next, I will go out when the Rust goes right. So no, no. Should I stick to the Go? Okay, we can do both. Yeah, so a lot of developers are using databases with Go. Of course. You can use whatever it did or whatever operating system you are. By the way, a lot of people are using Windows, which is not common for like Postgres community, for example. But it's fine if your system can produce whatever you want. You don't care. You just work on what you have, right? So Kubernetes, you can use whatever you want with the Postgres. If you want to use Orm, please do. But remember, you're responsible for that. Use it wisely. Otherwise, you can use LITPQ package or new PGX. And you can use whatever GitHub, GitHub, Bitbucket you want. And the most amazing thing about Go is the backward compatibility. You can build whatever in the future. Yeah, in the future. Whatever code you want. And it still will be compatible with the oldest something written ages before. Even now, when we have generics, when we have a cool thing is in Go, they are still compatible with that old things. Okay, so yeah, don't be stranger, check my GitHub account, check our blog. Yeah, some of our projects. And if you have a question, or maybe you have a question to Devrim why he hates Go. No, I don't hate Go. It says I don't package. I'm not sure what the problem is. I provide everything you need. Take my binders and put them in your packaging, whatever. These conditions don't like to be in Go, because either it should be a binary or the long internet. Not internet. No, no, not internet. There are only four dependencies for a new created application to connect to the possible scale. There are only one direct dependency is PGX, and there is only four indirect dependency. Two of them are libraries from Google. One of them library from KOROS. I don't remember. And one of them is by the same author, because he's using this package in other way. Yeah, so, questions? Hi. A couple of slides back. You went to a certain functionality where you were asking, do you do select, and then you put in a structure in order to get the results from? Yeah, couple of back. I have a question on that one. Yeah, that's one. Yeah, that's one. Exactly. So you're asking a select star, and then some stuff, and then you ask it by the rows. Does the actual connection, so if you're running this on one machine, you're running Postgres on another machine, there is a network, of course, in between. There's data going back and forth. Is all the data being sent from Postgres SQL server to your Go program or not? The reason I'm asking this is because, let's say, there's a fourth field, which is, let's say, a huge JSON field or a huge binary field, which contains like a megabyte of data per record. Is it then sending, if I'm asking 100 records, a thousand records, is it sending a gigabyte over the network, or is it only sending those three fields? Okay, I got you. Yeah, thank you. Very good question. So in this particular case, there shouldn't be star, first of all. We should always list columns we want to have. I'm just too lazy, and this is not my code. But it's like, you know, it shows. Yeah. So in this case, yes, everything. Can you do it automatically? Can we add columns from a database automatically? Yes, we can. But for that, we should use SQLC package, which is exactly for that. So it is pre-built or hooks or whatever. So when you say, go build, you have special SQL files. Like, I want this field from that and that, and it will go through it, and it will build automatically the appropriate structures for go, and then you can use it. Yeah, it's just a lot of information. I cannot, like, put it into the one talk. Yeah, but yeah. About if we are loading at once, yes, we do in this case. But the Postgres protocol itself supports row by row functionality, and it's possible to use that functionality with this package. So you can, like, yeah, say that. Hello. Thank you for the talk. I have one question about this driver. Actually, it's kind of only way to work with Postgres, for my opinion. And I'm a little bit worried that this driver is not supported by Postgres community, let's say. It's supported by someone. And what is the life cycle of this software? And maybe it will die. You say, how is about new features to it, and all this question arises when you work with it, because if your management says, okay, let's use Java, and in Java it's kind of stable, this Postgres driver, and you know that you always have the new version. What is about this software? Yeah, thank you for the question. So versioning and owner, who is owner, and that kind of stuff. So as a Postgres community, we support on the C library, which is live PQ, and Java, which is JDBC, right? That's all. All others? Yeah. Who uses C++? All other libraries are maintained by someone. By the way, live PQ is not a standard library in terms of made by go. It's also maintained by one person. So how we do in this case, we just fork it and use it if you want something new. If I did everything better than the maintainer, the owner of the PGX will accept my progress proposals and we are stinked, right? If not, I will beat them and I will be popular. I have a question regarding testing strategies in CI CD. So you have shown that it's possible to mock Postgres scale, right? But sometimes you are relying on some feature of Postgres scale, or possibly you are relying on some extension Postgres. Do you want to test with a real Postgres scale? Yes. What you can recommend, so I have seen in your CI CD, you are executing some peer scale comments. Do you have a dedicated instance for running tests? No. So my GitHub actions are using pre-installed Postgres QL on the GitHub workers. They already have Postgres 15.1 probably nowadays. So I'm okay if they are behind several versions. I don't need to test for a specific feature or bug or whatever. But if I want to, in my GitHub action, I may specify the Docker image against which I want to test. So for example, if I want to test the latest master from the Postgres QL community, I will build my own image docker and will run my test against it. And I'm fine. Okay, thank you. Excellent from the back. Yes.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 12.0, "text": " We are starting, please be quiet.", "tokens": [492, 366, 2891, 11, 1767, 312, 5677, 13], "temperature": 0.0, "avg_logprob": -0.36244427074085583, "compression_ratio": 1.392638036809816, "no_speech_prob": 0.6163099408149719}, {"id": 1, "seek": 0, "start": 12.0, "end": 14.0, "text": " Couple of things, first of all, welcome.", "tokens": [38266, 295, 721, 11, 700, 295, 439, 11, 2928, 13], "temperature": 0.0, "avg_logprob": -0.36244427074085583, "compression_ratio": 1.392638036809816, "no_speech_prob": 0.6163099408149719}, {"id": 2, "seek": 0, "start": 14.0, "end": 21.0, "text": " Here I am to introduce our next speaker, Pablo, who is going to talk about to go.", "tokens": [1692, 286, 669, 281, 5366, 527, 958, 8145, 11, 31554, 11, 567, 307, 516, 281, 751, 466, 281, 352, 13], "temperature": 0.0, "avg_logprob": -0.36244427074085583, "compression_ratio": 1.392638036809816, "no_speech_prob": 0.6163099408149719}, {"id": 3, "seek": 0, "start": 21.0, "end": 23.0, "text": " Just a few practical things.", "tokens": [1449, 257, 1326, 8496, 721, 13], "temperature": 0.0, "avg_logprob": -0.36244427074085583, "compression_ratio": 1.392638036809816, "no_speech_prob": 0.6163099408149719}, {"id": 4, "seek": 0, "start": 23.0, "end": 26.0, "text": " When you exit, please exit from the back.", "tokens": [1133, 291, 11043, 11, 1767, 11043, 490, 264, 646, 13], "temperature": 0.0, "avg_logprob": -0.36244427074085583, "compression_ratio": 1.392638036809816, "no_speech_prob": 0.6163099408149719}, {"id": 5, "seek": 2600, "start": 26.0, "end": 31.0, "text": " And if you want to go out in between the talk, please be quiet.", "tokens": [400, 498, 291, 528, 281, 352, 484, 294, 1296, 264, 751, 11, 1767, 312, 5677, 13], "temperature": 0.0, "avg_logprob": -0.23727493598812915, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.003101909765973687}, {"id": 6, "seek": 2600, "start": 31.0, "end": 36.0, "text": " Because this diaphragm is very loud and these chairs are very squeaky.", "tokens": [1436, 341, 46711, 76, 307, 588, 6588, 293, 613, 18299, 366, 588, 8447, 15681, 13], "temperature": 0.0, "avg_logprob": -0.23727493598812915, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.003101909765973687}, {"id": 7, "seek": 2600, "start": 36.0, "end": 38.0, "text": " So, yes.", "tokens": [407, 11, 2086, 13], "temperature": 0.0, "avg_logprob": -0.23727493598812915, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.003101909765973687}, {"id": 8, "seek": 2600, "start": 38.0, "end": 47.0, "text": " That being said, enjoy.", "tokens": [663, 885, 848, 11, 2103, 13], "temperature": 0.0, "avg_logprob": -0.23727493598812915, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.003101909765973687}, {"id": 9, "seek": 2600, "start": 47.0, "end": 50.0, "text": " Hello people. How are you today?", "tokens": [2425, 561, 13, 1012, 366, 291, 965, 30], "temperature": 0.0, "avg_logprob": -0.23727493598812915, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.003101909765973687}, {"id": 10, "seek": 5000, "start": 50.0, "end": 56.0, "text": " It's very fun. Because first two talks were not really crowded.", "tokens": [467, 311, 588, 1019, 13, 1436, 700, 732, 6686, 645, 406, 534, 21634, 13], "temperature": 0.0, "avg_logprob": -0.32278345398983715, "compression_ratio": 1.294871794871795, "no_speech_prob": 0.0005579154822044075}, {"id": 11, "seek": 5000, "start": 56.0, "end": 61.0, "text": " But mine is good already.", "tokens": [583, 3892, 307, 665, 1217, 13], "temperature": 0.0, "avg_logprob": -0.32278345398983715, "compression_ratio": 1.294871794871795, "no_speech_prob": 0.0005579154822044075}, {"id": 12, "seek": 5000, "start": 61.0, "end": 64.0, "text": " My name is Pablo Golub. I'm working for Cybertech.", "tokens": [1222, 1315, 307, 31554, 36319, 836, 13, 286, 478, 1364, 337, 22935, 25970, 13], "temperature": 0.0, "avg_logprob": -0.32278345398983715, "compression_ratio": 1.294871794871795, "no_speech_prob": 0.0005579154822044075}, {"id": 13, "seek": 5000, "start": 64.0, "end": 71.0, "text": " So, I'm a senior consultant in the body of a young developer.", "tokens": [407, 11, 286, 478, 257, 7965, 24676, 294, 264, 1772, 295, 257, 2037, 10754, 13], "temperature": 0.0, "avg_logprob": -0.32278345398983715, "compression_ratio": 1.294871794871795, "no_speech_prob": 0.0005579154822044075}, {"id": 14, "seek": 7100, "start": 71.0, "end": 80.0, "text": " So, today, a couple of words about my company. Cybertech is purely PostgreSQL company.", "tokens": [407, 11, 965, 11, 257, 1916, 295, 2283, 466, 452, 2237, 13, 22935, 25970, 307, 17491, 10223, 33248, 39934, 2237, 13], "temperature": 0.0, "avg_logprob": -0.12804345761315297, "compression_ratio": 1.4217687074829932, "no_speech_prob": 0.0006348663009703159}, {"id": 15, "seek": 7100, "start": 80.0, "end": 85.0, "text": " We work with clients only if they have PostgreSQL.", "tokens": [492, 589, 365, 6982, 787, 498, 436, 362, 10223, 33248, 39934, 13], "temperature": 0.0, "avg_logprob": -0.12804345761315297, "compression_ratio": 1.4217687074829932, "no_speech_prob": 0.0006348663009703159}, {"id": 16, "seek": 7100, "start": 85.0, "end": 92.0, "text": " If they don't, we install it and they can work with us from that point.", "tokens": [759, 436, 500, 380, 11, 321, 3625, 309, 293, 436, 393, 589, 365, 505, 490, 300, 935, 13], "temperature": 0.0, "avg_logprob": -0.12804345761315297, "compression_ratio": 1.4217687074829932, "no_speech_prob": 0.0006348663009703159}, {"id": 17, "seek": 9200, "start": 92.0, "end": 101.0, "text": " We are having several branches all over, not all over, but the world.", "tokens": [492, 366, 1419, 2940, 14770, 439, 670, 11, 406, 439, 670, 11, 457, 264, 1002, 13], "temperature": 0.0, "avg_logprob": -0.19137094815572103, "compression_ratio": 1.4217687074829932, "no_speech_prob": 0.0008610700606368482}, {"id": 18, "seek": 9200, "start": 101.0, "end": 110.0, "text": " Some of them in South America, most of them are in Europe.", "tokens": [2188, 295, 552, 294, 4242, 3374, 11, 881, 295, 552, 366, 294, 3315, 13], "temperature": 0.0, "avg_logprob": -0.19137094815572103, "compression_ratio": 1.4217687074829932, "no_speech_prob": 0.0008610700606368482}, {"id": 19, "seek": 9200, "start": 110.0, "end": 114.0, "text": " Not now. I wanted to restart.", "tokens": [1726, 586, 13, 286, 1415, 281, 21022, 13], "temperature": 0.0, "avg_logprob": -0.19137094815572103, "compression_ratio": 1.4217687074829932, "no_speech_prob": 0.0008610700606368482}, {"id": 20, "seek": 9200, "start": 114.0, "end": 118.0, "text": " So, some of our customers, so choose your fighter.", "tokens": [407, 11, 512, 295, 527, 4581, 11, 370, 2826, 428, 15932, 13], "temperature": 0.0, "avg_logprob": -0.19137094815572103, "compression_ratio": 1.4217687074829932, "no_speech_prob": 0.0008610700606368482}, {"id": 21, "seek": 11800, "start": 118.0, "end": 127.0, "text": " Some of our products. So, we are not only consulting people, but we do products.", "tokens": [2188, 295, 527, 3383, 13, 407, 11, 321, 366, 406, 787, 23682, 561, 11, 457, 321, 360, 3383, 13], "temperature": 0.0, "avg_logprob": -0.1254406194577272, "compression_ratio": 1.4673366834170853, "no_speech_prob": 0.0005791414878331125}, {"id": 22, "seek": 11800, "start": 127.0, "end": 134.0, "text": " Yeah. Why PostgreSQL? You know why. It's cool. Absolutely.", "tokens": [865, 13, 1545, 10223, 33248, 39934, 30, 509, 458, 983, 13, 467, 311, 1627, 13, 7021, 13], "temperature": 0.0, "avg_logprob": -0.1254406194577272, "compression_ratio": 1.4673366834170853, "no_speech_prob": 0.0005791414878331125}, {"id": 23, "seek": 11800, "start": 134.0, "end": 138.0, "text": " So, what I'm talking about today.", "tokens": [407, 11, 437, 286, 478, 1417, 466, 965, 13], "temperature": 0.0, "avg_logprob": -0.1254406194577272, "compression_ratio": 1.4673366834170853, "no_speech_prob": 0.0005791414878331125}, {"id": 24, "seek": 11800, "start": 138.0, "end": 140.0, "text": " So, first of all, I want to introduce you to the Go language.", "tokens": [407, 11, 700, 295, 439, 11, 286, 528, 281, 5366, 291, 281, 264, 1037, 2856, 13], "temperature": 0.0, "avg_logprob": -0.1254406194577272, "compression_ratio": 1.4673366834170853, "no_speech_prob": 0.0005791414878331125}, {"id": 25, "seek": 11800, "start": 140.0, "end": 146.0, "text": " How many of you have an idea of what the Go language is?", "tokens": [1012, 867, 295, 291, 362, 364, 1558, 295, 437, 264, 1037, 2856, 307, 30], "temperature": 0.0, "avg_logprob": -0.1254406194577272, "compression_ratio": 1.4673366834170853, "no_speech_prob": 0.0005791414878331125}, {"id": 26, "seek": 14600, "start": 146.0, "end": 153.0, "text": " Okay. So, I don't need to start from the beginning explaining what the compiler is.", "tokens": [1033, 13, 407, 11, 286, 500, 380, 643, 281, 722, 490, 264, 2863, 13468, 437, 264, 31958, 307, 13], "temperature": 0.0, "avg_logprob": -0.173055780850924, "compression_ratio": 1.377245508982036, "no_speech_prob": 0.0005465256399475038}, {"id": 27, "seek": 14600, "start": 153.0, "end": 155.0, "text": " So, yeah. Okay.", "tokens": [407, 11, 1338, 13, 1033, 13], "temperature": 0.0, "avg_logprob": -0.173055780850924, "compression_ratio": 1.377245508982036, "no_speech_prob": 0.0005465256399475038}, {"id": 28, "seek": 14600, "start": 155.0, "end": 163.0, "text": " Then, I will say a couple of words about IDEs and editors we are using.", "tokens": [1396, 11, 286, 486, 584, 257, 1916, 295, 2283, 466, 7348, 20442, 293, 31446, 321, 366, 1228, 13], "temperature": 0.0, "avg_logprob": -0.173055780850924, "compression_ratio": 1.377245508982036, "no_speech_prob": 0.0005465256399475038}, {"id": 29, "seek": 14600, "start": 163.0, "end": 171.0, "text": " Then, I will describe drivers for PostgreSQL specifically.", "tokens": [1396, 11, 286, 486, 6786, 11590, 337, 10223, 33248, 39934, 4682, 13], "temperature": 0.0, "avg_logprob": -0.173055780850924, "compression_ratio": 1.377245508982036, "no_speech_prob": 0.0005465256399475038}, {"id": 30, "seek": 17100, "start": 171.0, "end": 176.0, "text": " Some useful extensions. How we do testing, how we do releases,", "tokens": [2188, 4420, 25129, 13, 1012, 321, 360, 4997, 11, 577, 321, 360, 16952, 11], "temperature": 0.0, "avg_logprob": -0.12145367221555849, "compression_ratio": 1.391812865497076, "no_speech_prob": 0.00037641607923433185}, {"id": 31, "seek": 17100, "start": 176.0, "end": 179.0, "text": " how we do continuous integration, development, etc.", "tokens": [577, 321, 360, 10957, 10980, 11, 3250, 11, 5183, 13], "temperature": 0.0, "avg_logprob": -0.12145367221555849, "compression_ratio": 1.391812865497076, "no_speech_prob": 0.00037641607923433185}, {"id": 32, "seek": 17100, "start": 179.0, "end": 186.0, "text": " And then, probably, I hope, we will have a question session.", "tokens": [400, 550, 11, 1391, 11, 286, 1454, 11, 321, 486, 362, 257, 1168, 5481, 13], "temperature": 0.0, "avg_logprob": -0.12145367221555849, "compression_ratio": 1.391812865497076, "no_speech_prob": 0.00037641607923433185}, {"id": 33, "seek": 17100, "start": 186.0, "end": 194.0, "text": " Okay. So, why Go?", "tokens": [1033, 13, 407, 11, 983, 1037, 30], "temperature": 0.0, "avg_logprob": -0.12145367221555849, "compression_ratio": 1.391812865497076, "no_speech_prob": 0.00037641607923433185}, {"id": 34, "seek": 17100, "start": 194.0, "end": 197.0, "text": " First of all, when I start my first project,", "tokens": [2386, 295, 439, 11, 562, 286, 722, 452, 700, 1716, 11], "temperature": 0.0, "avg_logprob": -0.12145367221555849, "compression_ratio": 1.391812865497076, "no_speech_prob": 0.00037641607923433185}, {"id": 35, "seek": 19700, "start": 197.0, "end": 202.0, "text": " I like that Go produces the native one binary for every platform.", "tokens": [286, 411, 300, 1037, 14725, 264, 8470, 472, 17434, 337, 633, 3663, 13], "temperature": 0.0, "avg_logprob": -0.20692188209957546, "compression_ratio": 1.450261780104712, "no_speech_prob": 0.0004670110938604921}, {"id": 36, "seek": 19700, "start": 202.0, "end": 205.0, "text": " I said, wow. Wow.", "tokens": [286, 848, 11, 6076, 13, 3153, 13], "temperature": 0.0, "avg_logprob": -0.20692188209957546, "compression_ratio": 1.450261780104712, "no_speech_prob": 0.0004670110938604921}, {"id": 37, "seek": 19700, "start": 205.0, "end": 211.0, "text": " I just can build everything from the same command line for every operating system", "tokens": [286, 445, 393, 1322, 1203, 490, 264, 912, 5622, 1622, 337, 633, 7447, 1185], "temperature": 0.0, "avg_logprob": -0.20692188209957546, "compression_ratio": 1.450261780104712, "no_speech_prob": 0.0004670110938604921}, {"id": 38, "seek": 19700, "start": 211.0, "end": 216.0, "text": " and architecture I want to. And I don't need virtual machines and other crap.", "tokens": [293, 9482, 286, 528, 281, 13, 400, 286, 500, 380, 643, 6374, 8379, 293, 661, 12426, 13], "temperature": 0.0, "avg_logprob": -0.20692188209957546, "compression_ratio": 1.450261780104712, "no_speech_prob": 0.0004670110938604921}, {"id": 39, "seek": 19700, "start": 216.0, "end": 222.0, "text": " Just like Go. It's simple enough.", "tokens": [1449, 411, 1037, 13, 467, 311, 2199, 1547, 13], "temperature": 0.0, "avg_logprob": -0.20692188209957546, "compression_ratio": 1.450261780104712, "no_speech_prob": 0.0004670110938604921}, {"id": 40, "seek": 22200, "start": 222.0, "end": 229.0, "text": " It has a good community. It now has already very comprehensive tools", "tokens": [467, 575, 257, 665, 1768, 13, 467, 586, 575, 1217, 588, 13914, 3873], "temperature": 0.0, "avg_logprob": -0.21079362355745757, "compression_ratio": 1.3581081081081081, "no_speech_prob": 6.040611697244458e-05}, {"id": 41, "seek": 22200, "start": 229.0, "end": 236.0, "text": " support by GitHub, GitLab, etc., etc.", "tokens": [1406, 538, 23331, 11, 16939, 37880, 11, 5183, 7933, 5183, 13], "temperature": 0.0, "avg_logprob": -0.21079362355745757, "compression_ratio": 1.3581081081081081, "no_speech_prob": 6.040611697244458e-05}, {"id": 42, "seek": 22200, "start": 236.0, "end": 245.0, "text": " Yeah. So, cross-platform is somehow connected with the native binaries for every architecture.", "tokens": [865, 13, 407, 11, 3278, 12, 39975, 837, 307, 6063, 4582, 365, 264, 8470, 5171, 4889, 337, 633, 9482, 13], "temperature": 0.0, "avg_logprob": -0.21079362355745757, "compression_ratio": 1.3581081081081081, "no_speech_prob": 6.040611697244458e-05}, {"id": 43, "seek": 24500, "start": 245.0, "end": 256.0, "text": " So, this is the last developer survey for Go asking how people are using Go language", "tokens": [407, 11, 341, 307, 264, 1036, 10754, 8984, 337, 1037, 3365, 577, 561, 366, 1228, 1037, 2856], "temperature": 0.0, "avg_logprob": -0.12267495646621242, "compression_ratio": 1.4316939890710383, "no_speech_prob": 6.604890222661197e-05}, {"id": 44, "seek": 24500, "start": 256.0, "end": 260.0, "text": " for what kind of. So, speaking about PostgreSQL,", "tokens": [337, 437, 733, 295, 13, 407, 11, 4124, 466, 10223, 33248, 39934, 11], "temperature": 0.0, "avg_logprob": -0.12267495646621242, "compression_ratio": 1.4316939890710383, "no_speech_prob": 6.604890222661197e-05}, {"id": 45, "seek": 24500, "start": 260.0, "end": 263.0, "text": " I would say that data processing is somehow connected.", "tokens": [286, 576, 584, 300, 1412, 9007, 307, 6063, 4582, 13], "temperature": 0.0, "avg_logprob": -0.12267495646621242, "compression_ratio": 1.4316939890710383, "no_speech_prob": 6.604890222661197e-05}, {"id": 46, "seek": 24500, "start": 263.0, "end": 272.0, "text": " Before that, we had, like, these answers where you can see that databases", "tokens": [4546, 300, 11, 321, 632, 11, 411, 11, 613, 6338, 689, 291, 393, 536, 300, 22380], "temperature": 0.0, "avg_logprob": -0.12267495646621242, "compression_ratio": 1.4316939890710383, "no_speech_prob": 6.604890222661197e-05}, {"id": 47, "seek": 27200, "start": 272.0, "end": 281.0, "text": " is like a half of the projects people were using.", "tokens": [307, 411, 257, 1922, 295, 264, 4455, 561, 645, 1228, 13], "temperature": 0.0, "avg_logprob": -0.1898721694946289, "compression_ratio": 1.2972972972972974, "no_speech_prob": 0.00027939537540078163}, {"id": 48, "seek": 27200, "start": 281.0, "end": 288.0, "text": " Probably, you know, if not, so the top products written Go are Kubernetes and Docker,", "tokens": [9210, 11, 291, 458, 11, 498, 406, 11, 370, 264, 1192, 3383, 3720, 1037, 366, 23145, 293, 33772, 11], "temperature": 0.0, "avg_logprob": -0.1898721694946289, "compression_ratio": 1.2972972972972974, "no_speech_prob": 0.00027939537540078163}, {"id": 49, "seek": 27200, "start": 288.0, "end": 298.0, "text": " OpenShift, then Hugo, the fastest framework for building", "tokens": [7238, 7774, 2008, 11, 550, 32504, 11, 264, 14573, 8388, 337, 2390], "temperature": 0.0, "avg_logprob": -0.1898721694946289, "compression_ratio": 1.2972972972972974, "no_speech_prob": 0.00027939537540078163}, {"id": 50, "seek": 29800, "start": 298.0, "end": 302.0, "text": " statistical sites, etc., etc.", "tokens": [22820, 7533, 11, 5183, 7933, 5183, 13], "temperature": 0.0, "avg_logprob": -0.3691785646521527, "compression_ratio": 1.2845528455284554, "no_speech_prob": 0.00013657956151291728}, {"id": 51, "seek": 29800, "start": 302.0, "end": 314.0, "text": " Postgres-related Go products which are written in Go are the CockroachDB,", "tokens": [10223, 45189, 12, 12004, 1037, 3383, 597, 366, 3720, 294, 1037, 366, 264, 39410, 340, 608, 27735, 11], "temperature": 0.0, "avg_logprob": -0.3691785646521527, "compression_ratio": 1.2845528455284554, "no_speech_prob": 0.00013657956151291728}, {"id": 52, "seek": 29800, "start": 314.0, "end": 321.0, "text": " both Postgres operators from Zalando and from Crunchy,", "tokens": [1293, 10223, 45189, 19077, 490, 1176, 304, 1806, 293, 490, 44233, 88, 11], "temperature": 0.0, "avg_logprob": -0.3691785646521527, "compression_ratio": 1.2845528455284554, "no_speech_prob": 0.00013657956151291728}, {"id": 53, "seek": 32100, "start": 321.0, "end": 328.0, "text": " WallG, PgCenter, PgWatch, PgTimeTable, so on and so on.", "tokens": [9551, 38, 11, 430, 70, 34, 14278, 11, 430, 70, 36204, 11, 430, 70, 22233, 51, 712, 11, 370, 322, 293, 370, 322, 13], "temperature": 0.0, "avg_logprob": -0.20149005752011953, "compression_ratio": 1.4285714285714286, "no_speech_prob": 4.2404470150358975e-05}, {"id": 54, "seek": 32100, "start": 328.0, "end": 333.0, "text": " So, if you want to find more projects, more applications written in Go,", "tokens": [407, 11, 498, 291, 528, 281, 915, 544, 4455, 11, 544, 5821, 3720, 294, 1037, 11], "temperature": 0.0, "avg_logprob": -0.20149005752011953, "compression_ratio": 1.4285714285714286, "no_speech_prob": 4.2404470150358975e-05}, {"id": 55, "seek": 32100, "start": 333.0, "end": 337.0, "text": " please go to this site, to this repo.", "tokens": [1767, 352, 281, 341, 3621, 11, 281, 341, 49040, 13], "temperature": 0.0, "avg_logprob": -0.20149005752011953, "compression_ratio": 1.4285714285714286, "no_speech_prob": 4.2404470150358975e-05}, {"id": 56, "seek": 32100, "start": 337.0, "end": 342.0, "text": " There are a lot of them. A lot of them, yeah.", "tokens": [821, 366, 257, 688, 295, 552, 13, 316, 688, 295, 552, 11, 1338, 13], "temperature": 0.0, "avg_logprob": -0.20149005752011953, "compression_ratio": 1.4285714285714286, "no_speech_prob": 4.2404470150358975e-05}, {"id": 57, "seek": 32100, "start": 342.0, "end": 347.0, "text": " Okay, so what about tooling?", "tokens": [1033, 11, 370, 437, 466, 46593, 30], "temperature": 0.0, "avg_logprob": -0.20149005752011953, "compression_ratio": 1.4285714285714286, "no_speech_prob": 4.2404470150358975e-05}, {"id": 58, "seek": 34700, "start": 347.0, "end": 352.0, "text": " Because when I was started, I used sublime text.", "tokens": [1436, 562, 286, 390, 1409, 11, 286, 1143, 1422, 40941, 2487, 13], "temperature": 0.0, "avg_logprob": -0.15909638669755724, "compression_ratio": 1.3764705882352941, "no_speech_prob": 0.0002718998584896326}, {"id": 59, "seek": 34700, "start": 352.0, "end": 358.0, "text": " There was no proper IDE to work with, no debugger,", "tokens": [821, 390, 572, 2296, 40930, 281, 589, 365, 11, 572, 24083, 1321, 11], "temperature": 0.0, "avg_logprob": -0.15909638669755724, "compression_ratio": 1.3764705882352941, "no_speech_prob": 0.0002718998584896326}, {"id": 60, "seek": 34700, "start": 358.0, "end": 361.0, "text": " no these kind of things.", "tokens": [572, 613, 733, 295, 721, 13], "temperature": 0.0, "avg_logprob": -0.15909638669755724, "compression_ratio": 1.3764705882352941, "no_speech_prob": 0.0002718998584896326}, {"id": 61, "seek": 34700, "start": 361.0, "end": 366.0, "text": " Right now, according to the last year developer Sari,", "tokens": [1779, 586, 11, 4650, 281, 264, 1036, 1064, 10754, 318, 3504, 11], "temperature": 0.0, "avg_logprob": -0.15909638669755724, "compression_ratio": 1.3764705882352941, "no_speech_prob": 0.0002718998584896326}, {"id": 62, "seek": 34700, "start": 366.0, "end": 376.0, "text": " the most used IDE is VS Code, then GoLand by JetBrains,", "tokens": [264, 881, 1143, 40930, 307, 25091, 15549, 11, 550, 1037, 43, 474, 538, 28730, 45606, 1292, 11], "temperature": 0.0, "avg_logprob": -0.15909638669755724, "compression_ratio": 1.3764705882352941, "no_speech_prob": 0.0002718998584896326}, {"id": 63, "seek": 37600, "start": 376.0, "end": 382.0, "text": " and then Vim, and sublime text is 1%.", "tokens": [293, 550, 691, 332, 11, 293, 1422, 40941, 2487, 307, 502, 6856], "temperature": 0.0, "avg_logprob": -0.18347053942473038, "compression_ratio": 1.5048543689320388, "no_speech_prob": 0.0005542148137465119}, {"id": 64, "seek": 37600, "start": 382.0, "end": 386.0, "text": " I was saying at the conference that they talked that I will try GoLand", "tokens": [286, 390, 1566, 412, 264, 7586, 300, 436, 2825, 300, 286, 486, 853, 1037, 43, 474], "temperature": 0.0, "avg_logprob": -0.18347053942473038, "compression_ratio": 1.5048543689320388, "no_speech_prob": 0.0005542148137465119}, {"id": 65, "seek": 37600, "start": 386.0, "end": 390.0, "text": " and will tell you about how it is different from VS Code.", "tokens": [293, 486, 980, 291, 466, 577, 309, 307, 819, 490, 25091, 15549, 13], "temperature": 0.0, "avg_logprob": -0.18347053942473038, "compression_ratio": 1.5048543689320388, "no_speech_prob": 0.0005542148137465119}, {"id": 66, "seek": 37600, "start": 390.0, "end": 395.0, "text": " No, still didn't try it, but I think it's good.", "tokens": [883, 11, 920, 994, 380, 853, 309, 11, 457, 286, 519, 309, 311, 665, 13], "temperature": 0.0, "avg_logprob": -0.18347053942473038, "compression_ratio": 1.5048543689320388, "no_speech_prob": 0.0005542148137465119}, {"id": 67, "seek": 37600, "start": 395.0, "end": 400.0, "text": " So these are the answers from the previous years.", "tokens": [407, 613, 366, 264, 6338, 490, 264, 3894, 924, 13], "temperature": 0.0, "avg_logprob": -0.18347053942473038, "compression_ratio": 1.5048543689320388, "no_speech_prob": 0.0005542148137465119}, {"id": 68, "seek": 37600, "start": 400.0, "end": 404.0, "text": " So as you can see, the intention is the same.", "tokens": [407, 382, 291, 393, 536, 11, 264, 7789, 307, 264, 912, 13], "temperature": 0.0, "avg_logprob": -0.18347053942473038, "compression_ratio": 1.5048543689320388, "no_speech_prob": 0.0005542148137465119}, {"id": 69, "seek": 40400, "start": 404.0, "end": 408.0, "text": " So, VS Code on top, and GoLanguage, et cetera, et cetera.", "tokens": [407, 11, 25091, 15549, 322, 1192, 11, 293, 1037, 43, 656, 20473, 11, 1030, 11458, 11, 1030, 11458, 13], "temperature": 0.0, "avg_logprob": -0.2570580920657596, "compression_ratio": 1.462962962962963, "no_speech_prob": 7.107584679033607e-05}, {"id": 70, "seek": 40400, "start": 408.0, "end": 412.0, "text": " GoLand, sorry.", "tokens": [1037, 43, 474, 11, 2597, 13], "temperature": 0.0, "avg_logprob": -0.2570580920657596, "compression_ratio": 1.462962962962963, "no_speech_prob": 7.107584679033607e-05}, {"id": 71, "seek": 40400, "start": 412.0, "end": 417.0, "text": " What I'm using, I'm using VS Code with the official plugin installed.", "tokens": [708, 286, 478, 1228, 11, 286, 478, 1228, 25091, 15549, 365, 264, 4783, 23407, 8899, 13], "temperature": 0.0, "avg_logprob": -0.2570580920657596, "compression_ratio": 1.462962962962963, "no_speech_prob": 7.107584679033607e-05}, {"id": 72, "seek": 40400, "start": 417.0, "end": 423.0, "text": " Then I'm using the tipwars command line utility", "tokens": [1396, 286, 478, 1228, 264, 4125, 86, 685, 5622, 1622, 14877], "temperature": 0.0, "avg_logprob": -0.2570580920657596, "compression_ratio": 1.462962962962963, "no_speech_prob": 7.107584679033607e-05}, {"id": 73, "seek": 40400, "start": 423.0, "end": 430.0, "text": " to make these fancy tables out of test output.", "tokens": [281, 652, 613, 10247, 8020, 484, 295, 1500, 5598, 13], "temperature": 0.0, "avg_logprob": -0.2570580920657596, "compression_ratio": 1.462962962962963, "no_speech_prob": 7.107584679033607e-05}, {"id": 74, "seek": 43000, "start": 430.0, "end": 434.0, "text": " Linter, of course, tip nine.", "tokens": [441, 5106, 11, 295, 1164, 11, 4125, 4949, 13], "temperature": 0.0, "avg_logprob": -0.1829790971717056, "compression_ratio": 1.4205128205128206, "no_speech_prob": 0.00029333942802622914}, {"id": 75, "seek": 43000, "start": 434.0, "end": 437.0, "text": " I tried GitLab co-pilot.", "tokens": [286, 3031, 16939, 37880, 598, 12, 79, 31516, 13], "temperature": 0.0, "avg_logprob": -0.1829790971717056, "compression_ratio": 1.4205128205128206, "no_speech_prob": 0.00029333942802622914}, {"id": 76, "seek": 43000, "start": 437.0, "end": 441.0, "text": " It's not bad, but I don't want to spend my money on this.", "tokens": [467, 311, 406, 1578, 11, 457, 286, 500, 380, 528, 281, 3496, 452, 1460, 322, 341, 13], "temperature": 0.0, "avg_logprob": -0.1829790971717056, "compression_ratio": 1.4205128205128206, "no_speech_prob": 0.00029333942802622914}, {"id": 77, "seek": 43000, "start": 441.0, "end": 444.0, "text": " I have my own head, you know.", "tokens": [286, 362, 452, 1065, 1378, 11, 291, 458, 13], "temperature": 0.0, "avg_logprob": -0.1829790971717056, "compression_ratio": 1.4205128205128206, "no_speech_prob": 0.00029333942802622914}, {"id": 78, "seek": 43000, "start": 444.0, "end": 451.0, "text": " GoReleaser to produce the packages and binaries like in one go.", "tokens": [1037, 8524, 306, 17756, 281, 5258, 264, 17401, 293, 5171, 4889, 411, 294, 472, 352, 13], "temperature": 0.0, "avg_logprob": -0.1829790971717056, "compression_ratio": 1.4205128205128206, "no_speech_prob": 0.00029333942802622914}, {"id": 79, "seek": 43000, "start": 451.0, "end": 454.0, "text": " Then PostgreSQL, of course.", "tokens": [1396, 10223, 33248, 39934, 11, 295, 1164, 13], "temperature": 0.0, "avg_logprob": -0.1829790971717056, "compression_ratio": 1.4205128205128206, "no_speech_prob": 0.00029333942802622914}, {"id": 80, "seek": 43000, "start": 454.0, "end": 457.0, "text": " And the last, but not least, the Gitpod.io,", "tokens": [400, 264, 1036, 11, 457, 406, 1935, 11, 264, 16939, 43388, 13, 1004, 11], "temperature": 0.0, "avg_logprob": -0.1829790971717056, "compression_ratio": 1.4205128205128206, "no_speech_prob": 0.00029333942802622914}, {"id": 81, "seek": 45700, "start": 457.0, "end": 462.0, "text": " which is pretty much the same thing as a Git Hub workspace,", "tokens": [597, 307, 1238, 709, 264, 912, 551, 382, 257, 16939, 18986, 32706, 11], "temperature": 0.0, "avg_logprob": -0.09157547583946815, "compression_ratio": 1.6097560975609757, "no_speech_prob": 0.00033053691731765866}, {"id": 82, "seek": 45700, "start": 462.0, "end": 465.0, "text": " but it's free for open source developers.", "tokens": [457, 309, 311, 1737, 337, 1269, 4009, 8849, 13], "temperature": 0.0, "avg_logprob": -0.09157547583946815, "compression_ratio": 1.6097560975609757, "no_speech_prob": 0.00033053691731765866}, {"id": 83, "seek": 45700, "start": 465.0, "end": 468.0, "text": " So it's good if you want to try something new", "tokens": [407, 309, 311, 665, 498, 291, 528, 281, 853, 746, 777], "temperature": 0.0, "avg_logprob": -0.09157547583946815, "compression_ratio": 1.6097560975609757, "no_speech_prob": 0.00033053691731765866}, {"id": 84, "seek": 45700, "start": 468.0, "end": 471.0, "text": " and you don't want to install everything on your machine", "tokens": [293, 291, 500, 380, 528, 281, 3625, 1203, 322, 428, 3479], "temperature": 0.0, "avg_logprob": -0.09157547583946815, "compression_ratio": 1.6097560975609757, "no_speech_prob": 0.00033053691731765866}, {"id": 85, "seek": 45700, "start": 471.0, "end": 474.0, "text": " or to set up the virtual machine.", "tokens": [420, 281, 992, 493, 264, 6374, 3479, 13], "temperature": 0.0, "avg_logprob": -0.09157547583946815, "compression_ratio": 1.6097560975609757, "no_speech_prob": 0.00033053691731765866}, {"id": 86, "seek": 45700, "start": 474.0, "end": 478.0, "text": " You can go there, run it in your browser,", "tokens": [509, 393, 352, 456, 11, 1190, 309, 294, 428, 11185, 11], "temperature": 0.0, "avg_logprob": -0.09157547583946815, "compression_ratio": 1.6097560975609757, "no_speech_prob": 0.00033053691731765866}, {"id": 87, "seek": 45700, "start": 478.0, "end": 482.0, "text": " drink a beer on the beach, and try something new.", "tokens": [2822, 257, 8795, 322, 264, 7534, 11, 293, 853, 746, 777, 13], "temperature": 0.0, "avg_logprob": -0.09157547583946815, "compression_ratio": 1.6097560975609757, "no_speech_prob": 0.00033053691731765866}, {"id": 88, "seek": 48200, "start": 482.0, "end": 487.0, "text": " It's okay. If you're done, you just close your browser,", "tokens": [467, 311, 1392, 13, 759, 291, 434, 1096, 11, 291, 445, 1998, 428, 11185, 11], "temperature": 0.0, "avg_logprob": -0.1204109693828382, "compression_ratio": 1.5562130177514792, "no_speech_prob": 0.0003160459455102682}, {"id": 89, "seek": 48200, "start": 487.0, "end": 490.0, "text": " close your tab, and it's gone.", "tokens": [1998, 428, 4421, 11, 293, 309, 311, 2780, 13], "temperature": 0.0, "avg_logprob": -0.1204109693828382, "compression_ratio": 1.5562130177514792, "no_speech_prob": 0.0003160459455102682}, {"id": 90, "seek": 48200, "start": 490.0, "end": 498.0, "text": " Now, about drivers, about the PostgreSQL part of this talk.", "tokens": [823, 11, 466, 11590, 11, 466, 264, 10223, 33248, 39934, 644, 295, 341, 751, 13], "temperature": 0.0, "avg_logprob": -0.1204109693828382, "compression_ratio": 1.5562130177514792, "no_speech_prob": 0.0003160459455102682}, {"id": 91, "seek": 48200, "start": 498.0, "end": 505.0, "text": " The whole idea of this talk started after I tried to find", "tokens": [440, 1379, 1558, 295, 341, 751, 1409, 934, 286, 3031, 281, 915], "temperature": 0.0, "avg_logprob": -0.1204109693828382, "compression_ratio": 1.5562130177514792, "no_speech_prob": 0.0003160459455102682}, {"id": 92, "seek": 48200, "start": 505.0, "end": 510.0, "text": " good tutorials about how to start to work with PostgreSQL.", "tokens": [665, 17616, 466, 577, 281, 722, 281, 589, 365, 10223, 33248, 39934, 13], "temperature": 0.0, "avg_logprob": -0.1204109693828382, "compression_ratio": 1.5562130177514792, "no_speech_prob": 0.0003160459455102682}, {"id": 93, "seek": 51000, "start": 510.0, "end": 514.0, "text": " A lot of them, not all of them, but a lot of them say,", "tokens": [316, 688, 295, 552, 11, 406, 439, 295, 552, 11, 457, 257, 688, 295, 552, 584, 11], "temperature": 0.0, "avg_logprob": -0.1201663729788243, "compression_ratio": 1.4970059880239521, "no_speech_prob": 0.00025946073583327234}, {"id": 94, "seek": 51000, "start": 514.0, "end": 519.0, "text": " okay, just use ORM and you're fine.", "tokens": [1392, 11, 445, 764, 19654, 44, 293, 291, 434, 2489, 13], "temperature": 0.0, "avg_logprob": -0.1201663729788243, "compression_ratio": 1.4970059880239521, "no_speech_prob": 0.00025946073583327234}, {"id": 95, "seek": 51000, "start": 519.0, "end": 522.0, "text": " Well, why?", "tokens": [1042, 11, 983, 30], "temperature": 0.0, "avg_logprob": -0.1201663729788243, "compression_ratio": 1.4970059880239521, "no_speech_prob": 0.00025946073583327234}, {"id": 96, "seek": 51000, "start": 522.0, "end": 526.0, "text": " If I need to create utility to use three commands,", "tokens": [759, 286, 643, 281, 1884, 14877, 281, 764, 1045, 16901, 11], "temperature": 0.0, "avg_logprob": -0.1201663729788243, "compression_ratio": 1.4970059880239521, "no_speech_prob": 0.00025946073583327234}, {"id": 97, "seek": 51000, "start": 526.0, "end": 530.0, "text": " why should I use ORM?", "tokens": [983, 820, 286, 764, 19654, 44, 30], "temperature": 0.0, "avg_logprob": -0.1201663729788243, "compression_ratio": 1.4970059880239521, "no_speech_prob": 0.00025946073583327234}, {"id": 98, "seek": 51000, "start": 530.0, "end": 532.0, "text": " And yeah, don't get me wrong.", "tokens": [400, 1338, 11, 500, 380, 483, 385, 2085, 13], "temperature": 0.0, "avg_logprob": -0.1201663729788243, "compression_ratio": 1.4970059880239521, "no_speech_prob": 0.00025946073583327234}, {"id": 99, "seek": 51000, "start": 532.0, "end": 537.0, "text": " ORMs are fine if you know what you are doing.", "tokens": [19654, 26386, 366, 2489, 498, 291, 458, 437, 291, 366, 884, 13], "temperature": 0.0, "avg_logprob": -0.1201663729788243, "compression_ratio": 1.4970059880239521, "no_speech_prob": 0.00025946073583327234}, {"id": 100, "seek": 53700, "start": 537.0, "end": 546.0, "text": " They solve the problems, but you don't need to put it everywhere", "tokens": [814, 5039, 264, 2740, 11, 457, 291, 500, 380, 643, 281, 829, 309, 5315], "temperature": 0.0, "avg_logprob": -0.08817156807321017, "compression_ratio": 1.3806451612903226, "no_speech_prob": 0.00024437104002572596}, {"id": 101, "seek": 53700, "start": 546.0, "end": 549.0, "text": " and you don't need to start from it", "tokens": [293, 291, 500, 380, 643, 281, 722, 490, 309], "temperature": 0.0, "avg_logprob": -0.08817156807321017, "compression_ratio": 1.3806451612903226, "no_speech_prob": 0.00024437104002572596}, {"id": 102, "seek": 53700, "start": 549.0, "end": 552.0, "text": " because otherwise you will be learning ORM", "tokens": [570, 5911, 291, 486, 312, 2539, 19654, 44], "temperature": 0.0, "avg_logprob": -0.08817156807321017, "compression_ratio": 1.3806451612903226, "no_speech_prob": 0.00024437104002572596}, {"id": 103, "seek": 53700, "start": 552.0, "end": 557.0, "text": " but not learning PostgreSQL itself, right?", "tokens": [457, 406, 2539, 10223, 33248, 39934, 2564, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.08817156807321017, "compression_ratio": 1.3806451612903226, "no_speech_prob": 0.00024437104002572596}, {"id": 104, "seek": 53700, "start": 557.0, "end": 562.0, "text": " Yeah. We have SQL for that.", "tokens": [865, 13, 492, 362, 19200, 337, 300, 13], "temperature": 0.0, "avg_logprob": -0.08817156807321017, "compression_ratio": 1.3806451612903226, "no_speech_prob": 0.00024437104002572596}, {"id": 105, "seek": 56200, "start": 562.0, "end": 568.0, "text": " So, during this talk, I will not be explaining ORMs", "tokens": [407, 11, 1830, 341, 751, 11, 286, 486, 406, 312, 13468, 19654, 26386], "temperature": 0.0, "avg_logprob": -0.1341745802696715, "compression_ratio": 1.5025125628140703, "no_speech_prob": 0.00011977927351836115}, {"id": 106, "seek": 56200, "start": 568.0, "end": 570.0, "text": " on how to work with that.", "tokens": [322, 577, 281, 589, 365, 300, 13], "temperature": 0.0, "avg_logprob": -0.1341745802696715, "compression_ratio": 1.5025125628140703, "no_speech_prob": 0.00011977927351836115}, {"id": 107, "seek": 56200, "start": 570.0, "end": 572.0, "text": " I will explain the basic drivers.", "tokens": [286, 486, 2903, 264, 3875, 11590, 13], "temperature": 0.0, "avg_logprob": -0.1341745802696715, "compression_ratio": 1.5025125628140703, "no_speech_prob": 0.00011977927351836115}, {"id": 108, "seek": 56200, "start": 572.0, "end": 576.0, "text": " Anyway, ORMs are using drivers on the low level", "tokens": [5684, 11, 19654, 26386, 366, 1228, 11590, 322, 264, 2295, 1496], "temperature": 0.0, "avg_logprob": -0.1341745802696715, "compression_ratio": 1.5025125628140703, "no_speech_prob": 0.00011977927351836115}, {"id": 109, "seek": 56200, "start": 576.0, "end": 578.0, "text": " to speak to the PostgreSQL, right?", "tokens": [281, 1710, 281, 264, 10223, 33248, 39934, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.1341745802696715, "compression_ratio": 1.5025125628140703, "no_speech_prob": 0.00011977927351836115}, {"id": 110, "seek": 56200, "start": 578.0, "end": 582.0, "text": " So, we should know how to use them.", "tokens": [407, 11, 321, 820, 458, 577, 281, 764, 552, 13], "temperature": 0.0, "avg_logprob": -0.1341745802696715, "compression_ratio": 1.5025125628140703, "no_speech_prob": 0.00011977927351836115}, {"id": 111, "seek": 56200, "start": 582.0, "end": 586.0, "text": " So, the thing is, in Go,", "tokens": [407, 11, 264, 551, 307, 11, 294, 1037, 11], "temperature": 0.0, "avg_logprob": -0.1341745802696715, "compression_ratio": 1.5025125628140703, "no_speech_prob": 0.00011977927351836115}, {"id": 112, "seek": 56200, "start": 586.0, "end": 590.0, "text": " that we have these databases QL interfaces.", "tokens": [300, 321, 362, 613, 22380, 1249, 43, 28416, 13], "temperature": 0.0, "avg_logprob": -0.1341745802696715, "compression_ratio": 1.5025125628140703, "no_speech_prob": 0.00011977927351836115}, {"id": 113, "seek": 59000, "start": 590.0, "end": 593.0, "text": " Interfaces is just like an agreement", "tokens": [5751, 69, 2116, 307, 445, 411, 364, 8106], "temperature": 0.0, "avg_logprob": -0.1606349687318544, "compression_ratio": 1.5157894736842106, "no_speech_prob": 0.00018465651373844594}, {"id": 114, "seek": 59000, "start": 593.0, "end": 598.0, "text": " on what methods are available from, I don't know,", "tokens": [322, 437, 7150, 366, 2435, 490, 11, 286, 500, 380, 458, 11], "temperature": 0.0, "avg_logprob": -0.1606349687318544, "compression_ratio": 1.5157894736842106, "no_speech_prob": 0.00018465651373844594}, {"id": 115, "seek": 59000, "start": 598.0, "end": 601.0, "text": " from object, from structure, or whatever.", "tokens": [490, 2657, 11, 490, 3877, 11, 420, 2035, 13], "temperature": 0.0, "avg_logprob": -0.1606349687318544, "compression_ratio": 1.5157894736842106, "no_speech_prob": 0.00018465651373844594}, {"id": 116, "seek": 59000, "start": 601.0, "end": 609.0, "text": " And for each database, there should be a special driver,", "tokens": [400, 337, 1184, 8149, 11, 456, 820, 312, 257, 2121, 6787, 11], "temperature": 0.0, "avg_logprob": -0.1606349687318544, "compression_ratio": 1.5157894736842106, "no_speech_prob": 0.00018465651373844594}, {"id": 117, "seek": 59000, "start": 609.0, "end": 612.0, "text": " an implementation for these interface, right?", "tokens": [364, 11420, 337, 613, 9226, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.1606349687318544, "compression_ratio": 1.5157894736842106, "no_speech_prob": 0.00018465651373844594}, {"id": 118, "seek": 59000, "start": 612.0, "end": 617.0, "text": " So, the first official implementation for the PostgreSQL", "tokens": [407, 11, 264, 700, 4783, 11420, 337, 264, 10223, 33248, 39934], "temperature": 0.0, "avg_logprob": -0.1606349687318544, "compression_ratio": 1.5157894736842106, "no_speech_prob": 0.00018465651373844594}, {"id": 119, "seek": 61700, "start": 617.0, "end": 623.0, "text": " in the Go world was Leap2Q.", "tokens": [294, 264, 1037, 1002, 390, 1456, 569, 17, 48, 13], "temperature": 0.0, "avg_logprob": -0.14142566257052952, "compression_ratio": 1.4972972972972973, "no_speech_prob": 4.3001673475373536e-05}, {"id": 120, "seek": 61700, "start": 623.0, "end": 626.0, "text": " It's good. It's proven.", "tokens": [467, 311, 665, 13, 467, 311, 12785, 13], "temperature": 0.0, "avg_logprob": -0.14142566257052952, "compression_ratio": 1.4972972972972973, "no_speech_prob": 4.3001673475373536e-05}, {"id": 121, "seek": 61700, "start": 626.0, "end": 629.0, "text": " It's a long time on the market,", "tokens": [467, 311, 257, 938, 565, 322, 264, 2142, 11], "temperature": 0.0, "avg_logprob": -0.14142566257052952, "compression_ratio": 1.4972972972972973, "no_speech_prob": 4.3001673475373536e-05}, {"id": 122, "seek": 61700, "start": 629.0, "end": 634.0, "text": " but it is in maintenance mode right now for two years, probably.", "tokens": [457, 309, 307, 294, 11258, 4391, 558, 586, 337, 732, 924, 11, 1391, 13], "temperature": 0.0, "avg_logprob": -0.14142566257052952, "compression_ratio": 1.4972972972972973, "no_speech_prob": 4.3001673475373536e-05}, {"id": 123, "seek": 61700, "start": 634.0, "end": 636.0, "text": " It's not bad. It's okay.", "tokens": [467, 311, 406, 1578, 13, 467, 311, 1392, 13], "temperature": 0.0, "avg_logprob": -0.14142566257052952, "compression_ratio": 1.4972972972972973, "no_speech_prob": 4.3001673475373536e-05}, {"id": 124, "seek": 61700, "start": 636.0, "end": 641.0, "text": " You can be sure that this functionality is solid,", "tokens": [509, 393, 312, 988, 300, 341, 14980, 307, 5100, 11], "temperature": 0.0, "avg_logprob": -0.14142566257052952, "compression_ratio": 1.4972972972972973, "no_speech_prob": 4.3001673475373536e-05}, {"id": 125, "seek": 61700, "start": 641.0, "end": 646.0, "text": " but if you want more, and if you start a new project,", "tokens": [457, 498, 291, 528, 544, 11, 293, 498, 291, 722, 257, 777, 1716, 11], "temperature": 0.0, "avg_logprob": -0.14142566257052952, "compression_ratio": 1.4972972972972973, "no_speech_prob": 4.3001673475373536e-05}, {"id": 126, "seek": 64600, "start": 646.0, "end": 650.0, "text": " JXC-PGX is the way to go,", "tokens": [508, 55, 34, 12, 47, 38, 55, 307, 264, 636, 281, 352, 11], "temperature": 0.0, "avg_logprob": -0.19014458323633948, "compression_ratio": 1.391304347826087, "no_speech_prob": 0.00013828735973220319}, {"id": 127, "seek": 64600, "start": 650.0, "end": 657.0, "text": " because you can use it with whatever you want.", "tokens": [570, 291, 393, 764, 309, 365, 2035, 291, 528, 13], "temperature": 0.0, "avg_logprob": -0.19014458323633948, "compression_ratio": 1.391304347826087, "no_speech_prob": 0.00013828735973220319}, {"id": 128, "seek": 64600, "start": 657.0, "end": 660.0, "text": " I will show you later.", "tokens": [286, 486, 855, 291, 1780, 13], "temperature": 0.0, "avg_logprob": -0.19014458323633948, "compression_ratio": 1.391304347826087, "no_speech_prob": 0.00013828735973220319}, {"id": 129, "seek": 64600, "start": 660.0, "end": 665.0, "text": " So, yeah, we are scientists, and we do graphs.", "tokens": [407, 11, 1338, 11, 321, 366, 7708, 11, 293, 321, 360, 24877, 13], "temperature": 0.0, "avg_logprob": -0.19014458323633948, "compression_ratio": 1.391304347826087, "no_speech_prob": 0.00013828735973220319}, {"id": 130, "seek": 64600, "start": 665.0, "end": 668.0, "text": " So, unlike of Python, or not in Python,", "tokens": [407, 11, 8343, 295, 15329, 11, 420, 406, 294, 15329, 11], "temperature": 0.0, "avg_logprob": -0.19014458323633948, "compression_ratio": 1.391304347826087, "no_speech_prob": 0.00013828735973220319}, {"id": 131, "seek": 64600, "start": 668.0, "end": 671.0, "text": " but NPM, JavaScript work,", "tokens": [457, 426, 18819, 11, 15778, 589, 11], "temperature": 0.0, "avg_logprob": -0.19014458323633948, "compression_ratio": 1.391304347826087, "no_speech_prob": 0.00013828735973220319}, {"id": 132, "seek": 64600, "start": 671.0, "end": 675.0, "text": " we don't have this statistic for how many times", "tokens": [321, 500, 380, 362, 341, 29588, 337, 577, 867, 1413], "temperature": 0.0, "avg_logprob": -0.19014458323633948, "compression_ratio": 1.391304347826087, "no_speech_prob": 0.00013828735973220319}, {"id": 133, "seek": 67500, "start": 675.0, "end": 679.0, "text": " a particular package was downloaded, used, whatever.", "tokens": [257, 1729, 7372, 390, 21748, 11, 1143, 11, 2035, 13], "temperature": 0.0, "avg_logprob": -0.1293178446152631, "compression_ratio": 1.38125, "no_speech_prob": 0.000100745826784987}, {"id": 134, "seek": 67500, "start": 679.0, "end": 684.0, "text": " So, the most funny way is to use GitHub stars", "tokens": [407, 11, 264, 881, 4074, 636, 307, 281, 764, 23331, 6105], "temperature": 0.0, "avg_logprob": -0.1293178446152631, "compression_ratio": 1.38125, "no_speech_prob": 0.000100745826784987}, {"id": 135, "seek": 67500, "start": 684.0, "end": 688.0, "text": " and, yeah, to build this stuff.", "tokens": [293, 11, 1338, 11, 281, 1322, 341, 1507, 13], "temperature": 0.0, "avg_logprob": -0.1293178446152631, "compression_ratio": 1.38125, "no_speech_prob": 0.000100745826784987}, {"id": 136, "seek": 67500, "start": 688.0, "end": 696.0, "text": " So, as you can see, the PGX started one year later,", "tokens": [407, 11, 382, 291, 393, 536, 11, 264, 430, 38, 55, 1409, 472, 1064, 1780, 11], "temperature": 0.0, "avg_logprob": -0.1293178446152631, "compression_ratio": 1.38125, "no_speech_prob": 0.000100745826784987}, {"id": 137, "seek": 67500, "start": 696.0, "end": 700.0, "text": " but now it's going to be very popular.", "tokens": [457, 586, 309, 311, 516, 281, 312, 588, 3743, 13], "temperature": 0.0, "avg_logprob": -0.1293178446152631, "compression_ratio": 1.38125, "no_speech_prob": 0.000100745826784987}, {"id": 138, "seek": 70000, "start": 700.0, "end": 707.0, "text": " So, in 2019-20, there was an announcement", "tokens": [407, 11, 294, 6071, 12, 2009, 11, 456, 390, 364, 12847], "temperature": 0.0, "avg_logprob": -0.20808273706680688, "compression_ratio": 1.4270833333333333, "no_speech_prob": 7.201209518825635e-05}, {"id": 139, "seek": 70000, "start": 707.0, "end": 710.0, "text": " that the LPQ is going to maintain smart,", "tokens": [300, 264, 38095, 48, 307, 516, 281, 6909, 4069, 11], "temperature": 0.0, "avg_logprob": -0.20808273706680688, "compression_ratio": 1.4270833333333333, "no_speech_prob": 7.201209518825635e-05}, {"id": 140, "seek": 70000, "start": 710.0, "end": 714.0, "text": " and the PGX started to grow.", "tokens": [293, 264, 430, 38, 55, 1409, 281, 1852, 13], "temperature": 0.0, "avg_logprob": -0.20808273706680688, "compression_ratio": 1.4270833333333333, "no_speech_prob": 7.201209518825635e-05}, {"id": 141, "seek": 70000, "start": 714.0, "end": 720.0, "text": " So, what if your project is using already databases QL,", "tokens": [407, 11, 437, 498, 428, 1716, 307, 1228, 1217, 22380, 1249, 43, 11], "temperature": 0.0, "avg_logprob": -0.20808273706680688, "compression_ratio": 1.4270833333333333, "no_speech_prob": 7.201209518825635e-05}, {"id": 142, "seek": 70000, "start": 720.0, "end": 724.0, "text": " or you want to follow tutorials or techniques", "tokens": [420, 291, 528, 281, 1524, 17616, 420, 7512], "temperature": 0.0, "avg_logprob": -0.20808273706680688, "compression_ratio": 1.4270833333333333, "no_speech_prob": 7.201209518825635e-05}, {"id": 143, "seek": 70000, "start": 724.0, "end": 729.0, "text": " and to use these databases QL, standard de facto interfaces?", "tokens": [293, 281, 764, 613, 22380, 1249, 43, 11, 3832, 368, 42225, 28416, 30], "temperature": 0.0, "avg_logprob": -0.20808273706680688, "compression_ratio": 1.4270833333333333, "no_speech_prob": 7.201209518825635e-05}, {"id": 144, "seek": 72900, "start": 729.0, "end": 734.0, "text": " For that purpose, PGX has a special wrapper.", "tokens": [1171, 300, 4334, 11, 430, 38, 55, 575, 257, 2121, 46906, 13], "temperature": 0.0, "avg_logprob": -0.08905702829360962, "compression_ratio": 1.4522292993630572, "no_speech_prob": 0.00017245131311938167}, {"id": 145, "seek": 72900, "start": 734.0, "end": 740.0, "text": " So, you can still use databases QL interface,", "tokens": [407, 11, 291, 393, 920, 764, 22380, 1249, 43, 9226, 11], "temperature": 0.0, "avg_logprob": -0.08905702829360962, "compression_ratio": 1.4522292993630572, "no_speech_prob": 0.00017245131311938167}, {"id": 146, "seek": 72900, "start": 740.0, "end": 744.0, "text": " but you can, underneath, on the low level,", "tokens": [457, 291, 393, 11, 7223, 11, 322, 264, 2295, 1496, 11], "temperature": 0.0, "avg_logprob": -0.08905702829360962, "compression_ratio": 1.4522292993630572, "no_speech_prob": 0.00017245131311938167}, {"id": 147, "seek": 72900, "start": 744.0, "end": 750.0, "text": " you will use the PGX package.", "tokens": [291, 486, 764, 264, 430, 38, 55, 7372, 13], "temperature": 0.0, "avg_logprob": -0.08905702829360962, "compression_ratio": 1.4522292993630572, "no_speech_prob": 0.00017245131311938167}, {"id": 148, "seek": 72900, "start": 750.0, "end": 756.0, "text": " So, you should use PGX solely if you are starting a new project,", "tokens": [407, 11, 291, 820, 764, 430, 38, 55, 23309, 498, 291, 366, 2891, 257, 777, 1716, 11], "temperature": 0.0, "avg_logprob": -0.08905702829360962, "compression_ratio": 1.4522292993630572, "no_speech_prob": 0.00017245131311938167}, {"id": 149, "seek": 75600, "start": 756.0, "end": 761.0, "text": " and your project is aiming only POSQS QL.", "tokens": [293, 428, 1716, 307, 20253, 787, 430, 4367, 48, 50, 1249, 43, 13], "temperature": 0.0, "avg_logprob": -0.15333240333644824, "compression_ratio": 1.627906976744186, "no_speech_prob": 0.0007837536977604032}, {"id": 150, "seek": 75600, "start": 761.0, "end": 764.0, "text": " Then you don't need databases QL,", "tokens": [1396, 291, 500, 380, 643, 22380, 1249, 43, 11], "temperature": 0.0, "avg_logprob": -0.15333240333644824, "compression_ratio": 1.627906976744186, "no_speech_prob": 0.0007837536977604032}, {"id": 151, "seek": 75600, "start": 764.0, "end": 767.0, "text": " but if you are dependent on Orm,", "tokens": [457, 498, 291, 366, 12334, 322, 1610, 76, 11], "temperature": 0.0, "avg_logprob": -0.15333240333644824, "compression_ratio": 1.627906976744186, "no_speech_prob": 0.0007837536977604032}, {"id": 152, "seek": 75600, "start": 767.0, "end": 770.0, "text": " or you are dependent on other package", "tokens": [420, 291, 366, 12334, 322, 661, 7372], "temperature": 0.0, "avg_logprob": -0.15333240333644824, "compression_ratio": 1.627906976744186, "no_speech_prob": 0.0007837536977604032}, {"id": 153, "seek": 75600, "start": 770.0, "end": 773.0, "text": " which wants you to use databases QL,", "tokens": [597, 2738, 291, 281, 764, 22380, 1249, 43, 11], "temperature": 0.0, "avg_logprob": -0.15333240333644824, "compression_ratio": 1.627906976744186, "no_speech_prob": 0.0007837536977604032}, {"id": 154, "seek": 75600, "start": 773.0, "end": 777.0, "text": " you go for wrapper.", "tokens": [291, 352, 337, 46906, 13], "temperature": 0.0, "avg_logprob": -0.15333240333644824, "compression_ratio": 1.627906976744186, "no_speech_prob": 0.0007837536977604032}, {"id": 155, "seek": 75600, "start": 777.0, "end": 782.0, "text": " In that case, the dependency will use this wrapper", "tokens": [682, 300, 1389, 11, 264, 33621, 486, 764, 341, 46906], "temperature": 0.0, "avg_logprob": -0.15333240333644824, "compression_ratio": 1.627906976744186, "no_speech_prob": 0.0007837536977604032}, {"id": 156, "seek": 75600, "start": 782.0, "end": 785.0, "text": " to speak to databases QL,", "tokens": [281, 1710, 281, 22380, 1249, 43, 11], "temperature": 0.0, "avg_logprob": -0.15333240333644824, "compression_ratio": 1.627906976744186, "no_speech_prob": 0.0007837536977604032}, {"id": 157, "seek": 78500, "start": 785.0, "end": 790.0, "text": " and you will use the power of PGX.", "tokens": [293, 291, 486, 764, 264, 1347, 295, 430, 38, 55, 13], "temperature": 0.0, "avg_logprob": -0.1087229914135403, "compression_ratio": 1.5359116022099448, "no_speech_prob": 0.00011342507059453055}, {"id": 158, "seek": 78500, "start": 790.0, "end": 793.0, "text": " So, there are a lot of unique features", "tokens": [407, 11, 456, 366, 257, 688, 295, 3845, 4122], "temperature": 0.0, "avg_logprob": -0.1087229914135403, "compression_ratio": 1.5359116022099448, "no_speech_prob": 0.00011342507059453055}, {"id": 159, "seek": 78500, "start": 793.0, "end": 799.0, "text": " that are not implemented in the standard library,", "tokens": [300, 366, 406, 12270, 294, 264, 3832, 6405, 11], "temperature": 0.0, "avg_logprob": -0.1087229914135403, "compression_ratio": 1.5359116022099448, "no_speech_prob": 0.00011342507059453055}, {"id": 160, "seek": 78500, "start": 799.0, "end": 801.0, "text": " and they cannot be implemented", "tokens": [293, 436, 2644, 312, 12270], "temperature": 0.0, "avg_logprob": -0.1087229914135403, "compression_ratio": 1.5359116022099448, "no_speech_prob": 0.00011342507059453055}, {"id": 161, "seek": 78500, "start": 801.0, "end": 806.0, "text": " because this interface is the same for every possible database.", "tokens": [570, 341, 9226, 307, 264, 912, 337, 633, 1944, 8149, 13], "temperature": 0.0, "avg_logprob": -0.1087229914135403, "compression_ratio": 1.5359116022099448, "no_speech_prob": 0.00011342507059453055}, {"id": 162, "seek": 78500, "start": 806.0, "end": 812.0, "text": " So, for example, you cannot add methods with a copy support", "tokens": [407, 11, 337, 1365, 11, 291, 2644, 909, 7150, 365, 257, 5055, 1406], "temperature": 0.0, "avg_logprob": -0.1087229914135403, "compression_ratio": 1.5359116022099448, "no_speech_prob": 0.00011342507059453055}, {"id": 163, "seek": 81200, "start": 812.0, "end": 816.0, "text": " because only POSQS QL do copy support, right?", "tokens": [570, 787, 430, 4367, 48, 50, 1249, 43, 360, 5055, 1406, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.12009089167525129, "compression_ratio": 1.4385026737967914, "no_speech_prob": 0.00016996884369291365}, {"id": 164, "seek": 81200, "start": 816.0, "end": 823.0, "text": " So, the most cool feature is that PGX supports binary", "tokens": [407, 11, 264, 881, 1627, 4111, 307, 300, 430, 38, 55, 9346, 17434], "temperature": 0.0, "avg_logprob": -0.12009089167525129, "compression_ratio": 1.4385026737967914, "no_speech_prob": 0.00016996884369291365}, {"id": 165, "seek": 81200, "start": 823.0, "end": 828.0, "text": " transfer protocol, and it supports natively all built-in", "tokens": [5003, 10336, 11, 293, 309, 9346, 8470, 356, 439, 3094, 12, 259], "temperature": 0.0, "avg_logprob": -0.12009089167525129, "compression_ratio": 1.4385026737967914, "no_speech_prob": 0.00016996884369291365}, {"id": 166, "seek": 81200, "start": 828.0, "end": 830.0, "text": " POSQS types.", "tokens": [430, 4367, 48, 50, 3467, 13], "temperature": 0.0, "avg_logprob": -0.12009089167525129, "compression_ratio": 1.4385026737967914, "no_speech_prob": 0.00016996884369291365}, {"id": 167, "seek": 81200, "start": 830.0, "end": 834.0, "text": " And if you create user types,", "tokens": [400, 498, 291, 1884, 4195, 3467, 11], "temperature": 0.0, "avg_logprob": -0.12009089167525129, "compression_ratio": 1.4385026737967914, "no_speech_prob": 0.00016996884369291365}, {"id": 168, "seek": 81200, "start": 834.0, "end": 838.0, "text": " it will support them out of the box", "tokens": [309, 486, 1406, 552, 484, 295, 264, 2424], "temperature": 0.0, "avg_logprob": -0.12009089167525129, "compression_ratio": 1.4385026737967914, "no_speech_prob": 0.00016996884369291365}, {"id": 169, "seek": 81200, "start": 838.0, "end": 840.0, "text": " unless they are very complicated.", "tokens": [5969, 436, 366, 588, 6179, 13], "temperature": 0.0, "avg_logprob": -0.12009089167525129, "compression_ratio": 1.4385026737967914, "no_speech_prob": 0.00016996884369291365}, {"id": 170, "seek": 84000, "start": 840.0, "end": 843.0, "text": " But even in that case, you can create a special interface", "tokens": [583, 754, 294, 300, 1389, 11, 291, 393, 1884, 257, 2121, 9226], "temperature": 0.0, "avg_logprob": -0.13347727060317993, "compression_ratio": 1.4728260869565217, "no_speech_prob": 0.00014474887575488538}, {"id": 171, "seek": 84000, "start": 843.0, "end": 848.0, "text": " or a special object structure", "tokens": [420, 257, 2121, 2657, 3877], "temperature": 0.0, "avg_logprob": -0.13347727060317993, "compression_ratio": 1.4728260869565217, "no_speech_prob": 0.00014474887575488538}, {"id": 172, "seek": 84000, "start": 848.0, "end": 853.0, "text": " that will tell PGX how to encode, decode the developers", "tokens": [300, 486, 980, 430, 38, 55, 577, 281, 2058, 1429, 11, 979, 1429, 264, 8849], "temperature": 0.0, "avg_logprob": -0.13347727060317993, "compression_ratio": 1.4728260869565217, "no_speech_prob": 0.00014474887575488538}, {"id": 173, "seek": 84000, "start": 853.0, "end": 855.0, "text": " of your types.", "tokens": [295, 428, 3467, 13], "temperature": 0.0, "avg_logprob": -0.13347727060317993, "compression_ratio": 1.4728260869565217, "no_speech_prob": 0.00014474887575488538}, {"id": 174, "seek": 84000, "start": 855.0, "end": 861.0, "text": " So, as I said, yeah, copy protocol, logging,", "tokens": [407, 11, 382, 286, 848, 11, 1338, 11, 5055, 10336, 11, 27991, 11], "temperature": 0.0, "avg_logprob": -0.13347727060317993, "compression_ratio": 1.4728260869565217, "no_speech_prob": 0.00014474887575488538}, {"id": 175, "seek": 84000, "start": 861.0, "end": 863.0, "text": " yeah, and for connection pooling,", "tokens": [1338, 11, 293, 337, 4984, 7005, 278, 11], "temperature": 0.0, "avg_logprob": -0.13347727060317993, "compression_ratio": 1.4728260869565217, "no_speech_prob": 0.00014474887575488538}, {"id": 176, "seek": 84000, "start": 863.0, "end": 866.0, "text": " you have this after connect hook.", "tokens": [291, 362, 341, 934, 1745, 6328, 13], "temperature": 0.0, "avg_logprob": -0.13347727060317993, "compression_ratio": 1.4728260869565217, "no_speech_prob": 0.00014474887575488538}, {"id": 177, "seek": 86600, "start": 866.0, "end": 871.0, "text": " So, the idea in girl language is that the database object", "tokens": [407, 11, 264, 1558, 294, 2013, 2856, 307, 300, 264, 8149, 2657], "temperature": 0.0, "avg_logprob": -0.10394647386338976, "compression_ratio": 1.645320197044335, "no_speech_prob": 0.00020855000184383243}, {"id": 178, "seek": 86600, "start": 871.0, "end": 875.0, "text": " that you have is pooled by default.", "tokens": [300, 291, 362, 307, 7005, 292, 538, 7576, 13], "temperature": 0.0, "avg_logprob": -0.10394647386338976, "compression_ratio": 1.645320197044335, "no_speech_prob": 0.00020855000184383243}, {"id": 179, "seek": 86600, "start": 875.0, "end": 879.0, "text": " So, it can create additional connections,", "tokens": [407, 11, 309, 393, 1884, 4497, 9271, 11], "temperature": 0.0, "avg_logprob": -0.10394647386338976, "compression_ratio": 1.645320197044335, "no_speech_prob": 0.00020855000184383243}, {"id": 180, "seek": 86600, "start": 879.0, "end": 881.0, "text": " and you never know how many active...", "tokens": [293, 291, 1128, 458, 577, 867, 4967, 485], "temperature": 0.0, "avg_logprob": -0.10394647386338976, "compression_ratio": 1.645320197044335, "no_speech_prob": 0.00020855000184383243}, {"id": 181, "seek": 86600, "start": 881.0, "end": 885.0, "text": " Well, you can know, but you can never tell", "tokens": [1042, 11, 291, 393, 458, 11, 457, 291, 393, 1128, 980], "temperature": 0.0, "avg_logprob": -0.10394647386338976, "compression_ratio": 1.645320197044335, "no_speech_prob": 0.00020855000184383243}, {"id": 182, "seek": 86600, "start": 885.0, "end": 887.0, "text": " how many connections you have right now.", "tokens": [577, 867, 9271, 291, 362, 558, 586, 13], "temperature": 0.0, "avg_logprob": -0.10394647386338976, "compression_ratio": 1.645320197044335, "no_speech_prob": 0.00020855000184383243}, {"id": 183, "seek": 86600, "start": 887.0, "end": 890.0, "text": " And this, for example, after connect hook", "tokens": [400, 341, 11, 337, 1365, 11, 934, 1745, 6328], "temperature": 0.0, "avg_logprob": -0.10394647386338976, "compression_ratio": 1.645320197044335, "no_speech_prob": 0.00020855000184383243}, {"id": 184, "seek": 86600, "start": 890.0, "end": 893.0, "text": " helps you to prepare your session,", "tokens": [3665, 291, 281, 5940, 428, 5481, 11], "temperature": 0.0, "avg_logprob": -0.10394647386338976, "compression_ratio": 1.645320197044335, "no_speech_prob": 0.00020855000184383243}, {"id": 185, "seek": 89300, "start": 893.0, "end": 896.0, "text": " prepare your new open connection for something,", "tokens": [5940, 428, 777, 1269, 4984, 337, 746, 11], "temperature": 0.0, "avg_logprob": -0.21688634957840194, "compression_ratio": 1.3641618497109826, "no_speech_prob": 0.00015522143803536892}, {"id": 186, "seek": 89300, "start": 896.0, "end": 900.0, "text": " like add some identifier, login, or whatever.", "tokens": [411, 909, 512, 45690, 11, 24276, 11, 420, 2035, 13], "temperature": 0.0, "avg_logprob": -0.21688634957840194, "compression_ratio": 1.3641618497109826, "no_speech_prob": 0.00015522143803536892}, {"id": 187, "seek": 89300, "start": 900.0, "end": 908.0, "text": " Yeah, listen.notify is implemented natively.", "tokens": [865, 11, 2140, 13, 2247, 2505, 307, 12270, 8470, 356, 13], "temperature": 0.0, "avg_logprob": -0.21688634957840194, "compression_ratio": 1.3641618497109826, "no_speech_prob": 0.00015522143803536892}, {"id": 188, "seek": 89300, "start": 908.0, "end": 910.0, "text": " What else?", "tokens": [708, 1646, 30], "temperature": 0.0, "avg_logprob": -0.21688634957840194, "compression_ratio": 1.3641618497109826, "no_speech_prob": 0.00015522143803536892}, {"id": 189, "seek": 89300, "start": 910.0, "end": 915.0, "text": " Yeah, different JSON, HStore, large objects.", "tokens": [865, 11, 819, 31828, 11, 389, 4520, 418, 11, 2416, 6565, 13], "temperature": 0.0, "avg_logprob": -0.21688634957840194, "compression_ratio": 1.3641618497109826, "no_speech_prob": 0.00015522143803536892}, {"id": 190, "seek": 89300, "start": 915.0, "end": 919.0, "text": " So, everything you need is already there.", "tokens": [407, 11, 1203, 291, 643, 307, 1217, 456, 13], "temperature": 0.0, "avg_logprob": -0.21688634957840194, "compression_ratio": 1.3641618497109826, "no_speech_prob": 0.00015522143803536892}, {"id": 191, "seek": 91900, "start": 919.0, "end": 926.0, "text": " Nice thing about PGX is in December,", "tokens": [5490, 551, 466, 430, 38, 55, 307, 294, 7687, 11], "temperature": 0.0, "avg_logprob": -0.1715595765547319, "compression_ratio": 1.2746478873239437, "no_speech_prob": 0.0003273268521297723}, {"id": 192, "seek": 91900, "start": 926.0, "end": 934.0, "text": " probably the new major version 5 release was...", "tokens": [1391, 264, 777, 2563, 3037, 1025, 4374, 390, 485], "temperature": 0.0, "avg_logprob": -0.1715595765547319, "compression_ratio": 1.2746478873239437, "no_speech_prob": 0.0003273268521297723}, {"id": 193, "seek": 91900, "start": 934.0, "end": 938.0, "text": " And it was a huge step forward,", "tokens": [400, 309, 390, 257, 2603, 1823, 2128, 11], "temperature": 0.0, "avg_logprob": -0.1715595765547319, "compression_ratio": 1.2746478873239437, "no_speech_prob": 0.0003273268521297723}, {"id": 194, "seek": 91900, "start": 938.0, "end": 942.0, "text": " especially in the term of dependencies.", "tokens": [2318, 294, 264, 1433, 295, 36606, 13], "temperature": 0.0, "avg_logprob": -0.1715595765547319, "compression_ratio": 1.2746478873239437, "no_speech_prob": 0.0003273268521297723}, {"id": 195, "seek": 91900, "start": 942.0, "end": 947.0, "text": " v4, version 4, was good,", "tokens": [371, 19, 11, 3037, 1017, 11, 390, 665, 11], "temperature": 0.0, "avg_logprob": -0.1715595765547319, "compression_ratio": 1.2746478873239437, "no_speech_prob": 0.0003273268521297723}, {"id": 196, "seek": 94700, "start": 947.0, "end": 951.0, "text": " but it has so many external dependencies", "tokens": [457, 309, 575, 370, 867, 8320, 36606], "temperature": 0.0, "avg_logprob": -0.11196980365487032, "compression_ratio": 1.4439024390243902, "no_speech_prob": 0.0008979131234809756}, {"id": 197, "seek": 94700, "start": 951.0, "end": 954.0, "text": " that, for example, Magnus Agander said,", "tokens": [300, 11, 337, 1365, 11, 19664, 301, 2725, 4483, 848, 11], "temperature": 0.0, "avg_logprob": -0.11196980365487032, "compression_ratio": 1.4439024390243902, "no_speech_prob": 0.0008979131234809756}, {"id": 198, "seek": 94700, "start": 954.0, "end": 959.0, "text": " no, we will not rewrite our internal tool into PGX", "tokens": [572, 11, 321, 486, 406, 28132, 527, 6920, 2290, 666, 430, 38, 55], "temperature": 0.0, "avg_logprob": -0.11196980365487032, "compression_ratio": 1.4439024390243902, "no_speech_prob": 0.0008979131234809756}, {"id": 199, "seek": 94700, "start": 959.0, "end": 963.0, "text": " because it's too much dependencies.", "tokens": [570, 309, 311, 886, 709, 36606, 13], "temperature": 0.0, "avg_logprob": -0.11196980365487032, "compression_ratio": 1.4439024390243902, "no_speech_prob": 0.0008979131234809756}, {"id": 200, "seek": 94700, "start": 963.0, "end": 967.0, "text": " It's not the thing anymore, and it's very cool.", "tokens": [467, 311, 406, 264, 551, 3602, 11, 293, 309, 311, 588, 1627, 13], "temperature": 0.0, "avg_logprob": -0.11196980365487032, "compression_ratio": 1.4439024390243902, "no_speech_prob": 0.0008979131234809756}, {"id": 201, "seek": 94700, "start": 967.0, "end": 970.0, "text": " So, yeah, hello world.", "tokens": [407, 11, 1338, 11, 7751, 1002, 13], "temperature": 0.0, "avg_logprob": -0.11196980365487032, "compression_ratio": 1.4439024390243902, "no_speech_prob": 0.0008979131234809756}, {"id": 202, "seek": 94700, "start": 970.0, "end": 976.0, "text": " You probably all know how to write it in the database SQL", "tokens": [509, 1391, 439, 458, 577, 281, 2464, 309, 294, 264, 8149, 19200], "temperature": 0.0, "avg_logprob": -0.11196980365487032, "compression_ratio": 1.4439024390243902, "no_speech_prob": 0.0008979131234809756}, {"id": 203, "seek": 97600, "start": 976.0, "end": 984.0, "text": " interface, so you're just using that import package,", "tokens": [9226, 11, 370, 291, 434, 445, 1228, 300, 974, 7372, 11], "temperature": 0.0, "avg_logprob": -0.24327339759239783, "compression_ratio": 1.381578947368421, "no_speech_prob": 0.00028874853160232306}, {"id": 204, "seek": 97600, "start": 984.0, "end": 988.0, "text": " but instead of using libpq,", "tokens": [457, 2602, 295, 1228, 22854, 79, 80, 11], "temperature": 0.0, "avg_logprob": -0.24327339759239783, "compression_ratio": 1.381578947368421, "no_speech_prob": 0.00028874853160232306}, {"id": 205, "seek": 97600, "start": 988.0, "end": 992.0, "text": " you are specifying PGX as the libp,", "tokens": [291, 366, 1608, 5489, 430, 38, 55, 382, 264, 22854, 79, 11], "temperature": 0.0, "avg_logprob": -0.24327339759239783, "compression_ratio": 1.381578947368421, "no_speech_prob": 0.00028874853160232306}, {"id": 206, "seek": 97600, "start": 992.0, "end": 996.0, "text": " which is a wrapper for the standard library.", "tokens": [597, 307, 257, 46906, 337, 264, 3832, 6405, 13], "temperature": 0.0, "avg_logprob": -0.24327339759239783, "compression_ratio": 1.381578947368421, "no_speech_prob": 0.00028874853160232306}, {"id": 207, "seek": 97600, "start": 996.0, "end": 999.0, "text": " And then all things are the same.", "tokens": [400, 550, 439, 721, 366, 264, 912, 13], "temperature": 0.0, "avg_logprob": -0.24327339759239783, "compression_ratio": 1.381578947368421, "no_speech_prob": 0.00028874853160232306}, {"id": 208, "seek": 97600, "start": 999.0, "end": 1001.0, "text": " No difference.", "tokens": [883, 2649, 13], "temperature": 0.0, "avg_logprob": -0.24327339759239783, "compression_ratio": 1.381578947368421, "no_speech_prob": 0.00028874853160232306}, {"id": 209, "seek": 100100, "start": 1001.0, "end": 1006.0, "text": " So, if you want to update your project,", "tokens": [407, 11, 498, 291, 528, 281, 5623, 428, 1716, 11], "temperature": 0.0, "avg_logprob": -0.16150620617444003, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.00016630900790914893}, {"id": 210, "seek": 100100, "start": 1006.0, "end": 1009.0, "text": " you just change the import part,", "tokens": [291, 445, 1319, 264, 974, 644, 11], "temperature": 0.0, "avg_logprob": -0.16150620617444003, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.00016630900790914893}, {"id": 211, "seek": 100100, "start": 1009.0, "end": 1013.0, "text": " the import of libpq to the PGX standard lib,", "tokens": [264, 974, 295, 22854, 79, 80, 281, 264, 430, 38, 55, 3832, 22854, 11], "temperature": 0.0, "avg_logprob": -0.16150620617444003, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.00016630900790914893}, {"id": 212, "seek": 100100, "start": 1013.0, "end": 1016.0, "text": " and you are fine.", "tokens": [293, 291, 366, 2489, 13], "temperature": 0.0, "avg_logprob": -0.16150620617444003, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.00016630900790914893}, {"id": 213, "seek": 100100, "start": 1016.0, "end": 1020.0, "text": " If you want to use PGX directly,", "tokens": [759, 291, 528, 281, 764, 430, 38, 55, 3838, 11], "temperature": 0.0, "avg_logprob": -0.16150620617444003, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.00016630900790914893}, {"id": 214, "seek": 100100, "start": 1020.0, "end": 1024.0, "text": " you are fine to do that.", "tokens": [291, 366, 2489, 281, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.16150620617444003, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.00016630900790914893}, {"id": 215, "seek": 100100, "start": 1024.0, "end": 1030.0, "text": " The thing is here that the PGX return", "tokens": [440, 551, 307, 510, 300, 264, 430, 38, 55, 2736], "temperature": 0.0, "avg_logprob": -0.16150620617444003, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.00016630900790914893}, {"id": 216, "seek": 103000, "start": 1030.0, "end": 1035.0, "text": " the connect method return the one connection only.", "tokens": [264, 1745, 3170, 2736, 264, 472, 4984, 787, 13], "temperature": 0.0, "avg_logprob": -0.12218271493911743, "compression_ratio": 1.702247191011236, "no_speech_prob": 7.642235868843272e-05}, {"id": 217, "seek": 103000, "start": 1035.0, "end": 1038.0, "text": " So, if you don't need a pool of connections,", "tokens": [407, 11, 498, 291, 500, 380, 643, 257, 7005, 295, 9271, 11], "temperature": 0.0, "avg_logprob": -0.12218271493911743, "compression_ratio": 1.702247191011236, "no_speech_prob": 7.642235868843272e-05}, {"id": 218, "seek": 103000, "start": 1038.0, "end": 1042.0, "text": " or if you want to be sure that only one connection is live,", "tokens": [420, 498, 291, 528, 281, 312, 988, 300, 787, 472, 4984, 307, 1621, 11], "temperature": 0.0, "avg_logprob": -0.12218271493911743, "compression_ratio": 1.702247191011236, "no_speech_prob": 7.642235868843272e-05}, {"id": 219, "seek": 103000, "start": 1042.0, "end": 1046.0, "text": " one connection is used, you are going with PGX connect, right?", "tokens": [472, 4984, 307, 1143, 11, 291, 366, 516, 365, 430, 38, 55, 1745, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.12218271493911743, "compression_ratio": 1.702247191011236, "no_speech_prob": 7.642235868843272e-05}, {"id": 220, "seek": 103000, "start": 1046.0, "end": 1052.0, "text": " But please remember that you cannot use this structure,", "tokens": [583, 1767, 1604, 300, 291, 2644, 764, 341, 3877, 11], "temperature": 0.0, "avg_logprob": -0.12218271493911743, "compression_ratio": 1.702247191011236, "no_speech_prob": 7.642235868843272e-05}, {"id": 221, "seek": 103000, "start": 1052.0, "end": 1055.0, "text": " this connection in parallel,", "tokens": [341, 4984, 294, 8952, 11], "temperature": 0.0, "avg_logprob": -0.12218271493911743, "compression_ratio": 1.702247191011236, "no_speech_prob": 7.642235868843272e-05}, {"id": 222, "seek": 105500, "start": 1055.0, "end": 1060.0, "text": " so you need to know that at one point in time,", "tokens": [370, 291, 643, 281, 458, 300, 412, 472, 935, 294, 565, 11], "temperature": 0.0, "avg_logprob": -0.136184024810791, "compression_ratio": 1.4204545454545454, "no_speech_prob": 0.00016795468400232494}, {"id": 223, "seek": 105500, "start": 1060.0, "end": 1066.0, "text": " only one thread or one go routine can talk to the database.", "tokens": [787, 472, 7207, 420, 472, 352, 9927, 393, 751, 281, 264, 8149, 13], "temperature": 0.0, "avg_logprob": -0.136184024810791, "compression_ratio": 1.4204545454545454, "no_speech_prob": 0.00016795468400232494}, {"id": 224, "seek": 105500, "start": 1066.0, "end": 1068.0, "text": " Otherwise, you're good.", "tokens": [10328, 11, 291, 434, 665, 13], "temperature": 0.0, "avg_logprob": -0.136184024810791, "compression_ratio": 1.4204545454545454, "no_speech_prob": 0.00016795468400232494}, {"id": 225, "seek": 105500, "start": 1068.0, "end": 1071.0, "text": " But if you want a pool of connections,", "tokens": [583, 498, 291, 528, 257, 7005, 295, 9271, 11], "temperature": 0.0, "avg_logprob": -0.136184024810791, "compression_ratio": 1.4204545454545454, "no_speech_prob": 0.00016795468400232494}, {"id": 226, "seek": 105500, "start": 1071.0, "end": 1076.0, "text": " you are going with PGX pool.", "tokens": [291, 366, 516, 365, 430, 38, 55, 7005, 13], "temperature": 0.0, "avg_logprob": -0.136184024810791, "compression_ratio": 1.4204545454545454, "no_speech_prob": 0.00016795468400232494}, {"id": 227, "seek": 105500, "start": 1076.0, "end": 1080.0, "text": " And I don't know what can I add here.", "tokens": [400, 286, 500, 380, 458, 437, 393, 286, 909, 510, 13], "temperature": 0.0, "avg_logprob": -0.136184024810791, "compression_ratio": 1.4204545454545454, "no_speech_prob": 0.00016795468400232494}, {"id": 228, "seek": 105500, "start": 1080.0, "end": 1082.0, "text": " It's obvious.", "tokens": [467, 311, 6322, 13], "temperature": 0.0, "avg_logprob": -0.136184024810791, "compression_ratio": 1.4204545454545454, "no_speech_prob": 0.00016795468400232494}, {"id": 229, "seek": 108200, "start": 1082.0, "end": 1085.0, "text": " You can pass it to the go routines,", "tokens": [509, 393, 1320, 309, 281, 264, 352, 33827, 11], "temperature": 0.0, "avg_logprob": -0.1394812778760028, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.0003987124946434051}, {"id": 230, "seek": 108200, "start": 1085.0, "end": 1089.0, "text": " and it will create additional connections as you go,", "tokens": [293, 309, 486, 1884, 4497, 9271, 382, 291, 352, 11], "temperature": 0.0, "avg_logprob": -0.1394812778760028, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.0003987124946434051}, {"id": 231, "seek": 108200, "start": 1089.0, "end": 1093.0, "text": " and you can limit up a number of connections, etc., etc.", "tokens": [293, 291, 393, 4948, 493, 257, 1230, 295, 9271, 11, 5183, 7933, 5183, 13], "temperature": 0.0, "avg_logprob": -0.1394812778760028, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.0003987124946434051}, {"id": 232, "seek": 108200, "start": 1093.0, "end": 1096.0, "text": " It's very, very, very flexible.", "tokens": [467, 311, 588, 11, 588, 11, 588, 11358, 13], "temperature": 0.0, "avg_logprob": -0.1394812778760028, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.0003987124946434051}, {"id": 233, "seek": 108200, "start": 1096.0, "end": 1101.0, "text": " Okay, about useful extensions.", "tokens": [1033, 11, 466, 4420, 25129, 13], "temperature": 0.0, "avg_logprob": -0.1394812778760028, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.0003987124946434051}, {"id": 234, "seek": 108200, "start": 1101.0, "end": 1106.0, "text": " For my first project, I started with the libpq as well.", "tokens": [1171, 452, 700, 1716, 11, 286, 1409, 365, 264, 22854, 79, 80, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.1394812778760028, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.0003987124946434051}, {"id": 235, "seek": 108200, "start": 1106.0, "end": 1108.0, "text": " It's way to go.", "tokens": [467, 311, 636, 281, 352, 13], "temperature": 0.0, "avg_logprob": -0.1394812778760028, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.0003987124946434051}, {"id": 236, "seek": 108200, "start": 1108.0, "end": 1110.0, "text": " That's how we grow.", "tokens": [663, 311, 577, 321, 1852, 13], "temperature": 0.0, "avg_logprob": -0.1394812778760028, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.0003987124946434051}, {"id": 237, "seek": 111000, "start": 1110.0, "end": 1117.0, "text": " And later, I understand that I want this copy functionality badly.", "tokens": [400, 1780, 11, 286, 1223, 300, 286, 528, 341, 5055, 14980, 13425, 13], "temperature": 0.0, "avg_logprob": -0.1411547315293464, "compression_ratio": 1.4191616766467066, "no_speech_prob": 0.00034238872467540205}, {"id": 238, "seek": 111000, "start": 1117.0, "end": 1119.0, "text": " I need that.", "tokens": [286, 643, 300, 13], "temperature": 0.0, "avg_logprob": -0.1411547315293464, "compression_ratio": 1.4191616766467066, "no_speech_prob": 0.00034238872467540205}, {"id": 239, "seek": 111000, "start": 1119.0, "end": 1124.0, "text": " So I started to look to the PGX, how to switch it,", "tokens": [407, 286, 1409, 281, 574, 281, 264, 430, 38, 55, 11, 577, 281, 3679, 309, 11], "temperature": 0.0, "avg_logprob": -0.1411547315293464, "compression_ratio": 1.4191616766467066, "no_speech_prob": 0.00034238872467540205}, {"id": 240, "seek": 111000, "start": 1124.0, "end": 1131.0, "text": " and I didn't want to lose these SQL things", "tokens": [293, 286, 994, 380, 528, 281, 3624, 613, 19200, 721], "temperature": 0.0, "avg_logprob": -0.1411547315293464, "compression_ratio": 1.4191616766467066, "no_speech_prob": 0.00034238872467540205}, {"id": 241, "seek": 111000, "start": 1131.0, "end": 1136.0, "text": " when you're encoding, decoding your structures, slices, arrays,", "tokens": [562, 291, 434, 43430, 11, 979, 8616, 428, 9227, 11, 19793, 11, 41011, 11], "temperature": 0.0, "avg_logprob": -0.1411547315293464, "compression_ratio": 1.4191616766467066, "no_speech_prob": 0.00034238872467540205}, {"id": 242, "seek": 113600, "start": 1136.0, "end": 1141.0, "text": " whatever, right from rows or two rows, right?", "tokens": [2035, 11, 558, 490, 13241, 420, 732, 13241, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.14103279532967034, "compression_ratio": 1.458937198067633, "no_speech_prob": 0.00019166278070770204}, {"id": 243, "seek": 113600, "start": 1141.0, "end": 1145.0, "text": " That's what most people think the ORM do.", "tokens": [663, 311, 437, 881, 561, 519, 264, 19654, 44, 360, 13], "temperature": 0.0, "avg_logprob": -0.14103279532967034, "compression_ratio": 1.458937198067633, "no_speech_prob": 0.00019166278070770204}, {"id": 244, "seek": 113600, "start": 1145.0, "end": 1149.0, "text": " It just translates the rows into the structures.", "tokens": [467, 445, 28468, 264, 13241, 666, 264, 9227, 13], "temperature": 0.0, "avg_logprob": -0.14103279532967034, "compression_ratio": 1.458937198067633, "no_speech_prob": 0.00019166278070770204}, {"id": 245, "seek": 113600, "start": 1149.0, "end": 1152.0, "text": " But, yeah, it's very useful.", "tokens": [583, 11, 1338, 11, 309, 311, 588, 4420, 13], "temperature": 0.0, "avg_logprob": -0.14103279532967034, "compression_ratio": 1.458937198067633, "no_speech_prob": 0.00019166278070770204}, {"id": 246, "seek": 113600, "start": 1152.0, "end": 1157.0, "text": " So, like, if you are working with an old database SQL or libpq,", "tokens": [407, 11, 411, 11, 498, 291, 366, 1364, 365, 364, 1331, 8149, 19200, 420, 22854, 79, 80, 11], "temperature": 0.0, "avg_logprob": -0.14103279532967034, "compression_ratio": 1.458937198067633, "no_speech_prob": 0.00019166278070770204}, {"id": 247, "seek": 113600, "start": 1157.0, "end": 1160.0, "text": " you are importing this SQL thing,", "tokens": [291, 366, 43866, 341, 19200, 551, 11], "temperature": 0.0, "avg_logprob": -0.14103279532967034, "compression_ratio": 1.458937198067633, "no_speech_prob": 0.00019166278070770204}, {"id": 248, "seek": 113600, "start": 1160.0, "end": 1162.0, "text": " and you can have a lot of new methods,", "tokens": [293, 291, 393, 362, 257, 688, 295, 777, 7150, 11], "temperature": 0.0, "avg_logprob": -0.14103279532967034, "compression_ratio": 1.458937198067633, "no_speech_prob": 0.00019166278070770204}, {"id": 249, "seek": 116200, "start": 1162.0, "end": 1170.0, "text": " like you can struct the row into the structure,", "tokens": [411, 291, 393, 6594, 264, 5386, 666, 264, 3877, 11], "temperature": 0.0, "avg_logprob": -0.11115624953289421, "compression_ratio": 1.528301886792453, "no_speech_prob": 0.0001242000435013324}, {"id": 250, "seek": 116200, "start": 1170.0, "end": 1176.0, "text": " or you can scan the scalar into the variable,", "tokens": [420, 291, 393, 11049, 264, 39684, 666, 264, 7006, 11], "temperature": 0.0, "avg_logprob": -0.11115624953289421, "compression_ratio": 1.528301886792453, "no_speech_prob": 0.0001242000435013324}, {"id": 251, "seek": 116200, "start": 1176.0, "end": 1181.0, "text": " or you can create a slice from your rows, etc., etc.", "tokens": [420, 291, 393, 1884, 257, 13153, 490, 428, 13241, 11, 5183, 7933, 5183, 13], "temperature": 0.0, "avg_logprob": -0.11115624953289421, "compression_ratio": 1.528301886792453, "no_speech_prob": 0.0001242000435013324}, {"id": 252, "seek": 116200, "start": 1181.0, "end": 1183.0, "text": " It's very cool.", "tokens": [467, 311, 588, 1627, 13], "temperature": 0.0, "avg_logprob": -0.11115624953289421, "compression_ratio": 1.528301886792453, "no_speech_prob": 0.0001242000435013324}, {"id": 253, "seek": 118300, "start": 1183.0, "end": 1194.0, "text": " PGX, at that time, didn't provide that.", "tokens": [430, 38, 55, 11, 412, 300, 565, 11, 994, 380, 2893, 300, 13], "temperature": 0.0, "avg_logprob": -0.1967188732044117, "compression_ratio": 1.1442307692307692, "no_speech_prob": 9.783160203369334e-05}, {"id": 254, "seek": 118300, "start": 1194.0, "end": 1203.0, "text": " But with the latest version 5, everything is already there.", "tokens": [583, 365, 264, 6792, 3037, 1025, 11, 1203, 307, 1217, 456, 13], "temperature": 0.0, "avg_logprob": -0.1967188732044117, "compression_ratio": 1.1442307692307692, "no_speech_prob": 9.783160203369334e-05}, {"id": 255, "seek": 118300, "start": 1203.0, "end": 1205.0, "text": " Better is included.", "tokens": [15753, 307, 5556, 13], "temperature": 0.0, "avg_logprob": -0.1967188732044117, "compression_ratio": 1.1442307692307692, "no_speech_prob": 9.783160203369334e-05}, {"id": 256, "seek": 120500, "start": 1205.0, "end": 1213.0, "text": " Probably you can find cases where you want more control", "tokens": [9210, 291, 393, 915, 3331, 689, 291, 528, 544, 1969], "temperature": 0.0, "avg_logprob": -0.18963940390225115, "compression_ratio": 1.460431654676259, "no_speech_prob": 0.00011179951252415776}, {"id": 257, "seek": 120500, "start": 1213.0, "end": 1215.0, "text": " over decoding and coding,", "tokens": [670, 979, 8616, 293, 17720, 11], "temperature": 0.0, "avg_logprob": -0.18963940390225115, "compression_ratio": 1.460431654676259, "no_speech_prob": 0.00011179951252415776}, {"id": 258, "seek": 120500, "start": 1215.0, "end": 1221.0, "text": " but after this guy was introduced,", "tokens": [457, 934, 341, 2146, 390, 7268, 11], "temperature": 0.0, "avg_logprob": -0.18963940390225115, "compression_ratio": 1.460431654676259, "no_speech_prob": 0.00011179951252415776}, {"id": 259, "seek": 120500, "start": 1221.0, "end": 1223.0, "text": " wrote to struct by name,", "tokens": [4114, 281, 6594, 538, 1315, 11], "temperature": 0.0, "avg_logprob": -0.18963940390225115, "compression_ratio": 1.460431654676259, "no_speech_prob": 0.00011179951252415776}, {"id": 260, "seek": 120500, "start": 1223.0, "end": 1225.0, "text": " written by me, by the way,", "tokens": [3720, 538, 385, 11, 538, 264, 636, 11], "temperature": 0.0, "avg_logprob": -0.18963940390225115, "compression_ratio": 1.460431654676259, "no_speech_prob": 0.00011179951252415776}, {"id": 261, "seek": 120500, "start": 1225.0, "end": 1229.0, "text": " yeah, everything became very easy.", "tokens": [1338, 11, 1203, 3062, 588, 1858, 13], "temperature": 0.0, "avg_logprob": -0.18963940390225115, "compression_ratio": 1.460431654676259, "no_speech_prob": 0.00011179951252415776}, {"id": 262, "seek": 122900, "start": 1229.0, "end": 1237.0, "text": " So, before that, we had only row to struct by position, right?", "tokens": [407, 11, 949, 300, 11, 321, 632, 787, 5386, 281, 6594, 538, 2535, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.14109004722846732, "compression_ratio": 1.5759162303664922, "no_speech_prob": 0.00015755477943457663}, {"id": 263, "seek": 122900, "start": 1237.0, "end": 1243.0, "text": " So, if your structure fields are in the same position", "tokens": [407, 11, 498, 428, 3877, 7909, 366, 294, 264, 912, 2535], "temperature": 0.0, "avg_logprob": -0.14109004722846732, "compression_ratio": 1.5759162303664922, "no_speech_prob": 0.00015755477943457663}, {"id": 264, "seek": 122900, "start": 1243.0, "end": 1247.0, "text": " as your field in your row result set,", "tokens": [382, 428, 2519, 294, 428, 5386, 1874, 992, 11], "temperature": 0.0, "avg_logprob": -0.14109004722846732, "compression_ratio": 1.5759162303664922, "no_speech_prob": 0.00015755477943457663}, {"id": 265, "seek": 122900, "start": 1247.0, "end": 1248.0, "text": " you're fine.", "tokens": [291, 434, 2489, 13], "temperature": 0.0, "avg_logprob": -0.14109004722846732, "compression_ratio": 1.5759162303664922, "no_speech_prob": 0.00015755477943457663}, {"id": 266, "seek": 122900, "start": 1248.0, "end": 1250.0, "text": " You're just, like, doing the back and forth.", "tokens": [509, 434, 445, 11, 411, 11, 884, 264, 646, 293, 5220, 13], "temperature": 0.0, "avg_logprob": -0.14109004722846732, "compression_ratio": 1.5759162303664922, "no_speech_prob": 0.00015755477943457663}, {"id": 267, "seek": 122900, "start": 1250.0, "end": 1253.0, "text": " But if you want to skip some fields,", "tokens": [583, 498, 291, 528, 281, 10023, 512, 7909, 11], "temperature": 0.0, "avg_logprob": -0.14109004722846732, "compression_ratio": 1.5759162303664922, "no_speech_prob": 0.00015755477943457663}, {"id": 268, "seek": 122900, "start": 1253.0, "end": 1258.0, "text": " or, for example, if you have some non-public fields", "tokens": [420, 11, 337, 1365, 11, 498, 291, 362, 512, 2107, 12, 79, 3865, 7909], "temperature": 0.0, "avg_logprob": -0.14109004722846732, "compression_ratio": 1.5759162303664922, "no_speech_prob": 0.00015755477943457663}, {"id": 269, "seek": 125800, "start": 1258.0, "end": 1261.0, "text": " in the structure, but still want to use this functionality", "tokens": [294, 264, 3877, 11, 457, 920, 528, 281, 764, 341, 14980], "temperature": 0.0, "avg_logprob": -0.15562903575408152, "compression_ratio": 1.4444444444444444, "no_speech_prob": 9.462069283472374e-05}, {"id": 270, "seek": 125800, "start": 1261.0, "end": 1265.0, "text": " to decode and code from the result set,", "tokens": [281, 979, 1429, 293, 3089, 490, 264, 1874, 992, 11], "temperature": 0.0, "avg_logprob": -0.15562903575408152, "compression_ratio": 1.4444444444444444, "no_speech_prob": 9.462069283472374e-05}, {"id": 271, "seek": 125800, "start": 1265.0, "end": 1268.0, "text": " this is the way to go.", "tokens": [341, 307, 264, 636, 281, 352, 13], "temperature": 0.0, "avg_logprob": -0.15562903575408152, "compression_ratio": 1.4444444444444444, "no_speech_prob": 9.462069283472374e-05}, {"id": 272, "seek": 125800, "start": 1268.0, "end": 1270.0, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.15562903575408152, "compression_ratio": 1.4444444444444444, "no_speech_prob": 9.462069283472374e-05}, {"id": 273, "seek": 125800, "start": 1270.0, "end": 1275.0, "text": " Now about testing.", "tokens": [823, 466, 4997, 13], "temperature": 0.0, "avg_logprob": -0.15562903575408152, "compression_ratio": 1.4444444444444444, "no_speech_prob": 9.462069283472374e-05}, {"id": 274, "seek": 125800, "start": 1275.0, "end": 1280.0, "text": " We all know it's very essential, right?", "tokens": [492, 439, 458, 309, 311, 588, 7115, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.15562903575408152, "compression_ratio": 1.4444444444444444, "no_speech_prob": 9.462069283472374e-05}, {"id": 275, "seek": 125800, "start": 1280.0, "end": 1284.0, "text": " And I heard a lot this statement", "tokens": [400, 286, 2198, 257, 688, 341, 5629], "temperature": 0.0, "avg_logprob": -0.15562903575408152, "compression_ratio": 1.4444444444444444, "no_speech_prob": 9.462069283472374e-05}, {"id": 276, "seek": 125800, "start": 1284.0, "end": 1287.0, "text": " that you need to write your tests first,", "tokens": [300, 291, 643, 281, 2464, 428, 6921, 700, 11], "temperature": 0.0, "avg_logprob": -0.15562903575408152, "compression_ratio": 1.4444444444444444, "no_speech_prob": 9.462069283472374e-05}, {"id": 277, "seek": 128700, "start": 1287.0, "end": 1290.0, "text": " and only then implementation.", "tokens": [293, 787, 550, 11420, 13], "temperature": 0.0, "avg_logprob": -0.17106014920264176, "compression_ratio": 1.5628415300546448, "no_speech_prob": 7.30617466615513e-05}, {"id": 278, "seek": 128700, "start": 1290.0, "end": 1292.0, "text": " I never did.", "tokens": [286, 1128, 630, 13], "temperature": 0.0, "avg_logprob": -0.17106014920264176, "compression_ratio": 1.5628415300546448, "no_speech_prob": 7.30617466615513e-05}, {"id": 279, "seek": 128700, "start": 1292.0, "end": 1297.0, "text": " Maybe one of us tried it.", "tokens": [2704, 472, 295, 505, 3031, 309, 13], "temperature": 0.0, "avg_logprob": -0.17106014920264176, "compression_ratio": 1.5628415300546448, "no_speech_prob": 7.30617466615513e-05}, {"id": 280, "seek": 128700, "start": 1297.0, "end": 1301.0, "text": " Oh, go, go, go.", "tokens": [876, 11, 352, 11, 352, 11, 352, 13], "temperature": 0.0, "avg_logprob": -0.17106014920264176, "compression_ratio": 1.5628415300546448, "no_speech_prob": 7.30617466615513e-05}, {"id": 281, "seek": 128700, "start": 1301.0, "end": 1304.0, "text": " I'm too lazy, because I never know", "tokens": [286, 478, 886, 14847, 11, 570, 286, 1128, 458], "temperature": 0.0, "avg_logprob": -0.17106014920264176, "compression_ratio": 1.5628415300546448, "no_speech_prob": 7.30617466615513e-05}, {"id": 282, "seek": 128700, "start": 1304.0, "end": 1308.0, "text": " where at the end I will go with my code.", "tokens": [689, 412, 264, 917, 286, 486, 352, 365, 452, 3089, 13], "temperature": 0.0, "avg_logprob": -0.17106014920264176, "compression_ratio": 1.5628415300546448, "no_speech_prob": 7.30617466615513e-05}, {"id": 283, "seek": 128700, "start": 1308.0, "end": 1310.0, "text": " I'm starting like, okay, I will implement this thing", "tokens": [286, 478, 2891, 411, 11, 1392, 11, 286, 486, 4445, 341, 551], "temperature": 0.0, "avg_logprob": -0.17106014920264176, "compression_ratio": 1.5628415300546448, "no_speech_prob": 7.30617466615513e-05}, {"id": 284, "seek": 128700, "start": 1310.0, "end": 1312.0, "text": " that will return this integer,", "tokens": [300, 486, 2736, 341, 24922, 11], "temperature": 0.0, "avg_logprob": -0.17106014920264176, "compression_ratio": 1.5628415300546448, "no_speech_prob": 7.30617466615513e-05}, {"id": 285, "seek": 128700, "start": 1312.0, "end": 1315.0, "text": " and then I'm like, oh, no, let's do this.", "tokens": [293, 550, 286, 478, 411, 11, 1954, 11, 572, 11, 718, 311, 360, 341, 13], "temperature": 0.0, "avg_logprob": -0.17106014920264176, "compression_ratio": 1.5628415300546448, "no_speech_prob": 7.30617466615513e-05}, {"id": 286, "seek": 131500, "start": 1315.0, "end": 1318.0, "text": " CTE with a lot of things, yeah.", "tokens": [383, 13639, 365, 257, 688, 295, 721, 11, 1338, 13], "temperature": 0.0, "avg_logprob": -0.15427206932230197, "compression_ratio": 1.3870967741935485, "no_speech_prob": 0.00012041631998727098}, {"id": 287, "seek": 131500, "start": 1318.0, "end": 1322.0, "text": " And if I write a test before I need to follow it, right?", "tokens": [400, 498, 286, 2464, 257, 1500, 949, 286, 643, 281, 1524, 309, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.15427206932230197, "compression_ratio": 1.3870967741935485, "no_speech_prob": 0.00012041631998727098}, {"id": 288, "seek": 131500, "start": 1322.0, "end": 1324.0, "text": " No, it's not funny.", "tokens": [883, 11, 309, 311, 406, 4074, 13], "temperature": 0.0, "avg_logprob": -0.15427206932230197, "compression_ratio": 1.3870967741935485, "no_speech_prob": 0.00012041631998727098}, {"id": 289, "seek": 131500, "start": 1324.0, "end": 1326.0, "text": " How we do testing?", "tokens": [1012, 321, 360, 4997, 30], "temperature": 0.0, "avg_logprob": -0.15427206932230197, "compression_ratio": 1.3870967741935485, "no_speech_prob": 0.00012041631998727098}, {"id": 290, "seek": 131500, "start": 1326.0, "end": 1329.0, "text": " So I would say there are three main approaches.", "tokens": [407, 286, 576, 584, 456, 366, 1045, 2135, 11587, 13], "temperature": 0.0, "avg_logprob": -0.15427206932230197, "compression_ratio": 1.3870967741935485, "no_speech_prob": 0.00012041631998727098}, {"id": 291, "seek": 131500, "start": 1329.0, "end": 1332.0, "text": " The first one, obviously,", "tokens": [440, 700, 472, 11, 2745, 11], "temperature": 0.0, "avg_logprob": -0.15427206932230197, "compression_ratio": 1.3870967741935485, "no_speech_prob": 0.00012041631998727098}, {"id": 292, "seek": 131500, "start": 1332.0, "end": 1338.0, "text": " is to start a real PostgreSQL server.", "tokens": [307, 281, 722, 257, 957, 10223, 33248, 39934, 7154, 13], "temperature": 0.0, "avg_logprob": -0.15427206932230197, "compression_ratio": 1.3870967741935485, "no_speech_prob": 0.00012041631998727098}, {"id": 293, "seek": 131500, "start": 1338.0, "end": 1340.0, "text": " You can have your local installation", "tokens": [509, 393, 362, 428, 2654, 13260], "temperature": 0.0, "avg_logprob": -0.15427206932230197, "compression_ratio": 1.3870967741935485, "no_speech_prob": 0.00012041631998727098}, {"id": 294, "seek": 131500, "start": 1340.0, "end": 1342.0, "text": " on the test environment,", "tokens": [322, 264, 1500, 2823, 11], "temperature": 0.0, "avg_logprob": -0.15427206932230197, "compression_ratio": 1.3870967741935485, "no_speech_prob": 0.00012041631998727098}, {"id": 295, "seek": 134200, "start": 1342.0, "end": 1345.0, "text": " or you can download it during the test running,", "tokens": [420, 291, 393, 5484, 309, 1830, 264, 1500, 2614, 11], "temperature": 0.0, "avg_logprob": -0.17865657806396484, "compression_ratio": 1.4261363636363635, "no_speech_prob": 0.00033008286845870316}, {"id": 296, "seek": 134200, "start": 1345.0, "end": 1348.0, "text": " install it, initialize, et cetera,", "tokens": [3625, 309, 11, 5883, 1125, 11, 1030, 11458, 11], "temperature": 0.0, "avg_logprob": -0.17865657806396484, "compression_ratio": 1.4261363636363635, "no_speech_prob": 0.00033008286845870316}, {"id": 297, "seek": 134200, "start": 1348.0, "end": 1351.0, "text": " then cache, but it's still the same.", "tokens": [550, 19459, 11, 457, 309, 311, 920, 264, 912, 13], "temperature": 0.0, "avg_logprob": -0.17865657806396484, "compression_ratio": 1.4261363636363635, "no_speech_prob": 0.00033008286845870316}, {"id": 298, "seek": 134200, "start": 1351.0, "end": 1354.0, "text": " It's a real PostgreSQL server.", "tokens": [467, 311, 257, 957, 10223, 33248, 39934, 7154, 13], "temperature": 0.0, "avg_logprob": -0.17865657806396484, "compression_ratio": 1.4261363636363635, "no_speech_prob": 0.00033008286845870316}, {"id": 299, "seek": 134200, "start": 1354.0, "end": 1358.0, "text": " The second approach would be Mockin libraries.", "tokens": [440, 1150, 3109, 576, 312, 376, 1560, 259, 15148, 13], "temperature": 0.0, "avg_logprob": -0.17865657806396484, "compression_ratio": 1.4261363636363635, "no_speech_prob": 0.00033008286845870316}, {"id": 300, "seek": 134200, "start": 1358.0, "end": 1363.0, "text": " For database SQL,", "tokens": [1171, 8149, 19200, 11], "temperature": 0.0, "avg_logprob": -0.17865657806396484, "compression_ratio": 1.4261363636363635, "no_speech_prob": 0.00033008286845870316}, {"id": 301, "seek": 134200, "start": 1363.0, "end": 1366.0, "text": " that would be Datadog,", "tokens": [300, 576, 312, 9315, 345, 664, 11], "temperature": 0.0, "avg_logprob": -0.17865657806396484, "compression_ratio": 1.4261363636363635, "no_speech_prob": 0.00033008286845870316}, {"id": 302, "seek": 134200, "start": 1366.0, "end": 1369.0, "text": " go SQL Mock.", "tokens": [352, 19200, 376, 1560, 13], "temperature": 0.0, "avg_logprob": -0.17865657806396484, "compression_ratio": 1.4261363636363635, "no_speech_prob": 0.00033008286845870316}, {"id": 303, "seek": 136900, "start": 1369.0, "end": 1373.0, "text": " And for PGX, I created this PGX Mock,", "tokens": [400, 337, 40975, 55, 11, 286, 2942, 341, 40975, 55, 376, 1560, 11], "temperature": 0.0, "avg_logprob": -0.1171773015236368, "compression_ratio": 1.5572139303482586, "no_speech_prob": 0.0002140356955351308}, {"id": 304, "seek": 136900, "start": 1373.0, "end": 1376.0, "text": " which is the brother of the SQL Mock,", "tokens": [597, 307, 264, 3708, 295, 264, 19200, 376, 1560, 11], "temperature": 0.0, "avg_logprob": -0.1171773015236368, "compression_ratio": 1.5572139303482586, "no_speech_prob": 0.0002140356955351308}, {"id": 305, "seek": 136900, "start": 1376.0, "end": 1380.0, "text": " but, yeah, works with PGX.", "tokens": [457, 11, 1338, 11, 1985, 365, 40975, 55, 13], "temperature": 0.0, "avg_logprob": -0.1171773015236368, "compression_ratio": 1.5572139303482586, "no_speech_prob": 0.0002140356955351308}, {"id": 306, "seek": 136900, "start": 1380.0, "end": 1383.0, "text": " I hope you know what is Mockin", "tokens": [286, 1454, 291, 458, 437, 307, 376, 1560, 259], "temperature": 0.0, "avg_logprob": -0.1171773015236368, "compression_ratio": 1.5572139303482586, "no_speech_prob": 0.0002140356955351308}, {"id": 307, "seek": 136900, "start": 1383.0, "end": 1386.0, "text": " and how these things are working, right?", "tokens": [293, 577, 613, 721, 366, 1364, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.1171773015236368, "compression_ratio": 1.5572139303482586, "no_speech_prob": 0.0002140356955351308}, {"id": 308, "seek": 136900, "start": 1386.0, "end": 1390.0, "text": " We are pretending that we are a PostgreSQL server,", "tokens": [492, 366, 22106, 300, 321, 366, 257, 10223, 33248, 39934, 7154, 11], "temperature": 0.0, "avg_logprob": -0.1171773015236368, "compression_ratio": 1.5572139303482586, "no_speech_prob": 0.0002140356955351308}, {"id": 309, "seek": 136900, "start": 1390.0, "end": 1394.0, "text": " and our application, our tests,", "tokens": [293, 527, 3861, 11, 527, 6921, 11], "temperature": 0.0, "avg_logprob": -0.1171773015236368, "compression_ratio": 1.5572139303482586, "no_speech_prob": 0.0002140356955351308}, {"id": 310, "seek": 136900, "start": 1394.0, "end": 1397.0, "text": " are thinking that they are speaking to the real server,", "tokens": [366, 1953, 300, 436, 366, 4124, 281, 264, 957, 7154, 11], "temperature": 0.0, "avg_logprob": -0.1171773015236368, "compression_ratio": 1.5572139303482586, "no_speech_prob": 0.0002140356955351308}, {"id": 311, "seek": 139700, "start": 1397.0, "end": 1400.0, "text": " but in fact, we just throw the needed answers", "tokens": [457, 294, 1186, 11, 321, 445, 3507, 264, 2978, 6338], "temperature": 0.0, "avg_logprob": -0.1548366345857319, "compression_ratio": 1.5544041450777202, "no_speech_prob": 0.00015918475401122123}, {"id": 312, "seek": 139700, "start": 1400.0, "end": 1402.0, "text": " to the application.", "tokens": [281, 264, 3861, 13], "temperature": 0.0, "avg_logprob": -0.1548366345857319, "compression_ratio": 1.5544041450777202, "no_speech_prob": 0.00015918475401122123}, {"id": 313, "seek": 139700, "start": 1402.0, "end": 1404.0, "text": " So, do we need rows?", "tokens": [407, 11, 360, 321, 643, 13241, 30], "temperature": 0.0, "avg_logprob": -0.1548366345857319, "compression_ratio": 1.5544041450777202, "no_speech_prob": 0.00015918475401122123}, {"id": 314, "seek": 139700, "start": 1404.0, "end": 1407.0, "text": " Okay, this is row, this is the answer.", "tokens": [1033, 11, 341, 307, 5386, 11, 341, 307, 264, 1867, 13], "temperature": 0.0, "avg_logprob": -0.1548366345857319, "compression_ratio": 1.5544041450777202, "no_speech_prob": 0.00015918475401122123}, {"id": 315, "seek": 139700, "start": 1407.0, "end": 1409.0, "text": " Oh, no, that one is a row.", "tokens": [876, 11, 572, 11, 300, 472, 307, 257, 5386, 13], "temperature": 0.0, "avg_logprob": -0.1548366345857319, "compression_ratio": 1.5544041450777202, "no_speech_prob": 0.00015918475401122123}, {"id": 316, "seek": 139700, "start": 1409.0, "end": 1413.0, "text": " Let's see how you will react with that, et cetera, et cetera.", "tokens": [961, 311, 536, 577, 291, 486, 4515, 365, 300, 11, 1030, 11458, 11, 1030, 11458, 13], "temperature": 0.0, "avg_logprob": -0.1548366345857319, "compression_ratio": 1.5544041450777202, "no_speech_prob": 0.00015918475401122123}, {"id": 317, "seek": 139700, "start": 1413.0, "end": 1419.0, "text": " But if you want to test on the protocol level,", "tokens": [583, 498, 291, 528, 281, 1500, 322, 264, 10336, 1496, 11], "temperature": 0.0, "avg_logprob": -0.1548366345857319, "compression_ratio": 1.5544041450777202, "no_speech_prob": 0.00015918475401122123}, {"id": 318, "seek": 139700, "start": 1419.0, "end": 1425.0, "text": " there is also some very low libraries,", "tokens": [456, 307, 611, 512, 588, 2295, 15148, 11], "temperature": 0.0, "avg_logprob": -0.1548366345857319, "compression_ratio": 1.5544041450777202, "no_speech_prob": 0.00015918475401122123}, {"id": 319, "seek": 142500, "start": 1425.0, "end": 1429.0, "text": " like PG Mock,", "tokens": [411, 40975, 376, 1560, 11], "temperature": 0.0, "avg_logprob": -0.19237427150501923, "compression_ratio": 1.4822695035460993, "no_speech_prob": 0.0003682940441649407}, {"id": 320, "seek": 142500, "start": 1429.0, "end": 1435.0, "text": " which is just like the real low-level Mockin protocol.", "tokens": [597, 307, 445, 411, 264, 957, 2295, 12, 12418, 376, 1560, 259, 10336, 13], "temperature": 0.0, "avg_logprob": -0.19237427150501923, "compression_ratio": 1.4822695035460993, "no_speech_prob": 0.0003682940441649407}, {"id": 321, "seek": 142500, "start": 1435.0, "end": 1440.0, "text": " KacrosDB has its own test server,", "tokens": [591, 326, 2635, 27735, 575, 1080, 1065, 1500, 7154, 11], "temperature": 0.0, "avg_logprob": -0.19237427150501923, "compression_ratio": 1.4822695035460993, "no_speech_prob": 0.0003682940441649407}, {"id": 322, "seek": 142500, "start": 1440.0, "end": 1443.0, "text": " which is just like an import KacrosDB test server", "tokens": [597, 307, 445, 411, 364, 974, 591, 326, 2635, 27735, 1500, 7154], "temperature": 0.0, "avg_logprob": -0.19237427150501923, "compression_ratio": 1.4822695035460993, "no_speech_prob": 0.0003682940441649407}, {"id": 323, "seek": 142500, "start": 1443.0, "end": 1446.0, "text": " and use it in your tests.", "tokens": [293, 764, 309, 294, 428, 6921, 13], "temperature": 0.0, "avg_logprob": -0.19237427150501923, "compression_ratio": 1.4822695035460993, "no_speech_prob": 0.0003682940441649407}, {"id": 324, "seek": 142500, "start": 1446.0, "end": 1453.0, "text": " And another library is copied.", "tokens": [400, 1071, 6405, 307, 25365, 13], "temperature": 0.0, "avg_logprob": -0.19237427150501923, "compression_ratio": 1.4822695035460993, "no_speech_prob": 0.0003682940441649407}, {"id": 325, "seek": 145300, "start": 1453.0, "end": 1459.0, "text": " Let's try to maybe...", "tokens": [961, 311, 853, 281, 1310, 485], "temperature": 0.0, "avg_logprob": -0.244889429637364, "compression_ratio": 1.1779661016949152, "no_speech_prob": 0.0005767880938947201}, {"id": 326, "seek": 145300, "start": 1459.0, "end": 1464.0, "text": " It's not very useful.", "tokens": [467, 311, 406, 588, 4420, 13], "temperature": 0.0, "avg_logprob": -0.244889429637364, "compression_ratio": 1.1779661016949152, "no_speech_prob": 0.0005767880938947201}, {"id": 327, "seek": 145300, "start": 1464.0, "end": 1467.0, "text": " No, let's get back.", "tokens": [883, 11, 718, 311, 483, 646, 13], "temperature": 0.0, "avg_logprob": -0.244889429637364, "compression_ratio": 1.1779661016949152, "no_speech_prob": 0.0005767880938947201}, {"id": 328, "seek": 145300, "start": 1467.0, "end": 1471.0, "text": " Can it work?", "tokens": [1664, 309, 589, 30], "temperature": 0.0, "avg_logprob": -0.244889429637364, "compression_ratio": 1.1779661016949152, "no_speech_prob": 0.0005767880938947201}, {"id": 329, "seek": 145300, "start": 1471.0, "end": 1477.0, "text": " Okay, so how to create a test,", "tokens": [1033, 11, 370, 577, 281, 1884, 257, 1500, 11], "temperature": 0.0, "avg_logprob": -0.244889429637364, "compression_ratio": 1.1779661016949152, "no_speech_prob": 0.0005767880938947201}, {"id": 330, "seek": 145300, "start": 1477.0, "end": 1481.0, "text": " how to use this PGX Mock thing.", "tokens": [577, 281, 764, 341, 40975, 55, 376, 1560, 551, 13], "temperature": 0.0, "avg_logprob": -0.244889429637364, "compression_ratio": 1.1779661016949152, "no_speech_prob": 0.0005767880938947201}, {"id": 331, "seek": 148100, "start": 1481.0, "end": 1485.0, "text": " So, if you read me on the repository,", "tokens": [407, 11, 498, 291, 1401, 385, 322, 264, 25841, 11], "temperature": 0.0, "avg_logprob": -0.11023633103621633, "compression_ratio": 1.4913294797687862, "no_speech_prob": 0.0002531508798711002}, {"id": 332, "seek": 148100, "start": 1485.0, "end": 1487.0, "text": " you will see that now change is required", "tokens": [291, 486, 536, 300, 586, 1319, 307, 4739], "temperature": 0.0, "avg_logprob": -0.11023633103621633, "compression_ratio": 1.4913294797687862, "no_speech_prob": 0.0002531508798711002}, {"id": 333, "seek": 148100, "start": 1487.0, "end": 1489.0, "text": " to your application.", "tokens": [281, 428, 3861, 13], "temperature": 0.0, "avg_logprob": -0.11023633103621633, "compression_ratio": 1.4913294797687862, "no_speech_prob": 0.0002531508798711002}, {"id": 334, "seek": 148100, "start": 1489.0, "end": 1493.0, "text": " That's a lie.", "tokens": [663, 311, 257, 4544, 13], "temperature": 0.0, "avg_logprob": -0.11023633103621633, "compression_ratio": 1.4913294797687862, "no_speech_prob": 0.0002531508798711002}, {"id": 335, "seek": 148100, "start": 1493.0, "end": 1496.0, "text": " You need to provide an interface", "tokens": [509, 643, 281, 2893, 364, 9226], "temperature": 0.0, "avg_logprob": -0.11023633103621633, "compression_ratio": 1.4913294797687862, "no_speech_prob": 0.0002531508798711002}, {"id": 336, "seek": 148100, "start": 1496.0, "end": 1500.0, "text": " because the PGX return structures", "tokens": [570, 264, 40975, 55, 2736, 9227], "temperature": 0.0, "avg_logprob": -0.11023633103621633, "compression_ratio": 1.4913294797687862, "no_speech_prob": 0.0002531508798711002}, {"id": 337, "seek": 148100, "start": 1500.0, "end": 1503.0, "text": " is a connection or a pool.", "tokens": [307, 257, 4984, 420, 257, 7005, 13], "temperature": 0.0, "avg_logprob": -0.11023633103621633, "compression_ratio": 1.4913294797687862, "no_speech_prob": 0.0002531508798711002}, {"id": 338, "seek": 148100, "start": 1503.0, "end": 1505.0, "text": " We cannot mock structures.", "tokens": [492, 2644, 17362, 9227, 13], "temperature": 0.0, "avg_logprob": -0.11023633103621633, "compression_ratio": 1.4913294797687862, "no_speech_prob": 0.0002531508798711002}, {"id": 339, "seek": 148100, "start": 1505.0, "end": 1507.0, "text": " We can mock interfaces.", "tokens": [492, 393, 17362, 28416, 13], "temperature": 0.0, "avg_logprob": -0.11023633103621633, "compression_ratio": 1.4913294797687862, "no_speech_prob": 0.0002531508798711002}, {"id": 340, "seek": 150700, "start": 1507.0, "end": 1513.0, "text": " So, I am defining PGX interface here", "tokens": [407, 11, 286, 669, 17827, 40975, 55, 9226, 510], "temperature": 0.0, "avg_logprob": -0.15904397024235256, "compression_ratio": 1.4967320261437909, "no_speech_prob": 0.00017665915947873145}, {"id": 341, "seek": 150700, "start": 1513.0, "end": 1517.0, "text": " and say to my method, to my function,", "tokens": [293, 584, 281, 452, 3170, 11, 281, 452, 2445, 11], "temperature": 0.0, "avg_logprob": -0.15904397024235256, "compression_ratio": 1.4967320261437909, "no_speech_prob": 0.00017665915947873145}, {"id": 342, "seek": 150700, "start": 1517.0, "end": 1521.0, "text": " that I will use this interface.", "tokens": [300, 286, 486, 764, 341, 9226, 13], "temperature": 0.0, "avg_logprob": -0.15904397024235256, "compression_ratio": 1.4967320261437909, "no_speech_prob": 0.00017665915947873145}, {"id": 343, "seek": 150700, "start": 1521.0, "end": 1523.0, "text": " Please use that.", "tokens": [2555, 764, 300, 13], "temperature": 0.0, "avg_logprob": -0.15904397024235256, "compression_ratio": 1.4967320261437909, "no_speech_prob": 0.00017665915947873145}, {"id": 344, "seek": 150700, "start": 1523.0, "end": 1528.0, "text": " And for my function, it doesn't care", "tokens": [400, 337, 452, 2445, 11, 309, 1177, 380, 1127], "temperature": 0.0, "avg_logprob": -0.15904397024235256, "compression_ratio": 1.4967320261437909, "no_speech_prob": 0.00017665915947873145}, {"id": 345, "seek": 150700, "start": 1528.0, "end": 1530.0, "text": " whether it be a real connection", "tokens": [1968, 309, 312, 257, 957, 4984], "temperature": 0.0, "avg_logprob": -0.15904397024235256, "compression_ratio": 1.4967320261437909, "no_speech_prob": 0.00017665915947873145}, {"id": 346, "seek": 150700, "start": 1530.0, "end": 1532.0, "text": " or whether it be Mockin or anything.", "tokens": [420, 1968, 309, 312, 376, 1560, 259, 420, 1340, 13], "temperature": 0.0, "avg_logprob": -0.15904397024235256, "compression_ratio": 1.4967320261437909, "no_speech_prob": 0.00017665915947873145}, {"id": 347, "seek": 153200, "start": 1532.0, "end": 1537.0, "text": " It just knows that this object has this method", "tokens": [467, 445, 3255, 300, 341, 2657, 575, 341, 3170], "temperature": 0.0, "avg_logprob": -0.17256728890015907, "compression_ratio": 1.6040609137055837, "no_speech_prob": 0.00031429430237039924}, {"id": 348, "seek": 153200, "start": 1537.0, "end": 1540.0, "text": " and it's enough for that, okay?", "tokens": [293, 309, 311, 1547, 337, 300, 11, 1392, 30], "temperature": 0.0, "avg_logprob": -0.17256728890015907, "compression_ratio": 1.6040609137055837, "no_speech_prob": 0.00031429430237039924}, {"id": 349, "seek": 153200, "start": 1540.0, "end": 1546.0, "text": " So, yeah, we write a code, kind of shit even, okay?", "tokens": [407, 11, 1338, 11, 321, 2464, 257, 3089, 11, 733, 295, 4611, 754, 11, 1392, 30], "temperature": 0.0, "avg_logprob": -0.17256728890015907, "compression_ratio": 1.6040609137055837, "no_speech_prob": 0.00031429430237039924}, {"id": 350, "seek": 153200, "start": 1546.0, "end": 1550.0, "text": " We are trying to call me, we are trying to roll back,", "tokens": [492, 366, 1382, 281, 818, 385, 11, 321, 366, 1382, 281, 3373, 646, 11], "temperature": 0.0, "avg_logprob": -0.17256728890015907, "compression_ratio": 1.6040609137055837, "no_speech_prob": 0.00031429430237039924}, {"id": 351, "seek": 153200, "start": 1550.0, "end": 1553.0, "text": " et cetera, et cetera, et cetera, how to test it.", "tokens": [1030, 11458, 11, 1030, 11458, 11, 1030, 11458, 11, 577, 281, 1500, 309, 13], "temperature": 0.0, "avg_logprob": -0.17256728890015907, "compression_ratio": 1.6040609137055837, "no_speech_prob": 0.00031429430237039924}, {"id": 352, "seek": 153200, "start": 1553.0, "end": 1558.0, "text": " So, I will always start with a successful test cases.", "tokens": [407, 11, 286, 486, 1009, 722, 365, 257, 4406, 1500, 3331, 13], "temperature": 0.0, "avg_logprob": -0.17256728890015907, "compression_ratio": 1.6040609137055837, "no_speech_prob": 0.00031429430237039924}, {"id": 353, "seek": 153200, "start": 1558.0, "end": 1561.0, "text": " I am a very positive person.", "tokens": [286, 669, 257, 588, 3353, 954, 13], "temperature": 0.0, "avg_logprob": -0.17256728890015907, "compression_ratio": 1.6040609137055837, "no_speech_prob": 0.00031429430237039924}, {"id": 354, "seek": 156100, "start": 1561.0, "end": 1564.0, "text": " First thing, first though,", "tokens": [2386, 551, 11, 700, 1673, 11], "temperature": 0.0, "avg_logprob": -0.14337342824691382, "compression_ratio": 1.5, "no_speech_prob": 0.00015629918198101223}, {"id": 355, "seek": 156100, "start": 1564.0, "end": 1569.0, "text": " I am creating the Mockin object.", "tokens": [286, 669, 4084, 264, 376, 1560, 259, 2657, 13], "temperature": 0.0, "avg_logprob": -0.14337342824691382, "compression_ratio": 1.5, "no_speech_prob": 0.00015629918198101223}, {"id": 356, "seek": 156100, "start": 1569.0, "end": 1573.0, "text": " PGX mock new pool.", "tokens": [40975, 55, 17362, 777, 7005, 13], "temperature": 0.0, "avg_logprob": -0.14337342824691382, "compression_ratio": 1.5, "no_speech_prob": 0.00015629918198101223}, {"id": 357, "seek": 156100, "start": 1573.0, "end": 1576.0, "text": " Then I will tell my Mockin object", "tokens": [1396, 286, 486, 980, 452, 376, 1560, 259, 2657], "temperature": 0.0, "avg_logprob": -0.14337342824691382, "compression_ratio": 1.5, "no_speech_prob": 0.00015629918198101223}, {"id": 358, "seek": 156100, "start": 1576.0, "end": 1580.0, "text": " how should my session looks like, right?", "tokens": [577, 820, 452, 5481, 1542, 411, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.14337342824691382, "compression_ratio": 1.5, "no_speech_prob": 0.00015629918198101223}, {"id": 359, "seek": 156100, "start": 1580.0, "end": 1583.0, "text": " So, I am saying I am expecting", "tokens": [407, 11, 286, 669, 1566, 286, 669, 9650], "temperature": 0.0, "avg_logprob": -0.14337342824691382, "compression_ratio": 1.5, "no_speech_prob": 0.00015629918198101223}, {"id": 360, "seek": 156100, "start": 1583.0, "end": 1587.0, "text": " that we will start a transaction.", "tokens": [300, 321, 486, 722, 257, 14425, 13], "temperature": 0.0, "avg_logprob": -0.14337342824691382, "compression_ratio": 1.5, "no_speech_prob": 0.00015629918198101223}, {"id": 361, "seek": 156100, "start": 1587.0, "end": 1589.0, "text": " I am expecting to begin.", "tokens": [286, 669, 9650, 281, 1841, 13], "temperature": 0.0, "avg_logprob": -0.14337342824691382, "compression_ratio": 1.5, "no_speech_prob": 0.00015629918198101223}, {"id": 362, "seek": 158900, "start": 1589.0, "end": 1592.0, "text": " Then I am expecting that the code", "tokens": [1396, 286, 669, 9650, 300, 264, 3089], "temperature": 0.0, "avg_logprob": -0.08160411743890672, "compression_ratio": 1.761111111111111, "no_speech_prob": 8.147177868522704e-05}, {"id": 363, "seek": 158900, "start": 1592.0, "end": 1595.0, "text": " will try to execute update statement, right?", "tokens": [486, 853, 281, 14483, 5623, 5629, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.08160411743890672, "compression_ratio": 1.761111111111111, "no_speech_prob": 8.147177868522704e-05}, {"id": 364, "seek": 158900, "start": 1595.0, "end": 1598.0, "text": " And when this happens,", "tokens": [400, 562, 341, 2314, 11], "temperature": 0.0, "avg_logprob": -0.08160411743890672, "compression_ratio": 1.761111111111111, "no_speech_prob": 8.147177868522704e-05}, {"id": 365, "seek": 158900, "start": 1598.0, "end": 1601.0, "text": " please return to this code", "tokens": [1767, 2736, 281, 341, 3089], "temperature": 0.0, "avg_logprob": -0.08160411743890672, "compression_ratio": 1.761111111111111, "no_speech_prob": 8.147177868522704e-05}, {"id": 366, "seek": 158900, "start": 1601.0, "end": 1604.0, "text": " the new result that update was successful", "tokens": [264, 777, 1874, 300, 5623, 390, 4406], "temperature": 0.0, "avg_logprob": -0.08160411743890672, "compression_ratio": 1.761111111111111, "no_speech_prob": 8.147177868522704e-05}, {"id": 367, "seek": 158900, "start": 1604.0, "end": 1607.0, "text": " and we updated one row, right?", "tokens": [293, 321, 10588, 472, 5386, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.08160411743890672, "compression_ratio": 1.761111111111111, "no_speech_prob": 8.147177868522704e-05}, {"id": 368, "seek": 158900, "start": 1607.0, "end": 1610.0, "text": " After that, I expect that the code", "tokens": [2381, 300, 11, 286, 2066, 300, 264, 3089], "temperature": 0.0, "avg_logprob": -0.08160411743890672, "compression_ratio": 1.761111111111111, "no_speech_prob": 8.147177868522704e-05}, {"id": 369, "seek": 158900, "start": 1610.0, "end": 1614.0, "text": " will try to insert something.", "tokens": [486, 853, 281, 8969, 746, 13], "temperature": 0.0, "avg_logprob": -0.08160411743890672, "compression_ratio": 1.761111111111111, "no_speech_prob": 8.147177868522704e-05}, {"id": 370, "seek": 158900, "start": 1614.0, "end": 1617.0, "text": " And I expect that the arguments for this statement", "tokens": [400, 286, 2066, 300, 264, 12869, 337, 341, 5629], "temperature": 0.0, "avg_logprob": -0.08160411743890672, "compression_ratio": 1.761111111111111, "no_speech_prob": 8.147177868522704e-05}, {"id": 371, "seek": 161700, "start": 1617.0, "end": 1620.0, "text": " would be two and three.", "tokens": [576, 312, 732, 293, 1045, 13], "temperature": 0.0, "avg_logprob": -0.1190905137495561, "compression_ratio": 1.5465116279069768, "no_speech_prob": 0.00010247210593661293}, {"id": 372, "seek": 161700, "start": 1620.0, "end": 1622.0, "text": " If that is the case,", "tokens": [759, 300, 307, 264, 1389, 11], "temperature": 0.0, "avg_logprob": -0.1190905137495561, "compression_ratio": 1.5465116279069768, "no_speech_prob": 0.00010247210593661293}, {"id": 373, "seek": 161700, "start": 1622.0, "end": 1625.0, "text": " please tell that everything is good.", "tokens": [1767, 980, 300, 1203, 307, 665, 13], "temperature": 0.0, "avg_logprob": -0.1190905137495561, "compression_ratio": 1.5465116279069768, "no_speech_prob": 0.00010247210593661293}, {"id": 374, "seek": 161700, "start": 1625.0, "end": 1628.0, "text": " We insert one row.", "tokens": [492, 8969, 472, 5386, 13], "temperature": 0.0, "avg_logprob": -0.1190905137495561, "compression_ratio": 1.5465116279069768, "no_speech_prob": 0.00010247210593661293}, {"id": 375, "seek": 161700, "start": 1628.0, "end": 1630.0, "text": " And after all that,", "tokens": [400, 934, 439, 300, 11], "temperature": 0.0, "avg_logprob": -0.1190905137495561, "compression_ratio": 1.5465116279069768, "no_speech_prob": 0.00010247210593661293}, {"id": 376, "seek": 161700, "start": 1630.0, "end": 1634.0, "text": " I expect that the code will commit the transaction, right?", "tokens": [286, 2066, 300, 264, 3089, 486, 5599, 264, 14425, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.1190905137495561, "compression_ratio": 1.5465116279069768, "no_speech_prob": 0.00010247210593661293}, {"id": 377, "seek": 161700, "start": 1634.0, "end": 1639.0, "text": " That is what I am expecting from the code.", "tokens": [663, 307, 437, 286, 669, 9650, 490, 264, 3089, 13], "temperature": 0.0, "avg_logprob": -0.1190905137495561, "compression_ratio": 1.5465116279069768, "no_speech_prob": 0.00010247210593661293}, {"id": 378, "seek": 161700, "start": 1639.0, "end": 1643.0, "text": " Then I am calling my function record starts", "tokens": [1396, 286, 669, 5141, 452, 2445, 2136, 3719], "temperature": 0.0, "avg_logprob": -0.1190905137495561, "compression_ratio": 1.5465116279069768, "no_speech_prob": 0.00010247210593661293}, {"id": 379, "seek": 164300, "start": 1643.0, "end": 1649.0, "text": " and instead of the PGX, I am passing the Mockin object, Mock.", "tokens": [293, 2602, 295, 264, 40975, 55, 11, 286, 669, 8437, 264, 376, 1560, 259, 2657, 11, 376, 1560, 13], "temperature": 0.0, "avg_logprob": -0.1392921013168142, "compression_ratio": 1.4207650273224044, "no_speech_prob": 4.3043353798566386e-05}, {"id": 380, "seek": 164300, "start": 1649.0, "end": 1652.0, "text": " And two and three arguments, right?", "tokens": [400, 732, 293, 1045, 12869, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.1392921013168142, "compression_ratio": 1.4207650273224044, "no_speech_prob": 4.3043353798566386e-05}, {"id": 381, "seek": 164300, "start": 1652.0, "end": 1655.0, "text": " And if anything goes wrong,", "tokens": [400, 498, 1340, 1709, 2085, 11], "temperature": 0.0, "avg_logprob": -0.1392921013168142, "compression_ratio": 1.4207650273224044, "no_speech_prob": 4.3043353798566386e-05}, {"id": 382, "seek": 164300, "start": 1655.0, "end": 1658.0, "text": " the taste case is failed, right?", "tokens": [264, 3939, 1389, 307, 7612, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.1392921013168142, "compression_ratio": 1.4207650273224044, "no_speech_prob": 4.3043353798566386e-05}, {"id": 383, "seek": 164300, "start": 1658.0, "end": 1662.0, "text": " But another thing I want to check", "tokens": [583, 1071, 551, 286, 528, 281, 1520], "temperature": 0.0, "avg_logprob": -0.1392921013168142, "compression_ratio": 1.4207650273224044, "no_speech_prob": 4.3043353798566386e-05}, {"id": 384, "seek": 164300, "start": 1662.0, "end": 1665.0, "text": " is every expectation I set were met.", "tokens": [307, 633, 14334, 286, 992, 645, 1131, 13], "temperature": 0.0, "avg_logprob": -0.1392921013168142, "compression_ratio": 1.4207650273224044, "no_speech_prob": 4.3043353798566386e-05}, {"id": 385, "seek": 164300, "start": 1665.0, "end": 1669.0, "text": " For example, after the commit,", "tokens": [1171, 1365, 11, 934, 264, 5599, 11], "temperature": 0.0, "avg_logprob": -0.1392921013168142, "compression_ratio": 1.4207650273224044, "no_speech_prob": 4.3043353798566386e-05}, {"id": 386, "seek": 166900, "start": 1669.0, "end": 1674.0, "text": " my code might want to write a log to the database", "tokens": [452, 3089, 1062, 528, 281, 2464, 257, 3565, 281, 264, 8149], "temperature": 0.0, "avg_logprob": -0.0892696460088094, "compression_ratio": 1.4805194805194806, "no_speech_prob": 8.826852717902511e-05}, {"id": 387, "seek": 166900, "start": 1674.0, "end": 1677.0, "text": " or do other things.", "tokens": [420, 360, 661, 721, 13], "temperature": 0.0, "avg_logprob": -0.0892696460088094, "compression_ratio": 1.4805194805194806, "no_speech_prob": 8.826852717902511e-05}, {"id": 388, "seek": 166900, "start": 1677.0, "end": 1680.0, "text": " I don't expect that thing from it", "tokens": [286, 500, 380, 2066, 300, 551, 490, 309], "temperature": 0.0, "avg_logprob": -0.0892696460088094, "compression_ratio": 1.4805194805194806, "no_speech_prob": 8.826852717902511e-05}, {"id": 389, "seek": 166900, "start": 1680.0, "end": 1684.0, "text": " and these expectations were met", "tokens": [293, 613, 9843, 645, 1131], "temperature": 0.0, "avg_logprob": -0.0892696460088094, "compression_ratio": 1.4805194805194806, "no_speech_prob": 8.826852717902511e-05}, {"id": 390, "seek": 166900, "start": 1684.0, "end": 1690.0, "text": " will fail if something else happens inside this function", "tokens": [486, 3061, 498, 746, 1646, 2314, 1854, 341, 2445], "temperature": 0.0, "avg_logprob": -0.0892696460088094, "compression_ratio": 1.4805194805194806, "no_speech_prob": 8.826852717902511e-05}, {"id": 391, "seek": 166900, "start": 1690.0, "end": 1694.0, "text": " which is not being expected, right?", "tokens": [597, 307, 406, 885, 5176, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.0892696460088094, "compression_ratio": 1.4805194805194806, "no_speech_prob": 8.826852717902511e-05}, {"id": 392, "seek": 169400, "start": 1694.0, "end": 1700.0, "text": " So for fail, for failure is pretty much the same.", "tokens": [407, 337, 3061, 11, 337, 7763, 307, 1238, 709, 264, 912, 13], "temperature": 0.0, "avg_logprob": -0.13573758742388556, "compression_ratio": 1.6193548387096774, "no_speech_prob": 0.00010069592826766893}, {"id": 393, "seek": 169400, "start": 1700.0, "end": 1705.0, "text": " We are telling that we expect to start transaction,", "tokens": [492, 366, 3585, 300, 321, 2066, 281, 722, 14425, 11], "temperature": 0.0, "avg_logprob": -0.13573758742388556, "compression_ratio": 1.6193548387096774, "no_speech_prob": 0.00010069592826766893}, {"id": 394, "seek": 169400, "start": 1705.0, "end": 1709.0, "text": " we expect to start update statement,", "tokens": [321, 2066, 281, 722, 5623, 5629, 11], "temperature": 0.0, "avg_logprob": -0.13573758742388556, "compression_ratio": 1.6193548387096774, "no_speech_prob": 0.00010069592826766893}, {"id": 395, "seek": 169400, "start": 1709.0, "end": 1715.0, "text": " but let's pretend we want to test how our code will behave", "tokens": [457, 718, 311, 11865, 321, 528, 281, 1500, 577, 527, 3089, 486, 15158], "temperature": 0.0, "avg_logprob": -0.13573758742388556, "compression_ratio": 1.6193548387096774, "no_speech_prob": 0.00010069592826766893}, {"id": 396, "seek": 169400, "start": 1715.0, "end": 1719.0, "text": " if the insert statement will fail.", "tokens": [498, 264, 8969, 5629, 486, 3061, 13], "temperature": 0.0, "avg_logprob": -0.13573758742388556, "compression_ratio": 1.6193548387096774, "no_speech_prob": 0.00010069592826766893}, {"id": 397, "seek": 169400, "start": 1719.0, "end": 1721.0, "text": " So we are telling,", "tokens": [407, 321, 366, 3585, 11], "temperature": 0.0, "avg_logprob": -0.13573758742388556, "compression_ratio": 1.6193548387096774, "no_speech_prob": 0.00010069592826766893}, {"id": 398, "seek": 172100, "start": 1721.0, "end": 1725.0, "text": " when insert statement is coming with the arguments two and three,", "tokens": [562, 8969, 5629, 307, 1348, 365, 264, 12869, 732, 293, 1045, 11], "temperature": 0.0, "avg_logprob": -0.11000447046189081, "compression_ratio": 1.619047619047619, "no_speech_prob": 6.203715020092204e-05}, {"id": 399, "seek": 172100, "start": 1725.0, "end": 1728.0, "text": " let's pretend that error happened.", "tokens": [718, 311, 11865, 300, 6713, 2011, 13], "temperature": 0.0, "avg_logprob": -0.11000447046189081, "compression_ratio": 1.619047619047619, "no_speech_prob": 6.203715020092204e-05}, {"id": 400, "seek": 172100, "start": 1728.0, "end": 1731.0, "text": " Return error to our code", "tokens": [24350, 6713, 281, 527, 3089], "temperature": 0.0, "avg_logprob": -0.11000447046189081, "compression_ratio": 1.619047619047619, "no_speech_prob": 6.203715020092204e-05}, {"id": 401, "seek": 172100, "start": 1731.0, "end": 1735.0, "text": " and the error with some error text.", "tokens": [293, 264, 6713, 365, 512, 6713, 2487, 13], "temperature": 0.0, "avg_logprob": -0.11000447046189081, "compression_ratio": 1.619047619047619, "no_speech_prob": 6.203715020092204e-05}, {"id": 402, "seek": 172100, "start": 1735.0, "end": 1737.0, "text": " Very beautiful.", "tokens": [4372, 2238, 13], "temperature": 0.0, "avg_logprob": -0.11000447046189081, "compression_ratio": 1.619047619047619, "no_speech_prob": 6.203715020092204e-05}, {"id": 403, "seek": 172100, "start": 1737.0, "end": 1740.0, "text": " We are starting our function,", "tokens": [492, 366, 2891, 527, 2445, 11], "temperature": 0.0, "avg_logprob": -0.11000447046189081, "compression_ratio": 1.619047619047619, "no_speech_prob": 6.203715020092204e-05}, {"id": 404, "seek": 172100, "start": 1740.0, "end": 1743.0, "text": " but in that case, we know that it should fail.", "tokens": [457, 294, 300, 1389, 11, 321, 458, 300, 309, 820, 3061, 13], "temperature": 0.0, "avg_logprob": -0.11000447046189081, "compression_ratio": 1.619047619047619, "no_speech_prob": 6.203715020092204e-05}, {"id": 405, "seek": 172100, "start": 1743.0, "end": 1749.0, "text": " That's why we are checking our error to be not new.", "tokens": [663, 311, 983, 321, 366, 8568, 527, 6713, 281, 312, 406, 777, 13], "temperature": 0.0, "avg_logprob": -0.11000447046189081, "compression_ratio": 1.619047619047619, "no_speech_prob": 6.203715020092204e-05}, {"id": 406, "seek": 174900, "start": 1749.0, "end": 1752.0, "text": " We are waiting error, right?", "tokens": [492, 366, 3806, 6713, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.22456121444702148, "compression_ratio": 1.4628571428571429, "no_speech_prob": 0.0002959433477371931}, {"id": 407, "seek": 174900, "start": 1752.0, "end": 1755.0, "text": " And the same for expectations were met.", "tokens": [400, 264, 912, 337, 9843, 645, 1131, 13], "temperature": 0.0, "avg_logprob": -0.22456121444702148, "compression_ratio": 1.4628571428571429, "no_speech_prob": 0.0002959433477371931}, {"id": 408, "seek": 174900, "start": 1755.0, "end": 1757.0, "text": " So for example, if we failed", "tokens": [407, 337, 1365, 11, 498, 321, 7612], "temperature": 0.0, "avg_logprob": -0.22456121444702148, "compression_ratio": 1.4628571428571429, "no_speech_prob": 0.0002959433477371931}, {"id": 409, "seek": 174900, "start": 1757.0, "end": 1761.0, "text": " and our code tries to do more than we are expecting,", "tokens": [293, 527, 3089, 9898, 281, 360, 544, 813, 321, 366, 9650, 11], "temperature": 0.0, "avg_logprob": -0.22456121444702148, "compression_ratio": 1.4628571428571429, "no_speech_prob": 0.0002959433477371931}, {"id": 410, "seek": 174900, "start": 1761.0, "end": 1764.0, "text": " we say, no, please don't.", "tokens": [321, 584, 11, 572, 11, 1767, 500, 380, 13], "temperature": 0.0, "avg_logprob": -0.22456121444702148, "compression_ratio": 1.4628571428571429, "no_speech_prob": 0.0002959433477371931}, {"id": 411, "seek": 174900, "start": 1764.0, "end": 1766.0, "text": " Please don't.", "tokens": [2555, 500, 380, 13], "temperature": 0.0, "avg_logprob": -0.22456121444702148, "compression_ratio": 1.4628571428571429, "no_speech_prob": 0.0002959433477371931}, {"id": 412, "seek": 174900, "start": 1766.0, "end": 1771.0, "text": " Yeah, so then you are just using go test", "tokens": [865, 11, 370, 550, 291, 366, 445, 1228, 352, 1500], "temperature": 0.0, "avg_logprob": -0.22456121444702148, "compression_ratio": 1.4628571428571429, "no_speech_prob": 0.0002959433477371931}, {"id": 413, "seek": 174900, "start": 1771.0, "end": 1776.0, "text": " with the t-parts thingy.", "tokens": [365, 264, 256, 12, 6971, 82, 551, 88, 13], "temperature": 0.0, "avg_logprob": -0.22456121444702148, "compression_ratio": 1.4628571428571429, "no_speech_prob": 0.0002959433477371931}, {"id": 414, "seek": 177600, "start": 1776.0, "end": 1784.0, "text": " I just love how the tables look after this output.", "tokens": [286, 445, 959, 577, 264, 8020, 574, 934, 341, 5598, 13], "temperature": 0.0, "avg_logprob": -0.11206470517551198, "compression_ratio": 1.5276073619631902, "no_speech_prob": 0.0004172957269474864}, {"id": 415, "seek": 177600, "start": 1784.0, "end": 1788.0, "text": " So like for this case, we have like one package", "tokens": [407, 411, 337, 341, 1389, 11, 321, 362, 411, 472, 7372], "temperature": 0.0, "avg_logprob": -0.11206470517551198, "compression_ratio": 1.5276073619631902, "no_speech_prob": 0.0004172957269474864}, {"id": 416, "seek": 177600, "start": 1788.0, "end": 1791.0, "text": " and we have two test cases, right?", "tokens": [293, 321, 362, 732, 1500, 3331, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.11206470517551198, "compression_ratio": 1.5276073619631902, "no_speech_prob": 0.0004172957269474864}, {"id": 417, "seek": 177600, "start": 1791.0, "end": 1794.0, "text": " But in real application, you might have hundreds,", "tokens": [583, 294, 957, 3861, 11, 291, 1062, 362, 6779, 11], "temperature": 0.0, "avg_logprob": -0.11206470517551198, "compression_ratio": 1.5276073619631902, "no_speech_prob": 0.0004172957269474864}, {"id": 418, "seek": 177600, "start": 1794.0, "end": 1799.0, "text": " hundreds of test cases and dozens of packages.", "tokens": [6779, 295, 1500, 3331, 293, 18431, 295, 17401, 13], "temperature": 0.0, "avg_logprob": -0.11206470517551198, "compression_ratio": 1.5276073619631902, "no_speech_prob": 0.0004172957269474864}, {"id": 419, "seek": 177600, "start": 1799.0, "end": 1802.0, "text": " They all be listed", "tokens": [814, 439, 312, 10052], "temperature": 0.0, "avg_logprob": -0.11206470517551198, "compression_ratio": 1.5276073619631902, "no_speech_prob": 0.0004172957269474864}, {"id": 420, "seek": 180200, "start": 1802.0, "end": 1807.0, "text": " and you can see a coverage for every package", "tokens": [293, 291, 393, 536, 257, 9645, 337, 633, 7372], "temperature": 0.0, "avg_logprob": -0.12180470131539009, "compression_ratio": 1.7402597402597402, "no_speech_prob": 0.00015858039841987193}, {"id": 421, "seek": 180200, "start": 1807.0, "end": 1813.0, "text": " and you can see probably coverage for every test case,", "tokens": [293, 291, 393, 536, 1391, 9645, 337, 633, 1500, 1389, 11], "temperature": 0.0, "avg_logprob": -0.12180470131539009, "compression_ratio": 1.7402597402597402, "no_speech_prob": 0.00015858039841987193}, {"id": 422, "seek": 180200, "start": 1813.0, "end": 1818.0, "text": " how many passes, how many fails, et cetera, et cetera.", "tokens": [577, 867, 11335, 11, 577, 867, 18199, 11, 1030, 11458, 11, 1030, 11458, 13], "temperature": 0.0, "avg_logprob": -0.12180470131539009, "compression_ratio": 1.7402597402597402, "no_speech_prob": 0.00015858039841987193}, {"id": 423, "seek": 180200, "start": 1818.0, "end": 1822.0, "text": " Also, you want to probably investigate", "tokens": [2743, 11, 291, 528, 281, 1391, 15013], "temperature": 0.0, "avg_logprob": -0.12180470131539009, "compression_ratio": 1.7402597402597402, "no_speech_prob": 0.00015858039841987193}, {"id": 424, "seek": 180200, "start": 1822.0, "end": 1824.0, "text": " what is the coverage.", "tokens": [437, 307, 264, 9645, 13], "temperature": 0.0, "avg_logprob": -0.12180470131539009, "compression_ratio": 1.7402597402597402, "no_speech_prob": 0.00015858039841987193}, {"id": 425, "seek": 180200, "start": 1824.0, "end": 1830.0, "text": " For that, you are using the built-in go to cover two", "tokens": [1171, 300, 11, 291, 366, 1228, 264, 3094, 12, 259, 352, 281, 2060, 732], "temperature": 0.0, "avg_logprob": -0.12180470131539009, "compression_ratio": 1.7402597402597402, "no_speech_prob": 0.00015858039841987193}, {"id": 426, "seek": 183000, "start": 1830.0, "end": 1833.0, "text": " test cases that will produce temporary HTML files", "tokens": [1500, 3331, 300, 486, 5258, 13413, 17995, 7098], "temperature": 0.0, "avg_logprob": -0.14385978654883375, "compression_ratio": 1.6597938144329898, "no_speech_prob": 0.00027354012127034366}, {"id": 427, "seek": 183000, "start": 1833.0, "end": 1837.0, "text": " and will open them in your browser.", "tokens": [293, 486, 1269, 552, 294, 428, 11185, 13], "temperature": 0.0, "avg_logprob": -0.14385978654883375, "compression_ratio": 1.6597938144329898, "no_speech_prob": 0.00027354012127034366}, {"id": 428, "seek": 183000, "start": 1837.0, "end": 1841.0, "text": " So you see a combo box with the list of files", "tokens": [407, 291, 536, 257, 16859, 2424, 365, 264, 1329, 295, 7098], "temperature": 0.0, "avg_logprob": -0.14385978654883375, "compression_ratio": 1.6597938144329898, "no_speech_prob": 0.00027354012127034366}, {"id": 429, "seek": 183000, "start": 1841.0, "end": 1844.0, "text": " in your application and you just go through", "tokens": [294, 428, 3861, 293, 291, 445, 352, 807], "temperature": 0.0, "avg_logprob": -0.14385978654883375, "compression_ratio": 1.6597938144329898, "no_speech_prob": 0.00027354012127034366}, {"id": 430, "seek": 183000, "start": 1844.0, "end": 1846.0, "text": " all your code.", "tokens": [439, 428, 3089, 13], "temperature": 0.0, "avg_logprob": -0.14385978654883375, "compression_ratio": 1.6597938144329898, "no_speech_prob": 0.00027354012127034366}, {"id": 431, "seek": 183000, "start": 1846.0, "end": 1850.0, "text": " The red one is not covered by our test cases.", "tokens": [440, 2182, 472, 307, 406, 5343, 538, 527, 1500, 3331, 13], "temperature": 0.0, "avg_logprob": -0.14385978654883375, "compression_ratio": 1.6597938144329898, "no_speech_prob": 0.00027354012127034366}, {"id": 432, "seek": 183000, "start": 1850.0, "end": 1853.0, "text": " The green one covered by our test cases.", "tokens": [440, 3092, 472, 5343, 538, 527, 1500, 3331, 13], "temperature": 0.0, "avg_logprob": -0.14385978654883375, "compression_ratio": 1.6597938144329898, "no_speech_prob": 0.00027354012127034366}, {"id": 433, "seek": 183000, "start": 1853.0, "end": 1858.0, "text": " For example, in this case, our main function", "tokens": [1171, 1365, 11, 294, 341, 1389, 11, 527, 2135, 2445], "temperature": 0.0, "avg_logprob": -0.14385978654883375, "compression_ratio": 1.6597938144329898, "no_speech_prob": 0.00027354012127034366}, {"id": 434, "seek": 185800, "start": 1858.0, "end": 1863.0, "text": " is to test it all because it's tricky to test", "tokens": [307, 281, 1500, 309, 439, 570, 309, 311, 12414, 281, 1500], "temperature": 0.0, "avg_logprob": -0.17846624968481845, "compression_ratio": 1.4331210191082802, "no_speech_prob": 8.25778188300319e-05}, {"id": 435, "seek": 185800, "start": 1863.0, "end": 1865.0, "text": " the main function.", "tokens": [264, 2135, 2445, 13], "temperature": 0.0, "avg_logprob": -0.17846624968481845, "compression_ratio": 1.4331210191082802, "no_speech_prob": 8.25778188300319e-05}, {"id": 436, "seek": 185800, "start": 1865.0, "end": 1868.0, "text": " That's why you should put it outside of everything", "tokens": [663, 311, 983, 291, 820, 829, 309, 2380, 295, 1203], "temperature": 0.0, "avg_logprob": -0.17846624968481845, "compression_ratio": 1.4331210191082802, "no_speech_prob": 8.25778188300319e-05}, {"id": 437, "seek": 185800, "start": 1868.0, "end": 1870.0, "text": " and make it like two, three lines", "tokens": [293, 652, 309, 411, 732, 11, 1045, 3876], "temperature": 0.0, "avg_logprob": -0.17846624968481845, "compression_ratio": 1.4331210191082802, "no_speech_prob": 8.25778188300319e-05}, {"id": 438, "seek": 185800, "start": 1870.0, "end": 1877.0, "text": " and only use your packages inside.", "tokens": [293, 787, 764, 428, 17401, 1854, 13], "temperature": 0.0, "avg_logprob": -0.17846624968481845, "compression_ratio": 1.4331210191082802, "no_speech_prob": 8.25778188300319e-05}, {"id": 439, "seek": 185800, "start": 1877.0, "end": 1886.0, "text": " Okay, so time for continuous integration", "tokens": [1033, 11, 370, 565, 337, 10957, 10980], "temperature": 0.0, "avg_logprob": -0.17846624968481845, "compression_ratio": 1.4331210191082802, "no_speech_prob": 8.25778188300319e-05}, {"id": 440, "seek": 188600, "start": 1886.0, "end": 1892.0, "text": " and continuous delivery.", "tokens": [293, 10957, 8982, 13], "temperature": 0.0, "avg_logprob": -0.1975873629252116, "compression_ratio": 1.3209876543209877, "no_speech_prob": 0.00012477707059588283}, {"id": 441, "seek": 188600, "start": 1892.0, "end": 1896.0, "text": " As a company, we are working in GitHub,", "tokens": [1018, 257, 2237, 11, 321, 366, 1364, 294, 23331, 11], "temperature": 0.0, "avg_logprob": -0.1975873629252116, "compression_ratio": 1.3209876543209877, "no_speech_prob": 0.00012477707059588283}, {"id": 442, "seek": 188600, "start": 1896.0, "end": 1899.0, "text": " but I'm pretty sure that the same functionality", "tokens": [457, 286, 478, 1238, 988, 300, 264, 912, 14980], "temperature": 0.0, "avg_logprob": -0.1975873629252116, "compression_ratio": 1.3209876543209877, "no_speech_prob": 0.00012477707059588283}, {"id": 443, "seek": 188600, "start": 1899.0, "end": 1907.0, "text": " is available on GitLab and BigBucket and everywhere.", "tokens": [307, 2435, 322, 16939, 37880, 293, 5429, 33, 1134, 302, 293, 5315, 13], "temperature": 0.0, "avg_logprob": -0.1975873629252116, "compression_ratio": 1.3209876543209877, "no_speech_prob": 0.00012477707059588283}, {"id": 444, "seek": 188600, "start": 1907.0, "end": 1911.0, "text": " So for every my project, I want to have at least", "tokens": [407, 337, 633, 452, 1716, 11, 286, 528, 281, 362, 412, 1935], "temperature": 0.0, "avg_logprob": -0.1975873629252116, "compression_ratio": 1.3209876543209877, "no_speech_prob": 0.00012477707059588283}, {"id": 445, "seek": 191100, "start": 1911.0, "end": 1916.0, "text": " five actions, GitHub actions.", "tokens": [1732, 5909, 11, 23331, 5909, 13], "temperature": 0.0, "avg_logprob": -0.13009206260122905, "compression_ratio": 1.5376884422110553, "no_speech_prob": 0.0006139280740171671}, {"id": 446, "seek": 191100, "start": 1916.0, "end": 1919.0, "text": " First one is a dependent bot.", "tokens": [2386, 472, 307, 257, 12334, 10592, 13], "temperature": 0.0, "avg_logprob": -0.13009206260122905, "compression_ratio": 1.5376884422110553, "no_speech_prob": 0.0006139280740171671}, {"id": 447, "seek": 191100, "start": 1919.0, "end": 1923.0, "text": " I want my repository is constantly being checked", "tokens": [286, 528, 452, 25841, 307, 6460, 885, 10033], "temperature": 0.0, "avg_logprob": -0.13009206260122905, "compression_ratio": 1.5376884422110553, "no_speech_prob": 0.0006139280740171671}, {"id": 448, "seek": 191100, "start": 1923.0, "end": 1928.0, "text": " if any package I'm dependent on is updated.", "tokens": [498, 604, 7372, 286, 478, 12334, 322, 307, 10588, 13], "temperature": 0.0, "avg_logprob": -0.13009206260122905, "compression_ratio": 1.5376884422110553, "no_speech_prob": 0.0006139280740171671}, {"id": 449, "seek": 191100, "start": 1928.0, "end": 1932.0, "text": " So it will update, okay, we have a new", "tokens": [407, 309, 486, 5623, 11, 1392, 11, 321, 362, 257, 777], "temperature": 0.0, "avg_logprob": -0.13009206260122905, "compression_ratio": 1.5376884422110553, "no_speech_prob": 0.0006139280740171671}, {"id": 450, "seek": 191100, "start": 1932.0, "end": 1935.0, "text": " minor or whatever version of this package.", "tokens": [6696, 420, 2035, 3037, 295, 341, 7372, 13], "temperature": 0.0, "avg_logprob": -0.13009206260122905, "compression_ratio": 1.5376884422110553, "no_speech_prob": 0.0006139280740171671}, {"id": 451, "seek": 191100, "start": 1935.0, "end": 1937.0, "text": " It will automatically create the pull request.", "tokens": [467, 486, 6772, 1884, 264, 2235, 5308, 13], "temperature": 0.0, "avg_logprob": -0.13009206260122905, "compression_ratio": 1.5376884422110553, "no_speech_prob": 0.0006139280740171671}, {"id": 452, "seek": 191100, "start": 1937.0, "end": 1939.0, "text": " I will check the output.", "tokens": [286, 486, 1520, 264, 5598, 13], "temperature": 0.0, "avg_logprob": -0.13009206260122905, "compression_ratio": 1.5376884422110553, "no_speech_prob": 0.0006139280740171671}, {"id": 453, "seek": 193900, "start": 1939.0, "end": 1943.0, "text": " I will check if tests are fine, if everything is okay.", "tokens": [286, 486, 1520, 498, 6921, 366, 2489, 11, 498, 1203, 307, 1392, 13], "temperature": 0.0, "avg_logprob": -0.13923192024230957, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.0005265342188067734}, {"id": 454, "seek": 193900, "start": 1943.0, "end": 1946.0, "text": " Okay, very good.", "tokens": [1033, 11, 588, 665, 13], "temperature": 0.0, "avg_logprob": -0.13923192024230957, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.0005265342188067734}, {"id": 455, "seek": 193900, "start": 1946.0, "end": 1949.0, "text": " I like this because you can do three pull requests", "tokens": [286, 411, 341, 570, 291, 393, 360, 1045, 2235, 12475], "temperature": 0.0, "avg_logprob": -0.13923192024230957, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.0005265342188067734}, {"id": 456, "seek": 193900, "start": 1949.0, "end": 1953.0, "text": " per day and you are super productive.", "tokens": [680, 786, 293, 291, 366, 1687, 13304, 13], "temperature": 0.0, "avg_logprob": -0.13923192024230957, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.0005265342188067734}, {"id": 457, "seek": 193900, "start": 1953.0, "end": 1958.0, "text": " Then what I want to also always have is a code QL", "tokens": [1396, 437, 286, 528, 281, 611, 1009, 362, 307, 257, 3089, 1249, 43], "temperature": 0.0, "avg_logprob": -0.13923192024230957, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.0005265342188067734}, {"id": 458, "seek": 193900, "start": 1958.0, "end": 1965.0, "text": " which will build your sources", "tokens": [597, 486, 1322, 428, 7139], "temperature": 0.0, "avg_logprob": -0.13923192024230957, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.0005265342188067734}, {"id": 459, "seek": 196500, "start": 1965.0, "end": 1973.0, "text": " and will instigate the possible security vulnerabilities.", "tokens": [293, 486, 1058, 328, 473, 264, 1944, 3825, 37633, 13], "temperature": 0.0, "avg_logprob": -0.12757364908854166, "compression_ratio": 1.375886524822695, "no_speech_prob": 8.171386434696615e-05}, {"id": 460, "seek": 196500, "start": 1973.0, "end": 1979.0, "text": " Building tests, I'm using that for pull requests only", "tokens": [18974, 6921, 11, 286, 478, 1228, 300, 337, 2235, 12475, 787], "temperature": 0.0, "avg_logprob": -0.12757364908854166, "compression_ratio": 1.375886524822695, "no_speech_prob": 8.171386434696615e-05}, {"id": 461, "seek": 196500, "start": 1979.0, "end": 1983.0, "text": " because if you have fired them on every push", "tokens": [570, 498, 291, 362, 11777, 552, 322, 633, 2944], "temperature": 0.0, "avg_logprob": -0.12757364908854166, "compression_ratio": 1.375886524822695, "no_speech_prob": 8.171386434696615e-05}, {"id": 462, "seek": 196500, "start": 1983.0, "end": 1990.0, "text": " and the test is heavy, it's not fine.", "tokens": [293, 264, 1500, 307, 4676, 11, 309, 311, 406, 2489, 13], "temperature": 0.0, "avg_logprob": -0.12757364908854166, "compression_ratio": 1.375886524822695, "no_speech_prob": 8.171386434696615e-05}, {"id": 463, "seek": 199000, "start": 1990.0, "end": 1995.0, "text": " Release will produce the binaries and packages", "tokens": [34278, 486, 5258, 264, 5171, 4889, 293, 17401], "temperature": 0.0, "avg_logprob": -0.18598711649576824, "compression_ratio": 1.6608187134502923, "no_speech_prob": 9.359454270452261e-05}, {"id": 464, "seek": 199000, "start": 1995.0, "end": 1998.0, "text": " when the new release is created.", "tokens": [562, 264, 777, 4374, 307, 2942, 13], "temperature": 0.0, "avg_logprob": -0.18598711649576824, "compression_ratio": 1.6608187134502923, "no_speech_prob": 9.359454270452261e-05}, {"id": 465, "seek": 199000, "start": 1998.0, "end": 2002.0, "text": " And the docker is the same like for release,", "tokens": [400, 264, 360, 9178, 307, 264, 912, 411, 337, 4374, 11], "temperature": 0.0, "avg_logprob": -0.18598711649576824, "compression_ratio": 1.6608187134502923, "no_speech_prob": 9.359454270452261e-05}, {"id": 466, "seek": 199000, "start": 2002.0, "end": 2006.0, "text": " it will produce a special tag and an image and push it.", "tokens": [309, 486, 5258, 257, 2121, 6162, 293, 364, 3256, 293, 2944, 309, 13], "temperature": 0.0, "avg_logprob": -0.18598711649576824, "compression_ratio": 1.6608187134502923, "no_speech_prob": 9.359454270452261e-05}, {"id": 467, "seek": 199000, "start": 2006.0, "end": 2013.0, "text": " But for every commit, it will produce a special docker image", "tokens": [583, 337, 633, 5599, 11, 309, 486, 5258, 257, 2121, 360, 9178, 3256], "temperature": 0.0, "avg_logprob": -0.18598711649576824, "compression_ratio": 1.6608187134502923, "no_speech_prob": 9.359454270452261e-05}, {"id": 468, "seek": 199000, "start": 2013.0, "end": 2017.0, "text": " which you can just try immediately, right?", "tokens": [597, 291, 393, 445, 853, 4258, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.18598711649576824, "compression_ratio": 1.6608187134502923, "no_speech_prob": 9.359454270452261e-05}, {"id": 469, "seek": 201700, "start": 2017.0, "end": 2021.0, "text": " Like a night build or whatever.", "tokens": [1743, 257, 1818, 1322, 420, 2035, 13], "temperature": 0.0, "avg_logprob": -0.19802697125603172, "compression_ratio": 1.446078431372549, "no_speech_prob": 5.854613482370041e-05}, {"id": 470, "seek": 201700, "start": 2021.0, "end": 2023.0, "text": " Dependable is very simple.", "tokens": [4056, 521, 712, 307, 588, 2199, 13], "temperature": 0.0, "avg_logprob": -0.19802697125603172, "compression_ratio": 1.446078431372549, "no_speech_prob": 5.854613482370041e-05}, {"id": 471, "seek": 201700, "start": 2023.0, "end": 2027.0, "text": " For example, for almost all my repositories,", "tokens": [1171, 1365, 11, 337, 1920, 439, 452, 22283, 2083, 11], "temperature": 0.0, "avg_logprob": -0.19802697125603172, "compression_ratio": 1.446078431372549, "no_speech_prob": 5.854613482370041e-05}, {"id": 472, "seek": 201700, "start": 2027.0, "end": 2031.0, "text": " I first want to check the Go code itself,", "tokens": [286, 700, 528, 281, 1520, 264, 1037, 3089, 2564, 11], "temperature": 0.0, "avg_logprob": -0.19802697125603172, "compression_ratio": 1.446078431372549, "no_speech_prob": 5.854613482370041e-05}, {"id": 473, "seek": 201700, "start": 2031.0, "end": 2034.0, "text": " so package ecosystem Go mode.", "tokens": [370, 7372, 11311, 1037, 4391, 13], "temperature": 0.0, "avg_logprob": -0.19802697125603172, "compression_ratio": 1.446078431372549, "no_speech_prob": 5.854613482370041e-05}, {"id": 474, "seek": 201700, "start": 2034.0, "end": 2039.0, "text": " And I want to use the latest GitHub actions as well.", "tokens": [400, 286, 528, 281, 764, 264, 6792, 23331, 5909, 382, 731, 13], "temperature": 0.0, "avg_logprob": -0.19802697125603172, "compression_ratio": 1.446078431372549, "no_speech_prob": 5.854613482370041e-05}, {"id": 475, "seek": 201700, "start": 2039.0, "end": 2041.0, "text": " That's important.", "tokens": [663, 311, 1021, 13], "temperature": 0.0, "avg_logprob": -0.19802697125603172, "compression_ratio": 1.446078431372549, "no_speech_prob": 5.854613482370041e-05}, {"id": 476, "seek": 201700, "start": 2041.0, "end": 2046.0, "text": " So I check them daily and that's usually enough.", "tokens": [407, 286, 1520, 552, 5212, 293, 300, 311, 2673, 1547, 13], "temperature": 0.0, "avg_logprob": -0.19802697125603172, "compression_ratio": 1.446078431372549, "no_speech_prob": 5.854613482370041e-05}, {"id": 477, "seek": 204600, "start": 2046.0, "end": 2050.0, "text": " For code QL, nothing special.", "tokens": [1171, 3089, 1249, 43, 11, 1825, 2121, 13], "temperature": 0.0, "avg_logprob": -0.13996353414323595, "compression_ratio": 1.4385026737967914, "no_speech_prob": 0.00039802465471439064}, {"id": 478, "seek": 204600, "start": 2050.0, "end": 2054.0, "text": " When you create these actions from the GitHub interface,", "tokens": [1133, 291, 1884, 613, 5909, 490, 264, 23331, 9226, 11], "temperature": 0.0, "avg_logprob": -0.13996353414323595, "compression_ratio": 1.4385026737967914, "no_speech_prob": 0.00039802465471439064}, {"id": 479, "seek": 204600, "start": 2054.0, "end": 2057.0, "text": " it will fill all the fields for you.", "tokens": [309, 486, 2836, 439, 264, 7909, 337, 291, 13], "temperature": 0.0, "avg_logprob": -0.13996353414323595, "compression_ratio": 1.4385026737967914, "no_speech_prob": 0.00039802465471439064}, {"id": 480, "seek": 204600, "start": 2057.0, "end": 2062.0, "text": " I never changed the important thing there,", "tokens": [286, 1128, 3105, 264, 1021, 551, 456, 11], "temperature": 0.0, "avg_logprob": -0.13996353414323595, "compression_ratio": 1.4385026737967914, "no_speech_prob": 0.00039802465471439064}, {"id": 481, "seek": 204600, "start": 2062.0, "end": 2065.0, "text": " only removed some comments and we are fine.", "tokens": [787, 7261, 512, 3053, 293, 321, 366, 2489, 13], "temperature": 0.0, "avg_logprob": -0.13996353414323595, "compression_ratio": 1.4385026737967914, "no_speech_prob": 0.00039802465471439064}, {"id": 482, "seek": 204600, "start": 2065.0, "end": 2070.0, "text": " Building tests, I hope you can see what is going on there.", "tokens": [18974, 6921, 11, 286, 1454, 291, 393, 536, 437, 307, 516, 322, 456, 13], "temperature": 0.0, "avg_logprob": -0.13996353414323595, "compression_ratio": 1.4385026737967914, "no_speech_prob": 0.00039802465471439064}, {"id": 483, "seek": 207000, "start": 2070.0, "end": 2077.0, "text": " No. Sorry, I don't want to switch to the editor", "tokens": [883, 13, 4919, 11, 286, 500, 380, 528, 281, 3679, 281, 264, 9839], "temperature": 0.0, "avg_logprob": -0.1912208012172154, "compression_ratio": 1.3579545454545454, "no_speech_prob": 0.00031111505813896656}, {"id": 484, "seek": 207000, "start": 2077.0, "end": 2080.0, "text": " because I cannot work like that.", "tokens": [570, 286, 2644, 589, 411, 300, 13], "temperature": 0.0, "avg_logprob": -0.1912208012172154, "compression_ratio": 1.3579545454545454, "no_speech_prob": 0.00031111505813896656}, {"id": 485, "seek": 207000, "start": 2080.0, "end": 2082.0, "text": " Yeah, so I will tell you.", "tokens": [865, 11, 370, 286, 486, 980, 291, 13], "temperature": 0.0, "avg_logprob": -0.1912208012172154, "compression_ratio": 1.3579545454545454, "no_speech_prob": 0.00031111505813896656}, {"id": 486, "seek": 207000, "start": 2082.0, "end": 2088.0, "text": " So I usually run all my tests on three different platforms,", "tokens": [407, 286, 2673, 1190, 439, 452, 6921, 322, 1045, 819, 9473, 11], "temperature": 0.0, "avg_logprob": -0.1912208012172154, "compression_ratio": 1.3579545454545454, "no_speech_prob": 0.00031111505813896656}, {"id": 487, "seek": 207000, "start": 2088.0, "end": 2094.0, "text": " Windows, MacOS and Linux.", "tokens": [8591, 11, 5707, 4367, 293, 18734, 13], "temperature": 0.0, "avg_logprob": -0.1912208012172154, "compression_ratio": 1.3579545454545454, "no_speech_prob": 0.00031111505813896656}, {"id": 488, "seek": 207000, "start": 2094.0, "end": 2099.0, "text": " The good thing is all the workers already have", "tokens": [440, 665, 551, 307, 439, 264, 5600, 1217, 362], "temperature": 0.0, "avg_logprob": -0.1912208012172154, "compression_ratio": 1.3579545454545454, "no_speech_prob": 0.00031111505813896656}, {"id": 489, "seek": 209900, "start": 2099.0, "end": 2101.0, "text": " PostgreSQL installed on them,", "tokens": [10223, 33248, 39934, 8899, 322, 552, 11], "temperature": 0.0, "avg_logprob": -0.15904664501701435, "compression_ratio": 1.5841121495327102, "no_speech_prob": 0.0006287105497904122}, {"id": 490, "seek": 209900, "start": 2101.0, "end": 2104.0, "text": " but the thing is that it's not started.", "tokens": [457, 264, 551, 307, 300, 309, 311, 406, 1409, 13], "temperature": 0.0, "avg_logprob": -0.15904664501701435, "compression_ratio": 1.5841121495327102, "no_speech_prob": 0.0006287105497904122}, {"id": 491, "seek": 209900, "start": 2104.0, "end": 2108.0, "text": " So for you, essentially it's to start PostgreSQL", "tokens": [407, 337, 291, 11, 4476, 309, 311, 281, 722, 10223, 33248, 39934], "temperature": 0.0, "avg_logprob": -0.15904664501701435, "compression_ratio": 1.5841121495327102, "no_speech_prob": 0.0006287105497904122}, {"id": 492, "seek": 209900, "start": 2108.0, "end": 2111.0, "text": " and then run your tests and you are fine.", "tokens": [293, 550, 1190, 428, 6921, 293, 291, 366, 2489, 13], "temperature": 0.0, "avg_logprob": -0.15904664501701435, "compression_ratio": 1.5841121495327102, "no_speech_prob": 0.0006287105497904122}, {"id": 493, "seek": 209900, "start": 2111.0, "end": 2115.0, "text": " Usually the version of Postgres is behind", "tokens": [11419, 264, 3037, 295, 10223, 45189, 307, 2261], "temperature": 0.0, "avg_logprob": -0.15904664501701435, "compression_ratio": 1.5841121495327102, "no_speech_prob": 0.0006287105497904122}, {"id": 494, "seek": 209900, "start": 2115.0, "end": 2120.0, "text": " two or three minor versions, but it's okay.", "tokens": [732, 420, 1045, 6696, 9606, 11, 457, 309, 311, 1392, 13], "temperature": 0.0, "avg_logprob": -0.15904664501701435, "compression_ratio": 1.5841121495327102, "no_speech_prob": 0.0006287105497904122}, {"id": 495, "seek": 209900, "start": 2120.0, "end": 2123.0, "text": " If you want just like the latest one,", "tokens": [759, 291, 528, 445, 411, 264, 6792, 472, 11], "temperature": 0.0, "avg_logprob": -0.15904664501701435, "compression_ratio": 1.5841121495327102, "no_speech_prob": 0.0006287105497904122}, {"id": 496, "seek": 209900, "start": 2123.0, "end": 2128.0, "text": " you can go with the Docker images instead of that one.", "tokens": [291, 393, 352, 365, 264, 33772, 5267, 2602, 295, 300, 472, 13], "temperature": 0.0, "avg_logprob": -0.15904664501701435, "compression_ratio": 1.5841121495327102, "no_speech_prob": 0.0006287105497904122}, {"id": 497, "seek": 212800, "start": 2128.0, "end": 2131.0, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.20499087602664262, "compression_ratio": 1.5, "no_speech_prob": 0.00010506613034522161}, {"id": 498, "seek": 212800, "start": 2131.0, "end": 2137.0, "text": " So there in the build action we have Linter,", "tokens": [407, 456, 294, 264, 1322, 3069, 321, 362, 441, 5106, 11], "temperature": 0.0, "avg_logprob": -0.20499087602664262, "compression_ratio": 1.5, "no_speech_prob": 0.00010506613034522161}, {"id": 499, "seek": 212800, "start": 2137.0, "end": 2142.0, "text": " so no, without Linter we cannot accept any changes", "tokens": [370, 572, 11, 1553, 441, 5106, 321, 2644, 3241, 604, 2962], "temperature": 0.0, "avg_logprob": -0.20499087602664262, "compression_ratio": 1.5, "no_speech_prob": 0.00010506613034522161}, {"id": 500, "seek": 212800, "start": 2142.0, "end": 2145.0, "text": " or pull requests, pull requests.", "tokens": [420, 2235, 12475, 11, 2235, 12475, 13], "temperature": 0.0, "avg_logprob": -0.20499087602664262, "compression_ratio": 1.5, "no_speech_prob": 0.00010506613034522161}, {"id": 501, "seek": 212800, "start": 2145.0, "end": 2149.0, "text": " And yeah, and then we are using,", "tokens": [400, 1338, 11, 293, 550, 321, 366, 1228, 11], "temperature": 0.0, "avg_logprob": -0.20499087602664262, "compression_ratio": 1.5, "no_speech_prob": 0.00010506613034522161}, {"id": 502, "seek": 212800, "start": 2149.0, "end": 2152.0, "text": " we are generating the coverage report", "tokens": [321, 366, 17746, 264, 9645, 2275], "temperature": 0.0, "avg_logprob": -0.20499087602664262, "compression_ratio": 1.5, "no_speech_prob": 0.00010506613034522161}, {"id": 503, "seek": 212800, "start": 2152.0, "end": 2154.0, "text": " to put them everywhere.", "tokens": [281, 829, 552, 5315, 13], "temperature": 0.0, "avg_logprob": -0.20499087602664262, "compression_ratio": 1.5, "no_speech_prob": 0.00010506613034522161}, {"id": 504, "seek": 212800, "start": 2154.0, "end": 2157.0, "text": " See, 99% of code is covered.", "tokens": [3008, 11, 11803, 4, 295, 3089, 307, 5343, 13], "temperature": 0.0, "avg_logprob": -0.20499087602664262, "compression_ratio": 1.5, "no_speech_prob": 0.00010506613034522161}, {"id": 505, "seek": 215700, "start": 2157.0, "end": 2161.0, "text": " Yeah, let's lie.", "tokens": [865, 11, 718, 311, 4544, 13], "temperature": 0.0, "avg_logprob": -0.15980815887451172, "compression_ratio": 1.470899470899471, "no_speech_prob": 0.00014775971067138016}, {"id": 506, "seek": 215700, "start": 2161.0, "end": 2165.0, "text": " Okay, so release is a little bit simpler.", "tokens": [1033, 11, 370, 4374, 307, 257, 707, 857, 18587, 13], "temperature": 0.0, "avg_logprob": -0.15980815887451172, "compression_ratio": 1.470899470899471, "no_speech_prob": 0.00014775971067138016}, {"id": 507, "seek": 215700, "start": 2165.0, "end": 2169.0, "text": " As I said, we are using Go Releaser.", "tokens": [1018, 286, 848, 11, 321, 366, 1228, 1037, 1300, 306, 17756, 13], "temperature": 0.0, "avg_logprob": -0.15980815887451172, "compression_ratio": 1.470899470899471, "no_speech_prob": 0.00014775971067138016}, {"id": 508, "seek": 215700, "start": 2169.0, "end": 2172.0, "text": " It's absolutely fabulous piece of software", "tokens": [467, 311, 3122, 17692, 2522, 295, 4722], "temperature": 0.0, "avg_logprob": -0.15980815887451172, "compression_ratio": 1.470899470899471, "no_speech_prob": 0.00014775971067138016}, {"id": 509, "seek": 215700, "start": 2172.0, "end": 2175.0, "text": " that may produce everything for everything.", "tokens": [300, 815, 5258, 1203, 337, 1203, 13], "temperature": 0.0, "avg_logprob": -0.15980815887451172, "compression_ratio": 1.470899470899471, "no_speech_prob": 0.00014775971067138016}, {"id": 510, "seek": 215700, "start": 2175.0, "end": 2179.0, "text": " So the GitHub action code is simple", "tokens": [407, 264, 23331, 3069, 3089, 307, 2199], "temperature": 0.0, "avg_logprob": -0.15980815887451172, "compression_ratio": 1.470899470899471, "no_speech_prob": 0.00014775971067138016}, {"id": 511, "seek": 215700, "start": 2179.0, "end": 2184.0, "text": " because everything is stored in the YAML configuration file", "tokens": [570, 1203, 307, 12187, 294, 264, 398, 2865, 43, 11694, 3991], "temperature": 0.0, "avg_logprob": -0.15980815887451172, "compression_ratio": 1.470899470899471, "no_speech_prob": 0.00014775971067138016}, {"id": 512, "seek": 218400, "start": 2184.0, "end": 2187.0, "text": " where you set up the name, the architecture,", "tokens": [689, 291, 992, 493, 264, 1315, 11, 264, 9482, 11], "temperature": 0.0, "avg_logprob": -0.17346480051676433, "compression_ratio": 1.432748538011696, "no_speech_prob": 0.00014099766849540174}, {"id": 513, "seek": 218400, "start": 2187.0, "end": 2190.0, "text": " the OSIS, everything.", "tokens": [264, 12731, 2343, 11, 1203, 13], "temperature": 0.0, "avg_logprob": -0.17346480051676433, "compression_ratio": 1.432748538011696, "no_speech_prob": 0.00014099766849540174}, {"id": 514, "seek": 218400, "start": 2190.0, "end": 2193.0, "text": " And then you just like, okay,", "tokens": [400, 550, 291, 445, 411, 11, 1392, 11], "temperature": 0.0, "avg_logprob": -0.17346480051676433, "compression_ratio": 1.432748538011696, "no_speech_prob": 0.00014099766849540174}, {"id": 515, "seek": 218400, "start": 2193.0, "end": 2200.0, "text": " let's check out our code and let's release it.", "tokens": [718, 311, 1520, 484, 527, 3089, 293, 718, 311, 4374, 309, 13], "temperature": 0.0, "avg_logprob": -0.17346480051676433, "compression_ratio": 1.432748538011696, "no_speech_prob": 0.00014099766849540174}, {"id": 516, "seek": 218400, "start": 2200.0, "end": 2203.0, "text": " And the cool thing about it,", "tokens": [400, 264, 1627, 551, 466, 309, 11], "temperature": 0.0, "avg_logprob": -0.17346480051676433, "compression_ratio": 1.432748538011696, "no_speech_prob": 0.00014099766849540174}, {"id": 517, "seek": 218400, "start": 2203.0, "end": 2206.0, "text": " this is the Go Releaser,", "tokens": [341, 307, 264, 1037, 1300, 306, 17756, 11], "temperature": 0.0, "avg_logprob": -0.17346480051676433, "compression_ratio": 1.432748538011696, "no_speech_prob": 0.00014099766849540174}, {"id": 518, "seek": 218400, "start": 2206.0, "end": 2211.0, "text": " will create a change lock automatically for you", "tokens": [486, 1884, 257, 1319, 4017, 6772, 337, 291], "temperature": 0.0, "avg_logprob": -0.17346480051676433, "compression_ratio": 1.432748538011696, "no_speech_prob": 0.00014099766849540174}, {"id": 519, "seek": 221100, "start": 2211.0, "end": 2214.0, "text": " based on your pull requests.", "tokens": [2361, 322, 428, 2235, 12475, 13], "temperature": 0.0, "avg_logprob": -0.2031237477003926, "compression_ratio": 1.5365853658536586, "no_speech_prob": 0.00039860422839410603}, {"id": 520, "seek": 221100, "start": 2214.0, "end": 2217.0, "text": " So when I'm releasing, it's just like,", "tokens": [407, 562, 286, 478, 16327, 11, 309, 311, 445, 411, 11], "temperature": 0.0, "avg_logprob": -0.2031237477003926, "compression_ratio": 1.5365853658536586, "no_speech_prob": 0.00039860422839410603}, {"id": 521, "seek": 221100, "start": 2217.0, "end": 2222.0, "text": " I copy paste it, just sort it by the,", "tokens": [286, 5055, 9163, 309, 11, 445, 1333, 309, 538, 264, 11], "temperature": 0.0, "avg_logprob": -0.2031237477003926, "compression_ratio": 1.5365853658536586, "no_speech_prob": 0.00039860422839410603}, {"id": 522, "seek": 221100, "start": 2222.0, "end": 2227.0, "text": " like, what's added, what's fixed, and whatever.", "tokens": [411, 11, 437, 311, 3869, 11, 437, 311, 6806, 11, 293, 2035, 13], "temperature": 0.0, "avg_logprob": -0.2031237477003926, "compression_ratio": 1.5365853658536586, "no_speech_prob": 0.00039860422839410603}, {"id": 523, "seek": 221100, "start": 2227.0, "end": 2228.0, "text": " And I'm done.", "tokens": [400, 286, 478, 1096, 13], "temperature": 0.0, "avg_logprob": -0.2031237477003926, "compression_ratio": 1.5365853658536586, "no_speech_prob": 0.00039860422839410603}, {"id": 524, "seek": 221100, "start": 2228.0, "end": 2230.0, "text": " The release is very simple for me.", "tokens": [440, 4374, 307, 588, 2199, 337, 385, 13], "temperature": 0.0, "avg_logprob": -0.2031237477003926, "compression_ratio": 1.5365853658536586, "no_speech_prob": 0.00039860422839410603}, {"id": 525, "seek": 221100, "start": 2230.0, "end": 2232.0, "text": " Absolutely.", "tokens": [7021, 13], "temperature": 0.0, "avg_logprob": -0.2031237477003926, "compression_ratio": 1.5365853658536586, "no_speech_prob": 0.00039860422839410603}, {"id": 526, "seek": 221100, "start": 2232.0, "end": 2236.0, "text": " Before that I may spend two days on each release", "tokens": [4546, 300, 286, 815, 3496, 732, 1708, 322, 1184, 4374], "temperature": 0.0, "avg_logprob": -0.2031237477003926, "compression_ratio": 1.5365853658536586, "no_speech_prob": 0.00039860422839410603}, {"id": 527, "seek": 221100, "start": 2236.0, "end": 2240.0, "text": " to produce all these binders, et cetera, et cetera.", "tokens": [281, 5258, 439, 613, 14786, 433, 11, 1030, 11458, 11, 1030, 11458, 13], "temperature": 0.0, "avg_logprob": -0.2031237477003926, "compression_ratio": 1.5365853658536586, "no_speech_prob": 0.00039860422839410603}, {"id": 528, "seek": 224000, "start": 2240.0, "end": 2243.0, "text": " Okay, Docker.", "tokens": [1033, 11, 33772, 13], "temperature": 0.0, "avg_logprob": -0.16262858254568918, "compression_ratio": 1.434782608695652, "no_speech_prob": 0.00028089486295357347}, {"id": 529, "seek": 224000, "start": 2243.0, "end": 2247.0, "text": " Go Releaser can produce Docker images.", "tokens": [1037, 1300, 306, 17756, 393, 5258, 33772, 5267, 13], "temperature": 0.0, "avg_logprob": -0.16262858254568918, "compression_ratio": 1.434782608695652, "no_speech_prob": 0.00028089486295357347}, {"id": 530, "seek": 224000, "start": 2247.0, "end": 2250.0, "text": " I'm too lazy to rewrite this.", "tokens": [286, 478, 886, 14847, 281, 28132, 341, 13], "temperature": 0.0, "avg_logprob": -0.16262858254568918, "compression_ratio": 1.434782608695652, "no_speech_prob": 0.00028089486295357347}, {"id": 531, "seek": 224000, "start": 2250.0, "end": 2254.0, "text": " And yeah, I'm using like another special,", "tokens": [400, 1338, 11, 286, 478, 1228, 411, 1071, 2121, 11], "temperature": 0.0, "avg_logprob": -0.16262858254568918, "compression_ratio": 1.434782608695652, "no_speech_prob": 0.00028089486295357347}, {"id": 532, "seek": 224000, "start": 2254.0, "end": 2258.0, "text": " special GitHub actions to build a Docker.", "tokens": [2121, 23331, 5909, 281, 1322, 257, 33772, 13], "temperature": 0.0, "avg_logprob": -0.16262858254568918, "compression_ratio": 1.434782608695652, "no_speech_prob": 0.00028089486295357347}, {"id": 533, "seek": 224000, "start": 2258.0, "end": 2262.0, "text": " You can build them for every possible platforms.", "tokens": [509, 393, 1322, 552, 337, 633, 1944, 9473, 13], "temperature": 0.0, "avg_logprob": -0.16262858254568918, "compression_ratio": 1.434782608695652, "no_speech_prob": 0.00028089486295357347}, {"id": 534, "seek": 224000, "start": 2262.0, "end": 2267.0, "text": " And this Apple M1, M2 silicon thing is whatever,", "tokens": [400, 341, 6373, 376, 16, 11, 376, 17, 22848, 551, 307, 2035, 11], "temperature": 0.0, "avg_logprob": -0.16262858254568918, "compression_ratio": 1.434782608695652, "no_speech_prob": 0.00028089486295357347}, {"id": 535, "seek": 226700, "start": 2267.0, "end": 2270.0, "text": " it's just working.", "tokens": [309, 311, 445, 1364, 13], "temperature": 0.0, "avg_logprob": -0.19091707346390704, "compression_ratio": 1.1367521367521367, "no_speech_prob": 0.00017714056593831629}, {"id": 536, "seek": 226700, "start": 2270.0, "end": 2273.0, "text": " Okay, takeaways.", "tokens": [1033, 11, 45584, 13], "temperature": 0.0, "avg_logprob": -0.19091707346390704, "compression_ratio": 1.1367521367521367, "no_speech_prob": 0.00017714056593831629}, {"id": 537, "seek": 226700, "start": 2281.0, "end": 2284.0, "text": " The Go is popular.", "tokens": [440, 1037, 307, 3743, 13], "temperature": 0.0, "avg_logprob": -0.19091707346390704, "compression_ratio": 1.1367521367521367, "no_speech_prob": 0.00017714056593831629}, {"id": 538, "seek": 226700, "start": 2284.0, "end": 2287.0, "text": " Devrim doesn't like Go.", "tokens": [9096, 5565, 1177, 380, 411, 1037, 13], "temperature": 0.0, "avg_logprob": -0.19091707346390704, "compression_ratio": 1.1367521367521367, "no_speech_prob": 0.00017714056593831629}, {"id": 539, "seek": 226700, "start": 2287.0, "end": 2288.0, "text": " Yes?", "tokens": [1079, 30], "temperature": 0.0, "avg_logprob": -0.19091707346390704, "compression_ratio": 1.1367521367521367, "no_speech_prob": 0.00017714056593831629}, {"id": 540, "seek": 226700, "start": 2288.0, "end": 2294.0, "text": " So maybe this is the last time you see this talk,", "tokens": [407, 1310, 341, 307, 264, 1036, 565, 291, 536, 341, 751, 11], "temperature": 0.0, "avg_logprob": -0.19091707346390704, "compression_ratio": 1.1367521367521367, "no_speech_prob": 0.00017714056593831629}, {"id": 541, "seek": 229400, "start": 2294.0, "end": 2297.0, "text": " like when everything goes right,", "tokens": [411, 562, 1203, 1709, 558, 11], "temperature": 0.0, "avg_logprob": -0.1827979943691156, "compression_ratio": 1.4210526315789473, "no_speech_prob": 0.0020569267217069864}, {"id": 542, "seek": 229400, "start": 2297.0, "end": 2300.0, "text": " he said that I need to switch to Rust.", "tokens": [415, 848, 300, 286, 643, 281, 3679, 281, 34952, 13], "temperature": 0.0, "avg_logprob": -0.1827979943691156, "compression_ratio": 1.4210526315789473, "no_speech_prob": 0.0020569267217069864}, {"id": 543, "seek": 229400, "start": 2300.0, "end": 2310.0, "text": " So maybe next, I will go out when the Rust goes right.", "tokens": [407, 1310, 958, 11, 286, 486, 352, 484, 562, 264, 34952, 1709, 558, 13], "temperature": 0.0, "avg_logprob": -0.1827979943691156, "compression_ratio": 1.4210526315789473, "no_speech_prob": 0.0020569267217069864}, {"id": 544, "seek": 229400, "start": 2310.0, "end": 2312.0, "text": " So no, no.", "tokens": [407, 572, 11, 572, 13], "temperature": 0.0, "avg_logprob": -0.1827979943691156, "compression_ratio": 1.4210526315789473, "no_speech_prob": 0.0020569267217069864}, {"id": 545, "seek": 229400, "start": 2312.0, "end": 2314.0, "text": " Should I stick to the Go?", "tokens": [6454, 286, 2897, 281, 264, 1037, 30], "temperature": 0.0, "avg_logprob": -0.1827979943691156, "compression_ratio": 1.4210526315789473, "no_speech_prob": 0.0020569267217069864}, {"id": 546, "seek": 229400, "start": 2314.0, "end": 2316.0, "text": " Okay, we can do both.", "tokens": [1033, 11, 321, 393, 360, 1293, 13], "temperature": 0.0, "avg_logprob": -0.1827979943691156, "compression_ratio": 1.4210526315789473, "no_speech_prob": 0.0020569267217069864}, {"id": 547, "seek": 229400, "start": 2316.0, "end": 2323.0, "text": " Yeah, so a lot of developers are using databases with Go.", "tokens": [865, 11, 370, 257, 688, 295, 8849, 366, 1228, 22380, 365, 1037, 13], "temperature": 0.0, "avg_logprob": -0.1827979943691156, "compression_ratio": 1.4210526315789473, "no_speech_prob": 0.0020569267217069864}, {"id": 548, "seek": 232300, "start": 2323.0, "end": 2326.0, "text": " Of course.", "tokens": [2720, 1164, 13], "temperature": 0.0, "avg_logprob": -0.13549436681410845, "compression_ratio": 1.5151515151515151, "no_speech_prob": 3.742494300240651e-05}, {"id": 549, "seek": 232300, "start": 2326.0, "end": 2330.0, "text": " You can use whatever it did or whatever operating system you are.", "tokens": [509, 393, 764, 2035, 309, 630, 420, 2035, 7447, 1185, 291, 366, 13], "temperature": 0.0, "avg_logprob": -0.13549436681410845, "compression_ratio": 1.5151515151515151, "no_speech_prob": 3.742494300240651e-05}, {"id": 550, "seek": 232300, "start": 2330.0, "end": 2333.0, "text": " By the way, a lot of people are using Windows,", "tokens": [3146, 264, 636, 11, 257, 688, 295, 561, 366, 1228, 8591, 11], "temperature": 0.0, "avg_logprob": -0.13549436681410845, "compression_ratio": 1.5151515151515151, "no_speech_prob": 3.742494300240651e-05}, {"id": 551, "seek": 232300, "start": 2333.0, "end": 2338.0, "text": " which is not common for like Postgres community, for example.", "tokens": [597, 307, 406, 2689, 337, 411, 10223, 45189, 1768, 11, 337, 1365, 13], "temperature": 0.0, "avg_logprob": -0.13549436681410845, "compression_ratio": 1.5151515151515151, "no_speech_prob": 3.742494300240651e-05}, {"id": 552, "seek": 232300, "start": 2338.0, "end": 2346.0, "text": " But it's fine if your system can produce whatever you want.", "tokens": [583, 309, 311, 2489, 498, 428, 1185, 393, 5258, 2035, 291, 528, 13], "temperature": 0.0, "avg_logprob": -0.13549436681410845, "compression_ratio": 1.5151515151515151, "no_speech_prob": 3.742494300240651e-05}, {"id": 553, "seek": 232300, "start": 2346.0, "end": 2347.0, "text": " You don't care.", "tokens": [509, 500, 380, 1127, 13], "temperature": 0.0, "avg_logprob": -0.13549436681410845, "compression_ratio": 1.5151515151515151, "no_speech_prob": 3.742494300240651e-05}, {"id": 554, "seek": 232300, "start": 2347.0, "end": 2351.0, "text": " You just work on what you have, right?", "tokens": [509, 445, 589, 322, 437, 291, 362, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.13549436681410845, "compression_ratio": 1.5151515151515151, "no_speech_prob": 3.742494300240651e-05}, {"id": 555, "seek": 235100, "start": 2351.0, "end": 2357.0, "text": " So Kubernetes, you can use whatever you want with the Postgres.", "tokens": [407, 23145, 11, 291, 393, 764, 2035, 291, 528, 365, 264, 10223, 45189, 13], "temperature": 0.0, "avg_logprob": -0.2116604862791119, "compression_ratio": 1.3486842105263157, "no_speech_prob": 0.0002531592908781022}, {"id": 556, "seek": 235100, "start": 2357.0, "end": 2360.0, "text": " If you want to use Orm, please do.", "tokens": [759, 291, 528, 281, 764, 1610, 76, 11, 1767, 360, 13], "temperature": 0.0, "avg_logprob": -0.2116604862791119, "compression_ratio": 1.3486842105263157, "no_speech_prob": 0.0002531592908781022}, {"id": 557, "seek": 235100, "start": 2360.0, "end": 2364.0, "text": " But remember, you're responsible for that.", "tokens": [583, 1604, 11, 291, 434, 6250, 337, 300, 13], "temperature": 0.0, "avg_logprob": -0.2116604862791119, "compression_ratio": 1.3486842105263157, "no_speech_prob": 0.0002531592908781022}, {"id": 558, "seek": 235100, "start": 2364.0, "end": 2366.0, "text": " Use it wisely.", "tokens": [8278, 309, 37632, 13], "temperature": 0.0, "avg_logprob": -0.2116604862791119, "compression_ratio": 1.3486842105263157, "no_speech_prob": 0.0002531592908781022}, {"id": 559, "seek": 235100, "start": 2366.0, "end": 2375.0, "text": " Otherwise, you can use LITPQ package or new PGX.", "tokens": [10328, 11, 291, 393, 764, 441, 3927, 47, 48, 7372, 420, 777, 430, 38, 55, 13], "temperature": 0.0, "avg_logprob": -0.2116604862791119, "compression_ratio": 1.3486842105263157, "no_speech_prob": 0.0002531592908781022}, {"id": 560, "seek": 237500, "start": 2375.0, "end": 2381.0, "text": " And you can use whatever GitHub, GitHub, Bitbucket you want.", "tokens": [400, 291, 393, 764, 2035, 23331, 11, 23331, 11, 9101, 65, 1134, 302, 291, 528, 13], "temperature": 0.0, "avg_logprob": -0.15211656538106627, "compression_ratio": 1.5107913669064748, "no_speech_prob": 8.146576146828011e-05}, {"id": 561, "seek": 237500, "start": 2381.0, "end": 2389.0, "text": " And the most amazing thing about Go is the backward compatibility.", "tokens": [400, 264, 881, 2243, 551, 466, 1037, 307, 264, 23897, 34237, 13], "temperature": 0.0, "avg_logprob": -0.15211656538106627, "compression_ratio": 1.5107913669064748, "no_speech_prob": 8.146576146828011e-05}, {"id": 562, "seek": 237500, "start": 2389.0, "end": 2394.0, "text": " You can build whatever in the future.", "tokens": [509, 393, 1322, 2035, 294, 264, 2027, 13], "temperature": 0.0, "avg_logprob": -0.15211656538106627, "compression_ratio": 1.5107913669064748, "no_speech_prob": 8.146576146828011e-05}, {"id": 563, "seek": 237500, "start": 2394.0, "end": 2395.0, "text": " Yeah, in the future.", "tokens": [865, 11, 294, 264, 2027, 13], "temperature": 0.0, "avg_logprob": -0.15211656538106627, "compression_ratio": 1.5107913669064748, "no_speech_prob": 8.146576146828011e-05}, {"id": 564, "seek": 237500, "start": 2395.0, "end": 2396.0, "text": " Whatever code you want.", "tokens": [8541, 3089, 291, 528, 13], "temperature": 0.0, "avg_logprob": -0.15211656538106627, "compression_ratio": 1.5107913669064748, "no_speech_prob": 8.146576146828011e-05}, {"id": 565, "seek": 239600, "start": 2396.0, "end": 2406.0, "text": " And it still will be compatible with the oldest something written ages before.", "tokens": [400, 309, 920, 486, 312, 18218, 365, 264, 14026, 746, 3720, 12357, 949, 13], "temperature": 0.0, "avg_logprob": -0.1382170295715332, "compression_ratio": 1.5234375, "no_speech_prob": 0.0012693247990682721}, {"id": 566, "seek": 239600, "start": 2406.0, "end": 2413.0, "text": " Even now, when we have generics, when we have a cool thing is in Go,", "tokens": [2754, 586, 11, 562, 321, 362, 1337, 1167, 11, 562, 321, 362, 257, 1627, 551, 307, 294, 1037, 11], "temperature": 0.0, "avg_logprob": -0.1382170295715332, "compression_ratio": 1.5234375, "no_speech_prob": 0.0012693247990682721}, {"id": 567, "seek": 239600, "start": 2413.0, "end": 2418.0, "text": " they are still compatible with that old things.", "tokens": [436, 366, 920, 18218, 365, 300, 1331, 721, 13], "temperature": 0.0, "avg_logprob": -0.1382170295715332, "compression_ratio": 1.5234375, "no_speech_prob": 0.0012693247990682721}, {"id": 568, "seek": 241800, "start": 2418.0, "end": 2427.0, "text": " Okay, so yeah, don't be stranger, check my GitHub account,", "tokens": [1033, 11, 370, 1338, 11, 500, 380, 312, 18834, 11, 1520, 452, 23331, 2696, 11], "temperature": 0.0, "avg_logprob": -0.25172170003255206, "compression_ratio": 1.4081632653061225, "no_speech_prob": 0.0010660376865416765}, {"id": 569, "seek": 241800, "start": 2427.0, "end": 2431.0, "text": " check our blog.", "tokens": [1520, 527, 6968, 13], "temperature": 0.0, "avg_logprob": -0.25172170003255206, "compression_ratio": 1.4081632653061225, "no_speech_prob": 0.0010660376865416765}, {"id": 570, "seek": 241800, "start": 2431.0, "end": 2436.0, "text": " Yeah, some of our projects.", "tokens": [865, 11, 512, 295, 527, 4455, 13], "temperature": 0.0, "avg_logprob": -0.25172170003255206, "compression_ratio": 1.4081632653061225, "no_speech_prob": 0.0010660376865416765}, {"id": 571, "seek": 241800, "start": 2436.0, "end": 2440.0, "text": " And if you have a question, or maybe you have a question to Devrim", "tokens": [400, 498, 291, 362, 257, 1168, 11, 420, 1310, 291, 362, 257, 1168, 281, 9096, 5565], "temperature": 0.0, "avg_logprob": -0.25172170003255206, "compression_ratio": 1.4081632653061225, "no_speech_prob": 0.0010660376865416765}, {"id": 572, "seek": 241800, "start": 2440.0, "end": 2443.0, "text": " why he hates Go.", "tokens": [983, 415, 23000, 1037, 13], "temperature": 0.0, "avg_logprob": -0.25172170003255206, "compression_ratio": 1.4081632653061225, "no_speech_prob": 0.0010660376865416765}, {"id": 573, "seek": 241800, "start": 2443.0, "end": 2445.0, "text": " No, I don't hate Go.", "tokens": [883, 11, 286, 500, 380, 4700, 1037, 13], "temperature": 0.0, "avg_logprob": -0.25172170003255206, "compression_ratio": 1.4081632653061225, "no_speech_prob": 0.0010660376865416765}, {"id": 574, "seek": 244500, "start": 2445.0, "end": 2448.0, "text": " It says I don't package.", "tokens": [467, 1619, 286, 500, 380, 7372, 13], "temperature": 0.0, "avg_logprob": -0.2991329271768786, "compression_ratio": 1.5799086757990868, "no_speech_prob": 0.0015894591342657804}, {"id": 575, "seek": 244500, "start": 2448.0, "end": 2450.0, "text": " I'm not sure what the problem is.", "tokens": [286, 478, 406, 988, 437, 264, 1154, 307, 13], "temperature": 0.0, "avg_logprob": -0.2991329271768786, "compression_ratio": 1.5799086757990868, "no_speech_prob": 0.0015894591342657804}, {"id": 576, "seek": 244500, "start": 2450.0, "end": 2452.0, "text": " I provide everything you need.", "tokens": [286, 2893, 1203, 291, 643, 13], "temperature": 0.0, "avg_logprob": -0.2991329271768786, "compression_ratio": 1.5799086757990868, "no_speech_prob": 0.0015894591342657804}, {"id": 577, "seek": 244500, "start": 2452.0, "end": 2456.0, "text": " Take my binders and put them in your packaging, whatever.", "tokens": [3664, 452, 14786, 433, 293, 829, 552, 294, 428, 16836, 11, 2035, 13], "temperature": 0.0, "avg_logprob": -0.2991329271768786, "compression_ratio": 1.5799086757990868, "no_speech_prob": 0.0015894591342657804}, {"id": 578, "seek": 244500, "start": 2456.0, "end": 2459.0, "text": " These conditions don't like to be in Go,", "tokens": [1981, 4487, 500, 380, 411, 281, 312, 294, 1037, 11], "temperature": 0.0, "avg_logprob": -0.2991329271768786, "compression_ratio": 1.5799086757990868, "no_speech_prob": 0.0015894591342657804}, {"id": 579, "seek": 244500, "start": 2459.0, "end": 2464.0, "text": " because either it should be a binary or the long internet.", "tokens": [570, 2139, 309, 820, 312, 257, 17434, 420, 264, 938, 4705, 13], "temperature": 0.0, "avg_logprob": -0.2991329271768786, "compression_ratio": 1.5799086757990868, "no_speech_prob": 0.0015894591342657804}, {"id": 580, "seek": 244500, "start": 2464.0, "end": 2466.0, "text": " Not internet.", "tokens": [1726, 4705, 13], "temperature": 0.0, "avg_logprob": -0.2991329271768786, "compression_ratio": 1.5799086757990868, "no_speech_prob": 0.0015894591342657804}, {"id": 581, "seek": 244500, "start": 2466.0, "end": 2469.0, "text": " No, no, not internet.", "tokens": [883, 11, 572, 11, 406, 4705, 13], "temperature": 0.0, "avg_logprob": -0.2991329271768786, "compression_ratio": 1.5799086757990868, "no_speech_prob": 0.0015894591342657804}, {"id": 582, "seek": 244500, "start": 2469.0, "end": 2474.0, "text": " There are only four dependencies for a new created application", "tokens": [821, 366, 787, 1451, 36606, 337, 257, 777, 2942, 3861], "temperature": 0.0, "avg_logprob": -0.2991329271768786, "compression_ratio": 1.5799086757990868, "no_speech_prob": 0.0015894591342657804}, {"id": 583, "seek": 247400, "start": 2474.0, "end": 2476.0, "text": " to connect to the possible scale.", "tokens": [281, 1745, 281, 264, 1944, 4373, 13], "temperature": 0.0, "avg_logprob": -0.21473103353421982, "compression_ratio": 1.4792899408284024, "no_speech_prob": 0.0006108510424382985}, {"id": 584, "seek": 247400, "start": 2476.0, "end": 2480.0, "text": " There are only one direct dependency is PGX,", "tokens": [821, 366, 787, 472, 2047, 33621, 307, 40975, 55, 11], "temperature": 0.0, "avg_logprob": -0.21473103353421982, "compression_ratio": 1.4792899408284024, "no_speech_prob": 0.0006108510424382985}, {"id": 585, "seek": 247400, "start": 2480.0, "end": 2483.0, "text": " and there is only four indirect dependency.", "tokens": [293, 456, 307, 787, 1451, 19523, 33621, 13], "temperature": 0.0, "avg_logprob": -0.21473103353421982, "compression_ratio": 1.4792899408284024, "no_speech_prob": 0.0006108510424382985}, {"id": 586, "seek": 247400, "start": 2483.0, "end": 2487.0, "text": " Two of them are libraries from Google.", "tokens": [4453, 295, 552, 366, 15148, 490, 3329, 13], "temperature": 0.0, "avg_logprob": -0.21473103353421982, "compression_ratio": 1.4792899408284024, "no_speech_prob": 0.0006108510424382985}, {"id": 587, "seek": 247400, "start": 2487.0, "end": 2492.0, "text": " One of them library from KOROS.", "tokens": [1485, 295, 552, 6405, 490, 591, 2483, 4367, 13], "temperature": 0.0, "avg_logprob": -0.21473103353421982, "compression_ratio": 1.4792899408284024, "no_speech_prob": 0.0006108510424382985}, {"id": 588, "seek": 247400, "start": 2492.0, "end": 2494.0, "text": " I don't remember.", "tokens": [286, 500, 380, 1604, 13], "temperature": 0.0, "avg_logprob": -0.21473103353421982, "compression_ratio": 1.4792899408284024, "no_speech_prob": 0.0006108510424382985}, {"id": 589, "seek": 247400, "start": 2494.0, "end": 2498.0, "text": " And one of them is by the same author,", "tokens": [400, 472, 295, 552, 307, 538, 264, 912, 3793, 11], "temperature": 0.0, "avg_logprob": -0.21473103353421982, "compression_ratio": 1.4792899408284024, "no_speech_prob": 0.0006108510424382985}, {"id": 590, "seek": 249800, "start": 2498.0, "end": 2504.0, "text": " because he's using this package in other way.", "tokens": [570, 415, 311, 1228, 341, 7372, 294, 661, 636, 13], "temperature": 0.0, "avg_logprob": -0.2049012285597781, "compression_ratio": 1.232, "no_speech_prob": 0.000856950820889324}, {"id": 591, "seek": 249800, "start": 2504.0, "end": 2509.0, "text": " Yeah, so, questions?", "tokens": [865, 11, 370, 11, 1651, 30], "temperature": 0.0, "avg_logprob": -0.2049012285597781, "compression_ratio": 1.232, "no_speech_prob": 0.000856950820889324}, {"id": 592, "seek": 249800, "start": 2519.0, "end": 2520.0, "text": " Hi.", "tokens": [2421, 13], "temperature": 0.0, "avg_logprob": -0.2049012285597781, "compression_ratio": 1.232, "no_speech_prob": 0.000856950820889324}, {"id": 593, "seek": 249800, "start": 2520.0, "end": 2521.0, "text": " A couple of slides back.", "tokens": [316, 1916, 295, 9788, 646, 13], "temperature": 0.0, "avg_logprob": -0.2049012285597781, "compression_ratio": 1.232, "no_speech_prob": 0.000856950820889324}, {"id": 594, "seek": 249800, "start": 2521.0, "end": 2525.0, "text": " You went to a certain functionality where you were asking,", "tokens": [509, 1437, 281, 257, 1629, 14980, 689, 291, 645, 3365, 11], "temperature": 0.0, "avg_logprob": -0.2049012285597781, "compression_ratio": 1.232, "no_speech_prob": 0.000856950820889324}, {"id": 595, "seek": 252500, "start": 2525.0, "end": 2528.0, "text": " do you do select, and then you put in a structure", "tokens": [360, 291, 360, 3048, 11, 293, 550, 291, 829, 294, 257, 3877], "temperature": 0.0, "avg_logprob": -0.22787104308150197, "compression_ratio": 1.7377049180327868, "no_speech_prob": 0.0003289390879217535}, {"id": 596, "seek": 252500, "start": 2528.0, "end": 2531.0, "text": " in order to get the results from?", "tokens": [294, 1668, 281, 483, 264, 3542, 490, 30], "temperature": 0.0, "avg_logprob": -0.22787104308150197, "compression_ratio": 1.7377049180327868, "no_speech_prob": 0.0003289390879217535}, {"id": 597, "seek": 252500, "start": 2531.0, "end": 2533.0, "text": " Yeah, couple of back.", "tokens": [865, 11, 1916, 295, 646, 13], "temperature": 0.0, "avg_logprob": -0.22787104308150197, "compression_ratio": 1.7377049180327868, "no_speech_prob": 0.0003289390879217535}, {"id": 598, "seek": 252500, "start": 2533.0, "end": 2536.0, "text": " I have a question on that one.", "tokens": [286, 362, 257, 1168, 322, 300, 472, 13], "temperature": 0.0, "avg_logprob": -0.22787104308150197, "compression_ratio": 1.7377049180327868, "no_speech_prob": 0.0003289390879217535}, {"id": 599, "seek": 252500, "start": 2536.0, "end": 2537.0, "text": " Yeah, that's one.", "tokens": [865, 11, 300, 311, 472, 13], "temperature": 0.0, "avg_logprob": -0.22787104308150197, "compression_ratio": 1.7377049180327868, "no_speech_prob": 0.0003289390879217535}, {"id": 600, "seek": 252500, "start": 2537.0, "end": 2538.0, "text": " Yeah, that's one.", "tokens": [865, 11, 300, 311, 472, 13], "temperature": 0.0, "avg_logprob": -0.22787104308150197, "compression_ratio": 1.7377049180327868, "no_speech_prob": 0.0003289390879217535}, {"id": 601, "seek": 252500, "start": 2538.0, "end": 2539.0, "text": " Exactly.", "tokens": [7587, 13], "temperature": 0.0, "avg_logprob": -0.22787104308150197, "compression_ratio": 1.7377049180327868, "no_speech_prob": 0.0003289390879217535}, {"id": 602, "seek": 252500, "start": 2539.0, "end": 2542.0, "text": " So you're asking a select star, and then some stuff,", "tokens": [407, 291, 434, 3365, 257, 3048, 3543, 11, 293, 550, 512, 1507, 11], "temperature": 0.0, "avg_logprob": -0.22787104308150197, "compression_ratio": 1.7377049180327868, "no_speech_prob": 0.0003289390879217535}, {"id": 603, "seek": 252500, "start": 2542.0, "end": 2544.0, "text": " and then you ask it by the rows.", "tokens": [293, 550, 291, 1029, 309, 538, 264, 13241, 13], "temperature": 0.0, "avg_logprob": -0.22787104308150197, "compression_ratio": 1.7377049180327868, "no_speech_prob": 0.0003289390879217535}, {"id": 604, "seek": 252500, "start": 2544.0, "end": 2548.0, "text": " Does the actual connection, so if you're running this", "tokens": [4402, 264, 3539, 4984, 11, 370, 498, 291, 434, 2614, 341], "temperature": 0.0, "avg_logprob": -0.22787104308150197, "compression_ratio": 1.7377049180327868, "no_speech_prob": 0.0003289390879217535}, {"id": 605, "seek": 252500, "start": 2548.0, "end": 2551.0, "text": " on one machine, you're running Postgres on another machine,", "tokens": [322, 472, 3479, 11, 291, 434, 2614, 10223, 45189, 322, 1071, 3479, 11], "temperature": 0.0, "avg_logprob": -0.22787104308150197, "compression_ratio": 1.7377049180327868, "no_speech_prob": 0.0003289390879217535}, {"id": 606, "seek": 252500, "start": 2551.0, "end": 2553.0, "text": " there is a network, of course, in between.", "tokens": [456, 307, 257, 3209, 11, 295, 1164, 11, 294, 1296, 13], "temperature": 0.0, "avg_logprob": -0.22787104308150197, "compression_ratio": 1.7377049180327868, "no_speech_prob": 0.0003289390879217535}, {"id": 607, "seek": 255300, "start": 2553.0, "end": 2555.0, "text": " There's data going back and forth.", "tokens": [821, 311, 1412, 516, 646, 293, 5220, 13], "temperature": 0.0, "avg_logprob": -0.1617580439081255, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.0004657187673728913}, {"id": 608, "seek": 255300, "start": 2555.0, "end": 2558.0, "text": " Is all the data being sent from Postgres SQL server", "tokens": [1119, 439, 264, 1412, 885, 2279, 490, 10223, 45189, 19200, 7154], "temperature": 0.0, "avg_logprob": -0.1617580439081255, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.0004657187673728913}, {"id": 609, "seek": 255300, "start": 2558.0, "end": 2560.0, "text": " to your Go program or not?", "tokens": [281, 428, 1037, 1461, 420, 406, 30], "temperature": 0.0, "avg_logprob": -0.1617580439081255, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.0004657187673728913}, {"id": 610, "seek": 255300, "start": 2560.0, "end": 2562.0, "text": " The reason I'm asking this is because, let's say,", "tokens": [440, 1778, 286, 478, 3365, 341, 307, 570, 11, 718, 311, 584, 11], "temperature": 0.0, "avg_logprob": -0.1617580439081255, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.0004657187673728913}, {"id": 611, "seek": 255300, "start": 2562.0, "end": 2564.0, "text": " there's a fourth field, which is, let's say,", "tokens": [456, 311, 257, 6409, 2519, 11, 597, 307, 11, 718, 311, 584, 11], "temperature": 0.0, "avg_logprob": -0.1617580439081255, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.0004657187673728913}, {"id": 612, "seek": 255300, "start": 2564.0, "end": 2567.0, "text": " a huge JSON field or a huge binary field,", "tokens": [257, 2603, 31828, 2519, 420, 257, 2603, 17434, 2519, 11], "temperature": 0.0, "avg_logprob": -0.1617580439081255, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.0004657187673728913}, {"id": 613, "seek": 255300, "start": 2567.0, "end": 2570.0, "text": " which contains like a megabyte of data per record.", "tokens": [597, 8306, 411, 257, 10816, 34529, 295, 1412, 680, 2136, 13], "temperature": 0.0, "avg_logprob": -0.1617580439081255, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.0004657187673728913}, {"id": 614, "seek": 255300, "start": 2570.0, "end": 2572.0, "text": " Is it then sending, if I'm asking 100 records,", "tokens": [1119, 309, 550, 7750, 11, 498, 286, 478, 3365, 2319, 7724, 11], "temperature": 0.0, "avg_logprob": -0.1617580439081255, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.0004657187673728913}, {"id": 615, "seek": 255300, "start": 2572.0, "end": 2575.0, "text": " a thousand records, is it sending a gigabyte over the network,", "tokens": [257, 4714, 7724, 11, 307, 309, 7750, 257, 8741, 34529, 670, 264, 3209, 11], "temperature": 0.0, "avg_logprob": -0.1617580439081255, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.0004657187673728913}, {"id": 616, "seek": 255300, "start": 2575.0, "end": 2577.0, "text": " or is it only sending those three fields?", "tokens": [420, 307, 309, 787, 7750, 729, 1045, 7909, 30], "temperature": 0.0, "avg_logprob": -0.1617580439081255, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.0004657187673728913}, {"id": 617, "seek": 255300, "start": 2577.0, "end": 2578.0, "text": " Okay, I got you.", "tokens": [1033, 11, 286, 658, 291, 13], "temperature": 0.0, "avg_logprob": -0.1617580439081255, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.0004657187673728913}, {"id": 618, "seek": 255300, "start": 2578.0, "end": 2580.0, "text": " Yeah, thank you.", "tokens": [865, 11, 1309, 291, 13], "temperature": 0.0, "avg_logprob": -0.1617580439081255, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.0004657187673728913}, {"id": 619, "seek": 255300, "start": 2580.0, "end": 2581.0, "text": " Very good question.", "tokens": [4372, 665, 1168, 13], "temperature": 0.0, "avg_logprob": -0.1617580439081255, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.0004657187673728913}, {"id": 620, "seek": 258100, "start": 2581.0, "end": 2586.0, "text": " So in this particular case, there shouldn't be star,", "tokens": [407, 294, 341, 1729, 1389, 11, 456, 4659, 380, 312, 3543, 11], "temperature": 0.0, "avg_logprob": -0.1306810626735935, "compression_ratio": 1.3892215568862276, "no_speech_prob": 0.0005397656350396574}, {"id": 621, "seek": 258100, "start": 2586.0, "end": 2588.0, "text": " first of all.", "tokens": [700, 295, 439, 13], "temperature": 0.0, "avg_logprob": -0.1306810626735935, "compression_ratio": 1.3892215568862276, "no_speech_prob": 0.0005397656350396574}, {"id": 622, "seek": 258100, "start": 2588.0, "end": 2591.0, "text": " We should always list columns we want to have.", "tokens": [492, 820, 1009, 1329, 13766, 321, 528, 281, 362, 13], "temperature": 0.0, "avg_logprob": -0.1306810626735935, "compression_ratio": 1.3892215568862276, "no_speech_prob": 0.0005397656350396574}, {"id": 623, "seek": 258100, "start": 2591.0, "end": 2596.0, "text": " I'm just too lazy, and this is not my code.", "tokens": [286, 478, 445, 886, 14847, 11, 293, 341, 307, 406, 452, 3089, 13], "temperature": 0.0, "avg_logprob": -0.1306810626735935, "compression_ratio": 1.3892215568862276, "no_speech_prob": 0.0005397656350396574}, {"id": 624, "seek": 258100, "start": 2596.0, "end": 2601.0, "text": " But it's like, you know, it shows.", "tokens": [583, 309, 311, 411, 11, 291, 458, 11, 309, 3110, 13], "temperature": 0.0, "avg_logprob": -0.1306810626735935, "compression_ratio": 1.3892215568862276, "no_speech_prob": 0.0005397656350396574}, {"id": 625, "seek": 258100, "start": 2601.0, "end": 2602.0, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.1306810626735935, "compression_ratio": 1.3892215568862276, "no_speech_prob": 0.0005397656350396574}, {"id": 626, "seek": 258100, "start": 2602.0, "end": 2605.0, "text": " So in this case, yes, everything.", "tokens": [407, 294, 341, 1389, 11, 2086, 11, 1203, 13], "temperature": 0.0, "avg_logprob": -0.1306810626735935, "compression_ratio": 1.3892215568862276, "no_speech_prob": 0.0005397656350396574}, {"id": 627, "seek": 260500, "start": 2605.0, "end": 2615.0, "text": " Can you do it automatically?", "tokens": [1664, 291, 360, 309, 6772, 30], "temperature": 0.0, "avg_logprob": -0.2774709841100181, "compression_ratio": 1.2201834862385321, "no_speech_prob": 0.0005477636586874723}, {"id": 628, "seek": 260500, "start": 2615.0, "end": 2623.0, "text": " Can we add columns from a database automatically?", "tokens": [1664, 321, 909, 13766, 490, 257, 8149, 6772, 30], "temperature": 0.0, "avg_logprob": -0.2774709841100181, "compression_ratio": 1.2201834862385321, "no_speech_prob": 0.0005477636586874723}, {"id": 629, "seek": 260500, "start": 2623.0, "end": 2624.0, "text": " Yes, we can.", "tokens": [1079, 11, 321, 393, 13], "temperature": 0.0, "avg_logprob": -0.2774709841100181, "compression_ratio": 1.2201834862385321, "no_speech_prob": 0.0005477636586874723}, {"id": 630, "seek": 260500, "start": 2624.0, "end": 2633.0, "text": " But for that, we should use SQLC package,", "tokens": [583, 337, 300, 11, 321, 820, 764, 19200, 34, 7372, 11], "temperature": 0.0, "avg_logprob": -0.2774709841100181, "compression_ratio": 1.2201834862385321, "no_speech_prob": 0.0005477636586874723}, {"id": 631, "seek": 263300, "start": 2633.0, "end": 2635.0, "text": " which is exactly for that.", "tokens": [597, 307, 2293, 337, 300, 13], "temperature": 0.0, "avg_logprob": -0.1949470684092532, "compression_ratio": 1.5454545454545454, "no_speech_prob": 9.594483708497137e-05}, {"id": 632, "seek": 263300, "start": 2635.0, "end": 2640.0, "text": " So it is pre-built or hooks or whatever.", "tokens": [407, 309, 307, 659, 12, 23018, 420, 26485, 420, 2035, 13], "temperature": 0.0, "avg_logprob": -0.1949470684092532, "compression_ratio": 1.5454545454545454, "no_speech_prob": 9.594483708497137e-05}, {"id": 633, "seek": 263300, "start": 2640.0, "end": 2646.0, "text": " So when you say, go build, you have special SQL files.", "tokens": [407, 562, 291, 584, 11, 352, 1322, 11, 291, 362, 2121, 19200, 7098, 13], "temperature": 0.0, "avg_logprob": -0.1949470684092532, "compression_ratio": 1.5454545454545454, "no_speech_prob": 9.594483708497137e-05}, {"id": 634, "seek": 263300, "start": 2646.0, "end": 2650.0, "text": " Like, I want this field from that and that,", "tokens": [1743, 11, 286, 528, 341, 2519, 490, 300, 293, 300, 11], "temperature": 0.0, "avg_logprob": -0.1949470684092532, "compression_ratio": 1.5454545454545454, "no_speech_prob": 9.594483708497137e-05}, {"id": 635, "seek": 263300, "start": 2650.0, "end": 2654.0, "text": " and it will go through it, and it will build automatically", "tokens": [293, 309, 486, 352, 807, 309, 11, 293, 309, 486, 1322, 6772], "temperature": 0.0, "avg_logprob": -0.1949470684092532, "compression_ratio": 1.5454545454545454, "no_speech_prob": 9.594483708497137e-05}, {"id": 636, "seek": 263300, "start": 2654.0, "end": 2659.0, "text": " the appropriate structures for go, and then you can use it.", "tokens": [264, 6854, 9227, 337, 352, 11, 293, 550, 291, 393, 764, 309, 13], "temperature": 0.0, "avg_logprob": -0.1949470684092532, "compression_ratio": 1.5454545454545454, "no_speech_prob": 9.594483708497137e-05}, {"id": 637, "seek": 263300, "start": 2659.0, "end": 2661.0, "text": " Yeah, it's just a lot of information.", "tokens": [865, 11, 309, 311, 445, 257, 688, 295, 1589, 13], "temperature": 0.0, "avg_logprob": -0.1949470684092532, "compression_ratio": 1.5454545454545454, "no_speech_prob": 9.594483708497137e-05}, {"id": 638, "seek": 266100, "start": 2661.0, "end": 2665.0, "text": " I cannot, like, put it into the one talk.", "tokens": [286, 2644, 11, 411, 11, 829, 309, 666, 264, 472, 751, 13], "temperature": 0.0, "avg_logprob": -0.22432306538457455, "compression_ratio": 1.455621301775148, "no_speech_prob": 0.001069942838512361}, {"id": 639, "seek": 266100, "start": 2665.0, "end": 2666.0, "text": " Yeah, but yeah.", "tokens": [865, 11, 457, 1338, 13], "temperature": 0.0, "avg_logprob": -0.22432306538457455, "compression_ratio": 1.455621301775148, "no_speech_prob": 0.001069942838512361}, {"id": 640, "seek": 266100, "start": 2666.0, "end": 2672.0, "text": " About if we are loading at once, yes, we do in this case.", "tokens": [7769, 498, 321, 366, 15114, 412, 1564, 11, 2086, 11, 321, 360, 294, 341, 1389, 13], "temperature": 0.0, "avg_logprob": -0.22432306538457455, "compression_ratio": 1.455621301775148, "no_speech_prob": 0.001069942838512361}, {"id": 641, "seek": 266100, "start": 2672.0, "end": 2680.0, "text": " But the Postgres protocol itself supports row by row functionality,", "tokens": [583, 264, 10223, 45189, 10336, 2564, 9346, 5386, 538, 5386, 14980, 11], "temperature": 0.0, "avg_logprob": -0.22432306538457455, "compression_ratio": 1.455621301775148, "no_speech_prob": 0.001069942838512361}, {"id": 642, "seek": 266100, "start": 2680.0, "end": 2685.0, "text": " and it's possible to use that functionality with this package.", "tokens": [293, 309, 311, 1944, 281, 764, 300, 14980, 365, 341, 7372, 13], "temperature": 0.0, "avg_logprob": -0.22432306538457455, "compression_ratio": 1.455621301775148, "no_speech_prob": 0.001069942838512361}, {"id": 643, "seek": 268500, "start": 2685.0, "end": 2693.0, "text": " So you can, like, yeah, say that.", "tokens": [407, 291, 393, 11, 411, 11, 1338, 11, 584, 300, 13], "temperature": 0.0, "avg_logprob": -0.10076003946283812, "compression_ratio": 1.5126903553299493, "no_speech_prob": 0.00546273123472929}, {"id": 644, "seek": 268500, "start": 2693.0, "end": 2694.0, "text": " Hello.", "tokens": [2425, 13], "temperature": 0.0, "avg_logprob": -0.10076003946283812, "compression_ratio": 1.5126903553299493, "no_speech_prob": 0.00546273123472929}, {"id": 645, "seek": 268500, "start": 2694.0, "end": 2695.0, "text": " Thank you for the talk.", "tokens": [1044, 291, 337, 264, 751, 13], "temperature": 0.0, "avg_logprob": -0.10076003946283812, "compression_ratio": 1.5126903553299493, "no_speech_prob": 0.00546273123472929}, {"id": 646, "seek": 268500, "start": 2695.0, "end": 2698.0, "text": " I have one question about this driver.", "tokens": [286, 362, 472, 1168, 466, 341, 6787, 13], "temperature": 0.0, "avg_logprob": -0.10076003946283812, "compression_ratio": 1.5126903553299493, "no_speech_prob": 0.00546273123472929}, {"id": 647, "seek": 268500, "start": 2698.0, "end": 2702.0, "text": " Actually, it's kind of only way to work with Postgres,", "tokens": [5135, 11, 309, 311, 733, 295, 787, 636, 281, 589, 365, 10223, 45189, 11], "temperature": 0.0, "avg_logprob": -0.10076003946283812, "compression_ratio": 1.5126903553299493, "no_speech_prob": 0.00546273123472929}, {"id": 648, "seek": 268500, "start": 2702.0, "end": 2703.0, "text": " for my opinion.", "tokens": [337, 452, 4800, 13], "temperature": 0.0, "avg_logprob": -0.10076003946283812, "compression_ratio": 1.5126903553299493, "no_speech_prob": 0.00546273123472929}, {"id": 649, "seek": 268500, "start": 2703.0, "end": 2708.0, "text": " And I'm a little bit worried that this driver is not supported", "tokens": [400, 286, 478, 257, 707, 857, 5804, 300, 341, 6787, 307, 406, 8104], "temperature": 0.0, "avg_logprob": -0.10076003946283812, "compression_ratio": 1.5126903553299493, "no_speech_prob": 0.00546273123472929}, {"id": 650, "seek": 268500, "start": 2708.0, "end": 2711.0, "text": " by Postgres community, let's say.", "tokens": [538, 10223, 45189, 1768, 11, 718, 311, 584, 13], "temperature": 0.0, "avg_logprob": -0.10076003946283812, "compression_ratio": 1.5126903553299493, "no_speech_prob": 0.00546273123472929}, {"id": 651, "seek": 268500, "start": 2711.0, "end": 2713.0, "text": " It's supported by someone.", "tokens": [467, 311, 8104, 538, 1580, 13], "temperature": 0.0, "avg_logprob": -0.10076003946283812, "compression_ratio": 1.5126903553299493, "no_speech_prob": 0.00546273123472929}, {"id": 652, "seek": 271300, "start": 2713.0, "end": 2717.0, "text": " And what is the life cycle of this software?", "tokens": [400, 437, 307, 264, 993, 6586, 295, 341, 4722, 30], "temperature": 0.0, "avg_logprob": -0.14186337210915306, "compression_ratio": 1.63135593220339, "no_speech_prob": 0.0024103778414428234}, {"id": 653, "seek": 271300, "start": 2717.0, "end": 2719.0, "text": " And maybe it will die.", "tokens": [400, 1310, 309, 486, 978, 13], "temperature": 0.0, "avg_logprob": -0.14186337210915306, "compression_ratio": 1.63135593220339, "no_speech_prob": 0.0024103778414428234}, {"id": 654, "seek": 271300, "start": 2719.0, "end": 2722.0, "text": " You say, how is about new features to it,", "tokens": [509, 584, 11, 577, 307, 466, 777, 4122, 281, 309, 11], "temperature": 0.0, "avg_logprob": -0.14186337210915306, "compression_ratio": 1.63135593220339, "no_speech_prob": 0.0024103778414428234}, {"id": 655, "seek": 271300, "start": 2722.0, "end": 2725.0, "text": " and all this question arises when you work with it,", "tokens": [293, 439, 341, 1168, 27388, 562, 291, 589, 365, 309, 11], "temperature": 0.0, "avg_logprob": -0.14186337210915306, "compression_ratio": 1.63135593220339, "no_speech_prob": 0.0024103778414428234}, {"id": 656, "seek": 271300, "start": 2725.0, "end": 2729.0, "text": " because if your management says, okay, let's use Java,", "tokens": [570, 498, 428, 4592, 1619, 11, 1392, 11, 718, 311, 764, 10745, 11], "temperature": 0.0, "avg_logprob": -0.14186337210915306, "compression_ratio": 1.63135593220339, "no_speech_prob": 0.0024103778414428234}, {"id": 657, "seek": 271300, "start": 2729.0, "end": 2732.0, "text": " and in Java it's kind of stable, this Postgres driver,", "tokens": [293, 294, 10745, 309, 311, 733, 295, 8351, 11, 341, 10223, 45189, 6787, 11], "temperature": 0.0, "avg_logprob": -0.14186337210915306, "compression_ratio": 1.63135593220339, "no_speech_prob": 0.0024103778414428234}, {"id": 658, "seek": 271300, "start": 2732.0, "end": 2735.0, "text": " and you know that you always have the new version.", "tokens": [293, 291, 458, 300, 291, 1009, 362, 264, 777, 3037, 13], "temperature": 0.0, "avg_logprob": -0.14186337210915306, "compression_ratio": 1.63135593220339, "no_speech_prob": 0.0024103778414428234}, {"id": 659, "seek": 271300, "start": 2735.0, "end": 2737.0, "text": " What is about this software?", "tokens": [708, 307, 466, 341, 4722, 30], "temperature": 0.0, "avg_logprob": -0.14186337210915306, "compression_ratio": 1.63135593220339, "no_speech_prob": 0.0024103778414428234}, {"id": 660, "seek": 271300, "start": 2737.0, "end": 2738.0, "text": " Yeah, thank you for the question.", "tokens": [865, 11, 1309, 291, 337, 264, 1168, 13], "temperature": 0.0, "avg_logprob": -0.14186337210915306, "compression_ratio": 1.63135593220339, "no_speech_prob": 0.0024103778414428234}, {"id": 661, "seek": 273800, "start": 2738.0, "end": 2743.0, "text": " So versioning and owner, who is owner, and that kind of stuff.", "tokens": [407, 3037, 278, 293, 7289, 11, 567, 307, 7289, 11, 293, 300, 733, 295, 1507, 13], "temperature": 0.0, "avg_logprob": -0.23472876297800163, "compression_ratio": 1.3148148148148149, "no_speech_prob": 0.00037594756577163935}, {"id": 662, "seek": 273800, "start": 2743.0, "end": 2747.0, "text": " So as a Postgres community, we support on the C library,", "tokens": [407, 382, 257, 10223, 45189, 1768, 11, 321, 1406, 322, 264, 383, 6405, 11], "temperature": 0.0, "avg_logprob": -0.23472876297800163, "compression_ratio": 1.3148148148148149, "no_speech_prob": 0.00037594756577163935}, {"id": 663, "seek": 273800, "start": 2747.0, "end": 2755.0, "text": " which is live PQ, and Java, which is JDBC, right?", "tokens": [597, 307, 1621, 430, 48, 11, 293, 10745, 11, 597, 307, 37082, 7869, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.23472876297800163, "compression_ratio": 1.3148148148148149, "no_speech_prob": 0.00037594756577163935}, {"id": 664, "seek": 273800, "start": 2755.0, "end": 2756.0, "text": " That's all.", "tokens": [663, 311, 439, 13], "temperature": 0.0, "avg_logprob": -0.23472876297800163, "compression_ratio": 1.3148148148148149, "no_speech_prob": 0.00037594756577163935}, {"id": 665, "seek": 273800, "start": 2756.0, "end": 2759.0, "text": " All others?", "tokens": [1057, 2357, 30], "temperature": 0.0, "avg_logprob": -0.23472876297800163, "compression_ratio": 1.3148148148148149, "no_speech_prob": 0.00037594756577163935}, {"id": 666, "seek": 273800, "start": 2759.0, "end": 2760.0, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.23472876297800163, "compression_ratio": 1.3148148148148149, "no_speech_prob": 0.00037594756577163935}, {"id": 667, "seek": 273800, "start": 2760.0, "end": 2763.0, "text": " Who uses C++?", "tokens": [2102, 4960, 383, 25472, 30], "temperature": 0.0, "avg_logprob": -0.23472876297800163, "compression_ratio": 1.3148148148148149, "no_speech_prob": 0.00037594756577163935}, {"id": 668, "seek": 276300, "start": 2763.0, "end": 2768.0, "text": " All other libraries are maintained by someone.", "tokens": [1057, 661, 15148, 366, 17578, 538, 1580, 13], "temperature": 0.0, "avg_logprob": -0.11344288616645627, "compression_ratio": 1.5026737967914439, "no_speech_prob": 0.00016615710046608}, {"id": 669, "seek": 276300, "start": 2768.0, "end": 2773.0, "text": " By the way, live PQ is not a standard library", "tokens": [3146, 264, 636, 11, 1621, 430, 48, 307, 406, 257, 3832, 6405], "temperature": 0.0, "avg_logprob": -0.11344288616645627, "compression_ratio": 1.5026737967914439, "no_speech_prob": 0.00016615710046608}, {"id": 670, "seek": 276300, "start": 2773.0, "end": 2775.0, "text": " in terms of made by go.", "tokens": [294, 2115, 295, 1027, 538, 352, 13], "temperature": 0.0, "avg_logprob": -0.11344288616645627, "compression_ratio": 1.5026737967914439, "no_speech_prob": 0.00016615710046608}, {"id": 671, "seek": 276300, "start": 2775.0, "end": 2779.0, "text": " It's also maintained by one person.", "tokens": [467, 311, 611, 17578, 538, 472, 954, 13], "temperature": 0.0, "avg_logprob": -0.11344288616645627, "compression_ratio": 1.5026737967914439, "no_speech_prob": 0.00016615710046608}, {"id": 672, "seek": 276300, "start": 2779.0, "end": 2784.0, "text": " So how we do in this case, we just fork it and use it", "tokens": [407, 577, 321, 360, 294, 341, 1389, 11, 321, 445, 17716, 309, 293, 764, 309], "temperature": 0.0, "avg_logprob": -0.11344288616645627, "compression_ratio": 1.5026737967914439, "no_speech_prob": 0.00016615710046608}, {"id": 673, "seek": 276300, "start": 2784.0, "end": 2786.0, "text": " if you want something new.", "tokens": [498, 291, 528, 746, 777, 13], "temperature": 0.0, "avg_logprob": -0.11344288616645627, "compression_ratio": 1.5026737967914439, "no_speech_prob": 0.00016615710046608}, {"id": 674, "seek": 276300, "start": 2786.0, "end": 2790.0, "text": " If I did everything better than the maintainer,", "tokens": [759, 286, 630, 1203, 1101, 813, 264, 6909, 260, 11], "temperature": 0.0, "avg_logprob": -0.11344288616645627, "compression_ratio": 1.5026737967914439, "no_speech_prob": 0.00016615710046608}, {"id": 675, "seek": 279000, "start": 2790.0, "end": 2796.0, "text": " the owner of the PGX will accept my progress proposals", "tokens": [264, 7289, 295, 264, 430, 38, 55, 486, 3241, 452, 4205, 20198], "temperature": 0.0, "avg_logprob": -0.21131789684295654, "compression_ratio": 1.4033149171270718, "no_speech_prob": 0.0017819275381043553}, {"id": 676, "seek": 279000, "start": 2796.0, "end": 2798.0, "text": " and we are stinked, right?", "tokens": [293, 321, 366, 35843, 292, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.21131789684295654, "compression_ratio": 1.4033149171270718, "no_speech_prob": 0.0017819275381043553}, {"id": 677, "seek": 279000, "start": 2798.0, "end": 2810.0, "text": " If not, I will beat them and I will be popular.", "tokens": [759, 406, 11, 286, 486, 4224, 552, 293, 286, 486, 312, 3743, 13], "temperature": 0.0, "avg_logprob": -0.21131789684295654, "compression_ratio": 1.4033149171270718, "no_speech_prob": 0.0017819275381043553}, {"id": 678, "seek": 279000, "start": 2810.0, "end": 2814.0, "text": " I have a question regarding testing strategies in CI CD.", "tokens": [286, 362, 257, 1168, 8595, 4997, 9029, 294, 37777, 6743, 13], "temperature": 0.0, "avg_logprob": -0.21131789684295654, "compression_ratio": 1.4033149171270718, "no_speech_prob": 0.0017819275381043553}, {"id": 679, "seek": 279000, "start": 2814.0, "end": 2818.0, "text": " So you have shown that it's possible to mock Postgres scale, right?", "tokens": [407, 291, 362, 4898, 300, 309, 311, 1944, 281, 17362, 10223, 45189, 4373, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.21131789684295654, "compression_ratio": 1.4033149171270718, "no_speech_prob": 0.0017819275381043553}, {"id": 680, "seek": 281800, "start": 2818.0, "end": 2821.0, "text": " But sometimes you are relying on some feature of Postgres scale,", "tokens": [583, 2171, 291, 366, 24140, 322, 512, 4111, 295, 10223, 45189, 4373, 11], "temperature": 0.0, "avg_logprob": -0.21281164726324842, "compression_ratio": 1.6887966804979253, "no_speech_prob": 0.003044338431209326}, {"id": 681, "seek": 281800, "start": 2821.0, "end": 2824.0, "text": " or possibly you are relying on some extension Postgres.", "tokens": [420, 6264, 291, 366, 24140, 322, 512, 10320, 10223, 45189, 13], "temperature": 0.0, "avg_logprob": -0.21281164726324842, "compression_ratio": 1.6887966804979253, "no_speech_prob": 0.003044338431209326}, {"id": 682, "seek": 281800, "start": 2824.0, "end": 2826.0, "text": " Do you want to test with a real Postgres scale?", "tokens": [1144, 291, 528, 281, 1500, 365, 257, 957, 10223, 45189, 4373, 30], "temperature": 0.0, "avg_logprob": -0.21281164726324842, "compression_ratio": 1.6887966804979253, "no_speech_prob": 0.003044338431209326}, {"id": 683, "seek": 281800, "start": 2826.0, "end": 2827.0, "text": " Yes.", "tokens": [1079, 13], "temperature": 0.0, "avg_logprob": -0.21281164726324842, "compression_ratio": 1.6887966804979253, "no_speech_prob": 0.003044338431209326}, {"id": 684, "seek": 281800, "start": 2827.0, "end": 2829.0, "text": " What you can recommend, so I have seen in your CI CD,", "tokens": [708, 291, 393, 2748, 11, 370, 286, 362, 1612, 294, 428, 37777, 6743, 11], "temperature": 0.0, "avg_logprob": -0.21281164726324842, "compression_ratio": 1.6887966804979253, "no_speech_prob": 0.003044338431209326}, {"id": 685, "seek": 281800, "start": 2829.0, "end": 2832.0, "text": " you are executing some peer scale comments.", "tokens": [291, 366, 32368, 512, 15108, 4373, 3053, 13], "temperature": 0.0, "avg_logprob": -0.21281164726324842, "compression_ratio": 1.6887966804979253, "no_speech_prob": 0.003044338431209326}, {"id": 686, "seek": 281800, "start": 2832.0, "end": 2835.0, "text": " Do you have a dedicated instance for running tests?", "tokens": [1144, 291, 362, 257, 8374, 5197, 337, 2614, 6921, 30], "temperature": 0.0, "avg_logprob": -0.21281164726324842, "compression_ratio": 1.6887966804979253, "no_speech_prob": 0.003044338431209326}, {"id": 687, "seek": 281800, "start": 2835.0, "end": 2836.0, "text": " No.", "tokens": [883, 13], "temperature": 0.0, "avg_logprob": -0.21281164726324842, "compression_ratio": 1.6887966804979253, "no_speech_prob": 0.003044338431209326}, {"id": 688, "seek": 281800, "start": 2836.0, "end": 2843.0, "text": " So my GitHub actions are using pre-installed Postgres QL", "tokens": [407, 452, 23331, 5909, 366, 1228, 659, 12, 13911, 8907, 10223, 45189, 1249, 43], "temperature": 0.0, "avg_logprob": -0.21281164726324842, "compression_ratio": 1.6887966804979253, "no_speech_prob": 0.003044338431209326}, {"id": 689, "seek": 281800, "start": 2843.0, "end": 2845.0, "text": " on the GitHub workers.", "tokens": [322, 264, 23331, 5600, 13], "temperature": 0.0, "avg_logprob": -0.21281164726324842, "compression_ratio": 1.6887966804979253, "no_speech_prob": 0.003044338431209326}, {"id": 690, "seek": 284500, "start": 2845.0, "end": 2854.0, "text": " They already have Postgres 15.1 probably nowadays.", "tokens": [814, 1217, 362, 10223, 45189, 2119, 13, 16, 1391, 13434, 13], "temperature": 0.0, "avg_logprob": -0.1438149099480616, "compression_ratio": 1.3697916666666667, "no_speech_prob": 9.316766227129847e-05}, {"id": 691, "seek": 284500, "start": 2854.0, "end": 2858.0, "text": " So I'm okay if they are behind several versions.", "tokens": [407, 286, 478, 1392, 498, 436, 366, 2261, 2940, 9606, 13], "temperature": 0.0, "avg_logprob": -0.1438149099480616, "compression_ratio": 1.3697916666666667, "no_speech_prob": 9.316766227129847e-05}, {"id": 692, "seek": 284500, "start": 2858.0, "end": 2863.0, "text": " I don't need to test for a specific feature or bug or whatever.", "tokens": [286, 500, 380, 643, 281, 1500, 337, 257, 2685, 4111, 420, 7426, 420, 2035, 13], "temperature": 0.0, "avg_logprob": -0.1438149099480616, "compression_ratio": 1.3697916666666667, "no_speech_prob": 9.316766227129847e-05}, {"id": 693, "seek": 284500, "start": 2863.0, "end": 2866.0, "text": " But if I want to, in my GitHub action,", "tokens": [583, 498, 286, 528, 281, 11, 294, 452, 23331, 3069, 11], "temperature": 0.0, "avg_logprob": -0.1438149099480616, "compression_ratio": 1.3697916666666667, "no_speech_prob": 9.316766227129847e-05}, {"id": 694, "seek": 284500, "start": 2866.0, "end": 2874.0, "text": " I may specify the Docker image against which I want to test.", "tokens": [286, 815, 16500, 264, 33772, 3256, 1970, 597, 286, 528, 281, 1500, 13], "temperature": 0.0, "avg_logprob": -0.1438149099480616, "compression_ratio": 1.3697916666666667, "no_speech_prob": 9.316766227129847e-05}, {"id": 695, "seek": 287400, "start": 2874.0, "end": 2878.0, "text": " So for example, if I want to test the latest master", "tokens": [407, 337, 1365, 11, 498, 286, 528, 281, 1500, 264, 6792, 4505], "temperature": 0.0, "avg_logprob": -0.14259175693287568, "compression_ratio": 1.2734375, "no_speech_prob": 0.0002940974954981357}, {"id": 696, "seek": 287400, "start": 2878.0, "end": 2881.0, "text": " from the Postgres QL community,", "tokens": [490, 264, 10223, 45189, 1249, 43, 1768, 11], "temperature": 0.0, "avg_logprob": -0.14259175693287568, "compression_ratio": 1.2734375, "no_speech_prob": 0.0002940974954981357}, {"id": 697, "seek": 287400, "start": 2881.0, "end": 2887.0, "text": " I will build my own image docker and will run my test against it.", "tokens": [286, 486, 1322, 452, 1065, 3256, 360, 9178, 293, 486, 1190, 452, 1500, 1970, 309, 13], "temperature": 0.0, "avg_logprob": -0.14259175693287568, "compression_ratio": 1.2734375, "no_speech_prob": 0.0002940974954981357}, {"id": 698, "seek": 287400, "start": 2887.0, "end": 2895.0, "text": " And I'm fine.", "tokens": [400, 286, 478, 2489, 13], "temperature": 0.0, "avg_logprob": -0.14259175693287568, "compression_ratio": 1.2734375, "no_speech_prob": 0.0002940974954981357}, {"id": 699, "seek": 289500, "start": 2895.0, "end": 2907.0, "text": " Okay, thank you.", "tokens": [1033, 11, 1309, 291, 13], "temperature": 0.0, "avg_logprob": -0.3371132214864095, "compression_ratio": 0.6666666666666666, "no_speech_prob": 0.0023732376284897327}, {"id": 700, "seek": 290700, "start": 2907.0, "end": 2925.0, "text": " Excellent from the back. Yes.", "tokens": [50364, 16723, 490, 264, 646, 13, 1079, 13, 51264], "temperature": 0.0, "avg_logprob": -0.7122522354125976, "compression_ratio": 0.7837837837837838, "no_speech_prob": 0.003535978961735964}], "language": "en"}