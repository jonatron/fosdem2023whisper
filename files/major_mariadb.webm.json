{"text": " What's new in 11.0 and that's basically a new optimizer release, a new and new but at least the cost model is totally new. So I think that from the optimizer point this is one of the biggest milestones, the only time we did something comparable was in MariaDB 5.3 and the big change is that before one cost unit if you do, last query cost was one IO, the one IO was not really that exact, it could basically be one IO or one key read or one row read or one access to some file and that also meant and the things were not that balanced so some costs were just taking oh this sounds good, let's use that and even my SQL has that even now. So I decided to actually do something that you can measure and then that also makes it very easy to fix the optimizer that if you see that the cost is not something's milliseconds and something is off and then your justings accordingly. So and we decided to call this 11.0 because if you change things in the optimizer as drastically as we have done some plan may change, hopefully it should always be the better because now we actually have a proper cost and it's really easy to change things because almost all costs are available for the user to change. So I just think that this will be a good foundation for all future MariaDB releases. So with the optimizer the idea is to get better table combination and better plans. The old optimizer was actually pretty good in deciding things for simple things because if it found a good index it would use it and so on but when you had to decide that should I use this index or this index and this index I could use with the index and the lookup and the other one not, their things started to fall apart and also cost between different engines were not taking into account. The only one who had some information was the heap table although the ones were more or less the same. So I wanted to fix that and also allow people to function the optimizer. So what the new optimizer should be able to do, it should be able to use the different methods to access rows which is table scan, index scan, index merge and hash and be able to choose those correctly what is optimal for things. And I don't, only those who have complex queries should see a big difference. And I don't know how many user use optimizer trace that was added to MariaDB 10.4 but I couldn't have done this work without that because that shows me exactly how the planner is doing and we have, I've been able to use it to find out where the optimizer calculates things wrong and as part of 11.0 I've been, lots of things added to it so it's very easy to know look at the plan and see if the optimizer does something wrong. There's lots and lots of bug fixes related to optimizer like selectivity, you couldn't use selectivity level four at all before, sometimes the selectivity would become bigger than one which means that the optimizer would assume that you will get more rows when you have condition instead of less rows. So all that should be fixed. And we also added lots of new optimizations like if you have several indexes that you can use and one index is faster than another. But we noticed that the slow index actually will result in smaller set of rows. We actually used that as the estimated rows, something we didn't do before but that helps with a lot of different plans. When we have created the right tables before they were not using unique keys I don't really know why that decision was made but know most the right table using unique keys which are faster because the optimizer can estimate better how many rows we actually will do. Cost calculations we have, there's lots of different places where we calculate costs. I basically gone through as far as I know every single one and they show that the costs are comparable and will be close to microseconds for those. For example we didn't really have a good estimate before, what's the cost of file sort? No we haven't. We have filters, selectivity, metallization, using index for group buy and one big difference is that all these access costs are now based on SSDs, not hard disk as before. I think that most people use SSDs with the database but that's something actually you can change just by changing one variable. We also had a problem with cost that if we assume you have a big table and then you have a small lookup table. Basically before we assume that every read in the lookup table will have a disk access but in practice if the table is small after you have read a couple rows everything is in memory. No we assume that. So here you can see some of the cost and one can retrieve those for every engine and I just to show the difference between InnoDB and Aria. So InnoDB is using clustered index, Aria using a direct access to rows, cached. So with InnoDB basically the key lookup and the row lookup cost is roughly the same which means that if you search for a key and you search for a row both are using indexes so it's roughly the same. For example with Aria the row lookup cost is notable smaller. So this is one example why it's important to do this at a very very low level. All costs, all engine costs and most SQL costs are now available. So for example optimize disk read cost this is the time to read a 4k block from the device and that's a typical SSD. If you have a hard disk you just have to change that one cost. And the disk read ratio is how often we actually have to go to them. Is there a way on your system just to run something so you can populate these values automatically? You don't, the only one that you need to populate is basic, the optimator disk read cost. They are basically there so that assuming something goes really wrong then you can populate this. I don't see that. They are part of the engine behavior not part of the amount of behavior. So basically the three things that you normally would like to change is disk read cost if you have a fast SSD then the disk read ratio I plan to sometimes do that automatically based on engine statistics. I didn't want to do that at the beginning because if we do that automatically that means that you do a query and then you do the same query and then the plan changes. That confuses people. It may be better but so and the wear cost is the cost added to each row. So if you want to ensure that you get the minimal amount of row accesses you just increase that one. So how I checked all these things was that there's a part program part of the server check cost you can run it with any engine and it then produce that's a lot of different checks tables can index can key look up and so on and then it you get here you get the costs and here you have the timing milliseconds for doing that and if the if things are correct you get as far close to one and this I have a fixed for all engines. So that means that I have a way to verify that the cost is up or okay it's almost impossible to get them totally because even when you run things on a machine things actually changes from run to run but it's a millisecond yeah there were lots of things in the optimizer that was cost based sorry but still also a lot of things rule based no basically everything is everything I found is no cost base which means that it's easier for the optimizer to do choices therefore there is patches in the DB that's all still in MySQL where they recommend that MySQL prefers table scan so let's reduce all index scans to half just to force the optimizer to use indexes instead of table scans which is of course a disaster for the optimizer because then it gets wrong data and can do good decisions so all of those are removed so no inner DB gives the best optimizer it can and that helps things a lot and I spent a lot of time doing improving things from performance point of view especially is probably 50% faster than before more caching simplified code and had I haven't worked in the optimizer since the first version of MySQL in 95 maybe between 95 and 2000 I worked on it and then a lot of other people worked on it and they did a lot of amazing jobs in different parts of the server but nobody took the time to ensure that how things related to this one and this one and this one especially with costs so all of that's no done I also fixed small things then we also I also changed that we tried to use a longer indexes if they are there the one thing that is a problem is that especially for the test suite is that no when we actually have proper costs table scans is preferred for most queries in the test system because the tables can both in the DB and other engines is really really really fast one disk seek and you get hundred rows compared to index lookups so there's optimizers can set up cost that is is I think it's 10 milliseconds as default just to encourage the optimizer to use indexes for small tables mostly because if you don't that you can confuse both the test system and users and if they're small tables nobody like here if it takes one 10 to a milliseconds or 100 slow basically this affect tables that are less than than 20 rows and that's unfortunately most of the tests in my Maria DB have 10 rows or small yes what I see in concurrency is that it doesn't work very well because he's doing a lot of full scan at the end of the plan even if the index is there and could choose the accurate yeah but then no things are cost based and except with a small very small penalty for table scan but that's more for getting more and more chocolate so that you don't need indexes anymore because the hash algorithms are much faster hash is really really slow for you if you are going to fit a small of a small amount of rows I was in 10,000 20,000 12,000 of those that you have all in cash and also depending it depends on total on queries and and concurrency hashing takes a lot of memory no but that means that you get this concurrency because the CPU is just moving things from memory when it doesn't so hashing is good in some cases but it especially if you want to access a lot of rows directly or indirectly if you only need to access a few rows then hashing is really a disaster yeah and most if you look at banks and sections everything else hashing wouldn't work or any of those because usually just want to have everything from a small set of customers so here the from the user point of view those are the only variables that I think that you but may need those who create engines may need more and one thing to be aware of that from the use user variables they are in in microseconds not in milliseconds because I first had them in in milliseconds but the numbers get so small that it was very hard to look at those so there's a so when they internally they use the milliseconds but from user point the costs are in microseconds you have these variables here all these are just for memory and then you have a cost for fetching the fetching the disks fetching the blocks yeah so this is all memory yeah so optimize optimize a discrete cost that's the one that is an IO so there's like running more easy on like bare metal machine with very fast SSD like the IO is half it's one 10 of a millisecond but in the cloud IOs go through yeah network as you compare but I guess you need to tune this variable probably I haven't done that so I've been basically focused just to get this to work so everything is focused on getting the memory part of work but the disk is there and it's only two variables so it's very hard to get those totally wrong yeah if you run on a managed database in the cloud they might tune it with people like you might miss this would be interesting to see like the difference in how wrong things get if MeruDB thinks you're on fast SSDs but you're actually on network SSDs and this variable every engine has has its own variable so you can choose it changes for different engines if you want if you for example run on different devices so chasing cost variables is easy you just session or change global all engines are global but the wear cost and or that things are local so this is see I have a couple of minutes left so so question why does this matter to you if you ever had to go and say force index or have to try to tweak queries in any way or had to use analyze the analysis table is still useful because you get the statistics but I would say that one main thing is that much less tweaking queries these should just work and especially we use in a DBM memory engine for example or other engines things are not a little better and no even the server knows that no we have temporal tables in in in area or heap so it can take that that cost into account so state of things basically everything is done we have had QA testing this no form is one month founder some bugs most of the bugs is in the also in older releases so I in this I basically fixing everything related to optimizer in this one there's one issue left that I will push on at this week and then basically the level should be done we have a BB 11 0 that includes everything I think this is one of the most tested releases ever done internally just because I've been working so much with our QA team so I expect this be almost stable from from start or access table from start and for anybody who wants to help if you have a slave where you can put 11 0 on put it on send feedback make your entries anything related to optimizer will be fixed it immediately should it should be the same except something like row by the filters is faster so all code I don't think that anything will be slower in the optimizer but the plan should be better so the end result should be faster there are a couple of things that are not a little better row by the filter means that if you have two indexes you can use and then we then we create we take we will use the the faster one but if if it makes sense we take the other one fetch all primary keys and then when we read other ones we see that only those who has an existing primary key we need to consider so basically where there's a wind we don't have to fetch the row for things that we can filter out and the algorithm's name you know basically it's a lookup of all primary keys that are acceptable and we use the used we do a check against those which is actually pretty fast so state of things basically basically ready this will be released I think it's next in February yes so this month so future plans I will start working on parallel query there's still some optimized cleanups to be done I also want to enable all optimizers which is by default for example MariaD has supported has joins forever with the actually very hard to get to enable those bushy plans is something that we I would like to do because we have this you big users who would need that bushy plans basically have two big tables and then lots of tables that you have a relationship and then you have a join between those directly the big tables directly or indirectly and our optimizer currently can't do that very very efficiently so that's something I would like to do but the parallel query is the next big task that I will start was start on and I have some plans or ideas how to do that and I've been working with Sergi Petrugna who's know the leader the optimizer for doing this and then he got go got some help from the sensor Andrew so that's about 20 minutes okay thanks I don't think we have time for questions our next speaker set up but if you have questions from my team you can chat to him in the hallway we've got a stand downstairs where you can meet some other MariaD team as well it's the one without any uh any banner or anything like that because the person was supposed to bring all this work but let's say this way I'm really happy with this work and I think that for those who have complex plan which is especially when we're looking at things coming from oracle customers where we have lots of store procedures and really big queries queries that are in thousand of lines and this is just one query but this optimizer we really have so thank you", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 11.32, "text": " What's new in 11.0 and that's basically a new optimizer release, a new and new but", "tokens": [50364, 708, 311, 777, 294, 2975, 13, 15, 293, 300, 311, 1936, 257, 777, 5028, 6545, 4374, 11, 257, 777, 293, 777, 457, 50930], "temperature": 0.0, "avg_logprob": -0.2865812038553172, "compression_ratio": 1.4755244755244756, "no_speech_prob": 0.16092433035373688}, {"id": 1, "seek": 0, "start": 11.32, "end": 16.0, "text": " at least the cost model is totally new.", "tokens": [50930, 412, 1935, 264, 2063, 2316, 307, 3879, 777, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2865812038553172, "compression_ratio": 1.4755244755244756, "no_speech_prob": 0.16092433035373688}, {"id": 2, "seek": 0, "start": 16.0, "end": 24.400000000000002, "text": " So I think that from the optimizer point this is one of the biggest milestones, the only", "tokens": [51164, 407, 286, 519, 300, 490, 264, 5028, 6545, 935, 341, 307, 472, 295, 264, 3880, 42038, 11, 264, 787, 51584], "temperature": 0.0, "avg_logprob": -0.2865812038553172, "compression_ratio": 1.4755244755244756, "no_speech_prob": 0.16092433035373688}, {"id": 3, "seek": 2440, "start": 24.4, "end": 33.76, "text": " time we did something comparable was in MariaDB 5.3 and the big change is that before one", "tokens": [50364, 565, 321, 630, 746, 25323, 390, 294, 12734, 27735, 1025, 13, 18, 293, 264, 955, 1319, 307, 300, 949, 472, 50832], "temperature": 0.0, "avg_logprob": -0.2139024325779506, "compression_ratio": 1.5348837209302326, "no_speech_prob": 0.03622373938560486}, {"id": 4, "seek": 2440, "start": 33.76, "end": 43.519999999999996, "text": " cost unit if you do, last query cost was one IO, the one IO was not really that exact,", "tokens": [50832, 2063, 4985, 498, 291, 360, 11, 1036, 14581, 2063, 390, 472, 39839, 11, 264, 472, 39839, 390, 406, 534, 300, 1900, 11, 51320], "temperature": 0.0, "avg_logprob": -0.2139024325779506, "compression_ratio": 1.5348837209302326, "no_speech_prob": 0.03622373938560486}, {"id": 5, "seek": 2440, "start": 43.519999999999996, "end": 52.4, "text": " it could basically be one IO or one key read or one row read or one access to some file", "tokens": [51320, 309, 727, 1936, 312, 472, 39839, 420, 472, 2141, 1401, 420, 472, 5386, 1401, 420, 472, 2105, 281, 512, 3991, 51764], "temperature": 0.0, "avg_logprob": -0.2139024325779506, "compression_ratio": 1.5348837209302326, "no_speech_prob": 0.03622373938560486}, {"id": 6, "seek": 5240, "start": 52.4, "end": 62.16, "text": " and that also meant and the things were not that balanced so some costs were just taking", "tokens": [50364, 293, 300, 611, 4140, 293, 264, 721, 645, 406, 300, 13902, 370, 512, 5497, 645, 445, 1940, 50852], "temperature": 0.0, "avg_logprob": -0.2221440209282769, "compression_ratio": 1.661764705882353, "no_speech_prob": 0.00839619617909193}, {"id": 7, "seek": 5240, "start": 62.16, "end": 68.24, "text": " oh this sounds good, let's use that and even my SQL has that even now.", "tokens": [50852, 1954, 341, 3263, 665, 11, 718, 311, 764, 300, 293, 754, 452, 19200, 575, 300, 754, 586, 13, 51156], "temperature": 0.0, "avg_logprob": -0.2221440209282769, "compression_ratio": 1.661764705882353, "no_speech_prob": 0.00839619617909193}, {"id": 8, "seek": 5240, "start": 68.24, "end": 72.88, "text": " So I decided to actually do something that you can measure and then that also makes", "tokens": [51156, 407, 286, 3047, 281, 767, 360, 746, 300, 291, 393, 3481, 293, 550, 300, 611, 1669, 51388], "temperature": 0.0, "avg_logprob": -0.2221440209282769, "compression_ratio": 1.661764705882353, "no_speech_prob": 0.00839619617909193}, {"id": 9, "seek": 5240, "start": 72.88, "end": 79.28, "text": " it very easy to fix the optimizer that if you see that the cost is not something's milliseconds", "tokens": [51388, 309, 588, 1858, 281, 3191, 264, 5028, 6545, 300, 498, 291, 536, 300, 264, 2063, 307, 406, 746, 311, 34184, 51708], "temperature": 0.0, "avg_logprob": -0.2221440209282769, "compression_ratio": 1.661764705882353, "no_speech_prob": 0.00839619617909193}, {"id": 10, "seek": 7928, "start": 79.28, "end": 85.44, "text": " and something is off and then your justings accordingly.", "tokens": [50364, 293, 746, 307, 766, 293, 550, 428, 445, 1109, 19717, 13, 50672], "temperature": 0.0, "avg_logprob": -0.19467992048997146, "compression_ratio": 1.648780487804878, "no_speech_prob": 0.014292653650045395}, {"id": 11, "seek": 7928, "start": 85.44, "end": 93.52, "text": " So and we decided to call this 11.0 because if you change things in the optimizer as drastically", "tokens": [50672, 407, 293, 321, 3047, 281, 818, 341, 2975, 13, 15, 570, 498, 291, 1319, 721, 294, 264, 5028, 6545, 382, 29673, 51076], "temperature": 0.0, "avg_logprob": -0.19467992048997146, "compression_ratio": 1.648780487804878, "no_speech_prob": 0.014292653650045395}, {"id": 12, "seek": 7928, "start": 93.52, "end": 99.64, "text": " as we have done some plan may change, hopefully it should always be the better because now", "tokens": [51076, 382, 321, 362, 1096, 512, 1393, 815, 1319, 11, 4696, 309, 820, 1009, 312, 264, 1101, 570, 586, 51382], "temperature": 0.0, "avg_logprob": -0.19467992048997146, "compression_ratio": 1.648780487804878, "no_speech_prob": 0.014292653650045395}, {"id": 13, "seek": 7928, "start": 99.64, "end": 107.12, "text": " we actually have a proper cost and it's really easy to change things because almost all costs", "tokens": [51382, 321, 767, 362, 257, 2296, 2063, 293, 309, 311, 534, 1858, 281, 1319, 721, 570, 1920, 439, 5497, 51756], "temperature": 0.0, "avg_logprob": -0.19467992048997146, "compression_ratio": 1.648780487804878, "no_speech_prob": 0.014292653650045395}, {"id": 14, "seek": 10712, "start": 107.12, "end": 111.60000000000001, "text": " are available for the user to change.", "tokens": [50364, 366, 2435, 337, 264, 4195, 281, 1319, 13, 50588], "temperature": 0.0, "avg_logprob": -0.14828913352068732, "compression_ratio": 1.5473684210526315, "no_speech_prob": 0.018864084035158157}, {"id": 15, "seek": 10712, "start": 111.60000000000001, "end": 118.24000000000001, "text": " So I just think that this will be a good foundation for all future MariaDB releases.", "tokens": [50588, 407, 286, 445, 519, 300, 341, 486, 312, 257, 665, 7030, 337, 439, 2027, 12734, 27735, 16952, 13, 50920], "temperature": 0.0, "avg_logprob": -0.14828913352068732, "compression_ratio": 1.5473684210526315, "no_speech_prob": 0.018864084035158157}, {"id": 16, "seek": 10712, "start": 118.24000000000001, "end": 127.56, "text": " So with the optimizer the idea is to get better table combination and better plans.", "tokens": [50920, 407, 365, 264, 5028, 6545, 264, 1558, 307, 281, 483, 1101, 3199, 6562, 293, 1101, 5482, 13, 51386], "temperature": 0.0, "avg_logprob": -0.14828913352068732, "compression_ratio": 1.5473684210526315, "no_speech_prob": 0.018864084035158157}, {"id": 17, "seek": 10712, "start": 127.56, "end": 133.28, "text": " The old optimizer was actually pretty good in deciding things for simple things because", "tokens": [51386, 440, 1331, 5028, 6545, 390, 767, 1238, 665, 294, 17990, 721, 337, 2199, 721, 570, 51672], "temperature": 0.0, "avg_logprob": -0.14828913352068732, "compression_ratio": 1.5473684210526315, "no_speech_prob": 0.018864084035158157}, {"id": 18, "seek": 13328, "start": 133.28, "end": 139.72, "text": " if it found a good index it would use it and so on but when you had to decide that should", "tokens": [50364, 498, 309, 1352, 257, 665, 8186, 309, 576, 764, 309, 293, 370, 322, 457, 562, 291, 632, 281, 4536, 300, 820, 50686], "temperature": 0.0, "avg_logprob": -0.27957275390625, "compression_ratio": 1.7428571428571429, "no_speech_prob": 0.011308853514492512}, {"id": 19, "seek": 13328, "start": 139.72, "end": 146.52, "text": " I use this index or this index and this index I could use with the index and the lookup", "tokens": [50686, 286, 764, 341, 8186, 420, 341, 8186, 293, 341, 8186, 286, 727, 764, 365, 264, 8186, 293, 264, 574, 1010, 51026], "temperature": 0.0, "avg_logprob": -0.27957275390625, "compression_ratio": 1.7428571428571429, "no_speech_prob": 0.011308853514492512}, {"id": 20, "seek": 13328, "start": 146.52, "end": 154.96, "text": " and the other one not, their things started to fall apart and also cost between different", "tokens": [51026, 293, 264, 661, 472, 406, 11, 641, 721, 1409, 281, 2100, 4936, 293, 611, 2063, 1296, 819, 51448], "temperature": 0.0, "avg_logprob": -0.27957275390625, "compression_ratio": 1.7428571428571429, "no_speech_prob": 0.011308853514492512}, {"id": 21, "seek": 13328, "start": 154.96, "end": 158.64, "text": " engines were not taking into account.", "tokens": [51448, 12982, 645, 406, 1940, 666, 2696, 13, 51632], "temperature": 0.0, "avg_logprob": -0.27957275390625, "compression_ratio": 1.7428571428571429, "no_speech_prob": 0.011308853514492512}, {"id": 22, "seek": 15864, "start": 158.64, "end": 166.79999999999998, "text": " The only one who had some information was the heap table although the ones were more", "tokens": [50364, 440, 787, 472, 567, 632, 512, 1589, 390, 264, 33591, 3199, 4878, 264, 2306, 645, 544, 50772], "temperature": 0.0, "avg_logprob": -0.22255570141237174, "compression_ratio": 1.617283950617284, "no_speech_prob": 0.007786786183714867}, {"id": 23, "seek": 15864, "start": 166.79999999999998, "end": 167.79999999999998, "text": " or less the same.", "tokens": [50772, 420, 1570, 264, 912, 13, 50822], "temperature": 0.0, "avg_logprob": -0.22255570141237174, "compression_ratio": 1.617283950617284, "no_speech_prob": 0.007786786183714867}, {"id": 24, "seek": 15864, "start": 167.79999999999998, "end": 180.0, "text": " So I wanted to fix that and also allow people to function the optimizer.", "tokens": [50822, 407, 286, 1415, 281, 3191, 300, 293, 611, 2089, 561, 281, 2445, 264, 5028, 6545, 13, 51432], "temperature": 0.0, "avg_logprob": -0.22255570141237174, "compression_ratio": 1.617283950617284, "no_speech_prob": 0.007786786183714867}, {"id": 25, "seek": 15864, "start": 180.0, "end": 187.07999999999998, "text": " So what the new optimizer should be able to do, it should be able to use the different", "tokens": [51432, 407, 437, 264, 777, 5028, 6545, 820, 312, 1075, 281, 360, 11, 309, 820, 312, 1075, 281, 764, 264, 819, 51786], "temperature": 0.0, "avg_logprob": -0.22255570141237174, "compression_ratio": 1.617283950617284, "no_speech_prob": 0.007786786183714867}, {"id": 26, "seek": 18708, "start": 187.08, "end": 192.88000000000002, "text": " methods to access rows which is table scan, index scan, index merge and hash and be able", "tokens": [50364, 7150, 281, 2105, 13241, 597, 307, 3199, 11049, 11, 8186, 11049, 11, 8186, 22183, 293, 22019, 293, 312, 1075, 50654], "temperature": 0.0, "avg_logprob": -0.24315591958852914, "compression_ratio": 1.5, "no_speech_prob": 0.12851069867610931}, {"id": 27, "seek": 18708, "start": 192.88000000000002, "end": 199.84, "text": " to choose those correctly what is optimal for things.", "tokens": [50654, 281, 2826, 729, 8944, 437, 307, 16252, 337, 721, 13, 51002], "temperature": 0.0, "avg_logprob": -0.24315591958852914, "compression_ratio": 1.5, "no_speech_prob": 0.12851069867610931}, {"id": 28, "seek": 18708, "start": 199.84, "end": 212.12, "text": " And I don't, only those who have complex queries should see a big difference.", "tokens": [51002, 400, 286, 500, 380, 11, 787, 729, 567, 362, 3997, 24109, 820, 536, 257, 955, 2649, 13, 51616], "temperature": 0.0, "avg_logprob": -0.24315591958852914, "compression_ratio": 1.5, "no_speech_prob": 0.12851069867610931}, {"id": 29, "seek": 18708, "start": 212.12, "end": 217.0, "text": " And I don't know how many user use optimizer trace that was added to MariaDB 10.4 but", "tokens": [51616, 400, 286, 500, 380, 458, 577, 867, 4195, 764, 5028, 6545, 13508, 300, 390, 3869, 281, 12734, 27735, 1266, 13, 19, 457, 51860], "temperature": 0.0, "avg_logprob": -0.24315591958852914, "compression_ratio": 1.5, "no_speech_prob": 0.12851069867610931}, {"id": 30, "seek": 21700, "start": 217.0, "end": 222.64, "text": " I couldn't have done this work without that because that shows me exactly how the planner", "tokens": [50364, 286, 2809, 380, 362, 1096, 341, 589, 1553, 300, 570, 300, 3110, 385, 2293, 577, 264, 31268, 50646], "temperature": 0.0, "avg_logprob": -0.21221070878961112, "compression_ratio": 1.6346153846153846, "no_speech_prob": 0.02312127687036991}, {"id": 31, "seek": 21700, "start": 222.64, "end": 231.24, "text": " is doing and we have, I've been able to use it to find out where the optimizer calculates", "tokens": [50646, 307, 884, 293, 321, 362, 11, 286, 600, 668, 1075, 281, 764, 309, 281, 915, 484, 689, 264, 5028, 6545, 4322, 1024, 51076], "temperature": 0.0, "avg_logprob": -0.21221070878961112, "compression_ratio": 1.6346153846153846, "no_speech_prob": 0.02312127687036991}, {"id": 32, "seek": 21700, "start": 231.24, "end": 237.56, "text": " things wrong and as part of 11.0 I've been, lots of things added to it so it's very easy", "tokens": [51076, 721, 2085, 293, 382, 644, 295, 2975, 13, 15, 286, 600, 668, 11, 3195, 295, 721, 3869, 281, 309, 370, 309, 311, 588, 1858, 51392], "temperature": 0.0, "avg_logprob": -0.21221070878961112, "compression_ratio": 1.6346153846153846, "no_speech_prob": 0.02312127687036991}, {"id": 33, "seek": 21700, "start": 237.56, "end": 244.84, "text": " to know look at the plan and see if the optimizer does something wrong.", "tokens": [51392, 281, 458, 574, 412, 264, 1393, 293, 536, 498, 264, 5028, 6545, 775, 746, 2085, 13, 51756], "temperature": 0.0, "avg_logprob": -0.21221070878961112, "compression_ratio": 1.6346153846153846, "no_speech_prob": 0.02312127687036991}, {"id": 34, "seek": 24484, "start": 244.84, "end": 252.28, "text": " There's lots and lots of bug fixes related to optimizer like selectivity, you couldn't", "tokens": [50364, 821, 311, 3195, 293, 3195, 295, 7426, 32539, 4077, 281, 5028, 6545, 411, 3048, 4253, 11, 291, 2809, 380, 50736], "temperature": 0.0, "avg_logprob": -0.23057716914585658, "compression_ratio": 1.6096256684491979, "no_speech_prob": 0.0630013719201088}, {"id": 35, "seek": 24484, "start": 252.28, "end": 260.28000000000003, "text": " use selectivity level four at all before, sometimes the selectivity would become bigger", "tokens": [50736, 764, 3048, 4253, 1496, 1451, 412, 439, 949, 11, 2171, 264, 3048, 4253, 576, 1813, 3801, 51136], "temperature": 0.0, "avg_logprob": -0.23057716914585658, "compression_ratio": 1.6096256684491979, "no_speech_prob": 0.0630013719201088}, {"id": 36, "seek": 24484, "start": 260.28000000000003, "end": 269.12, "text": " than one which means that the optimizer would assume that you will get more rows when you", "tokens": [51136, 813, 472, 597, 1355, 300, 264, 5028, 6545, 576, 6552, 300, 291, 486, 483, 544, 13241, 562, 291, 51578], "temperature": 0.0, "avg_logprob": -0.23057716914585658, "compression_ratio": 1.6096256684491979, "no_speech_prob": 0.0630013719201088}, {"id": 37, "seek": 24484, "start": 269.12, "end": 272.64, "text": " have condition instead of less rows.", "tokens": [51578, 362, 4188, 2602, 295, 1570, 13241, 13, 51754], "temperature": 0.0, "avg_logprob": -0.23057716914585658, "compression_ratio": 1.6096256684491979, "no_speech_prob": 0.0630013719201088}, {"id": 38, "seek": 27264, "start": 272.64, "end": 278.47999999999996, "text": " So all that should be fixed.", "tokens": [50364, 407, 439, 300, 820, 312, 6806, 13, 50656], "temperature": 0.0, "avg_logprob": -0.2256536952784804, "compression_ratio": 1.4723926380368098, "no_speech_prob": 0.003326158504933119}, {"id": 39, "seek": 27264, "start": 278.47999999999996, "end": 286.28, "text": " And we also added lots of new optimizations like if you have several indexes that you", "tokens": [50656, 400, 321, 611, 3869, 3195, 295, 777, 5028, 14455, 411, 498, 291, 362, 2940, 8186, 279, 300, 291, 51046], "temperature": 0.0, "avg_logprob": -0.2256536952784804, "compression_ratio": 1.4723926380368098, "no_speech_prob": 0.003326158504933119}, {"id": 40, "seek": 27264, "start": 286.28, "end": 290.15999999999997, "text": " can use and one index is faster than another.", "tokens": [51046, 393, 764, 293, 472, 8186, 307, 4663, 813, 1071, 13, 51240], "temperature": 0.0, "avg_logprob": -0.2256536952784804, "compression_ratio": 1.4723926380368098, "no_speech_prob": 0.003326158504933119}, {"id": 41, "seek": 27264, "start": 290.15999999999997, "end": 296.36, "text": " But we noticed that the slow index actually will result in smaller set of rows.", "tokens": [51240, 583, 321, 5694, 300, 264, 2964, 8186, 767, 486, 1874, 294, 4356, 992, 295, 13241, 13, 51550], "temperature": 0.0, "avg_logprob": -0.2256536952784804, "compression_ratio": 1.4723926380368098, "no_speech_prob": 0.003326158504933119}, {"id": 42, "seek": 29636, "start": 296.36, "end": 303.76, "text": " We actually used that as the estimated rows, something we didn't do before but that helps", "tokens": [50364, 492, 767, 1143, 300, 382, 264, 14109, 13241, 11, 746, 321, 994, 380, 360, 949, 457, 300, 3665, 50734], "temperature": 0.0, "avg_logprob": -0.20205936431884766, "compression_ratio": 1.6149732620320856, "no_speech_prob": 0.014956721104681492}, {"id": 43, "seek": 29636, "start": 303.76, "end": 309.72, "text": " with a lot of different plans.", "tokens": [50734, 365, 257, 688, 295, 819, 5482, 13, 51032], "temperature": 0.0, "avg_logprob": -0.20205936431884766, "compression_ratio": 1.6149732620320856, "no_speech_prob": 0.014956721104681492}, {"id": 44, "seek": 29636, "start": 309.72, "end": 315.12, "text": " When we have created the right tables before they were not using unique keys I don't really", "tokens": [51032, 1133, 321, 362, 2942, 264, 558, 8020, 949, 436, 645, 406, 1228, 3845, 9317, 286, 500, 380, 534, 51302], "temperature": 0.0, "avg_logprob": -0.20205936431884766, "compression_ratio": 1.6149732620320856, "no_speech_prob": 0.014956721104681492}, {"id": 45, "seek": 29636, "start": 315.12, "end": 322.04, "text": " know why that decision was made but know most the right table using unique keys which are", "tokens": [51302, 458, 983, 300, 3537, 390, 1027, 457, 458, 881, 264, 558, 3199, 1228, 3845, 9317, 597, 366, 51648], "temperature": 0.0, "avg_logprob": -0.20205936431884766, "compression_ratio": 1.6149732620320856, "no_speech_prob": 0.014956721104681492}, {"id": 46, "seek": 32204, "start": 322.04, "end": 332.48, "text": " faster because the optimizer can estimate better how many rows we actually will do.", "tokens": [50364, 4663, 570, 264, 5028, 6545, 393, 12539, 1101, 577, 867, 13241, 321, 767, 486, 360, 13, 50886], "temperature": 0.0, "avg_logprob": -0.2808000301492625, "compression_ratio": 1.4855491329479769, "no_speech_prob": 0.311813086271286}, {"id": 47, "seek": 32204, "start": 332.48, "end": 338.32000000000005, "text": " Cost calculations we have, there's lots of different places where we calculate costs.", "tokens": [50886, 20863, 20448, 321, 362, 11, 456, 311, 3195, 295, 819, 3190, 689, 321, 8873, 5497, 13, 51178], "temperature": 0.0, "avg_logprob": -0.2808000301492625, "compression_ratio": 1.4855491329479769, "no_speech_prob": 0.311813086271286}, {"id": 48, "seek": 32204, "start": 338.32000000000005, "end": 345.12, "text": " I basically gone through as far as I know every single one and they show that the costs", "tokens": [51178, 286, 1936, 2780, 807, 382, 1400, 382, 286, 458, 633, 2167, 472, 293, 436, 855, 300, 264, 5497, 51518], "temperature": 0.0, "avg_logprob": -0.2808000301492625, "compression_ratio": 1.4855491329479769, "no_speech_prob": 0.311813086271286}, {"id": 49, "seek": 34512, "start": 345.12, "end": 352.8, "text": " are comparable and will be close to microseconds for those.", "tokens": [50364, 366, 25323, 293, 486, 312, 1998, 281, 3123, 37841, 28750, 337, 729, 13, 50748], "temperature": 0.0, "avg_logprob": -0.1792563965071493, "compression_ratio": 1.4065934065934067, "no_speech_prob": 0.13415776193141937}, {"id": 50, "seek": 34512, "start": 352.8, "end": 359.32, "text": " For example we didn't really have a good estimate before, what's the cost of file sort?", "tokens": [50748, 1171, 1365, 321, 994, 380, 534, 362, 257, 665, 12539, 949, 11, 437, 311, 264, 2063, 295, 3991, 1333, 30, 51074], "temperature": 0.0, "avg_logprob": -0.1792563965071493, "compression_ratio": 1.4065934065934067, "no_speech_prob": 0.13415776193141937}, {"id": 51, "seek": 34512, "start": 359.32, "end": 360.32, "text": " No we haven't.", "tokens": [51074, 883, 321, 2378, 380, 13, 51124], "temperature": 0.0, "avg_logprob": -0.1792563965071493, "compression_ratio": 1.4065934065934067, "no_speech_prob": 0.13415776193141937}, {"id": 52, "seek": 34512, "start": 360.32, "end": 370.6, "text": " We have filters, selectivity, metallization, using index for group buy and one big difference", "tokens": [51124, 492, 362, 15995, 11, 3048, 4253, 11, 20866, 2144, 11, 1228, 8186, 337, 1594, 2256, 293, 472, 955, 2649, 51638], "temperature": 0.0, "avg_logprob": -0.1792563965071493, "compression_ratio": 1.4065934065934067, "no_speech_prob": 0.13415776193141937}, {"id": 53, "seek": 37060, "start": 370.6, "end": 376.64000000000004, "text": " is that all these access costs are now based on SSDs, not hard disk as before.", "tokens": [50364, 307, 300, 439, 613, 2105, 5497, 366, 586, 2361, 322, 30262, 82, 11, 406, 1152, 12355, 382, 949, 13, 50666], "temperature": 0.0, "avg_logprob": -0.22866290953101182, "compression_ratio": 1.5771144278606966, "no_speech_prob": 0.1273040920495987}, {"id": 54, "seek": 37060, "start": 376.64000000000004, "end": 382.8, "text": " I think that most people use SSDs with the database but that's something actually you", "tokens": [50666, 286, 519, 300, 881, 561, 764, 30262, 82, 365, 264, 8149, 457, 300, 311, 746, 767, 291, 50974], "temperature": 0.0, "avg_logprob": -0.22866290953101182, "compression_ratio": 1.5771144278606966, "no_speech_prob": 0.1273040920495987}, {"id": 55, "seek": 37060, "start": 382.8, "end": 388.44, "text": " can change just by changing one variable.", "tokens": [50974, 393, 1319, 445, 538, 4473, 472, 7006, 13, 51256], "temperature": 0.0, "avg_logprob": -0.22866290953101182, "compression_ratio": 1.5771144278606966, "no_speech_prob": 0.1273040920495987}, {"id": 56, "seek": 37060, "start": 388.44, "end": 394.56, "text": " We also had a problem with cost that if we assume you have a big table and then you have", "tokens": [51256, 492, 611, 632, 257, 1154, 365, 2063, 300, 498, 321, 6552, 291, 362, 257, 955, 3199, 293, 550, 291, 362, 51562], "temperature": 0.0, "avg_logprob": -0.22866290953101182, "compression_ratio": 1.5771144278606966, "no_speech_prob": 0.1273040920495987}, {"id": 57, "seek": 37060, "start": 394.56, "end": 396.20000000000005, "text": " a small lookup table.", "tokens": [51562, 257, 1359, 574, 1010, 3199, 13, 51644], "temperature": 0.0, "avg_logprob": -0.22866290953101182, "compression_ratio": 1.5771144278606966, "no_speech_prob": 0.1273040920495987}, {"id": 58, "seek": 39620, "start": 396.2, "end": 403.76, "text": " Basically before we assume that every read in the lookup table will have a disk access", "tokens": [50364, 8537, 949, 321, 6552, 300, 633, 1401, 294, 264, 574, 1010, 3199, 486, 362, 257, 12355, 2105, 50742], "temperature": 0.0, "avg_logprob": -0.24646509777415881, "compression_ratio": 1.6056338028169015, "no_speech_prob": 0.010180728510022163}, {"id": 59, "seek": 39620, "start": 403.76, "end": 408.62, "text": " but in practice if the table is small after you have read a couple rows everything is", "tokens": [50742, 457, 294, 3124, 498, 264, 3199, 307, 1359, 934, 291, 362, 1401, 257, 1916, 13241, 1203, 307, 50985], "temperature": 0.0, "avg_logprob": -0.24646509777415881, "compression_ratio": 1.6056338028169015, "no_speech_prob": 0.010180728510022163}, {"id": 60, "seek": 39620, "start": 408.62, "end": 409.62, "text": " in memory.", "tokens": [50985, 294, 4675, 13, 51035], "temperature": 0.0, "avg_logprob": -0.24646509777415881, "compression_ratio": 1.6056338028169015, "no_speech_prob": 0.010180728510022163}, {"id": 61, "seek": 39620, "start": 409.62, "end": 413.12, "text": " No we assume that.", "tokens": [51035, 883, 321, 6552, 300, 13, 51210], "temperature": 0.0, "avg_logprob": -0.24646509777415881, "compression_ratio": 1.6056338028169015, "no_speech_prob": 0.010180728510022163}, {"id": 62, "seek": 39620, "start": 413.12, "end": 421.91999999999996, "text": " So here you can see some of the cost and one can retrieve those for every engine and I", "tokens": [51210, 407, 510, 291, 393, 536, 512, 295, 264, 2063, 293, 472, 393, 30254, 729, 337, 633, 2848, 293, 286, 51650], "temperature": 0.0, "avg_logprob": -0.24646509777415881, "compression_ratio": 1.6056338028169015, "no_speech_prob": 0.010180728510022163}, {"id": 63, "seek": 39620, "start": 421.91999999999996, "end": 425.28, "text": " just to show the difference between InnoDB and Aria.", "tokens": [51650, 445, 281, 855, 264, 2649, 1296, 682, 1771, 27735, 293, 316, 4668, 13, 51818], "temperature": 0.0, "avg_logprob": -0.24646509777415881, "compression_ratio": 1.6056338028169015, "no_speech_prob": 0.010180728510022163}, {"id": 64, "seek": 42528, "start": 425.28, "end": 432.79999999999995, "text": " So InnoDB is using clustered index, Aria using a direct access to rows, cached.", "tokens": [50364, 407, 682, 1771, 27735, 307, 1228, 596, 38624, 8186, 11, 316, 4668, 1228, 257, 2047, 2105, 281, 13241, 11, 269, 15095, 13, 50740], "temperature": 0.0, "avg_logprob": -0.19270158115821548, "compression_ratio": 1.6646706586826348, "no_speech_prob": 0.02647237293422222}, {"id": 65, "seek": 42528, "start": 432.79999999999995, "end": 439.4, "text": " So with InnoDB basically the key lookup and the row lookup cost is roughly the same which", "tokens": [50740, 407, 365, 682, 1771, 27735, 1936, 264, 2141, 574, 1010, 293, 264, 5386, 574, 1010, 2063, 307, 9810, 264, 912, 597, 51070], "temperature": 0.0, "avg_logprob": -0.19270158115821548, "compression_ratio": 1.6646706586826348, "no_speech_prob": 0.02647237293422222}, {"id": 66, "seek": 42528, "start": 439.4, "end": 446.52, "text": " means that if you search for a key and you search for a row both are using indexes so", "tokens": [51070, 1355, 300, 498, 291, 3164, 337, 257, 2141, 293, 291, 3164, 337, 257, 5386, 1293, 366, 1228, 8186, 279, 370, 51426], "temperature": 0.0, "avg_logprob": -0.19270158115821548, "compression_ratio": 1.6646706586826348, "no_speech_prob": 0.02647237293422222}, {"id": 67, "seek": 42528, "start": 446.52, "end": 449.11999999999995, "text": " it's roughly the same.", "tokens": [51426, 309, 311, 9810, 264, 912, 13, 51556], "temperature": 0.0, "avg_logprob": -0.19270158115821548, "compression_ratio": 1.6646706586826348, "no_speech_prob": 0.02647237293422222}, {"id": 68, "seek": 44912, "start": 449.12, "end": 455.2, "text": " For example with Aria the row lookup cost is notable smaller.", "tokens": [50364, 1171, 1365, 365, 316, 4668, 264, 5386, 574, 1010, 2063, 307, 22556, 4356, 13, 50668], "temperature": 0.0, "avg_logprob": -0.29522954767400567, "compression_ratio": 1.4109589041095891, "no_speech_prob": 0.07400377094745636}, {"id": 69, "seek": 44912, "start": 455.2, "end": 466.12, "text": " So this is one example why it's important to do this at a very very low level.", "tokens": [50668, 407, 341, 307, 472, 1365, 983, 309, 311, 1021, 281, 360, 341, 412, 257, 588, 588, 2295, 1496, 13, 51214], "temperature": 0.0, "avg_logprob": -0.29522954767400567, "compression_ratio": 1.4109589041095891, "no_speech_prob": 0.07400377094745636}, {"id": 70, "seek": 44912, "start": 466.12, "end": 472.12, "text": " All costs, all engine costs and most SQL costs are now available.", "tokens": [51214, 1057, 5497, 11, 439, 2848, 5497, 293, 881, 19200, 5497, 366, 586, 2435, 13, 51514], "temperature": 0.0, "avg_logprob": -0.29522954767400567, "compression_ratio": 1.4109589041095891, "no_speech_prob": 0.07400377094745636}, {"id": 71, "seek": 47212, "start": 472.12, "end": 479.84000000000003, "text": " So for example optimize disk read cost this is the time to read a 4k block from the device", "tokens": [50364, 407, 337, 1365, 19719, 12355, 1401, 2063, 341, 307, 264, 565, 281, 1401, 257, 1017, 74, 3461, 490, 264, 4302, 50750], "temperature": 0.0, "avg_logprob": -0.25423498714671416, "compression_ratio": 1.4850299401197604, "no_speech_prob": 0.3580937087535858}, {"id": 72, "seek": 47212, "start": 479.84000000000003, "end": 481.76, "text": " and that's a typical SSD.", "tokens": [50750, 293, 300, 311, 257, 7476, 30262, 13, 50846], "temperature": 0.0, "avg_logprob": -0.25423498714671416, "compression_ratio": 1.4850299401197604, "no_speech_prob": 0.3580937087535858}, {"id": 73, "seek": 47212, "start": 481.76, "end": 489.68, "text": " If you have a hard disk you just have to change that one cost.", "tokens": [50846, 759, 291, 362, 257, 1152, 12355, 291, 445, 362, 281, 1319, 300, 472, 2063, 13, 51242], "temperature": 0.0, "avg_logprob": -0.25423498714671416, "compression_ratio": 1.4850299401197604, "no_speech_prob": 0.3580937087535858}, {"id": 74, "seek": 47212, "start": 489.68, "end": 495.2, "text": " And the disk read ratio is how often we actually have to go to them.", "tokens": [51242, 400, 264, 12355, 1401, 8509, 307, 577, 2049, 321, 767, 362, 281, 352, 281, 552, 13, 51518], "temperature": 0.0, "avg_logprob": -0.25423498714671416, "compression_ratio": 1.4850299401197604, "no_speech_prob": 0.3580937087535858}, {"id": 75, "seek": 49520, "start": 495.32, "end": 501.2, "text": " Is there a way on your system just to run something so you can populate these values automatically?", "tokens": [50370, 1119, 456, 257, 636, 322, 428, 1185, 445, 281, 1190, 746, 370, 291, 393, 1665, 5256, 613, 4190, 6772, 30, 50664], "temperature": 0.0, "avg_logprob": -0.3398035764694214, "compression_ratio": 1.766355140186916, "no_speech_prob": 0.366252064704895}, {"id": 76, "seek": 49520, "start": 501.2, "end": 508.96, "text": " You don't, the only one that you need to populate is basic, the optimator disk read cost.", "tokens": [50664, 509, 500, 380, 11, 264, 787, 472, 300, 291, 643, 281, 1665, 5256, 307, 3875, 11, 264, 5028, 1639, 12355, 1401, 2063, 13, 51052], "temperature": 0.0, "avg_logprob": -0.3398035764694214, "compression_ratio": 1.766355140186916, "no_speech_prob": 0.366252064704895}, {"id": 77, "seek": 49520, "start": 508.96, "end": 515.4, "text": " They are basically there so that assuming something goes really wrong then you can populate", "tokens": [51052, 814, 366, 1936, 456, 370, 300, 11926, 746, 1709, 534, 2085, 550, 291, 393, 1665, 5256, 51374], "temperature": 0.0, "avg_logprob": -0.3398035764694214, "compression_ratio": 1.766355140186916, "no_speech_prob": 0.366252064704895}, {"id": 78, "seek": 49520, "start": 515.4, "end": 516.4, "text": " this.", "tokens": [51374, 341, 13, 51424], "temperature": 0.0, "avg_logprob": -0.3398035764694214, "compression_ratio": 1.766355140186916, "no_speech_prob": 0.366252064704895}, {"id": 79, "seek": 49520, "start": 516.4, "end": 517.4, "text": " I don't see that.", "tokens": [51424, 286, 500, 380, 536, 300, 13, 51474], "temperature": 0.0, "avg_logprob": -0.3398035764694214, "compression_ratio": 1.766355140186916, "no_speech_prob": 0.366252064704895}, {"id": 80, "seek": 49520, "start": 517.4, "end": 521.04, "text": " They are part of the engine behavior not part of the amount of behavior.", "tokens": [51474, 814, 366, 644, 295, 264, 2848, 5223, 406, 644, 295, 264, 2372, 295, 5223, 13, 51656], "temperature": 0.0, "avg_logprob": -0.3398035764694214, "compression_ratio": 1.766355140186916, "no_speech_prob": 0.366252064704895}, {"id": 81, "seek": 52104, "start": 521.04, "end": 525.9599999999999, "text": " So basically the three things that you normally would like to change is disk read cost if", "tokens": [50364, 407, 1936, 264, 1045, 721, 300, 291, 5646, 576, 411, 281, 1319, 307, 12355, 1401, 2063, 498, 50610], "temperature": 0.0, "avg_logprob": -0.18516802280507189, "compression_ratio": 1.7945205479452055, "no_speech_prob": 0.05783368647098541}, {"id": 82, "seek": 52104, "start": 525.9599999999999, "end": 535.12, "text": " you have a fast SSD then the disk read ratio I plan to sometimes do that automatically", "tokens": [50610, 291, 362, 257, 2370, 30262, 550, 264, 12355, 1401, 8509, 286, 1393, 281, 2171, 360, 300, 6772, 51068], "temperature": 0.0, "avg_logprob": -0.18516802280507189, "compression_ratio": 1.7945205479452055, "no_speech_prob": 0.05783368647098541}, {"id": 83, "seek": 52104, "start": 535.12, "end": 537.12, "text": " based on engine statistics.", "tokens": [51068, 2361, 322, 2848, 12523, 13, 51168], "temperature": 0.0, "avg_logprob": -0.18516802280507189, "compression_ratio": 1.7945205479452055, "no_speech_prob": 0.05783368647098541}, {"id": 84, "seek": 52104, "start": 537.12, "end": 541.24, "text": " I didn't want to do that at the beginning because if we do that automatically that means", "tokens": [51168, 286, 994, 380, 528, 281, 360, 300, 412, 264, 2863, 570, 498, 321, 360, 300, 6772, 300, 1355, 51374], "temperature": 0.0, "avg_logprob": -0.18516802280507189, "compression_ratio": 1.7945205479452055, "no_speech_prob": 0.05783368647098541}, {"id": 85, "seek": 52104, "start": 541.24, "end": 545.36, "text": " that you do a query and then you do the same query and then the plan changes.", "tokens": [51374, 300, 291, 360, 257, 14581, 293, 550, 291, 360, 264, 912, 14581, 293, 550, 264, 1393, 2962, 13, 51580], "temperature": 0.0, "avg_logprob": -0.18516802280507189, "compression_ratio": 1.7945205479452055, "no_speech_prob": 0.05783368647098541}, {"id": 86, "seek": 52104, "start": 545.36, "end": 546.36, "text": " That confuses people.", "tokens": [51580, 663, 1497, 8355, 561, 13, 51630], "temperature": 0.0, "avg_logprob": -0.18516802280507189, "compression_ratio": 1.7945205479452055, "no_speech_prob": 0.05783368647098541}, {"id": 87, "seek": 54636, "start": 546.88, "end": 554.6800000000001, "text": " It may be better but so and the wear cost is the cost added to each row.", "tokens": [50390, 467, 815, 312, 1101, 457, 370, 293, 264, 3728, 2063, 307, 264, 2063, 3869, 281, 1184, 5386, 13, 50780], "temperature": 0.0, "avg_logprob": -0.2301168021033792, "compression_ratio": 1.5636363636363637, "no_speech_prob": 0.0046575372107326984}, {"id": 88, "seek": 54636, "start": 554.6800000000001, "end": 561.08, "text": " So if you want to ensure that you get the minimal amount of row accesses you just increase", "tokens": [50780, 407, 498, 291, 528, 281, 5586, 300, 291, 483, 264, 13206, 2372, 295, 5386, 2105, 279, 291, 445, 3488, 51100], "temperature": 0.0, "avg_logprob": -0.2301168021033792, "compression_ratio": 1.5636363636363637, "no_speech_prob": 0.0046575372107326984}, {"id": 89, "seek": 54636, "start": 561.08, "end": 562.08, "text": " that one.", "tokens": [51100, 300, 472, 13, 51150], "temperature": 0.0, "avg_logprob": -0.2301168021033792, "compression_ratio": 1.5636363636363637, "no_speech_prob": 0.0046575372107326984}, {"id": 90, "seek": 54636, "start": 562.08, "end": 573.84, "text": " So how I checked all these things was that there's a part program part of the server", "tokens": [51150, 407, 577, 286, 10033, 439, 613, 721, 390, 300, 456, 311, 257, 644, 1461, 644, 295, 264, 7154, 51738], "temperature": 0.0, "avg_logprob": -0.2301168021033792, "compression_ratio": 1.5636363636363637, "no_speech_prob": 0.0046575372107326984}, {"id": 91, "seek": 57384, "start": 573.84, "end": 582.52, "text": " check cost you can run it with any engine and it then produce that's a lot of different", "tokens": [50364, 1520, 2063, 291, 393, 1190, 309, 365, 604, 2848, 293, 309, 550, 5258, 300, 311, 257, 688, 295, 819, 50798], "temperature": 0.0, "avg_logprob": -0.29559217599722054, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.019018258899450302}, {"id": 92, "seek": 57384, "start": 582.52, "end": 591.0, "text": " checks tables can index can key look up and so on and then it you get here you get the", "tokens": [50798, 13834, 8020, 393, 8186, 393, 2141, 574, 493, 293, 370, 322, 293, 550, 309, 291, 483, 510, 291, 483, 264, 51222], "temperature": 0.0, "avg_logprob": -0.29559217599722054, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.019018258899450302}, {"id": 93, "seek": 57384, "start": 591.0, "end": 599.0400000000001, "text": " costs and here you have the timing milliseconds for doing that and if the if things are correct", "tokens": [51222, 5497, 293, 510, 291, 362, 264, 10822, 34184, 337, 884, 300, 293, 498, 264, 498, 721, 366, 3006, 51624], "temperature": 0.0, "avg_logprob": -0.29559217599722054, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.019018258899450302}, {"id": 94, "seek": 59904, "start": 599.04, "end": 606.8399999999999, "text": " you get as far close to one and this I have a fixed for all engines.", "tokens": [50364, 291, 483, 382, 1400, 1998, 281, 472, 293, 341, 286, 362, 257, 6806, 337, 439, 12982, 13, 50754], "temperature": 0.0, "avg_logprob": -0.25365318790558844, "compression_ratio": 1.5120481927710843, "no_speech_prob": 0.18427737057209015}, {"id": 95, "seek": 59904, "start": 606.8399999999999, "end": 613.76, "text": " So that means that I have a way to verify that the cost is up or okay it's almost impossible", "tokens": [50754, 407, 300, 1355, 300, 286, 362, 257, 636, 281, 16888, 300, 264, 2063, 307, 493, 420, 1392, 309, 311, 1920, 6243, 51100], "temperature": 0.0, "avg_logprob": -0.25365318790558844, "compression_ratio": 1.5120481927710843, "no_speech_prob": 0.18427737057209015}, {"id": 96, "seek": 59904, "start": 613.76, "end": 620.16, "text": " to get them totally because even when you run things on a machine things actually changes", "tokens": [51100, 281, 483, 552, 3879, 570, 754, 562, 291, 1190, 721, 322, 257, 3479, 721, 767, 2962, 51420], "temperature": 0.0, "avg_logprob": -0.25365318790558844, "compression_ratio": 1.5120481927710843, "no_speech_prob": 0.18427737057209015}, {"id": 97, "seek": 62016, "start": 620.16, "end": 638.4, "text": " from run to run but it's a millisecond yeah there were lots of things in the optimizer", "tokens": [50364, 490, 1190, 281, 1190, 457, 309, 311, 257, 27940, 18882, 1338, 456, 645, 3195, 295, 721, 294, 264, 5028, 6545, 51276], "temperature": 0.0, "avg_logprob": -0.3937452005785565, "compression_ratio": 1.4710743801652892, "no_speech_prob": 0.08639895170927048}, {"id": 98, "seek": 62016, "start": 638.4, "end": 645.8, "text": " that was cost based sorry but still also a lot of things rule based no basically everything", "tokens": [51276, 300, 390, 2063, 2361, 2597, 457, 920, 611, 257, 688, 295, 721, 4978, 2361, 572, 1936, 1203, 51646], "temperature": 0.0, "avg_logprob": -0.3937452005785565, "compression_ratio": 1.4710743801652892, "no_speech_prob": 0.08639895170927048}, {"id": 99, "seek": 64580, "start": 645.8, "end": 658.16, "text": " is everything I found is no cost base which means that it's easier for the optimizer to", "tokens": [50364, 307, 1203, 286, 1352, 307, 572, 2063, 3096, 597, 1355, 300, 309, 311, 3571, 337, 264, 5028, 6545, 281, 50982], "temperature": 0.0, "avg_logprob": -0.3457561189478094, "compression_ratio": 1.348148148148148, "no_speech_prob": 0.09057190269231796}, {"id": 100, "seek": 64580, "start": 658.16, "end": 667.3199999999999, "text": " do choices therefore there is patches in the DB that's all still in MySQL where they recommend", "tokens": [50982, 360, 7994, 4412, 456, 307, 26531, 294, 264, 26754, 300, 311, 439, 920, 294, 1222, 39934, 689, 436, 2748, 51440], "temperature": 0.0, "avg_logprob": -0.3457561189478094, "compression_ratio": 1.348148148148148, "no_speech_prob": 0.09057190269231796}, {"id": 101, "seek": 66732, "start": 667.32, "end": 680.08, "text": " that MySQL prefers table scan so let's reduce all index scans to half just to force the", "tokens": [50364, 300, 1222, 39934, 44334, 3199, 11049, 370, 718, 311, 5407, 439, 8186, 35116, 281, 1922, 445, 281, 3464, 264, 51002], "temperature": 0.0, "avg_logprob": -0.2169888557926301, "compression_ratio": 1.5670731707317074, "no_speech_prob": 0.1555817425251007}, {"id": 102, "seek": 66732, "start": 680.08, "end": 686.5200000000001, "text": " optimizer to use indexes instead of table scans which is of course a disaster for the", "tokens": [51002, 5028, 6545, 281, 764, 8186, 279, 2602, 295, 3199, 35116, 597, 307, 295, 1164, 257, 11293, 337, 264, 51324], "temperature": 0.0, "avg_logprob": -0.2169888557926301, "compression_ratio": 1.5670731707317074, "no_speech_prob": 0.1555817425251007}, {"id": 103, "seek": 66732, "start": 686.5200000000001, "end": 692.48, "text": " optimizer because then it gets wrong data and can do good decisions so all of those", "tokens": [51324, 5028, 6545, 570, 550, 309, 2170, 2085, 1412, 293, 393, 360, 665, 5327, 370, 439, 295, 729, 51622], "temperature": 0.0, "avg_logprob": -0.2169888557926301, "compression_ratio": 1.5670731707317074, "no_speech_prob": 0.1555817425251007}, {"id": 104, "seek": 69248, "start": 692.48, "end": 708.08, "text": " are removed so no inner DB gives the best optimizer it can and that helps things a lot", "tokens": [50364, 366, 7261, 370, 572, 7284, 26754, 2709, 264, 1151, 5028, 6545, 309, 393, 293, 300, 3665, 721, 257, 688, 51144], "temperature": 0.0, "avg_logprob": -0.29456508450391816, "compression_ratio": 1.4274193548387097, "no_speech_prob": 0.03733627498149872}, {"id": 105, "seek": 69248, "start": 708.08, "end": 721.44, "text": " and I spent a lot of time doing improving things from performance point of view especially", "tokens": [51144, 293, 286, 4418, 257, 688, 295, 565, 884, 11470, 721, 490, 3389, 935, 295, 1910, 2318, 51812], "temperature": 0.0, "avg_logprob": -0.29456508450391816, "compression_ratio": 1.4274193548387097, "no_speech_prob": 0.03733627498149872}, {"id": 106, "seek": 72144, "start": 722.44, "end": 733.4000000000001, "text": " is probably 50% faster than before more caching simplified code and had I haven't worked in", "tokens": [50414, 307, 1391, 2625, 4, 4663, 813, 949, 544, 269, 2834, 26335, 3089, 293, 632, 286, 2378, 380, 2732, 294, 50962], "temperature": 0.0, "avg_logprob": -0.23245573043823242, "compression_ratio": 1.489247311827957, "no_speech_prob": 0.15133023262023926}, {"id": 107, "seek": 72144, "start": 733.4000000000001, "end": 740.72, "text": " the optimizer since the first version of MySQL in 95 maybe between 95 and 2000 I worked on", "tokens": [50962, 264, 5028, 6545, 1670, 264, 700, 3037, 295, 1222, 39934, 294, 13420, 1310, 1296, 13420, 293, 8132, 286, 2732, 322, 51328], "temperature": 0.0, "avg_logprob": -0.23245573043823242, "compression_ratio": 1.489247311827957, "no_speech_prob": 0.15133023262023926}, {"id": 108, "seek": 72144, "start": 740.72, "end": 747.2, "text": " it and then a lot of other people worked on it and they did a lot of amazing jobs in different", "tokens": [51328, 309, 293, 550, 257, 688, 295, 661, 561, 2732, 322, 309, 293, 436, 630, 257, 688, 295, 2243, 4782, 294, 819, 51652], "temperature": 0.0, "avg_logprob": -0.23245573043823242, "compression_ratio": 1.489247311827957, "no_speech_prob": 0.15133023262023926}, {"id": 109, "seek": 74720, "start": 747.2, "end": 753.48, "text": " parts of the server but nobody took the time to ensure that how things related to this one and", "tokens": [50364, 3166, 295, 264, 7154, 457, 5079, 1890, 264, 565, 281, 5586, 300, 577, 721, 4077, 281, 341, 472, 293, 50678], "temperature": 0.0, "avg_logprob": -0.19803897009955512, "compression_ratio": 1.5365853658536586, "no_speech_prob": 0.009319744072854519}, {"id": 110, "seek": 74720, "start": 753.48, "end": 765.0400000000001, "text": " this one and this one especially with costs so all of that's no done I also fixed small things", "tokens": [50678, 341, 472, 293, 341, 472, 2318, 365, 5497, 370, 439, 295, 300, 311, 572, 1096, 286, 611, 6806, 1359, 721, 51256], "temperature": 0.0, "avg_logprob": -0.19803897009955512, "compression_ratio": 1.5365853658536586, "no_speech_prob": 0.009319744072854519}, {"id": 111, "seek": 76504, "start": 765.04, "end": 777.48, "text": " then we also I also changed that we tried to use a longer indexes if they are there", "tokens": [50364, 550, 321, 611, 286, 611, 3105, 300, 321, 3031, 281, 764, 257, 2854, 8186, 279, 498, 436, 366, 456, 50986], "temperature": 0.0, "avg_logprob": -0.22313806414604187, "compression_ratio": 1.701219512195122, "no_speech_prob": 0.01934659853577614}, {"id": 112, "seek": 76504, "start": 777.48, "end": 786.36, "text": " the one thing that is a problem is that especially for the test suite is that no when we actually", "tokens": [50986, 264, 472, 551, 300, 307, 257, 1154, 307, 300, 2318, 337, 264, 1500, 14205, 307, 300, 572, 562, 321, 767, 51430], "temperature": 0.0, "avg_logprob": -0.22313806414604187, "compression_ratio": 1.701219512195122, "no_speech_prob": 0.01934659853577614}, {"id": 113, "seek": 76504, "start": 786.36, "end": 794.4399999999999, "text": " have proper costs table scans is preferred for most queries in the test system because the tables", "tokens": [51430, 362, 2296, 5497, 3199, 35116, 307, 16494, 337, 881, 24109, 294, 264, 1500, 1185, 570, 264, 8020, 51834], "temperature": 0.0, "avg_logprob": -0.22313806414604187, "compression_ratio": 1.701219512195122, "no_speech_prob": 0.01934659853577614}, {"id": 114, "seek": 79444, "start": 794.5200000000001, "end": 800.2, "text": " can both in the DB and other engines is really really really fast one disk seek and you get", "tokens": [50368, 393, 1293, 294, 264, 26754, 293, 661, 12982, 307, 534, 534, 534, 2370, 472, 12355, 8075, 293, 291, 483, 50652], "temperature": 0.0, "avg_logprob": -0.2447503456702599, "compression_ratio": 1.5083798882681565, "no_speech_prob": 0.004929565358906984}, {"id": 115, "seek": 79444, "start": 800.2, "end": 809.6, "text": " hundred rows compared to index lookups so there's optimizers can set up cost that is", "tokens": [50652, 3262, 13241, 5347, 281, 8186, 574, 7528, 370, 456, 311, 5028, 22525, 393, 992, 493, 2063, 300, 307, 51122], "temperature": 0.0, "avg_logprob": -0.2447503456702599, "compression_ratio": 1.5083798882681565, "no_speech_prob": 0.004929565358906984}, {"id": 116, "seek": 79444, "start": 809.6, "end": 820.5200000000001, "text": " is I think it's 10 milliseconds as default just to encourage the optimizer to use indexes for", "tokens": [51122, 307, 286, 519, 309, 311, 1266, 34184, 382, 7576, 445, 281, 5373, 264, 5028, 6545, 281, 764, 8186, 279, 337, 51668], "temperature": 0.0, "avg_logprob": -0.2447503456702599, "compression_ratio": 1.5083798882681565, "no_speech_prob": 0.004929565358906984}, {"id": 117, "seek": 82052, "start": 820.52, "end": 825.96, "text": " small tables mostly because if you don't that you can confuse both the test system and users", "tokens": [50364, 1359, 8020, 5240, 570, 498, 291, 500, 380, 300, 291, 393, 28584, 1293, 264, 1500, 1185, 293, 5022, 50636], "temperature": 0.0, "avg_logprob": -0.34268122911453247, "compression_ratio": 1.6228571428571428, "no_speech_prob": 0.04021603614091873}, {"id": 118, "seek": 82052, "start": 825.96, "end": 833.1999999999999, "text": " and if they're small tables nobody like here if it takes one 10 to a milliseconds or 100 slow", "tokens": [50636, 293, 498, 436, 434, 1359, 8020, 5079, 411, 510, 498, 309, 2516, 472, 1266, 281, 257, 34184, 420, 2319, 2964, 50998], "temperature": 0.0, "avg_logprob": -0.34268122911453247, "compression_ratio": 1.6228571428571428, "no_speech_prob": 0.04021603614091873}, {"id": 119, "seek": 82052, "start": 840.64, "end": 848.0, "text": " basically this affect tables that are less than than 20 rows and that's unfortunately most of the", "tokens": [51370, 1936, 341, 3345, 8020, 300, 366, 1570, 813, 813, 945, 13241, 293, 300, 311, 7015, 881, 295, 264, 51738], "temperature": 0.0, "avg_logprob": -0.34268122911453247, "compression_ratio": 1.6228571428571428, "no_speech_prob": 0.04021603614091873}, {"id": 120, "seek": 84800, "start": 848.0, "end": 856.08, "text": " tests in my Maria DB have 10 rows or small yes what I see in concurrency is that it doesn't work", "tokens": [50364, 6921, 294, 452, 12734, 26754, 362, 1266, 13241, 420, 1359, 2086, 437, 286, 536, 294, 23702, 10457, 307, 300, 309, 1177, 380, 589, 50768], "temperature": 0.0, "avg_logprob": -0.4004200945843707, "compression_ratio": 1.6277056277056277, "no_speech_prob": 0.01492940355092287}, {"id": 121, "seek": 84800, "start": 856.08, "end": 860.88, "text": " very well because he's doing a lot of full scan at the end of the plan even if the index is there", "tokens": [50768, 588, 731, 570, 415, 311, 884, 257, 688, 295, 1577, 11049, 412, 264, 917, 295, 264, 1393, 754, 498, 264, 8186, 307, 456, 51008], "temperature": 0.0, "avg_logprob": -0.4004200945843707, "compression_ratio": 1.6277056277056277, "no_speech_prob": 0.01492940355092287}, {"id": 122, "seek": 84800, "start": 860.88, "end": 868.48, "text": " and could choose the accurate yeah but then no things are cost based and except with a small", "tokens": [51008, 293, 727, 2826, 264, 8559, 1338, 457, 550, 572, 721, 366, 2063, 2361, 293, 3993, 365, 257, 1359, 51388], "temperature": 0.0, "avg_logprob": -0.4004200945843707, "compression_ratio": 1.6277056277056277, "no_speech_prob": 0.01492940355092287}, {"id": 123, "seek": 84800, "start": 868.48, "end": 876.76, "text": " very small penalty for table scan but that's more for getting more and more chocolate so", "tokens": [51388, 588, 1359, 16263, 337, 3199, 11049, 457, 300, 311, 544, 337, 1242, 544, 293, 544, 6215, 370, 51802], "temperature": 0.0, "avg_logprob": -0.4004200945843707, "compression_ratio": 1.6277056277056277, "no_speech_prob": 0.01492940355092287}, {"id": 124, "seek": 87676, "start": 876.76, "end": 883.28, "text": " that you don't need indexes anymore because the hash algorithms are much faster hash is really really", "tokens": [50364, 300, 291, 500, 380, 643, 8186, 279, 3602, 570, 264, 22019, 14642, 366, 709, 4663, 22019, 307, 534, 534, 50690], "temperature": 0.0, "avg_logprob": -0.4674441363360431, "compression_ratio": 1.598901098901099, "no_speech_prob": 0.022424649447202682}, {"id": 125, "seek": 87676, "start": 883.28, "end": 891.12, "text": " slow for you if you are going to fit a small of a small amount of rows I was in 10,000 20,000", "tokens": [50690, 2964, 337, 291, 498, 291, 366, 516, 281, 3318, 257, 1359, 295, 257, 1359, 2372, 295, 13241, 286, 390, 294, 1266, 11, 1360, 945, 11, 1360, 51082], "temperature": 0.0, "avg_logprob": -0.4674441363360431, "compression_ratio": 1.598901098901099, "no_speech_prob": 0.022424649447202682}, {"id": 126, "seek": 87676, "start": 891.12, "end": 899.04, "text": " 12,000 of those that you have all in cash and also depending it depends on total on queries and", "tokens": [51082, 2272, 11, 1360, 295, 729, 300, 291, 362, 439, 294, 6388, 293, 611, 5413, 309, 5946, 322, 3217, 322, 24109, 293, 51478], "temperature": 0.0, "avg_logprob": -0.4674441363360431, "compression_ratio": 1.598901098901099, "no_speech_prob": 0.022424649447202682}, {"id": 127, "seek": 89904, "start": 899.4399999999999, "end": 909.24, "text": " and concurrency hashing takes a lot of memory no but that means that you get this concurrency", "tokens": [50384, 293, 23702, 10457, 575, 571, 2516, 257, 688, 295, 4675, 572, 457, 300, 1355, 300, 291, 483, 341, 23702, 10457, 50874], "temperature": 0.0, "avg_logprob": -0.2332903820535411, "compression_ratio": 1.6514285714285715, "no_speech_prob": 0.09802008420228958}, {"id": 128, "seek": 89904, "start": 909.24, "end": 916.12, "text": " because the CPU is just moving things from memory when it doesn't so hashing is good in some cases", "tokens": [50874, 570, 264, 13199, 307, 445, 2684, 721, 490, 4675, 562, 309, 1177, 380, 370, 575, 571, 307, 665, 294, 512, 3331, 51218], "temperature": 0.0, "avg_logprob": -0.2332903820535411, "compression_ratio": 1.6514285714285715, "no_speech_prob": 0.09802008420228958}, {"id": 129, "seek": 89904, "start": 916.12, "end": 926.28, "text": " but it especially if you want to access a lot of rows directly or indirectly if you only need to", "tokens": [51218, 457, 309, 2318, 498, 291, 528, 281, 2105, 257, 688, 295, 13241, 3838, 420, 37779, 498, 291, 787, 643, 281, 51726], "temperature": 0.0, "avg_logprob": -0.2332903820535411, "compression_ratio": 1.6514285714285715, "no_speech_prob": 0.09802008420228958}, {"id": 130, "seek": 92628, "start": 926.28, "end": 933.92, "text": " access a few rows then hashing is really a disaster yeah and most if you look at banks and", "tokens": [50364, 2105, 257, 1326, 13241, 550, 575, 571, 307, 534, 257, 11293, 1338, 293, 881, 498, 291, 574, 412, 10237, 293, 50746], "temperature": 0.0, "avg_logprob": -0.2824811788705679, "compression_ratio": 1.630057803468208, "no_speech_prob": 0.018340647220611572}, {"id": 131, "seek": 92628, "start": 933.92, "end": 939.16, "text": " sections everything else hashing wouldn't work or any of those because usually just want to have", "tokens": [50746, 10863, 1203, 1646, 575, 571, 2759, 380, 589, 420, 604, 295, 729, 570, 2673, 445, 528, 281, 362, 51008], "temperature": 0.0, "avg_logprob": -0.2824811788705679, "compression_ratio": 1.630057803468208, "no_speech_prob": 0.018340647220611572}, {"id": 132, "seek": 92628, "start": 939.16, "end": 948.0, "text": " everything from a small set of customers so here the from the user point of view those are the", "tokens": [51008, 1203, 490, 257, 1359, 992, 295, 4581, 370, 510, 264, 490, 264, 4195, 935, 295, 1910, 729, 366, 264, 51450], "temperature": 0.0, "avg_logprob": -0.2824811788705679, "compression_ratio": 1.630057803468208, "no_speech_prob": 0.018340647220611572}, {"id": 133, "seek": 94800, "start": 948.0, "end": 958.56, "text": " only variables that I think that you but may need those who create engines may need more and one", "tokens": [50364, 787, 9102, 300, 286, 519, 300, 291, 457, 815, 643, 729, 567, 1884, 12982, 815, 643, 544, 293, 472, 50892], "temperature": 0.0, "avg_logprob": -0.21436443026103671, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.053334884345531464}, {"id": 134, "seek": 94800, "start": 958.56, "end": 966.92, "text": " thing to be aware of that from the use user variables they are in in microseconds not in", "tokens": [50892, 551, 281, 312, 3650, 295, 300, 490, 264, 764, 4195, 9102, 436, 366, 294, 294, 3123, 37841, 28750, 406, 294, 51310], "temperature": 0.0, "avg_logprob": -0.21436443026103671, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.053334884345531464}, {"id": 135, "seek": 94800, "start": 966.92, "end": 972.68, "text": " milliseconds because I first had them in in milliseconds but the numbers get so small that", "tokens": [51310, 34184, 570, 286, 700, 632, 552, 294, 294, 34184, 457, 264, 3547, 483, 370, 1359, 300, 51598], "temperature": 0.0, "avg_logprob": -0.21436443026103671, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.053334884345531464}, {"id": 136, "seek": 97268, "start": 972.68, "end": 981.04, "text": " it was very hard to look at those so there's a so when they internally they use the milliseconds", "tokens": [50364, 309, 390, 588, 1152, 281, 574, 412, 729, 370, 456, 311, 257, 370, 562, 436, 19501, 436, 764, 264, 34184, 50782], "temperature": 0.0, "avg_logprob": -0.25203668503534227, "compression_ratio": 1.4545454545454546, "no_speech_prob": 0.05096839740872383}, {"id": 137, "seek": 97268, "start": 981.04, "end": 1001.9599999999999, "text": " but from user point the costs are in microseconds you have these variables here", "tokens": [50782, 457, 490, 4195, 935, 264, 5497, 366, 294, 3123, 37841, 28750, 291, 362, 613, 9102, 510, 51828], "temperature": 0.0, "avg_logprob": -0.25203668503534227, "compression_ratio": 1.4545454545454546, "no_speech_prob": 0.05096839740872383}, {"id": 138, "seek": 100196, "start": 1001.96, "end": 1011.64, "text": " all these are just for memory and then you have a cost for fetching the fetching the disks fetching", "tokens": [50364, 439, 613, 366, 445, 337, 4675, 293, 550, 291, 362, 257, 2063, 337, 23673, 278, 264, 23673, 278, 264, 41617, 23673, 278, 50848], "temperature": 0.0, "avg_logprob": -0.26900183900873714, "compression_ratio": 1.6581196581196582, "no_speech_prob": 0.2145266830921173}, {"id": 139, "seek": 100196, "start": 1011.64, "end": 1024.44, "text": " the blocks yeah so this is all memory yeah so optimize optimize a discrete cost that's the one", "tokens": [50848, 264, 8474, 1338, 370, 341, 307, 439, 4675, 1338, 370, 19719, 19719, 257, 27706, 2063, 300, 311, 264, 472, 51488], "temperature": 0.0, "avg_logprob": -0.26900183900873714, "compression_ratio": 1.6581196581196582, "no_speech_prob": 0.2145266830921173}, {"id": 140, "seek": 102444, "start": 1024.44, "end": 1036.0800000000002, "text": " that is an IO so there's like running more easy on like bare metal machine with very fast SSD like", "tokens": [50364, 300, 307, 364, 39839, 370, 456, 311, 411, 2614, 544, 1858, 322, 411, 6949, 5760, 3479, 365, 588, 2370, 30262, 411, 50946], "temperature": 0.0, "avg_logprob": -0.4009191475662531, "compression_ratio": 1.3472222222222223, "no_speech_prob": 0.19483673572540283}, {"id": 141, "seek": 102444, "start": 1036.0800000000002, "end": 1044.72, "text": " the IO is half it's one 10 of a millisecond but in the cloud IOs go through yeah network as you", "tokens": [50946, 264, 39839, 307, 1922, 309, 311, 472, 1266, 295, 257, 27940, 18882, 457, 294, 264, 4588, 286, 31376, 352, 807, 1338, 3209, 382, 291, 51378], "temperature": 0.0, "avg_logprob": -0.4009191475662531, "compression_ratio": 1.3472222222222223, "no_speech_prob": 0.19483673572540283}, {"id": 142, "seek": 104472, "start": 1044.72, "end": 1057.0, "text": " compare but I guess you need to tune this variable probably I haven't done that so I've been basically", "tokens": [50364, 6794, 457, 286, 2041, 291, 643, 281, 10864, 341, 7006, 1391, 286, 2378, 380, 1096, 300, 370, 286, 600, 668, 1936, 50978], "temperature": 0.0, "avg_logprob": -0.20786811323726878, "compression_ratio": 1.6573033707865168, "no_speech_prob": 0.060108814388513565}, {"id": 143, "seek": 104472, "start": 1057.0, "end": 1062.1200000000001, "text": " focused just to get this to work so everything is focused on getting the memory part of work but", "tokens": [50978, 5178, 445, 281, 483, 341, 281, 589, 370, 1203, 307, 5178, 322, 1242, 264, 4675, 644, 295, 589, 457, 51234], "temperature": 0.0, "avg_logprob": -0.20786811323726878, "compression_ratio": 1.6573033707865168, "no_speech_prob": 0.060108814388513565}, {"id": 144, "seek": 104472, "start": 1062.1200000000001, "end": 1068.96, "text": " the disk is there and it's only two variables so it's very hard to get those totally wrong yeah", "tokens": [51234, 264, 12355, 307, 456, 293, 309, 311, 787, 732, 9102, 370, 309, 311, 588, 1152, 281, 483, 729, 3879, 2085, 1338, 51576], "temperature": 0.0, "avg_logprob": -0.20786811323726878, "compression_ratio": 1.6573033707865168, "no_speech_prob": 0.060108814388513565}, {"id": 145, "seek": 107472, "start": 1074.72, "end": 1081.76, "text": " if you run on a managed database in the cloud they might tune it with people like you might", "tokens": [50364, 498, 291, 1190, 322, 257, 6453, 8149, 294, 264, 4588, 436, 1062, 10864, 309, 365, 561, 411, 291, 1062, 50716], "temperature": 0.0, "avg_logprob": -0.35212360211272736, "compression_ratio": 1.5271739130434783, "no_speech_prob": 0.0154624218121171}, {"id": 146, "seek": 107472, "start": 1081.76, "end": 1089.68, "text": " miss this would be interesting to see like the difference in how wrong things get if MeruDB", "tokens": [50716, 1713, 341, 576, 312, 1880, 281, 536, 411, 264, 2649, 294, 577, 2085, 721, 483, 498, 6124, 84, 27735, 51112], "temperature": 0.0, "avg_logprob": -0.35212360211272736, "compression_ratio": 1.5271739130434783, "no_speech_prob": 0.0154624218121171}, {"id": 147, "seek": 107472, "start": 1089.68, "end": 1096.24, "text": " thinks you're on fast SSDs but you're actually on network SSDs and this variable every engine has", "tokens": [51112, 7309, 291, 434, 322, 2370, 30262, 82, 457, 291, 434, 767, 322, 3209, 30262, 82, 293, 341, 7006, 633, 2848, 575, 51440], "temperature": 0.0, "avg_logprob": -0.35212360211272736, "compression_ratio": 1.5271739130434783, "no_speech_prob": 0.0154624218121171}, {"id": 148, "seek": 109624, "start": 1096.6, "end": 1102.0, "text": " has its own variable so you can choose it changes for different engines if you want if you for", "tokens": [50382, 575, 1080, 1065, 7006, 370, 291, 393, 2826, 309, 2962, 337, 819, 12982, 498, 291, 528, 498, 291, 337, 50652], "temperature": 0.0, "avg_logprob": -0.2548868773413486, "compression_ratio": 1.725, "no_speech_prob": 0.020979948341846466}, {"id": 149, "seek": 109624, "start": 1102.0, "end": 1112.36, "text": " example run on different devices so chasing cost variables is easy you just session or", "tokens": [50652, 1365, 1190, 322, 819, 5759, 370, 17876, 2063, 9102, 307, 1858, 291, 445, 5481, 420, 51170], "temperature": 0.0, "avg_logprob": -0.2548868773413486, "compression_ratio": 1.725, "no_speech_prob": 0.020979948341846466}, {"id": 150, "seek": 109624, "start": 1112.36, "end": 1123.88, "text": " change global all engines are global but the wear cost and or that things are local so this is", "tokens": [51170, 1319, 4338, 439, 12982, 366, 4338, 457, 264, 3728, 2063, 293, 420, 300, 721, 366, 2654, 370, 341, 307, 51746], "temperature": 0.0, "avg_logprob": -0.2548868773413486, "compression_ratio": 1.725, "no_speech_prob": 0.020979948341846466}, {"id": 151, "seek": 112388, "start": 1124.5600000000002, "end": 1133.16, "text": " see I have a couple of minutes left so so question why does this matter to you if you ever had to", "tokens": [50398, 536, 286, 362, 257, 1916, 295, 2077, 1411, 370, 370, 1168, 983, 775, 341, 1871, 281, 291, 498, 291, 1562, 632, 281, 50828], "temperature": 0.0, "avg_logprob": -0.23506199972970146, "compression_ratio": 1.6022099447513811, "no_speech_prob": 0.002632753225043416}, {"id": 152, "seek": 112388, "start": 1133.16, "end": 1142.88, "text": " go and say force index or have to try to tweak queries in any way or had to use analyze the", "tokens": [50828, 352, 293, 584, 3464, 8186, 420, 362, 281, 853, 281, 29879, 24109, 294, 604, 636, 420, 632, 281, 764, 12477, 264, 51314], "temperature": 0.0, "avg_logprob": -0.23506199972970146, "compression_ratio": 1.6022099447513811, "no_speech_prob": 0.002632753225043416}, {"id": 153, "seek": 112388, "start": 1142.88, "end": 1152.1200000000001, "text": " analysis table is still useful because you get the statistics but I would say that one main thing is", "tokens": [51314, 5215, 3199, 307, 920, 4420, 570, 291, 483, 264, 12523, 457, 286, 576, 584, 300, 472, 2135, 551, 307, 51776], "temperature": 0.0, "avg_logprob": -0.23506199972970146, "compression_ratio": 1.6022099447513811, "no_speech_prob": 0.002632753225043416}, {"id": 154, "seek": 115212, "start": 1152.12, "end": 1162.8, "text": " that much less tweaking queries these should just work and especially we use in a DBM memory", "tokens": [50364, 300, 709, 1570, 6986, 2456, 24109, 613, 820, 445, 589, 293, 2318, 321, 764, 294, 257, 26754, 44, 4675, 50898], "temperature": 0.0, "avg_logprob": -0.2838021191683682, "compression_ratio": 1.532258064516129, "no_speech_prob": 0.0014529353938996792}, {"id": 155, "seek": 115212, "start": 1162.8, "end": 1171.12, "text": " engine for example or other engines things are not a little better and no even the server knows", "tokens": [50898, 2848, 337, 1365, 420, 661, 12982, 721, 366, 406, 257, 707, 1101, 293, 572, 754, 264, 7154, 3255, 51314], "temperature": 0.0, "avg_logprob": -0.2838021191683682, "compression_ratio": 1.532258064516129, "no_speech_prob": 0.0014529353938996792}, {"id": 156, "seek": 115212, "start": 1171.12, "end": 1178.6, "text": " that no we have temporal tables in in in area or heap so it can take that that cost into account", "tokens": [51314, 300, 572, 321, 362, 30881, 8020, 294, 294, 294, 1859, 420, 33591, 370, 309, 393, 747, 300, 300, 2063, 666, 2696, 51688], "temperature": 0.0, "avg_logprob": -0.2838021191683682, "compression_ratio": 1.532258064516129, "no_speech_prob": 0.0014529353938996792}, {"id": 157, "seek": 117860, "start": 1178.6, "end": 1187.9599999999998, "text": " so state of things basically everything is done we have had QA testing this no form is one month", "tokens": [50364, 370, 1785, 295, 721, 1936, 1203, 307, 1096, 321, 362, 632, 1249, 32, 4997, 341, 572, 1254, 307, 472, 1618, 50832], "temperature": 0.0, "avg_logprob": -0.2560547501293581, "compression_ratio": 1.654970760233918, "no_speech_prob": 0.005145379342138767}, {"id": 158, "seek": 117860, "start": 1187.9599999999998, "end": 1196.76, "text": " founder some bugs most of the bugs is in the also in older releases so I in this I basically fixing", "tokens": [50832, 14917, 512, 15120, 881, 295, 264, 15120, 307, 294, 264, 611, 294, 4906, 16952, 370, 286, 294, 341, 286, 1936, 19442, 51272], "temperature": 0.0, "avg_logprob": -0.2560547501293581, "compression_ratio": 1.654970760233918, "no_speech_prob": 0.005145379342138767}, {"id": 159, "seek": 117860, "start": 1196.76, "end": 1203.8799999999999, "text": " everything related to optimizer in this one there's one issue left that I will push on", "tokens": [51272, 1203, 4077, 281, 5028, 6545, 294, 341, 472, 456, 311, 472, 2734, 1411, 300, 286, 486, 2944, 322, 51628], "temperature": 0.0, "avg_logprob": -0.2560547501293581, "compression_ratio": 1.654970760233918, "no_speech_prob": 0.005145379342138767}, {"id": 160, "seek": 120388, "start": 1204.8400000000001, "end": 1214.5200000000002, "text": " at this week and then basically the level should be done we have a BB 11 0 that includes everything", "tokens": [50412, 412, 341, 1243, 293, 550, 1936, 264, 1496, 820, 312, 1096, 321, 362, 257, 19168, 2975, 1958, 300, 5974, 1203, 50896], "temperature": 0.0, "avg_logprob": -0.27936475417193246, "compression_ratio": 1.5364583333333333, "no_speech_prob": 0.01793254166841507}, {"id": 161, "seek": 120388, "start": 1214.5200000000002, "end": 1222.96, "text": " I think this is one of the most tested releases ever done internally just because I've been working", "tokens": [50896, 286, 519, 341, 307, 472, 295, 264, 881, 8246, 16952, 1562, 1096, 19501, 445, 570, 286, 600, 668, 1364, 51318], "temperature": 0.0, "avg_logprob": -0.27936475417193246, "compression_ratio": 1.5364583333333333, "no_speech_prob": 0.01793254166841507}, {"id": 162, "seek": 120388, "start": 1222.96, "end": 1231.64, "text": " so much with our QA team so I expect this be almost stable from from start or access table from", "tokens": [51318, 370, 709, 365, 527, 1249, 32, 1469, 370, 286, 2066, 341, 312, 1920, 8351, 490, 490, 722, 420, 2105, 3199, 490, 51752], "temperature": 0.0, "avg_logprob": -0.27936475417193246, "compression_ratio": 1.5364583333333333, "no_speech_prob": 0.01793254166841507}, {"id": 163, "seek": 123164, "start": 1231.64, "end": 1242.2, "text": " start and for anybody who wants to help if you have a slave where you can put 11 0 on put it on", "tokens": [50364, 722, 293, 337, 4472, 567, 2738, 281, 854, 498, 291, 362, 257, 14777, 689, 291, 393, 829, 2975, 1958, 322, 829, 309, 322, 50892], "temperature": 0.0, "avg_logprob": -0.386999867179177, "compression_ratio": 1.441860465116279, "no_speech_prob": 0.0223090797662735}, {"id": 164, "seek": 123164, "start": 1242.2, "end": 1248.3200000000002, "text": " send feedback make your entries anything related to optimizer will be fixed it immediately", "tokens": [50892, 2845, 5824, 652, 428, 23041, 1340, 4077, 281, 5028, 6545, 486, 312, 6806, 309, 4258, 51198], "temperature": 0.0, "avg_logprob": -0.386999867179177, "compression_ratio": 1.441860465116279, "no_speech_prob": 0.0223090797662735}, {"id": 165, "seek": 124832, "start": 1248.32, "end": 1269.4399999999998, "text": " should it should be the same except something like row by the filters is faster so all code", "tokens": [50364, 820, 309, 820, 312, 264, 912, 3993, 746, 411, 5386, 538, 264, 15995, 307, 4663, 370, 439, 3089, 51420], "temperature": 0.0, "avg_logprob": -0.2785516652193936, "compression_ratio": 1.472, "no_speech_prob": 0.07761799544095993}, {"id": 166, "seek": 124832, "start": 1269.4399999999998, "end": 1276.32, "text": " I don't think that anything will be slower in the optimizer but the plan should be better so", "tokens": [51420, 286, 500, 380, 519, 300, 1340, 486, 312, 14009, 294, 264, 5028, 6545, 457, 264, 1393, 820, 312, 1101, 370, 51764], "temperature": 0.0, "avg_logprob": -0.2785516652193936, "compression_ratio": 1.472, "no_speech_prob": 0.07761799544095993}, {"id": 167, "seek": 127632, "start": 1276.56, "end": 1280.8, "text": " the end result should be faster there are a couple of things that are not a little better", "tokens": [50376, 264, 917, 1874, 820, 312, 4663, 456, 366, 257, 1916, 295, 721, 300, 366, 406, 257, 707, 1101, 50588], "temperature": 0.0, "avg_logprob": -0.2748238577771543, "compression_ratio": 1.7337662337662338, "no_speech_prob": 0.0023081444669514894}, {"id": 168, "seek": 127632, "start": 1287.76, "end": 1294.8, "text": " row by the filter means that if you have two indexes you can use and then we then we create", "tokens": [50936, 5386, 538, 264, 6608, 1355, 300, 498, 291, 362, 732, 8186, 279, 291, 393, 764, 293, 550, 321, 550, 321, 1884, 51288], "temperature": 0.0, "avg_logprob": -0.2748238577771543, "compression_ratio": 1.7337662337662338, "no_speech_prob": 0.0023081444669514894}, {"id": 169, "seek": 127632, "start": 1296.0, "end": 1303.28, "text": " we take we will use the the faster one but if if it makes sense we take the other one", "tokens": [51348, 321, 747, 321, 486, 764, 264, 264, 4663, 472, 457, 498, 498, 309, 1669, 2020, 321, 747, 264, 661, 472, 51712], "temperature": 0.0, "avg_logprob": -0.2748238577771543, "compression_ratio": 1.7337662337662338, "no_speech_prob": 0.0023081444669514894}, {"id": 170, "seek": 130328, "start": 1304.24, "end": 1310.16, "text": " fetch all primary keys and then when we read other ones we see that only those who has", "tokens": [50412, 23673, 439, 6194, 9317, 293, 550, 562, 321, 1401, 661, 2306, 321, 536, 300, 787, 729, 567, 575, 50708], "temperature": 0.0, "avg_logprob": -0.17946729503694128, "compression_ratio": 1.5974842767295598, "no_speech_prob": 0.029347248375415802}, {"id": 171, "seek": 130328, "start": 1312.24, "end": 1317.6, "text": " an existing primary key we need to consider so basically where there's a wind we don't have", "tokens": [50812, 364, 6741, 6194, 2141, 321, 643, 281, 1949, 370, 1936, 689, 456, 311, 257, 2468, 321, 500, 380, 362, 51080], "temperature": 0.0, "avg_logprob": -0.17946729503694128, "compression_ratio": 1.5974842767295598, "no_speech_prob": 0.029347248375415802}, {"id": 172, "seek": 130328, "start": 1317.6, "end": 1323.04, "text": " to fetch the row for things that we can filter out and the algorithm's name", "tokens": [51080, 281, 23673, 264, 5386, 337, 721, 300, 321, 393, 6608, 484, 293, 264, 9284, 311, 1315, 51352], "temperature": 0.0, "avg_logprob": -0.17946729503694128, "compression_ratio": 1.5974842767295598, "no_speech_prob": 0.029347248375415802}, {"id": 173, "seek": 132304, "start": 1323.84, "end": 1332.56, "text": " you know basically it's a lookup of all primary keys that are acceptable and we", "tokens": [50404, 291, 458, 1936, 309, 311, 257, 574, 1010, 295, 439, 6194, 9317, 300, 366, 15513, 293, 321, 50840], "temperature": 0.0, "avg_logprob": -0.2715870666503906, "compression_ratio": 1.5390070921985815, "no_speech_prob": 0.017267625778913498}, {"id": 174, "seek": 132304, "start": 1332.56, "end": 1340.56, "text": " use the used we do a check against those which is actually pretty fast so state of things basically", "tokens": [50840, 764, 264, 1143, 321, 360, 257, 1520, 1970, 729, 597, 307, 767, 1238, 2370, 370, 1785, 295, 721, 1936, 51240], "temperature": 0.0, "avg_logprob": -0.2715870666503906, "compression_ratio": 1.5390070921985815, "no_speech_prob": 0.017267625778913498}, {"id": 175, "seek": 132304, "start": 1341.92, "end": 1344.1599999999999, "text": " basically ready this will be released", "tokens": [51308, 1936, 1919, 341, 486, 312, 4736, 51420], "temperature": 0.0, "avg_logprob": -0.2715870666503906, "compression_ratio": 1.5390070921985815, "no_speech_prob": 0.017267625778913498}, {"id": 176, "seek": 134416, "start": 1344.88, "end": 1355.92, "text": " I think it's next in February yes so this month so future plans I will start working on", "tokens": [50400, 286, 519, 309, 311, 958, 294, 8711, 2086, 370, 341, 1618, 370, 2027, 5482, 286, 486, 722, 1364, 322, 50952], "temperature": 0.0, "avg_logprob": -0.20490514078447897, "compression_ratio": 1.4486486486486487, "no_speech_prob": 0.012945410795509815}, {"id": 177, "seek": 134416, "start": 1355.92, "end": 1363.52, "text": " parallel query there's still some optimized cleanups to be done I also want to enable all", "tokens": [50952, 8952, 14581, 456, 311, 920, 512, 26941, 2541, 7528, 281, 312, 1096, 286, 611, 528, 281, 9528, 439, 51332], "temperature": 0.0, "avg_logprob": -0.20490514078447897, "compression_ratio": 1.4486486486486487, "no_speech_prob": 0.012945410795509815}, {"id": 178, "seek": 134416, "start": 1363.52, "end": 1371.0400000000002, "text": " optimizers which is by default for example MariaD has supported has joins forever with the", "tokens": [51332, 5028, 22525, 597, 307, 538, 7576, 337, 1365, 12734, 35, 575, 8104, 575, 24397, 5680, 365, 264, 51708], "temperature": 0.0, "avg_logprob": -0.20490514078447897, "compression_ratio": 1.4486486486486487, "no_speech_prob": 0.012945410795509815}, {"id": 179, "seek": 137104, "start": 1371.04, "end": 1380.48, "text": " actually very hard to get to enable those bushy plans is something that we", "tokens": [50364, 767, 588, 1152, 281, 483, 281, 9528, 729, 1255, 3495, 5482, 307, 746, 300, 321, 50836], "temperature": 0.0, "avg_logprob": -0.18802965255010695, "compression_ratio": 1.7179487179487178, "no_speech_prob": 0.010938523337244987}, {"id": 180, "seek": 137104, "start": 1382.8, "end": 1387.68, "text": " I would like to do because we have this you big users who would need that bushy plans basically", "tokens": [50952, 286, 576, 411, 281, 360, 570, 321, 362, 341, 291, 955, 5022, 567, 576, 643, 300, 1255, 3495, 5482, 1936, 51196], "temperature": 0.0, "avg_logprob": -0.18802965255010695, "compression_ratio": 1.7179487179487178, "no_speech_prob": 0.010938523337244987}, {"id": 181, "seek": 137104, "start": 1387.68, "end": 1396.24, "text": " have two big tables and then lots of tables that you have a relationship and then you have a join", "tokens": [51196, 362, 732, 955, 8020, 293, 550, 3195, 295, 8020, 300, 291, 362, 257, 2480, 293, 550, 291, 362, 257, 3917, 51624], "temperature": 0.0, "avg_logprob": -0.18802965255010695, "compression_ratio": 1.7179487179487178, "no_speech_prob": 0.010938523337244987}, {"id": 182, "seek": 139624, "start": 1396.24, "end": 1402.0, "text": " between those directly the big tables directly or indirectly and our optimizer currently can't do", "tokens": [50364, 1296, 729, 3838, 264, 955, 8020, 3838, 420, 37779, 293, 527, 5028, 6545, 4362, 393, 380, 360, 50652], "temperature": 0.0, "avg_logprob": -0.15261752870347764, "compression_ratio": 1.6981981981981982, "no_speech_prob": 0.022413665428757668}, {"id": 183, "seek": 139624, "start": 1402.0, "end": 1407.04, "text": " that very very efficiently so that's something I would like to do but the parallel query is the", "tokens": [50652, 300, 588, 588, 19621, 370, 300, 311, 746, 286, 576, 411, 281, 360, 457, 264, 8952, 14581, 307, 264, 50904], "temperature": 0.0, "avg_logprob": -0.15261752870347764, "compression_ratio": 1.6981981981981982, "no_speech_prob": 0.022413665428757668}, {"id": 184, "seek": 139624, "start": 1407.92, "end": 1412.72, "text": " next big task that I will start was start on and I have some plans or ideas how to do that", "tokens": [50948, 958, 955, 5633, 300, 286, 486, 722, 390, 722, 322, 293, 286, 362, 512, 5482, 420, 3487, 577, 281, 360, 300, 51188], "temperature": 0.0, "avg_logprob": -0.15261752870347764, "compression_ratio": 1.6981981981981982, "no_speech_prob": 0.022413665428757668}, {"id": 185, "seek": 139624, "start": 1415.92, "end": 1422.56, "text": " and I've been working with Sergi Petrugna who's know the leader the optimizer for doing this", "tokens": [51348, 293, 286, 600, 668, 1364, 365, 4210, 7834, 10472, 81, 697, 629, 567, 311, 458, 264, 5263, 264, 5028, 6545, 337, 884, 341, 51680], "temperature": 0.0, "avg_logprob": -0.15261752870347764, "compression_ratio": 1.6981981981981982, "no_speech_prob": 0.022413665428757668}, {"id": 186, "seek": 142256, "start": 1423.36, "end": 1427.9199999999998, "text": " and then he got go got some help from the sensor Andrew so that's about 20 minutes", "tokens": [50404, 293, 550, 415, 658, 352, 658, 512, 854, 490, 264, 10200, 10110, 370, 300, 311, 466, 945, 2077, 50632], "temperature": 0.0, "avg_logprob": -0.39976250891591986, "compression_ratio": 1.6525096525096525, "no_speech_prob": 0.0129650654271245}, {"id": 187, "seek": 142256, "start": 1430.8, "end": 1433.28, "text": " okay thanks I don't think we have time for questions our next speaker", "tokens": [50776, 1392, 3231, 286, 500, 380, 519, 321, 362, 565, 337, 1651, 527, 958, 8145, 50900], "temperature": 0.0, "avg_logprob": -0.39976250891591986, "compression_ratio": 1.6525096525096525, "no_speech_prob": 0.0129650654271245}, {"id": 188, "seek": 142256, "start": 1434.0, "end": 1436.96, "text": " set up but if you have questions from my team you can chat to him in the hallway", "tokens": [50936, 992, 493, 457, 498, 291, 362, 1651, 490, 452, 1469, 291, 393, 5081, 281, 796, 294, 264, 23903, 51084], "temperature": 0.0, "avg_logprob": -0.39976250891591986, "compression_ratio": 1.6525096525096525, "no_speech_prob": 0.0129650654271245}, {"id": 189, "seek": 142256, "start": 1437.52, "end": 1444.48, "text": " we've got a stand downstairs where you can meet some other MariaD team as well it's the one without", "tokens": [51112, 321, 600, 658, 257, 1463, 20148, 689, 291, 393, 1677, 512, 661, 12734, 35, 1469, 382, 731, 309, 311, 264, 472, 1553, 51460], "temperature": 0.0, "avg_logprob": -0.39976250891591986, "compression_ratio": 1.6525096525096525, "no_speech_prob": 0.0129650654271245}, {"id": 190, "seek": 142256, "start": 1444.48, "end": 1448.3999999999999, "text": " any uh any banner or anything like that because the person was supposed to bring all this work", "tokens": [51460, 604, 2232, 604, 24348, 420, 1340, 411, 300, 570, 264, 954, 390, 3442, 281, 1565, 439, 341, 589, 51656], "temperature": 0.0, "avg_logprob": -0.39976250891591986, "compression_ratio": 1.6525096525096525, "no_speech_prob": 0.0129650654271245}, {"id": 191, "seek": 144840, "start": 1449.3600000000001, "end": 1458.64, "text": " but let's say this way I'm really happy with this work and I think that for those who have", "tokens": [50412, 457, 718, 311, 584, 341, 636, 286, 478, 534, 2055, 365, 341, 589, 293, 286, 519, 300, 337, 729, 567, 362, 50876], "temperature": 0.0, "avg_logprob": -0.202804444328187, "compression_ratio": 1.5875706214689265, "no_speech_prob": 0.004352593328803778}, {"id": 192, "seek": 144840, "start": 1460.4, "end": 1466.88, "text": " complex plan which is especially when we're looking at things coming from oracle customers", "tokens": [50964, 3997, 1393, 597, 307, 2318, 562, 321, 434, 1237, 412, 721, 1348, 490, 420, 7041, 4581, 51288], "temperature": 0.0, "avg_logprob": -0.202804444328187, "compression_ratio": 1.5875706214689265, "no_speech_prob": 0.004352593328803778}, {"id": 193, "seek": 144840, "start": 1466.88, "end": 1473.52, "text": " where we have lots of store procedures and really big queries queries that are in thousand of lines", "tokens": [51288, 689, 321, 362, 3195, 295, 3531, 13846, 293, 534, 955, 24109, 24109, 300, 366, 294, 4714, 295, 3876, 51620], "temperature": 0.0, "avg_logprob": -0.202804444328187, "compression_ratio": 1.5875706214689265, "no_speech_prob": 0.004352593328803778}, {"id": 194, "seek": 147352, "start": 1473.52, "end": 1482.32, "text": " and this is just one query but this optimizer we really have so thank you", "tokens": [50384, 293, 341, 307, 445, 472, 14581, 457, 341, 5028, 6545, 321, 534, 362, 370, 1309, 291, 50804], "temperature": 0.0, "avg_logprob": -0.3603509852760716, "compression_ratio": 1.0579710144927537, "no_speech_prob": 0.016779033467173576}], "language": "en"}