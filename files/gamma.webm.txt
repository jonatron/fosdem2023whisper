[00:00.000 --> 00:13.560]  So, our museum is located in Namur, so it's not far from here, so if you have some time
[00:13.560 --> 00:16.560]  to come, you're welcome.
[00:16.560 --> 00:18.720]  So we have different missions, of course.
[00:18.720 --> 00:25.600]  One of it is to preserve all machines, to show them to the public, and also to study
[00:25.600 --> 00:27.880]  those machines to keep understanding them.
[00:27.880 --> 00:32.040]  So my talk is more precisely about that.
[00:32.040 --> 00:35.880]  And actually, why this machine?
[00:35.880 --> 00:44.280]  Actually we have a big collection, part of our museum is actually a big mechanical graphic
[00:44.280 --> 00:49.120]  collection, you can see it's here.
[00:49.120 --> 00:57.520]  So we have a whole bunch of machines, electrical and mechanical machines that are still being
[00:57.520 --> 00:58.520]  maintained.
[00:58.520 --> 01:06.360]  Unfortunately, we don't have the bull gamma tree, it's very rare, but it was connected
[01:06.360 --> 01:07.360]  with those machines.
[01:07.360 --> 01:15.440]  So we have many documentation about those machines, and we were interested to study
[01:15.440 --> 01:17.720]  that machine more specifically.
[01:17.720 --> 01:22.800]  So I will go through the historical context, make you discover the machine, and then go
[01:22.800 --> 01:30.400]  into it to try to emulate it, looking at some existing emulators, and then detailing our
[01:30.400 --> 01:34.360]  own emulator and what we learn with it.
[01:34.360 --> 01:42.160]  So let's go back in time, so you know we are here now in 2023.
[01:42.160 --> 01:51.800]  So if we go back, how long is it, 70 years ago, in the 50s, just after World War I, the
[01:51.800 --> 01:57.440]  first generation of computers was developed.
[01:57.440 --> 02:04.960]  So at that time, the technology was very different than today, because there were no integrated
[02:04.960 --> 02:11.760]  circuits, there were no CPU, microprocessor, they were developed in the 70s.
[02:11.760 --> 02:19.080]  There were no TTL circuits, there were no transistors, there were no magnetic cores.
[02:19.080 --> 02:25.160]  Actually when you really want to build a computer, you have technology like vacuum tubes and
[02:25.160 --> 02:29.120]  delay lines to try to store some memory and drums.
[02:29.120 --> 02:35.320]  So it was really a very different technology, and of course, you can imagine, the memory
[02:35.320 --> 02:39.160]  was very small.
[02:39.160 --> 02:49.480]  And so another point is that at that time, well, most of the processing was made because
[02:49.480 --> 02:55.320]  of course there was automation before the computer, so most of the automation was done
[02:55.320 --> 03:02.680]  through electromechanical machines, so a tabulating machine, you know it was developed in the end
[03:02.680 --> 03:12.480]  of the 19th century with the already tabulating machine, and then it became the IBM company.
[03:12.480 --> 03:19.240]  And you can see here that there was some kind of transition between that area and those
[03:19.240 --> 03:24.280]  machines, those computers that were starting to be developed.
[03:24.280 --> 03:31.240]  And actually the interesting point is that one that I will show you, actually at the
[03:31.240 --> 03:37.880]  beginning it was not really a computer, it was still some kind of auxiliary calculator
[03:37.880 --> 03:42.640]  for a tabulating machine, that one that you can see in our museum.
[03:42.640 --> 03:53.680]  And after, actually, it began to improve and the dependency between the machine was reversed.
[03:53.680 --> 04:01.600]  So the gamma-3 became the computer and the tabulating became the peripheral.
[04:01.600 --> 04:08.560]  So you can see other machines after, of course, you can see that both developed also the gamma-60,
[04:08.560 --> 04:16.160]  gamma-30 machine in the second generation, so I will not focus on that.
[04:16.160 --> 04:19.840]  So maybe in the next one.
[04:19.840 --> 04:22.320]  And so how did we study the machine?
[04:22.320 --> 04:27.080]  Of course, we have documentation at the museum.
[04:27.080 --> 04:33.440]  There is also a number of existing examples of that machine, one in Angers where it was
[04:33.440 --> 04:40.760]  built by Bull in Grenoble, they acquired one and they preserved it, and one in Frankfurt.
[04:40.760 --> 04:48.480]  So, of course, we don't have one, but we have those documentation and we have also many
[04:48.520 --> 04:55.520]  documentation that was also provided by Akonis, which is another museum located in Grenoble.
[04:55.520 --> 04:59.200]  And there are a few emulators, so we'll come back to that later.
[04:59.200 --> 05:08.200]  Have a look at the hardware, so as I told you, it's a first-generation computer, it's
[05:08.200 --> 05:12.000]  based on vacuum tube delay lines.
[05:12.000 --> 05:18.280]  Actually, the code was stored in a connection panel, so you can see it on the top there.
[05:18.280 --> 05:28.800]  So in order to program it, actually, you had to plug the instruction to say, well, the
[05:28.800 --> 05:37.200]  first instruction, it has four characters, but the first character, it's that exact decimal
[05:37.200 --> 05:39.800]  code, the second one is that code, and so on.
[05:39.800 --> 05:46.160]  So it's really like that spaghetti coding, and for that reason, actually, that spaghetti
[05:46.160 --> 05:52.960]  coding was also used in a tabulating machine, so it was the way to code at that time.
[05:52.960 --> 05:58.080]  And that's also the reason why we cannot really call it a computer in that form, because
[05:58.080 --> 06:03.400]  it does not follow the von Neumann architecture, because in that architecture, you have to
[06:03.400 --> 06:11.840]  have the code inside the main memory, although somehow that panel was memory mapped, so you
[06:11.840 --> 06:16.520]  could consider it like some kind of read-only memory.
[06:16.520 --> 06:18.520]  What about the memory?
[06:18.520 --> 06:22.880]  The memory itself, actually, it was only seven registers.
[06:22.880 --> 06:29.880]  And in order to keep the information, actually, the information, it was the equivalent of
[06:29.880 --> 06:38.040]  six bytes, so it's 12 characters of four bits.
[06:38.040 --> 06:47.320]  It was just circulating in a line with a regeneration system, so it's an LC circuit,
[06:47.320 --> 06:55.160]  and for just one word, for six bytes, you can see the device here, it's more than eight
[06:55.160 --> 06:56.160]  kilograms.
[06:56.160 --> 07:05.040]  You imagine the start of the...
[07:05.040 --> 07:08.320]  It was really very big.
[07:08.320 --> 07:14.600]  About the computation, it was also based more on diodes, so I will not go into all the details.
[07:14.600 --> 07:19.520]  It was mostly addition and subtraction, as I will see, the multiplication and division
[07:19.520 --> 07:24.080]  were implemented through iterative addition and subtraction.
[07:24.080 --> 07:25.520]  And what about the frequency?
[07:25.520 --> 07:29.000]  The frequency was 2.5 hertz.
[07:29.000 --> 07:30.000]  Why that?
[07:30.000 --> 07:35.880]  Actually, it could go, the inner could go faster, but it was just because it was synchronized
[07:35.880 --> 07:43.960]  with the mechanical machine, with punch cards, so it was limited by that part.
[07:43.960 --> 07:48.560]  And you can see also there is a nice drawer, it's really easy to open, of course, for the
[07:48.560 --> 07:56.600]  maintenance because when a vacuum tube had a problem, you had to replace it and it was
[07:56.600 --> 07:59.800]  designed for that.
[07:59.800 --> 08:02.360]  So is it a computer or a calculator?
[08:02.360 --> 08:12.040]  So in French, we have different names, but as I told you, we cannot really consider it
[08:12.040 --> 08:19.200]  as a computer first time because of that it was not following the von Neumann architecture
[08:19.200 --> 08:27.360]  and it was really designed as an auxiliary machine for the tabulating.
[08:27.360 --> 08:36.240]  So as you can see there, a quote from a guy who designed the machine in 1953.
[08:36.240 --> 08:45.520]  So it's really an extension and the good point is that that computation was so fast
[08:45.520 --> 08:53.600]  that there was no delay by the calculation, so it was really transparent for the tabulating.
[08:53.600 --> 08:59.800]  And actually at that time, the programs inside the machine were more like auxiliary computation
[08:59.800 --> 09:04.280]  that were augmenting the capability of the tabulating machine.
[09:04.320 --> 09:06.920]  And there there were evolution, that's the interesting point.
[09:06.920 --> 09:14.440]  There was a version, of course, that first version is only adding and subtracting integers,
[09:14.440 --> 09:20.240]  so there was a version that was able to do floating points.
[09:20.240 --> 09:27.600]  And then in 1957, there was a drum extension, that's the interesting point, it's about
[09:27.600 --> 09:33.520]  100 kilobytes and it could store the program.
[09:33.520 --> 09:39.080]  So from that time, we can say that it's really the first French computer and it's also the
[09:39.080 --> 09:47.760]  transition between the electro-mechanical device, the electro-mechanical area and the
[09:47.760 --> 09:50.960]  computer area.
[09:51.920 --> 10:05.720]  Also, another interesting point is that those first computers were not using binary or
[10:05.720 --> 10:11.160]  exact decimal representation, they were still computing in decimal.
[10:11.160 --> 10:16.720]  So it's interesting because I found, it's in French with this transition there, there
[10:16.720 --> 10:26.320]  was a whole discussion about should we use decimal or should we use binary or exact decimal
[10:26.320 --> 10:28.320]  for computation.
[10:28.320 --> 10:34.360]  So there were some advantages, benefits and some disadvantages.
[10:34.360 --> 10:40.520]  So you can see the advantages, two figures, zero and one, it's really powerful for the
[10:40.520 --> 10:47.880]  relay, it's ideal to map and for the disadvantageous binary, it's become very long, very long
[10:47.880 --> 10:52.520]  word and we need to translate back and forth with the decimal.
[10:52.520 --> 10:58.200]  So the conclusion, it's quite funny, we will use semi-decimal, which actually is the name
[10:58.200 --> 11:06.120]  for binary coded decimal and they introduce those coding for the binary coded decimal.
[11:06.120 --> 11:12.400]  So that was for the first version, after they came back on that decision and actually the
[11:12.400 --> 11:22.640]  update for the drum extension was able to support the binary, the full binary mode.
[11:22.640 --> 11:28.760]  So what do we have as memory, as I told you we have those registers, actually we have seven
[11:28.760 --> 11:33.400]  main registers, you can see here a bit more because there were extensions.
[11:33.400 --> 11:44.520]  So a register is one word of 12 digits, 12 characters, so those four bits, so it's actually
[11:44.520 --> 11:56.840]  six bytes, so the main memory was only 42 bytes, so you see it's very, very limited.
[11:56.840 --> 12:03.080]  And if you look at the full architecture here, the full gamma tree with all the extensions,
[12:03.080 --> 12:17.800]  you can see on the top left the panel, the main registers are on the left, the top one,
[12:17.800 --> 12:23.480]  the M1 actually is the only one where you can read and write, so all the computation will be
[12:23.480 --> 12:34.840]  performed in that one and the other one, M2 to M7 will be used as a register to read operands.
[12:34.840 --> 12:40.600]  And the instruction, you can see the decoding of the instruction, the structure of the instruction
[12:40.600 --> 12:48.280]  is composed of four parts, I will detail them after, it's called TO, AD, OD and OF and the
[12:48.280 --> 12:58.360]  rest are extensions, so this is more memory, so you can switch those registers with those ones
[12:58.360 --> 13:15.480]  and the drum extension can also map on those octets, so you can load a part of program from
[13:15.560 --> 13:24.200]  there, from the drum to those parts and then execute them into the computer. So about the
[13:27.160 --> 13:32.760]  instruction set, you can see that there are four parts, so the first is quite natural, it's just
[13:32.760 --> 13:39.960]  the type of operation, so you can have addition, subtraction, I will detail after. The second part
[13:39.960 --> 13:46.920]  also quite natural, it's just the address, it means which operand we will use, so for the addition
[13:47.800 --> 13:57.160]  for AOE we can see it means M4, the register number four and what's a bit different and
[13:57.160 --> 14:08.040]  word is that then we have two other pieces of information in the instruction that we tell you
[14:08.040 --> 14:15.880]  which range in a register you will manipulate, because the reason is that the memory was scarce
[14:15.880 --> 14:21.640]  and so if you wanted to store two different information in the same register you could then
[14:21.640 --> 14:28.440]  address one part of it and you could really select if it was two bits and then ten bits and
[14:28.440 --> 14:37.000]  things like that. So you can see here a very simple addition, so I can decode it with you,
[14:37.560 --> 14:48.360]  so this means a transfer from one register to the accumulator, so the M0 register,
[14:48.520 --> 15:00.600]  so it's from M4, so you can see M4 we have two parts A and B, so A is from 6 to 9 and B is
[15:00.600 --> 15:08.680]  from 1 to 5, so the first thing is that we will load the part 6 to 9 into the accumulator,
[15:09.320 --> 15:15.240]  then we will ask to perform an addition with what we can find in the same register four
[15:16.120 --> 15:27.000]  in part 1.5, you can see 1.5 here and you can see that as an internal flag it also
[15:27.000 --> 15:33.800]  remembers the part that is used for the shift part that it should use for the addition and then
[15:33.800 --> 15:41.560]  it can perform the addition and will have A plus B inside the register and then you will put back
[15:41.560 --> 15:48.840]  the result, so it's a reverse instead of B or it's UB to store back the result in M4 and of
[15:48.840 --> 15:58.440]  course here you have to think oh I've done an addition so maybe there is one carry overflow
[15:58.440 --> 16:03.480]  so you can see here that we have provisioned one byte more to be able to store the result back,
[16:03.480 --> 16:15.080]  so you can see all the mental gymnastics you have to do to be able to program with that kind of
[16:17.160 --> 16:23.720]  range in the registers, so it means that when you are coding you have to use that kind of sheet,
[16:24.920 --> 16:31.640]  you can see of course the mnemonic, you see here the translation where you have to think about
[16:31.640 --> 16:39.400]  those range and you have then to facilitate that for the range you have to allocate your range and
[16:39.400 --> 16:45.960]  reason about your range also on this sheet, so you can see here the problem is computing that
[16:45.960 --> 16:54.360]  formula and then you will just perform the different calculation, multiplication, shift shift to
[16:55.160 --> 17:02.680]  have the right power and then divide by a square root of three.
[17:06.120 --> 17:10.760]  Okay quickly this is the full instruction set that you can see it's not very regular,
[17:12.680 --> 17:18.600]  well a natural thing is that no operation is still zero, it was already zero,
[17:19.320 --> 17:29.640]  you have operations to different kind of jumps, there was an inner flag to remember how to jump,
[17:30.840 --> 17:39.720]  you have different memory transfer, I will not go into details, of course to set memory to zero or
[17:39.720 --> 17:49.800]  to load a value to make the transfer between different kind of registers to, there is a logical
[17:49.800 --> 17:57.000]  ant, I didn't find any logical or, I don't know if there was one to be true, but okay different
[17:57.000 --> 18:05.800]  comparison and then of course the most important one from A, B, C, D, E, F the addition and the
[18:05.800 --> 18:12.760]  arithmetic operation and you can see there are two flavors for the multiplication and division
[18:12.760 --> 18:18.680]  because there was one what was called reduced multiplication and reduced division that was
[18:19.320 --> 18:25.640]  faster but that we will not operate on a double register because of course if you have a big
[18:26.600 --> 18:33.080]  to the result of multiplication could of course take twice as much as space.
[18:33.080 --> 18:46.040]  Okay so this is the code card, so it summarizes the whole instruction set and it reflects
[18:46.840 --> 18:54.360]  the complexity of its organization, you can point just three things, first it's called ordinateur,
[18:54.360 --> 19:01.800]  so in French the name was ordinateur but the name ordinateur was coined one year after
[19:02.600 --> 19:08.520]  for IBM machine so it was not, it didn't exist yet so you have to think about all that,
[19:09.800 --> 19:22.280]  you can see here the different arithmetic operation for A to F, so 12, 13, 14, 15
[19:22.920 --> 19:29.400]  and you can see the order is not, it's not always in the order, the seven is presented
[19:29.400 --> 19:41.000]  higher because just the shift and operation and the two is not represented because it was
[19:41.000 --> 19:51.080]  an extension for the drum. Okay let me go quickly, so about existing emulators, so this one was
[19:51.160 --> 20:03.080]  written in 1995 by Vincent Gauguin, it's in sorry in x86 assembly code and it's still run but
[20:03.640 --> 20:10.840]  well thanks for the emulators because you need those bugs to run it, we don't have the source code,
[20:12.600 --> 20:17.000]  you can just see there, well it's just emulating everything so it's quite good
[20:17.720 --> 20:22.920]  complete and you can see there that it's just loading some information so it's just loading
[20:23.800 --> 20:31.560]  0, 9, 4, 2, 7 in the memory tree register and then you can, well there is a drum
[20:32.760 --> 20:41.000]  emulated and then you have a number of programs on the drum you can try, a more recent one
[20:41.960 --> 20:47.960]  it's available online so this one is very interesting because it's very well documented and you can
[20:47.960 --> 20:56.360]  even play with the panel, there is a full console where you can step in
[20:58.760 --> 21:05.080]  and actually it was one of the sources of inspiration of our work because
[21:05.640 --> 21:12.840]  that one was in java 6 and oh it's in java so we kind of transposed and first
[21:14.040 --> 21:20.440]  studied that code and there was there is also an extension visualization 3d visualization which
[21:20.440 --> 21:25.400]  is funny because you can you can explore inside the machine you can see here the connection
[21:25.400 --> 21:29.640]  and there were big cables to connect the machine with the tabulating
[21:29.720 --> 21:38.360]  okay about the emulation structure of course what we have modeled is all the components so
[21:38.360 --> 21:43.560]  you have the machine you have the different kind of memories, banal memories it's just the
[21:43.560 --> 21:49.880]  registers, different series groups and then a special one which is the panel which is actually
[21:49.880 --> 21:55.400]  as you can see memory mapped to one of the series and of course you can also have connected
[21:55.400 --> 22:00.360]  machines and the drum then of course the whole instruction set you can see there the
[22:01.800 --> 22:08.360]  modeling the way the instructions are structured depending on their kind if it's for drum transfer
[22:08.360 --> 22:18.200]  it's of all the arithmetic operations have some common parts so we have some hierarchy there
[22:18.520 --> 22:27.080]  and of course there is some execution management and test and you can see the code there on
[22:27.080 --> 22:34.920]  github and what's interesting from also the emulation point of view of course all operation will
[22:37.000 --> 22:44.840]  have to specify the different information so for the addition
[22:45.560 --> 22:52.600]  this is an inner operation just to show you how it's implemented so of course you have to specify
[22:52.600 --> 22:59.800]  the range where you are performing the addition and this is quite a standard
[23:02.680 --> 23:05.320]  implementation where you just loop over the different
[23:06.280 --> 23:16.680]  the different bit and then you propagate the carry what is interesting is just that
[23:16.680 --> 23:24.760]  you have the base so that code would work if both for the binary and for the decimal
[23:25.400 --> 23:29.160]  implementation actually the variant of the machine
[23:29.880 --> 23:39.160]  so this this is trying to mimic the whole the whole operations another one very
[23:39.160 --> 23:45.240]  much simple is just to use the Java operations for example for the for the subtraction we just
[23:45.240 --> 23:53.080]  translate everything in decimal perform the subtraction and then start the result there is
[23:53.080 --> 24:00.520]  only one one thing that that must be we must be careful is that we have to use long in Java because
[24:00.520 --> 24:10.920]  12 those 12 numbers are more than 32 bits in in Java we skip the division so the current
[24:10.920 --> 24:17.960]  implementation while we have our prototype just in Java so we are just using here the
[24:18.120 --> 24:27.480]  eclipses as an environment and running the the test so this is just test we have a small
[24:27.480 --> 24:32.920]  interface this not yet finished and you can see here a quick code that just showed the
[24:35.960 --> 24:43.400]  Fibonacci suite and well you can see the result here I will not go into the detail but you can
[24:44.200 --> 24:50.040]  you can see there is actually a loop so there is a jump for 10 iterations and then you you
[24:50.040 --> 24:55.800]  have the different number you can see the number after a few iterations you have 13 8 13 and
[24:55.800 --> 25:04.040]  six like that which which are being computed so it's it's working and now I will finish so
[25:04.120 --> 25:13.160]  what what what did we learn so it was quite quite funny to uh and strange to look at that machine
[25:13.160 --> 25:18.840]  it's not so complex to code but there are many many implementation details you see about those
[25:18.840 --> 25:25.160]  range manipulation and we are still have a lot a lot to explore for example all the floating points
[25:26.040 --> 25:31.000]  improving the user interface and of course we are at the start so we would like to
[25:31.000 --> 25:40.280]  really to study what was used and as as code at that time so in summary it was it was very
[25:40.280 --> 25:47.240]  and it's still very rewarding from the technical but also from the historical and cultural point of
[25:47.240 --> 25:53.640]  view okay thank you and if you have questions you're welcome you have some some reference there
[25:53.640 --> 25:56.280]  about all the the guys who have worked on the on that machine
[26:09.080 --> 26:10.280]  yeah
[26:10.440 --> 26:16.760]  like the core memory and the reading that was required to rewrite it again once you read
[26:17.800 --> 26:26.600]  so so the question is about the the core memory simulating the reading of the memory so the
[26:26.600 --> 26:34.840]  well it's a good question because I don't know how to call this a simulator or an emulator but
[26:35.480 --> 26:45.800]  uh the the components well the the machine is is quite quite also at it's uh what we are emulating
[26:45.800 --> 26:54.600]  it's kind of an abstraction of the machine I would say uh so one limitation is done that we
[26:54.600 --> 27:03.960]  don't really know the physics of the reading so uh we are assuming that we can read reliably the
[27:04.040 --> 27:10.040]  information and that we don't have any timing issue if the the things that are bothering you
[27:11.160 --> 27:18.120]  but of course we don't have a working machine to to compare with so we can only uh compare with
[27:18.120 --> 27:25.800]  expected result or with what order the older emulator as is delivering actually the older
[27:25.800 --> 27:31.720]  emulator had a problem we discovered there was a mistake discovered so it was corrected by the
[27:31.720 --> 27:39.800]  the guy who's still maintaining it somehow but yeah so the the point would be really to uh
[27:41.000 --> 27:47.240]  to be able to to study the electronic circuitry if we would like to go to that to that level
[27:47.880 --> 27:54.600]  but we don't have one sorry yeah there's a question from the stream yeah is there a compiler for
[27:54.600 --> 28:03.240]  gamma 3 a compiler uh well is there a compiler for the gamma 3 so you can you could see well
[28:03.240 --> 28:11.720]  assembly code was assembly language was invented two years before I think by uh uh and the assembly
[28:11.720 --> 28:17.240]  was was done manually at that time so at that time the question the answer is no there were no
[28:17.240 --> 28:25.720]  compiler but no today actually uh the guys from akonit have developed uh uh a compiler
[28:26.520 --> 28:33.240]  from a language that looks like uh java I think uh so you can uh you you you actually yes you can
[28:33.240 --> 28:40.360]  compile from that pseudo code language into uh into the gamma 3 yeah that was done
[28:41.320 --> 28:43.960]  I didn't try it but I did
[28:58.120 --> 29:07.640]  the question is was the program the program that I showed was uh in uh coded was was executed
[29:07.640 --> 29:15.960]  from the panel so well the panel is just a way to to specify the content of the memory
[29:15.960 --> 29:22.200]  is the is the same but just with wire but the the emulator supports the drum
[29:25.720 --> 29:30.280]  yeah yeah it could yeah yeah it could could load instructions so the drum could contain
[29:30.360 --> 29:34.040]  instructions or it could contain uh data yeah
[29:37.640 --> 29:48.040]  yeah yeah there is yeah so the the the question is about the the cycle count of the different
[29:48.040 --> 29:57.560]  instructions so yeah we we have uh time about timing uh about the uh the addition subtraction
[29:57.560 --> 30:03.720]  and different kind of multiplication so that's that's available and that's a good point because
[30:03.720 --> 30:11.720]  the emulator is not uh taking that into account so it would probably be a good good point to try to
[30:12.520 --> 30:14.360]  reproduce that that behavior
[30:16.760 --> 30:18.360]  thank you very much so maybe
