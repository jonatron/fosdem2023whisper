{"text": " Thank you for being here. I was not expecting such a large room of JavaScript developers and nothing has been broken yet, so it's unbelievable. So yeah, I'm here to talk about strong dynamic type checking for JavaScript, which may sound a bit weird because you are not expecting strong type checking in JavaScript in the same sentence, right? But I will prove that we can do something about it. So first, what is strong type checking? What do we mean by that? So let's do a bit of vocabulary. So I try to find one definition online of what is strong type checking and couldn't find any. It's like a never-ending argument about which one, which language is strong and which one isn't. But I found two definitions commonly accepted. The first one is that this strong type checking means that you have this kind of explicit binding between some variable name and some type. So this variable and this type are like bound together. That means that every time you are calling variable by its name, you will get some reference data that matches the type you expect. The second definition is more regarding the program-languaging features, like no lack of type safety due to loser-typing rules. For example, in the case of JavaScript, we have implicit type coercion. That means that it's perfectly fine to get the plus operator between a number and a string. For JavaScript, it's just string concatenation and automatically casting the number to a string. But for other languages, like Python, you will get a type error. So let's take on as an example to show that Python is more strong, stronger than JavaScript. So when it comes to JavaScript, whatever definition you pick, you might say that JavaScript is not a strongly typed language and you will be right. Because JavaScript is based on dynamic type checking, dynamic typing, that means that JavaScript variables, you can assign it to some type and then move to another type and go on. It doesn't matter. So because types can change during program execution, that makes types in JavaScript quite unpredictable. So the creator of the language, Prandon H, justified his choice by saying that developers can be more expressive when you get dynamic typing, which means that it can get to the result faster, but he also agrees that it is also more error-prone. So that's the image I took for static versus dynamic typing. I think it sums up pretty well. So yeah, JavaScript and strong type checking, not really. Actually, every time you see someone complaining about JavaScript or mocking JavaScript, it would be about one of these memes, right? So these are some of my favorites. Maybe you know others. But as you can see, almost all these jokes about JavaScript are basically about the lack of strong type checking, which is too bad. So some people will decide to just get rid of JavaScript and maybe go to Kotlin or.NET or whatever language we have seen this morning. But I think that's the most common solution to this approach has been TypeScript, right? I mean, this thing has been invented specially to address this issue by having some optional static type checking about JavaScript. So how many of you are using TypeScript? Raise your hand. Wow. I was expecting that. Like, almost 100% of these people in this room are using TypeScript. I mean, why wouldn't we use TypeScript? It's so popular. Almost all the ecosystems, all the libraries today on VNPM ecosystem have been converted to TypeScript or provide TypeScript definition files. So we have seen this kind of exponential growth in popularity among the years. TypeScript is 10 years now. It will be 11 in five days, actually. And it has never been so popular. So did we solve the issue of type checking JavaScript with TypeScript? I would say not entirely and I explain why. Here are some things I learned about TypeScript after 110 years. The first one is a bit of shock is that TypeShaking is not actually the main selling point of TypeScript. The main selling point of TypeScript is developer experience. So if you have practiced TypeScript and the whole room has done that, it's great. You have seen some improvements in your development experience. So many things like be able to explore some API by using the autocomplete, be able to detect some typos that you have done in your code, be able to refactor your code more easily thanks to the static type annotations, maybe have some documentation right inside your IDE. Some compilers are using static type annotations to bring some compile time optimizations, which is great. You get type inference, good type inference in TypeScript, so you don't have to write all the static type annotations at any time. And we have seen some innovative use of TypeScript. For example, the Angular community is using a lot of TypeScript annotations to make some code generation, which is great. So all of this is part of developer experience and is great, but it's not really about type checking anymore. It's much more than that. I figured out that type checking was not the main selling point of TypeScript or at least not anymore. When I looked at the ES build project, one of the most important JavaScript project of these last years, ES build, the famous bundler, so maybe you are using the VIT development server, some people in the room. So VIT is based on ES build. And does ES build support TypeScript? Of course it does. Everyone is using TypeScript. But the fact is that ES build does not actually do any type checking when it compiles some TypeScript code. All it does is look at the TypeScript code, look at the TypeScript part of the static type annotations, and just get rid of it. That's all it does. Nothing else. And they say that running the whole TypeScript compiler is actually a loss of time today. Because of this development experience, developers have this whole integrated type safe environment and development process. So that means that you don't need to do it twice a second time on compilation. The second point of TypeScript that I learned about 10 years later, it's that type safety in TypeScript can be easily defeated. What I mean by that is that in many scenarios in your application, you are relying on type assertions. That is these little elements like the ASCII word or the exclamation mark here, which is I ensure you the compiler that is not null. So all these things are not bringing any type safety. It's just the developer saying to the compiler, trust me, I know what I'm doing. And most of the time, we do not. So yeah, this problem, these type assertions, you can find them easily on any web application. There are actually many parts where you are forced to use these kind of assertions because of the nature of the web. You can have your perfectly type safe TypeScript application and still have to deal with lots of unpredictability. Unpredictable is like the most of your time, your job for a front-end web developer. And what I mean by unpredictable, it is known at runtime. That means it changes every time at every user and so on. So for example, your application may have some back-end services, may call some APIs, maybe some third-party cloud providers. And you are trusting the responses of these servers, right? You are not validating any of the response of the server from the application side. So this could break. You are also relying on a browser. And some browsers have bugs and queers. They do not fully support visual script APIs. The web standard APIs. I chose this logo for a reason, why? You may also have some client-side store data for your application. Maybe you are storing on a local storage some user preferences or some five-store age users' cache. So this is likely to break as well because sometimes the cache is outdated. It comes from an older version of your application or maybe it has been modified by the user itself, who knows. And finally, maybe the most unpredictable part of every developer's job, did you guess it? The user. The user can be very unpredictable. If you have some application in production and have a look at the production database, you will always find some crazy stuff like, how did it get there? I don't understand. This is the user. All these things need to be validated. Otherwise, this is a recipe for disaster and can break your perfectly safe application in TypeScript. So if you look at TypeScript and wonder, how can I do that? How can I type check all of these things? No luck. It's not a compiler problem because all these things happen at runtime. You cannot anticipate it. So it's more an applicative problem and not a compiler problem, which means that TypeScript is completely helpless and it is up to you, the developer, to find a solution to these problems. So how do we deal with runtime errors? Most of the time, the truth is that often we don't. Maybe in the best of scenarios, you are doing some custom logic to validate the data and trying to fix the stuff the best you can. But most of the time, you have so many different possible runtime errors that you would have like try catch blocks and trying to show some error messages to the user, saying them to call you and send us an email in case something bad happens. And I also saw that we have some kind of global unexpected exception handler that is just sending all the runtime errors that you didn't catch to maybe a monitoring service. And it is added to a log file that you are checking like once in a month, looking at a bunch of errors and saying it's not worth my time, so I should move to something else. I don't know if some of you do that, but it happens, right? So it's too bad because we could figure it, figure a way to solve all these runtime errors. So back to this idea of strong dynamic type checking. How can we do that? So I'm just taking to the definition of a strong binding between variable name and a time here. What if we could do this kind of strong binding but at runtime? What would it mean? First, it would mean that the type errors that we get would still be runtime errors, right? Because it happens at runtime. But at least there will be more explicit and more catch early. That means that instead of having like undefined is not a function, you will get an error message like this variable has been from undefined and it was not supposed to. So instead of pointing to the consequences, it points to the source of the problem. So that helps a lot to reduce the investigation job that you have to do as a developer when doing debugging. The second thing is that this strong binding, it should not be just a one-time validation pass. I'm sure that there are plenty of JavaScript libraries that do that. That is, you are throwing a bunch of data to it and it validates, saying true or false or just throwing a type error. But we need more than that. We actually need to have this binding. That means the type information needs to live along with your data. So it should be validated, this type checking thing, on every reassignment or mutation of this data. And finally, the goal of this is to get rid of maybe some silent errors because we have many mistakes in JavaScript that just are silent. That is, you are not noticing them until it's too late. And it can also make runtime errors maybe more predictable and so more manageable from a developer's point of view. So this is the main reasoning I have when I worked on the open source library that I want to present you today, which is object model. So definitely not a new project. Actually, I've been working on this for the past eight years. So I'm at the version of 4.4.1. That means that I have written the entire thing like four times now. It's obviously the hardest thing I had to code in my life, I would say. It's very complicated, but it works. So I'm glad. And I would say also that it is my most used for real open source project. By use for real, I mean that it is used in business projects. So I use it in my professional project. Other people are using it as a fundamental component of their business project and I receive lots of positive feedback about this library. You've got an example here. So what is this library doing? So how do you use it? It's pretty simple actually. The first thing you have to do is define the dynamic types, I would say, I would call them models. I explain the difference later. But basically, let's say you are working on e-commerce application. You can declare an object model for the order, for example, the customer order, saying that you have a product which has a name property which is a string, a quantity that is a number, and also an order date. After I've been declared this model, you can now bind it to some data. So this is where you have this strong binding between the type and the variable. Here, I used the constructor pattern, so that means you are calling new order. I think it's probably the most intuitive form of a binding for the developer. And also, it helps to store the type information on the prototype level of the object. So that's how I have this strong binding. We already have a binding between objects and prototypes in JavaScript. And after having done that, you get the myorder object, which you can manipulate just like you would do with a regular JavaScript object. But instead, when you are assigning, for example, quantity to Boolean instead of a number, you will get a dynamic type error at runtime with an explicit message saying, expecting product quantity to be number and got Boolean false instead. So because this happens, every time you are doing any mutation on an object, it is really easy to quickly find some mistake that you are doing as a developer and so improve the debugging experience. So that's great, but how does it work? So let's start from a pretty basic example. Here, I have a class user having a constructor taking a name and an age. And if you want to validate the parameters that are passed to a function and not rely on static type annotation in JavaScript, that means that you would validate this data at runtime. What you could do is use these if conditions and check the type of these different variables and throw type errors like that. Pretty easy. The problem with that is that it only works in the constructor. So maybe you could decide to declare some setters like set name, set age, and have this validation process on every single attribute, but it's a bit tedious and we can do better on that. So we can improve this by using a feature of JavaScript, which is the proxy. So I don't know if everyone knows about proxies. This is a feature of JavaScript that has been introduced in 2015 as part of Xmascript 6. And proxies are actually really great features, really powerful. The way proxy works is that they enable you to intercept some operations that are done on some object and react to these operations. So in this example, I just use the set trap of the proxy, which means that every time I am reassigning a property, I can execute some custom logic. So I can move my if type of name, different string and so on into the set trap and be able to detect the different issues. So that's great. So it works both for the constructor and the future reassignment, the future mutations. What we can do as a first step is try to make a generic function out of this. Like so. So now I just move the definition part on this generic type check function argument. So the type check function takes two arguments. First is the data. Second one is the definition or the type if you prefer. So it makes clear that you have this strong binding between objects and types. And as you can see, it is really easy to make a generic function to do this kind of stuff. So the type check function that you see here is a very basic version of what object model is. Of course, the library is much more complicated than that. It can cover many other use cases, but you get the idea with this example. So as you can see, it is really easy to reuse this type check function to apply to many different models. So why did I call these models and not types? Actually, I wanted to find another word just to make straight that there is a few differences from the types that you know from TypeScript, for example, because everything happens at runtime. This is runtime data validations. That means that models are more powerful than just the static types. For example, they can not only check the types, but also the values. Let's say I have a short model which can have a size which is either a number or a letter like MSL, Excel, and so on. I could decide to have this kind of type annotation to have both control that it is either a number or a letter M or a string matching this regular expression. I can also have some more complex assertions. For example, if I want integers in JavaScript, yeah, integers in JavaScript. So it will be the number in the end because that's how JavaScript handles numbers. It's double 64 bits. But I can add another assertion on this number model to say I need to check that it is an integer. And maybe if I want it to be a positive integer, I can add another assertion to make sure that it's above zero. So this is the kind of stuff of assertions that you can have. And again, every time you are manipulating this property, for example, the age of the user, it will check all these assertions automatically. And also the last difference from models to types is that model validation can affect application logic. Because it's happening at runtime, that means you need to react to it and have some strategies of how to handle these runtime errors. For example, if you got some error, some type error on your short model, maybe you just want to cancel the order so that you are making sure that everything is happening correctly on your application. So these are the main differences. So to get a look at the pros and cons of this library, first the pros. You get descriptive error messages. They are pointing to the initial problem, not the consequences. So just that saves you a lot of time. And it means that you now have this kind of continuous data validation as part of your development process. That means you get faster debugging and more reliable applications in the end. Regarding how you manage these runtime errors, because you need to do something, right? Not only showing an error message, but maybe doing some strategies that are planned. You can define some global or maybe per feature, per model strategies about how to manage these errors. Maybe some errors can be easily manageable. For example, clean up an outdated cache. Or maybe some of them are more complex and then you need to maybe log them into a monitoring service. Some of the cons of this library, one about performance, of course, because since it's happening at runtime, that means that it has a cost, a performance cost. Don't worry, it's not too much. But if you are doing some heavy mutations, like more than 100 times per second, maybe you should avoid using dynamic type checking for this specific scenario. But most of the times you don't have to do this, so it's great. The second problem is that it relies on proxies. So you need support for it. Today, modern browsers are supporting ES6 proxies very well. But if you have older browsers for some users, this can be an issue. So, which is better? Static type checking or dynamic type checking? The correct answer is you should use both because they address different issues. Type script, we saw it. It's awesome. It improves a lot with the developer experience. It makes you have a coding base which is reliable and makes sense, which is logical. But you should also take care of all the unpredictable parts that are happening at the runtime of your application. So my personal recommendation would be to stick to TypeScript for the core application logic but also add this object model layer for every external interface that you have to deal with, like the server, user inputs, the local stores or the browser APIs. And this can lead to a more reliable application. That's all I have for you today. So thank you for listening and I'm taking questions. Thank you very much. So, we have time for questions. Who would like to ask the first question? My question is, have you ever tried using this library with other libraries for like, as it called, immutable data or for other validation? Have you tried using this library with other libraries for dynamic checking like YAP or for immutable data like EMR or other libraries? Yeah, so immutable should work fine. For other validation libraries, I mean it's kind of the same thing, the same job, so maybe it doesn't work that well and doesn't make really sense. But I think it should work perfectly with immutable data structures. So EMR should work fine. Yeah. Hi. Do you think it would be possible to generate the object model, like definitions I don't know what's called, object models from TypeScript? Okay, that's a good question. So actually, you can do the opposite. That means that if you are using models, it will generate TypeScript types for you. But because this is more than type checking and as you saw, this can affect application logic. That means that we cannot do this simple conversion. If you use it dynamic type checking, just like you would do with TypeScript types, you are just using like 10% of the potential of a library and it wouldn't make any sense to me. So you should see the website maybe to have more example of that, but yeah, it's a bit more than that. Yeah, I see hands. You were there. The next speaker also, could you raise your hand or stand up? Okay, so we'll have to contact them. A fantastic idea. Love the library. You mentioned rewriting it four times over eight years. How stable would you consider the project to be? How often do breaking changes to the API get introduced, that kind of thing? Yeah, it's true that I've written it four times, but the API never changed. That's one thing. And also I use it for professional projects. So I would be embarrassed if I had to throw it away, all right? So it's quite stable for many years now. Hello. Thank you for the presentation. And I would like to know whether would you recommend using object model on projects that has not yet TypeScript, only JavaScript. Thank you. Yeah, I mean, that could be a thing. Although if you are into strong type checking, you're probably already using TypeScript. If it's not the case, maybe it's fine. I don't know. But yeah, it's totally possible. But most of people are using TypeScript. Thank you very much. We have time still if you have time for another question. Yeah, you'll have to be loud because people are moving. And if you sit down, please make sure there is no space because the room is pretty full. Hi. Thank you for your project. So one other approach is using, for example, JSON schemas that then translates to types, should I speak? Sorry, I can't hear you. One other approach is using JSON schemas, for example, on the validation side, let's say, in a controller. And the JSON schema then compiles to the or deduces the TypeScript type that the schema defined. So that's one way, for example, to do validation and not have a runtime penalty besides doing the validation itself. Have you considered this approach for your use case? Yeah, so good question. So you can indeed use this kind of type declaration. One problem is that, again, if you are sticking to what can TypeScript do with static type checking, you are only just using a fraction of what can be done. For example, I told you about custom assertions. I told you about the fact that you can check values along with the types. So all of these things would not match the model that you are describing with JSON. So that means we need to have another API for that, and that's why I have the on API for object model. Another last question, and then please, everybody, squeeze no empty seat. There are a lot of people still standing. So JavaScript is executed with V8, and there is a lot of optimization underneath where you have an inlining going on optimization of the function. When you use proxies, all of that is going to be gone immediately. Like the performance set is not only when you set something and when you would normally go through the proxy. It's not a hook. How's it called again? I forgot the name. Anyhow. Like when you have the trigger for it, but also for anything that relies upon that data from that point on. So it's going to be a huge performance. I would definitely not recommend this pretty much in production. Yeah, I talked about the performance issues. One thing is that it's only useful for applying to external interfaces like network request. You can just validate everything related to one request. So the loss of time due to the network request compared to the loss of time due to proxy, it's acceptable in my opinion. You can debate after. Don't worry. In his go. I mean, I run a bunch of assertions and it takes less than 10 milliseconds. So I don't think the loss of time is so much trouble. Thank you very much. Thanks again.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 26.080000000000002, "text": " Thank you for being here. I was not expecting such a large room of JavaScript developers", "tokens": [1044, 291, 337, 885, 510, 13, 286, 390, 406, 9650, 1270, 257, 2416, 1808, 295, 15778, 8849], "temperature": 0.0, "avg_logprob": -0.36499929428100586, "compression_ratio": 1.0602409638554218, "no_speech_prob": 0.14516732096672058}, {"id": 1, "seek": 2608, "start": 26.08, "end": 31.64, "text": " and nothing has been broken yet, so it's unbelievable. So yeah, I'm here to talk about", "tokens": [293, 1825, 575, 668, 5463, 1939, 11, 370, 309, 311, 16605, 13, 407, 1338, 11, 286, 478, 510, 281, 751, 466], "temperature": 0.0, "avg_logprob": -0.17229207940057878, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.000537741114385426}, {"id": 2, "seek": 2608, "start": 31.64, "end": 36.8, "text": " strong dynamic type checking for JavaScript, which may sound a bit weird because you are", "tokens": [2068, 8546, 2010, 8568, 337, 15778, 11, 597, 815, 1626, 257, 857, 3657, 570, 291, 366], "temperature": 0.0, "avg_logprob": -0.17229207940057878, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.000537741114385426}, {"id": 3, "seek": 2608, "start": 36.8, "end": 42.36, "text": " not expecting strong type checking in JavaScript in the same sentence, right? But I will prove", "tokens": [406, 9650, 2068, 2010, 8568, 294, 15778, 294, 264, 912, 8174, 11, 558, 30, 583, 286, 486, 7081], "temperature": 0.0, "avg_logprob": -0.17229207940057878, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.000537741114385426}, {"id": 4, "seek": 2608, "start": 42.36, "end": 50.2, "text": " that we can do something about it. So first, what is strong type checking? What do we mean", "tokens": [300, 321, 393, 360, 746, 466, 309, 13, 407, 700, 11, 437, 307, 2068, 2010, 8568, 30, 708, 360, 321, 914], "temperature": 0.0, "avg_logprob": -0.17229207940057878, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.000537741114385426}, {"id": 5, "seek": 2608, "start": 50.2, "end": 55.239999999999995, "text": " by that? So let's do a bit of vocabulary. So I try to find one definition online of", "tokens": [538, 300, 30, 407, 718, 311, 360, 257, 857, 295, 19864, 13, 407, 286, 853, 281, 915, 472, 7123, 2950, 295], "temperature": 0.0, "avg_logprob": -0.17229207940057878, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.000537741114385426}, {"id": 6, "seek": 5524, "start": 55.24, "end": 60.28, "text": " what is strong type checking and couldn't find any. It's like a never-ending argument", "tokens": [437, 307, 2068, 2010, 8568, 293, 2809, 380, 915, 604, 13, 467, 311, 411, 257, 1128, 12, 2029, 6770], "temperature": 0.0, "avg_logprob": -0.14335668205034616, "compression_ratio": 1.8072289156626506, "no_speech_prob": 0.00023762951605021954}, {"id": 7, "seek": 5524, "start": 60.28, "end": 66.04, "text": " about which one, which language is strong and which one isn't. But I found two definitions", "tokens": [466, 597, 472, 11, 597, 2856, 307, 2068, 293, 597, 472, 1943, 380, 13, 583, 286, 1352, 732, 21988], "temperature": 0.0, "avg_logprob": -0.14335668205034616, "compression_ratio": 1.8072289156626506, "no_speech_prob": 0.00023762951605021954}, {"id": 8, "seek": 5524, "start": 66.04, "end": 71.36, "text": " commonly accepted. The first one is that this strong type checking means that you have this", "tokens": [12719, 9035, 13, 440, 700, 472, 307, 300, 341, 2068, 2010, 8568, 1355, 300, 291, 362, 341], "temperature": 0.0, "avg_logprob": -0.14335668205034616, "compression_ratio": 1.8072289156626506, "no_speech_prob": 0.00023762951605021954}, {"id": 9, "seek": 5524, "start": 71.36, "end": 77.48, "text": " kind of explicit binding between some variable name and some type. So this variable and this", "tokens": [733, 295, 13691, 17359, 1296, 512, 7006, 1315, 293, 512, 2010, 13, 407, 341, 7006, 293, 341], "temperature": 0.0, "avg_logprob": -0.14335668205034616, "compression_ratio": 1.8072289156626506, "no_speech_prob": 0.00023762951605021954}, {"id": 10, "seek": 5524, "start": 77.48, "end": 81.2, "text": " type are like bound together. That means that every time you are calling variable by its", "tokens": [2010, 366, 411, 5472, 1214, 13, 663, 1355, 300, 633, 565, 291, 366, 5141, 7006, 538, 1080], "temperature": 0.0, "avg_logprob": -0.14335668205034616, "compression_ratio": 1.8072289156626506, "no_speech_prob": 0.00023762951605021954}, {"id": 11, "seek": 8120, "start": 81.2, "end": 87.76, "text": " name, you will get some reference data that matches the type you expect. The second definition", "tokens": [1315, 11, 291, 486, 483, 512, 6408, 1412, 300, 10676, 264, 2010, 291, 2066, 13, 440, 1150, 7123], "temperature": 0.0, "avg_logprob": -0.1673396458135587, "compression_ratio": 1.6593406593406594, "no_speech_prob": 9.963168122339994e-05}, {"id": 12, "seek": 8120, "start": 87.76, "end": 94.48, "text": " is more regarding the program-languaging features, like no lack of type safety due to", "tokens": [307, 544, 8595, 264, 1461, 12, 25241, 84, 3568, 4122, 11, 411, 572, 5011, 295, 2010, 4514, 3462, 281], "temperature": 0.0, "avg_logprob": -0.1673396458135587, "compression_ratio": 1.6593406593406594, "no_speech_prob": 9.963168122339994e-05}, {"id": 13, "seek": 8120, "start": 94.48, "end": 99.52000000000001, "text": " loser-typing rules. For example, in the case of JavaScript, we have implicit type coercion.", "tokens": [24606, 12, 874, 3381, 4474, 13, 1171, 1365, 11, 294, 264, 1389, 295, 15778, 11, 321, 362, 26947, 2010, 49741, 313, 13], "temperature": 0.0, "avg_logprob": -0.1673396458135587, "compression_ratio": 1.6593406593406594, "no_speech_prob": 9.963168122339994e-05}, {"id": 14, "seek": 8120, "start": 99.52000000000001, "end": 104.48, "text": " That means that it's perfectly fine to get the plus operator between a number and a string.", "tokens": [663, 1355, 300, 309, 311, 6239, 2489, 281, 483, 264, 1804, 12973, 1296, 257, 1230, 293, 257, 6798, 13], "temperature": 0.0, "avg_logprob": -0.1673396458135587, "compression_ratio": 1.6593406593406594, "no_speech_prob": 9.963168122339994e-05}, {"id": 15, "seek": 8120, "start": 104.48, "end": 108.28, "text": " For JavaScript, it's just string concatenation and automatically casting the number to a", "tokens": [1171, 15778, 11, 309, 311, 445, 6798, 1588, 7186, 399, 293, 6772, 17301, 264, 1230, 281, 257], "temperature": 0.0, "avg_logprob": -0.1673396458135587, "compression_ratio": 1.6593406593406594, "no_speech_prob": 9.963168122339994e-05}, {"id": 16, "seek": 10828, "start": 108.28, "end": 114.04, "text": " string. But for other languages, like Python, you will get a type error. So let's take on", "tokens": [6798, 13, 583, 337, 661, 8650, 11, 411, 15329, 11, 291, 486, 483, 257, 2010, 6713, 13, 407, 718, 311, 747, 322], "temperature": 0.0, "avg_logprob": -0.1808306568800801, "compression_ratio": 1.779591836734694, "no_speech_prob": 5.9423266066005453e-05}, {"id": 17, "seek": 10828, "start": 114.04, "end": 121.52, "text": " as an example to show that Python is more strong, stronger than JavaScript. So when", "tokens": [382, 364, 1365, 281, 855, 300, 15329, 307, 544, 2068, 11, 7249, 813, 15778, 13, 407, 562], "temperature": 0.0, "avg_logprob": -0.1808306568800801, "compression_ratio": 1.779591836734694, "no_speech_prob": 5.9423266066005453e-05}, {"id": 18, "seek": 10828, "start": 121.52, "end": 125.4, "text": " it comes to JavaScript, whatever definition you pick, you might say that JavaScript is", "tokens": [309, 1487, 281, 15778, 11, 2035, 7123, 291, 1888, 11, 291, 1062, 584, 300, 15778, 307], "temperature": 0.0, "avg_logprob": -0.1808306568800801, "compression_ratio": 1.779591836734694, "no_speech_prob": 5.9423266066005453e-05}, {"id": 19, "seek": 10828, "start": 125.4, "end": 131.64, "text": " not a strongly typed language and you will be right. Because JavaScript is based on dynamic", "tokens": [406, 257, 10613, 33941, 2856, 293, 291, 486, 312, 558, 13, 1436, 15778, 307, 2361, 322, 8546], "temperature": 0.0, "avg_logprob": -0.1808306568800801, "compression_ratio": 1.779591836734694, "no_speech_prob": 5.9423266066005453e-05}, {"id": 20, "seek": 10828, "start": 131.64, "end": 136.4, "text": " type checking, dynamic typing, that means that JavaScript variables, you can assign", "tokens": [2010, 8568, 11, 8546, 18444, 11, 300, 1355, 300, 15778, 9102, 11, 291, 393, 6269], "temperature": 0.0, "avg_logprob": -0.1808306568800801, "compression_ratio": 1.779591836734694, "no_speech_prob": 5.9423266066005453e-05}, {"id": 21, "seek": 13640, "start": 136.4, "end": 143.12, "text": " it to some type and then move to another type and go on. It doesn't matter. So because", "tokens": [309, 281, 512, 2010, 293, 550, 1286, 281, 1071, 2010, 293, 352, 322, 13, 467, 1177, 380, 1871, 13, 407, 570], "temperature": 0.0, "avg_logprob": -0.2143411190710335, "compression_ratio": 1.657992565055762, "no_speech_prob": 0.0001070400103344582}, {"id": 22, "seek": 13640, "start": 143.12, "end": 149.20000000000002, "text": " types can change during program execution, that makes types in JavaScript quite unpredictable.", "tokens": [3467, 393, 1319, 1830, 1461, 15058, 11, 300, 1669, 3467, 294, 15778, 1596, 31160, 13], "temperature": 0.0, "avg_logprob": -0.2143411190710335, "compression_ratio": 1.657992565055762, "no_speech_prob": 0.0001070400103344582}, {"id": 23, "seek": 13640, "start": 149.20000000000002, "end": 153.48000000000002, "text": " So the creator of the language, Prandon H, justified his choice by saying that developers", "tokens": [407, 264, 14181, 295, 264, 2856, 11, 430, 3699, 266, 389, 11, 27808, 702, 3922, 538, 1566, 300, 8849], "temperature": 0.0, "avg_logprob": -0.2143411190710335, "compression_ratio": 1.657992565055762, "no_speech_prob": 0.0001070400103344582}, {"id": 24, "seek": 13640, "start": 153.48000000000002, "end": 157.4, "text": " can be more expressive when you get dynamic typing, which means that it can get to the", "tokens": [393, 312, 544, 40189, 562, 291, 483, 8546, 18444, 11, 597, 1355, 300, 309, 393, 483, 281, 264], "temperature": 0.0, "avg_logprob": -0.2143411190710335, "compression_ratio": 1.657992565055762, "no_speech_prob": 0.0001070400103344582}, {"id": 25, "seek": 13640, "start": 157.4, "end": 164.56, "text": " result faster, but he also agrees that it is also more error-prone. So that's the image", "tokens": [1874, 4663, 11, 457, 415, 611, 26383, 300, 309, 307, 611, 544, 6713, 12, 1424, 546, 13, 407, 300, 311, 264, 3256], "temperature": 0.0, "avg_logprob": -0.2143411190710335, "compression_ratio": 1.657992565055762, "no_speech_prob": 0.0001070400103344582}, {"id": 26, "seek": 16456, "start": 164.56, "end": 174.04, "text": " I took for static versus dynamic typing. I think it sums up pretty well. So yeah, JavaScript", "tokens": [286, 1890, 337, 13437, 5717, 8546, 18444, 13, 286, 519, 309, 34499, 493, 1238, 731, 13, 407, 1338, 11, 15778], "temperature": 0.0, "avg_logprob": -0.15380997990452966, "compression_ratio": 1.58008658008658, "no_speech_prob": 0.00017723266500979662}, {"id": 27, "seek": 16456, "start": 174.04, "end": 178.32, "text": " and strong type checking, not really. Actually, every time you see someone complaining about", "tokens": [293, 2068, 2010, 8568, 11, 406, 534, 13, 5135, 11, 633, 565, 291, 536, 1580, 20740, 466], "temperature": 0.0, "avg_logprob": -0.15380997990452966, "compression_ratio": 1.58008658008658, "no_speech_prob": 0.00017723266500979662}, {"id": 28, "seek": 16456, "start": 178.32, "end": 184.6, "text": " JavaScript or mocking JavaScript, it would be about one of these memes, right? So these", "tokens": [15778, 420, 49792, 15778, 11, 309, 576, 312, 466, 472, 295, 613, 29730, 11, 558, 30, 407, 613], "temperature": 0.0, "avg_logprob": -0.15380997990452966, "compression_ratio": 1.58008658008658, "no_speech_prob": 0.00017723266500979662}, {"id": 29, "seek": 16456, "start": 184.6, "end": 189.88, "text": " are some of my favorites. Maybe you know others. But as you can see, almost all these jokes", "tokens": [366, 512, 295, 452, 16907, 13, 2704, 291, 458, 2357, 13, 583, 382, 291, 393, 536, 11, 1920, 439, 613, 14439], "temperature": 0.0, "avg_logprob": -0.15380997990452966, "compression_ratio": 1.58008658008658, "no_speech_prob": 0.00017723266500979662}, {"id": 30, "seek": 18988, "start": 189.88, "end": 196.64, "text": " about JavaScript are basically about the lack of strong type checking, which is too bad.", "tokens": [466, 15778, 366, 1936, 466, 264, 5011, 295, 2068, 2010, 8568, 11, 597, 307, 886, 1578, 13], "temperature": 0.0, "avg_logprob": -0.13710864384969076, "compression_ratio": 1.502092050209205, "no_speech_prob": 0.00026863269158639014}, {"id": 31, "seek": 18988, "start": 196.64, "end": 202.35999999999999, "text": " So some people will decide to just get rid of JavaScript and maybe go to Kotlin or.NET", "tokens": [407, 512, 561, 486, 4536, 281, 445, 483, 3973, 295, 15778, 293, 1310, 352, 281, 30123, 5045, 420, 2411, 35554], "temperature": 0.0, "avg_logprob": -0.13710864384969076, "compression_ratio": 1.502092050209205, "no_speech_prob": 0.00026863269158639014}, {"id": 32, "seek": 18988, "start": 202.35999999999999, "end": 207.96, "text": " or whatever language we have seen this morning. But I think that's the most common solution", "tokens": [420, 2035, 2856, 321, 362, 1612, 341, 2446, 13, 583, 286, 519, 300, 311, 264, 881, 2689, 3827], "temperature": 0.0, "avg_logprob": -0.13710864384969076, "compression_ratio": 1.502092050209205, "no_speech_prob": 0.00026863269158639014}, {"id": 33, "seek": 18988, "start": 207.96, "end": 214.16, "text": " to this approach has been TypeScript, right? I mean, this thing has been invented specially", "tokens": [281, 341, 3109, 575, 668, 15576, 14237, 11, 558, 30, 286, 914, 11, 341, 551, 575, 668, 14479, 22549], "temperature": 0.0, "avg_logprob": -0.13710864384969076, "compression_ratio": 1.502092050209205, "no_speech_prob": 0.00026863269158639014}, {"id": 34, "seek": 21416, "start": 214.16, "end": 221.64, "text": " to address this issue by having some optional static type checking about JavaScript. So how", "tokens": [281, 2985, 341, 2734, 538, 1419, 512, 17312, 13437, 2010, 8568, 466, 15778, 13, 407, 577], "temperature": 0.0, "avg_logprob": -0.16133858073841442, "compression_ratio": 1.644927536231884, "no_speech_prob": 9.478141873842105e-05}, {"id": 35, "seek": 21416, "start": 221.64, "end": 226.76, "text": " many of you are using TypeScript? Raise your hand. Wow. I was expecting that. Like, almost", "tokens": [867, 295, 291, 366, 1228, 15576, 14237, 30, 30062, 428, 1011, 13, 3153, 13, 286, 390, 9650, 300, 13, 1743, 11, 1920], "temperature": 0.0, "avg_logprob": -0.16133858073841442, "compression_ratio": 1.644927536231884, "no_speech_prob": 9.478141873842105e-05}, {"id": 36, "seek": 21416, "start": 226.76, "end": 233.16, "text": " 100% of these people in this room are using TypeScript. I mean, why wouldn't we use TypeScript?", "tokens": [2319, 4, 295, 613, 561, 294, 341, 1808, 366, 1228, 15576, 14237, 13, 286, 914, 11, 983, 2759, 380, 321, 764, 15576, 14237, 30], "temperature": 0.0, "avg_logprob": -0.16133858073841442, "compression_ratio": 1.644927536231884, "no_speech_prob": 9.478141873842105e-05}, {"id": 37, "seek": 21416, "start": 233.16, "end": 239.0, "text": " It's so popular. Almost all the ecosystems, all the libraries today on VNPM ecosystem", "tokens": [467, 311, 370, 3743, 13, 12627, 439, 264, 32647, 11, 439, 264, 15148, 965, 322, 691, 45, 18819, 11311], "temperature": 0.0, "avg_logprob": -0.16133858073841442, "compression_ratio": 1.644927536231884, "no_speech_prob": 9.478141873842105e-05}, {"id": 38, "seek": 21416, "start": 239.0, "end": 243.64, "text": " have been converted to TypeScript or provide TypeScript definition files. So we have seen", "tokens": [362, 668, 16424, 281, 15576, 14237, 420, 2893, 15576, 14237, 7123, 7098, 13, 407, 321, 362, 1612], "temperature": 0.0, "avg_logprob": -0.16133858073841442, "compression_ratio": 1.644927536231884, "no_speech_prob": 9.478141873842105e-05}, {"id": 39, "seek": 24364, "start": 243.64, "end": 249.16, "text": " this kind of exponential growth in popularity among the years. TypeScript is 10 years now.", "tokens": [341, 733, 295, 21510, 4599, 294, 19301, 3654, 264, 924, 13, 15576, 14237, 307, 1266, 924, 586, 13], "temperature": 0.0, "avg_logprob": -0.17176043659175208, "compression_ratio": 1.6654275092936803, "no_speech_prob": 8.71498414198868e-05}, {"id": 40, "seek": 24364, "start": 249.16, "end": 256.47999999999996, "text": " It will be 11 in five days, actually. And it has never been so popular. So did we solve", "tokens": [467, 486, 312, 2975, 294, 1732, 1708, 11, 767, 13, 400, 309, 575, 1128, 668, 370, 3743, 13, 407, 630, 321, 5039], "temperature": 0.0, "avg_logprob": -0.17176043659175208, "compression_ratio": 1.6654275092936803, "no_speech_prob": 8.71498414198868e-05}, {"id": 41, "seek": 24364, "start": 256.47999999999996, "end": 261.56, "text": " the issue of type checking JavaScript with TypeScript? I would say not entirely and I", "tokens": [264, 2734, 295, 2010, 8568, 15778, 365, 15576, 14237, 30, 286, 576, 584, 406, 7696, 293, 286], "temperature": 0.0, "avg_logprob": -0.17176043659175208, "compression_ratio": 1.6654275092936803, "no_speech_prob": 8.71498414198868e-05}, {"id": 42, "seek": 24364, "start": 261.56, "end": 267.36, "text": " explain why. Here are some things I learned about TypeScript after 110 years. The first", "tokens": [2903, 983, 13, 1692, 366, 512, 721, 286, 3264, 466, 15576, 14237, 934, 20154, 924, 13, 440, 700], "temperature": 0.0, "avg_logprob": -0.17176043659175208, "compression_ratio": 1.6654275092936803, "no_speech_prob": 8.71498414198868e-05}, {"id": 43, "seek": 24364, "start": 267.36, "end": 273.32, "text": " one is a bit of shock is that TypeShaking is not actually the main selling point of TypeScript.", "tokens": [472, 307, 257, 857, 295, 5588, 307, 300, 15576, 7774, 2456, 307, 406, 767, 264, 2135, 6511, 935, 295, 15576, 14237, 13], "temperature": 0.0, "avg_logprob": -0.17176043659175208, "compression_ratio": 1.6654275092936803, "no_speech_prob": 8.71498414198868e-05}, {"id": 44, "seek": 27332, "start": 273.32, "end": 279.56, "text": " The main selling point of TypeScript is developer experience. So if you have practiced TypeScript", "tokens": [440, 2135, 6511, 935, 295, 15576, 14237, 307, 10754, 1752, 13, 407, 498, 291, 362, 19268, 15576, 14237], "temperature": 0.0, "avg_logprob": -0.13593895321800595, "compression_ratio": 1.77734375, "no_speech_prob": 3.4754797525238246e-05}, {"id": 45, "seek": 27332, "start": 279.56, "end": 286.2, "text": " and the whole room has done that, it's great. You have seen some improvements in your development", "tokens": [293, 264, 1379, 1808, 575, 1096, 300, 11, 309, 311, 869, 13, 509, 362, 1612, 512, 13797, 294, 428, 3250], "temperature": 0.0, "avg_logprob": -0.13593895321800595, "compression_ratio": 1.77734375, "no_speech_prob": 3.4754797525238246e-05}, {"id": 46, "seek": 27332, "start": 286.2, "end": 292.52, "text": " experience. So many things like be able to explore some API by using the autocomplete,", "tokens": [1752, 13, 407, 867, 721, 411, 312, 1075, 281, 6839, 512, 9362, 538, 1228, 264, 45833, 298, 17220, 11], "temperature": 0.0, "avg_logprob": -0.13593895321800595, "compression_ratio": 1.77734375, "no_speech_prob": 3.4754797525238246e-05}, {"id": 47, "seek": 27332, "start": 292.52, "end": 297.52, "text": " be able to detect some typos that you have done in your code, be able to refactor your", "tokens": [312, 1075, 281, 5531, 512, 2125, 329, 300, 291, 362, 1096, 294, 428, 3089, 11, 312, 1075, 281, 1895, 15104, 428], "temperature": 0.0, "avg_logprob": -0.13593895321800595, "compression_ratio": 1.77734375, "no_speech_prob": 3.4754797525238246e-05}, {"id": 48, "seek": 27332, "start": 297.52, "end": 302.36, "text": " code more easily thanks to the static type annotations, maybe have some documentation", "tokens": [3089, 544, 3612, 3231, 281, 264, 13437, 2010, 25339, 763, 11, 1310, 362, 512, 14333], "temperature": 0.0, "avg_logprob": -0.13593895321800595, "compression_ratio": 1.77734375, "no_speech_prob": 3.4754797525238246e-05}, {"id": 49, "seek": 30236, "start": 302.36, "end": 307.68, "text": " right inside your IDE. Some compilers are using static type annotations to bring some", "tokens": [558, 1854, 428, 40930, 13, 2188, 715, 388, 433, 366, 1228, 13437, 2010, 25339, 763, 281, 1565, 512], "temperature": 0.0, "avg_logprob": -0.1564598440009857, "compression_ratio": 1.842323651452282, "no_speech_prob": 6.356441008392721e-05}, {"id": 50, "seek": 30236, "start": 307.68, "end": 312.96000000000004, "text": " compile time optimizations, which is great. You get type inference, good type inference", "tokens": [31413, 565, 5028, 14455, 11, 597, 307, 869, 13, 509, 483, 2010, 38253, 11, 665, 2010, 38253], "temperature": 0.0, "avg_logprob": -0.1564598440009857, "compression_ratio": 1.842323651452282, "no_speech_prob": 6.356441008392721e-05}, {"id": 51, "seek": 30236, "start": 312.96000000000004, "end": 317.96000000000004, "text": " in TypeScript, so you don't have to write all the static type annotations at any time.", "tokens": [294, 15576, 14237, 11, 370, 291, 500, 380, 362, 281, 2464, 439, 264, 13437, 2010, 25339, 763, 412, 604, 565, 13], "temperature": 0.0, "avg_logprob": -0.1564598440009857, "compression_ratio": 1.842323651452282, "no_speech_prob": 6.356441008392721e-05}, {"id": 52, "seek": 30236, "start": 317.96000000000004, "end": 322.88, "text": " And we have seen some innovative use of TypeScript. For example, the Angular community is using", "tokens": [400, 321, 362, 1612, 512, 12999, 764, 295, 15576, 14237, 13, 1171, 1365, 11, 264, 34107, 1768, 307, 1228], "temperature": 0.0, "avg_logprob": -0.1564598440009857, "compression_ratio": 1.842323651452282, "no_speech_prob": 6.356441008392721e-05}, {"id": 53, "seek": 30236, "start": 322.88, "end": 328.12, "text": " a lot of TypeScript annotations to make some code generation, which is great. So all of", "tokens": [257, 688, 295, 15576, 14237, 25339, 763, 281, 652, 512, 3089, 5125, 11, 597, 307, 869, 13, 407, 439, 295], "temperature": 0.0, "avg_logprob": -0.1564598440009857, "compression_ratio": 1.842323651452282, "no_speech_prob": 6.356441008392721e-05}, {"id": 54, "seek": 32812, "start": 328.12, "end": 333.04, "text": " this is part of developer experience and is great, but it's not really about type checking", "tokens": [341, 307, 644, 295, 10754, 1752, 293, 307, 869, 11, 457, 309, 311, 406, 534, 466, 2010, 8568], "temperature": 0.0, "avg_logprob": -0.18430470553311434, "compression_ratio": 1.6943396226415095, "no_speech_prob": 6.70316512696445e-05}, {"id": 55, "seek": 32812, "start": 333.04, "end": 340.32, "text": " anymore. It's much more than that. I figured out that type checking was not the main selling", "tokens": [3602, 13, 467, 311, 709, 544, 813, 300, 13, 286, 8932, 484, 300, 2010, 8568, 390, 406, 264, 2135, 6511], "temperature": 0.0, "avg_logprob": -0.18430470553311434, "compression_ratio": 1.6943396226415095, "no_speech_prob": 6.70316512696445e-05}, {"id": 56, "seek": 32812, "start": 340.32, "end": 345.16, "text": " point of TypeScript or at least not anymore. When I looked at the ES build project, one", "tokens": [935, 295, 15576, 14237, 420, 412, 1935, 406, 3602, 13, 1133, 286, 2956, 412, 264, 12564, 1322, 1716, 11, 472], "temperature": 0.0, "avg_logprob": -0.18430470553311434, "compression_ratio": 1.6943396226415095, "no_speech_prob": 6.70316512696445e-05}, {"id": 57, "seek": 32812, "start": 345.16, "end": 350.2, "text": " of the most important JavaScript project of these last years, ES build, the famous bundler,", "tokens": [295, 264, 881, 1021, 15778, 1716, 295, 613, 1036, 924, 11, 12564, 1322, 11, 264, 4618, 13882, 1918, 11], "temperature": 0.0, "avg_logprob": -0.18430470553311434, "compression_ratio": 1.6943396226415095, "no_speech_prob": 6.70316512696445e-05}, {"id": 58, "seek": 32812, "start": 350.2, "end": 354.52, "text": " so maybe you are using the VIT development server, some people in the room. So VIT is", "tokens": [370, 1310, 291, 366, 1228, 264, 691, 3927, 3250, 7154, 11, 512, 561, 294, 264, 1808, 13, 407, 691, 3927, 307], "temperature": 0.0, "avg_logprob": -0.18430470553311434, "compression_ratio": 1.6943396226415095, "no_speech_prob": 6.70316512696445e-05}, {"id": 59, "seek": 35452, "start": 354.52, "end": 360.2, "text": " based on ES build. And does ES build support TypeScript? Of course it does. Everyone is", "tokens": [2361, 322, 12564, 1322, 13, 400, 775, 12564, 1322, 1406, 15576, 14237, 30, 2720, 1164, 309, 775, 13, 5198, 307], "temperature": 0.0, "avg_logprob": -0.13560459677097017, "compression_ratio": 1.8518518518518519, "no_speech_prob": 0.00015256510232575238}, {"id": 60, "seek": 35452, "start": 360.2, "end": 365.64, "text": " using TypeScript. But the fact is that ES build does not actually do any type checking when", "tokens": [1228, 15576, 14237, 13, 583, 264, 1186, 307, 300, 12564, 1322, 775, 406, 767, 360, 604, 2010, 8568, 562], "temperature": 0.0, "avg_logprob": -0.13560459677097017, "compression_ratio": 1.8518518518518519, "no_speech_prob": 0.00015256510232575238}, {"id": 61, "seek": 35452, "start": 365.64, "end": 370.2, "text": " it compiles some TypeScript code. All it does is look at the TypeScript code, look at the", "tokens": [309, 715, 4680, 512, 15576, 14237, 3089, 13, 1057, 309, 775, 307, 574, 412, 264, 15576, 14237, 3089, 11, 574, 412, 264], "temperature": 0.0, "avg_logprob": -0.13560459677097017, "compression_ratio": 1.8518518518518519, "no_speech_prob": 0.00015256510232575238}, {"id": 62, "seek": 35452, "start": 370.2, "end": 374.91999999999996, "text": " TypeScript part of the static type annotations, and just get rid of it. That's all it does.", "tokens": [15576, 14237, 644, 295, 264, 13437, 2010, 25339, 763, 11, 293, 445, 483, 3973, 295, 309, 13, 663, 311, 439, 309, 775, 13], "temperature": 0.0, "avg_logprob": -0.13560459677097017, "compression_ratio": 1.8518518518518519, "no_speech_prob": 0.00015256510232575238}, {"id": 63, "seek": 35452, "start": 374.91999999999996, "end": 379.76, "text": " Nothing else. And they say that running the whole TypeScript compiler is actually a loss", "tokens": [6693, 1646, 13, 400, 436, 584, 300, 2614, 264, 1379, 15576, 14237, 31958, 307, 767, 257, 4470], "temperature": 0.0, "avg_logprob": -0.13560459677097017, "compression_ratio": 1.8518518518518519, "no_speech_prob": 0.00015256510232575238}, {"id": 64, "seek": 37976, "start": 379.76, "end": 386.24, "text": " of time today. Because of this development experience, developers have this whole integrated", "tokens": [295, 565, 965, 13, 1436, 295, 341, 3250, 1752, 11, 8849, 362, 341, 1379, 10919], "temperature": 0.0, "avg_logprob": -0.1644569299159906, "compression_ratio": 1.625, "no_speech_prob": 0.00012356272782199085}, {"id": 65, "seek": 37976, "start": 386.24, "end": 391.03999999999996, "text": " type safe environment and development process. So that means that you don't need to do it", "tokens": [2010, 3273, 2823, 293, 3250, 1399, 13, 407, 300, 1355, 300, 291, 500, 380, 643, 281, 360, 309], "temperature": 0.0, "avg_logprob": -0.1644569299159906, "compression_ratio": 1.625, "no_speech_prob": 0.00012356272782199085}, {"id": 66, "seek": 37976, "start": 391.03999999999996, "end": 399.48, "text": " twice a second time on compilation. The second point of TypeScript that I learned", "tokens": [6091, 257, 1150, 565, 322, 40261, 13, 440, 1150, 935, 295, 15576, 14237, 300, 286, 3264], "temperature": 0.0, "avg_logprob": -0.1644569299159906, "compression_ratio": 1.625, "no_speech_prob": 0.00012356272782199085}, {"id": 67, "seek": 37976, "start": 399.48, "end": 406.52, "text": " about 10 years later, it's that type safety in TypeScript can be easily defeated. What", "tokens": [466, 1266, 924, 1780, 11, 309, 311, 300, 2010, 4514, 294, 15576, 14237, 393, 312, 3612, 15563, 13, 708], "temperature": 0.0, "avg_logprob": -0.1644569299159906, "compression_ratio": 1.625, "no_speech_prob": 0.00012356272782199085}, {"id": 68, "seek": 40652, "start": 406.52, "end": 411.24, "text": " I mean by that is that in many scenarios in your application, you are relying on type", "tokens": [286, 914, 538, 300, 307, 300, 294, 867, 15077, 294, 428, 3861, 11, 291, 366, 24140, 322, 2010], "temperature": 0.0, "avg_logprob": -0.18078211908755096, "compression_ratio": 1.7011494252873562, "no_speech_prob": 6.227596895769238e-05}, {"id": 69, "seek": 40652, "start": 411.24, "end": 416.88, "text": " assertions. That is these little elements like the ASCII word or the exclamation mark", "tokens": [19810, 626, 13, 663, 307, 613, 707, 4959, 411, 264, 7469, 34, 9503, 1349, 420, 264, 1624, 43233, 1491], "temperature": 0.0, "avg_logprob": -0.18078211908755096, "compression_ratio": 1.7011494252873562, "no_speech_prob": 6.227596895769238e-05}, {"id": 70, "seek": 40652, "start": 416.88, "end": 423.0, "text": " here, which is I ensure you the compiler that is not null. So all these things are not bringing", "tokens": [510, 11, 597, 307, 286, 5586, 291, 264, 31958, 300, 307, 406, 18184, 13, 407, 439, 613, 721, 366, 406, 5062], "temperature": 0.0, "avg_logprob": -0.18078211908755096, "compression_ratio": 1.7011494252873562, "no_speech_prob": 6.227596895769238e-05}, {"id": 71, "seek": 40652, "start": 423.0, "end": 426.71999999999997, "text": " any type safety. It's just the developer saying to the compiler, trust me, I know what I'm", "tokens": [604, 2010, 4514, 13, 467, 311, 445, 264, 10754, 1566, 281, 264, 31958, 11, 3361, 385, 11, 286, 458, 437, 286, 478], "temperature": 0.0, "avg_logprob": -0.18078211908755096, "compression_ratio": 1.7011494252873562, "no_speech_prob": 6.227596895769238e-05}, {"id": 72, "seek": 40652, "start": 426.71999999999997, "end": 435.52, "text": " doing. And most of the time, we do not. So yeah, this problem, these type assertions,", "tokens": [884, 13, 400, 881, 295, 264, 565, 11, 321, 360, 406, 13, 407, 1338, 11, 341, 1154, 11, 613, 2010, 19810, 626, 11], "temperature": 0.0, "avg_logprob": -0.18078211908755096, "compression_ratio": 1.7011494252873562, "no_speech_prob": 6.227596895769238e-05}, {"id": 73, "seek": 43552, "start": 435.52, "end": 440.32, "text": " you can find them easily on any web application. There are actually many parts where you are", "tokens": [291, 393, 915, 552, 3612, 322, 604, 3670, 3861, 13, 821, 366, 767, 867, 3166, 689, 291, 366], "temperature": 0.0, "avg_logprob": -0.15847211413913304, "compression_ratio": 1.695167286245353, "no_speech_prob": 0.00013630010653287172}, {"id": 74, "seek": 43552, "start": 440.32, "end": 445.47999999999996, "text": " forced to use these kind of assertions because of the nature of the web. You can have your", "tokens": [7579, 281, 764, 613, 733, 295, 19810, 626, 570, 295, 264, 3687, 295, 264, 3670, 13, 509, 393, 362, 428], "temperature": 0.0, "avg_logprob": -0.15847211413913304, "compression_ratio": 1.695167286245353, "no_speech_prob": 0.00013630010653287172}, {"id": 75, "seek": 43552, "start": 445.47999999999996, "end": 451.32, "text": " perfectly type safe TypeScript application and still have to deal with lots of unpredictability.", "tokens": [6239, 2010, 3273, 15576, 14237, 3861, 293, 920, 362, 281, 2028, 365, 3195, 295, 28341, 2310, 13], "temperature": 0.0, "avg_logprob": -0.15847211413913304, "compression_ratio": 1.695167286245353, "no_speech_prob": 0.00013630010653287172}, {"id": 76, "seek": 43552, "start": 451.32, "end": 458.32, "text": " Unpredictable is like the most of your time, your job for a front-end web developer. And", "tokens": [1156, 79, 24945, 712, 307, 411, 264, 881, 295, 428, 565, 11, 428, 1691, 337, 257, 1868, 12, 521, 3670, 10754, 13, 400], "temperature": 0.0, "avg_logprob": -0.15847211413913304, "compression_ratio": 1.695167286245353, "no_speech_prob": 0.00013630010653287172}, {"id": 77, "seek": 43552, "start": 458.32, "end": 463.2, "text": " what I mean by unpredictable, it is known at runtime. That means it changes every time", "tokens": [437, 286, 914, 538, 31160, 11, 309, 307, 2570, 412, 34474, 13, 663, 1355, 309, 2962, 633, 565], "temperature": 0.0, "avg_logprob": -0.15847211413913304, "compression_ratio": 1.695167286245353, "no_speech_prob": 0.00013630010653287172}, {"id": 78, "seek": 46320, "start": 463.2, "end": 469.88, "text": " at every user and so on. So for example, your application may have some back-end services,", "tokens": [412, 633, 4195, 293, 370, 322, 13, 407, 337, 1365, 11, 428, 3861, 815, 362, 512, 646, 12, 521, 3328, 11], "temperature": 0.0, "avg_logprob": -0.2370474093428282, "compression_ratio": 1.7120622568093384, "no_speech_prob": 0.0001133910336648114}, {"id": 79, "seek": 46320, "start": 469.88, "end": 475.28, "text": " may call some APIs, maybe some third-party cloud providers. And you are trusting the", "tokens": [815, 818, 512, 21445, 11, 1310, 512, 2636, 12, 23409, 4588, 11330, 13, 400, 291, 366, 28235, 264], "temperature": 0.0, "avg_logprob": -0.2370474093428282, "compression_ratio": 1.7120622568093384, "no_speech_prob": 0.0001133910336648114}, {"id": 80, "seek": 46320, "start": 475.28, "end": 480.56, "text": " responses of these servers, right? You are not validating any of the response of the", "tokens": [13019, 295, 613, 15909, 11, 558, 30, 509, 366, 406, 7363, 990, 604, 295, 264, 4134, 295, 264], "temperature": 0.0, "avg_logprob": -0.2370474093428282, "compression_ratio": 1.7120622568093384, "no_speech_prob": 0.0001133910336648114}, {"id": 81, "seek": 46320, "start": 480.56, "end": 487.44, "text": " server from the application side. So this could break. You are also relying on a browser.", "tokens": [7154, 490, 264, 3861, 1252, 13, 407, 341, 727, 1821, 13, 509, 366, 611, 24140, 322, 257, 11185, 13], "temperature": 0.0, "avg_logprob": -0.2370474093428282, "compression_ratio": 1.7120622568093384, "no_speech_prob": 0.0001133910336648114}, {"id": 82, "seek": 46320, "start": 487.44, "end": 492.88, "text": " And some browsers have bugs and queers. They do not fully support visual script APIs. The", "tokens": [400, 512, 36069, 362, 15120, 293, 631, 433, 13, 814, 360, 406, 4498, 1406, 5056, 5755, 21445, 13, 440], "temperature": 0.0, "avg_logprob": -0.2370474093428282, "compression_ratio": 1.7120622568093384, "no_speech_prob": 0.0001133910336648114}, {"id": 83, "seek": 49288, "start": 492.88, "end": 500.6, "text": " web standard APIs. I chose this logo for a reason, why? You may also have some client-side", "tokens": [3670, 3832, 21445, 13, 286, 5111, 341, 9699, 337, 257, 1778, 11, 983, 30, 509, 815, 611, 362, 512, 6423, 12, 1812], "temperature": 0.0, "avg_logprob": -0.2124883936739516, "compression_ratio": 1.5844155844155845, "no_speech_prob": 5.712272832170129e-05}, {"id": 84, "seek": 49288, "start": 500.6, "end": 506.04, "text": " store data for your application. Maybe you are storing on a local storage some user preferences", "tokens": [3531, 1412, 337, 428, 3861, 13, 2704, 291, 366, 26085, 322, 257, 2654, 6725, 512, 4195, 21910], "temperature": 0.0, "avg_logprob": -0.2124883936739516, "compression_ratio": 1.5844155844155845, "no_speech_prob": 5.712272832170129e-05}, {"id": 85, "seek": 49288, "start": 506.04, "end": 513.64, "text": " or some five-store age users' cache. So this is likely to break as well because sometimes", "tokens": [420, 512, 1732, 12, 21624, 3205, 5022, 6, 19459, 13, 407, 341, 307, 3700, 281, 1821, 382, 731, 570, 2171], "temperature": 0.0, "avg_logprob": -0.2124883936739516, "compression_ratio": 1.5844155844155845, "no_speech_prob": 5.712272832170129e-05}, {"id": 86, "seek": 49288, "start": 513.64, "end": 518.16, "text": " the cache is outdated. It comes from an older version of your application or maybe it has", "tokens": [264, 19459, 307, 36313, 13, 467, 1487, 490, 364, 4906, 3037, 295, 428, 3861, 420, 1310, 309, 575], "temperature": 0.0, "avg_logprob": -0.2124883936739516, "compression_ratio": 1.5844155844155845, "no_speech_prob": 5.712272832170129e-05}, {"id": 87, "seek": 51816, "start": 518.16, "end": 524.4, "text": " been modified by the user itself, who knows. And finally, maybe the most unpredictable", "tokens": [668, 15873, 538, 264, 4195, 2564, 11, 567, 3255, 13, 400, 2721, 11, 1310, 264, 881, 31160], "temperature": 0.0, "avg_logprob": -0.15970320982091568, "compression_ratio": 1.5874439461883407, "no_speech_prob": 0.00010921373177552596}, {"id": 88, "seek": 51816, "start": 524.4, "end": 533.28, "text": " part of every developer's job, did you guess it? The user. The user can be very unpredictable.", "tokens": [644, 295, 633, 10754, 311, 1691, 11, 630, 291, 2041, 309, 30, 440, 4195, 13, 440, 4195, 393, 312, 588, 31160, 13], "temperature": 0.0, "avg_logprob": -0.15970320982091568, "compression_ratio": 1.5874439461883407, "no_speech_prob": 0.00010921373177552596}, {"id": 89, "seek": 51816, "start": 533.28, "end": 537.0, "text": " If you have some application in production and have a look at the production database,", "tokens": [759, 291, 362, 512, 3861, 294, 4265, 293, 362, 257, 574, 412, 264, 4265, 8149, 11], "temperature": 0.0, "avg_logprob": -0.15970320982091568, "compression_ratio": 1.5874439461883407, "no_speech_prob": 0.00010921373177552596}, {"id": 90, "seek": 51816, "start": 537.0, "end": 542.16, "text": " you will always find some crazy stuff like, how did it get there? I don't understand.", "tokens": [291, 486, 1009, 915, 512, 3219, 1507, 411, 11, 577, 630, 309, 483, 456, 30, 286, 500, 380, 1223, 13], "temperature": 0.0, "avg_logprob": -0.15970320982091568, "compression_ratio": 1.5874439461883407, "no_speech_prob": 0.00010921373177552596}, {"id": 91, "seek": 54216, "start": 542.16, "end": 548.16, "text": " This is the user. All these things need to be validated. Otherwise, this is a recipe", "tokens": [639, 307, 264, 4195, 13, 1057, 613, 721, 643, 281, 312, 40693, 13, 10328, 11, 341, 307, 257, 6782], "temperature": 0.0, "avg_logprob": -0.2464714707999394, "compression_ratio": 1.543859649122807, "no_speech_prob": 5.951715138508007e-05}, {"id": 92, "seek": 54216, "start": 548.16, "end": 557.88, "text": " for disaster and can break your perfectly safe application in TypeScript. So if you look", "tokens": [337, 11293, 293, 393, 1821, 428, 6239, 3273, 3861, 294, 15576, 14237, 13, 407, 498, 291, 574], "temperature": 0.0, "avg_logprob": -0.2464714707999394, "compression_ratio": 1.543859649122807, "no_speech_prob": 5.951715138508007e-05}, {"id": 93, "seek": 54216, "start": 557.88, "end": 562.88, "text": " at TypeScript and wonder, how can I do that? How can I type check all of these things? No", "tokens": [412, 15576, 14237, 293, 2441, 11, 577, 393, 286, 360, 300, 30, 1012, 393, 286, 2010, 1520, 439, 295, 613, 721, 30, 883], "temperature": 0.0, "avg_logprob": -0.2464714707999394, "compression_ratio": 1.543859649122807, "no_speech_prob": 5.951715138508007e-05}, {"id": 94, "seek": 54216, "start": 562.88, "end": 568.64, "text": " luck. It's not a compiler problem because all these things happen at runtime. You cannot", "tokens": [3668, 13, 467, 311, 406, 257, 31958, 1154, 570, 439, 613, 721, 1051, 412, 34474, 13, 509, 2644], "temperature": 0.0, "avg_logprob": -0.2464714707999394, "compression_ratio": 1.543859649122807, "no_speech_prob": 5.951715138508007e-05}, {"id": 95, "seek": 56864, "start": 568.64, "end": 573.1999999999999, "text": " anticipate it. So it's more an applicative problem and not a compiler problem, which", "tokens": [21685, 309, 13, 407, 309, 311, 544, 364, 2580, 1166, 1154, 293, 406, 257, 31958, 1154, 11, 597], "temperature": 0.0, "avg_logprob": -0.12742591354082217, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00010005930380430073}, {"id": 96, "seek": 56864, "start": 573.1999999999999, "end": 578.52, "text": " means that TypeScript is completely helpless and it is up to you, the developer, to find", "tokens": [1355, 300, 15576, 14237, 307, 2584, 27596, 293, 309, 307, 493, 281, 291, 11, 264, 10754, 11, 281, 915], "temperature": 0.0, "avg_logprob": -0.12742591354082217, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00010005930380430073}, {"id": 97, "seek": 56864, "start": 578.52, "end": 584.8, "text": " a solution to these problems. So how do we deal with runtime errors? Most", "tokens": [257, 3827, 281, 613, 2740, 13, 407, 577, 360, 321, 2028, 365, 34474, 13603, 30, 4534], "temperature": 0.0, "avg_logprob": -0.12742591354082217, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00010005930380430073}, {"id": 98, "seek": 56864, "start": 584.8, "end": 591.56, "text": " of the time, the truth is that often we don't. Maybe in the best of scenarios, you are doing", "tokens": [295, 264, 565, 11, 264, 3494, 307, 300, 2049, 321, 500, 380, 13, 2704, 294, 264, 1151, 295, 15077, 11, 291, 366, 884], "temperature": 0.0, "avg_logprob": -0.12742591354082217, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00010005930380430073}, {"id": 99, "seek": 56864, "start": 591.56, "end": 597.36, "text": " some custom logic to validate the data and trying to fix the stuff the best you can.", "tokens": [512, 2375, 9952, 281, 29562, 264, 1412, 293, 1382, 281, 3191, 264, 1507, 264, 1151, 291, 393, 13], "temperature": 0.0, "avg_logprob": -0.12742591354082217, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.00010005930380430073}, {"id": 100, "seek": 59736, "start": 597.36, "end": 601.84, "text": " But most of the time, you have so many different possible runtime errors that you would have", "tokens": [583, 881, 295, 264, 565, 11, 291, 362, 370, 867, 819, 1944, 34474, 13603, 300, 291, 576, 362], "temperature": 0.0, "avg_logprob": -0.1565143066702537, "compression_ratio": 1.7213740458015268, "no_speech_prob": 8.614543912699446e-05}, {"id": 101, "seek": 59736, "start": 601.84, "end": 608.6800000000001, "text": " like try catch blocks and trying to show some error messages to the user, saying them to", "tokens": [411, 853, 3745, 8474, 293, 1382, 281, 855, 512, 6713, 7897, 281, 264, 4195, 11, 1566, 552, 281], "temperature": 0.0, "avg_logprob": -0.1565143066702537, "compression_ratio": 1.7213740458015268, "no_speech_prob": 8.614543912699446e-05}, {"id": 102, "seek": 59736, "start": 608.6800000000001, "end": 615.48, "text": " call you and send us an email in case something bad happens. And I also saw that we have some", "tokens": [818, 291, 293, 2845, 505, 364, 3796, 294, 1389, 746, 1578, 2314, 13, 400, 286, 611, 1866, 300, 321, 362, 512], "temperature": 0.0, "avg_logprob": -0.1565143066702537, "compression_ratio": 1.7213740458015268, "no_speech_prob": 8.614543912699446e-05}, {"id": 103, "seek": 59736, "start": 615.48, "end": 620.64, "text": " kind of global unexpected exception handler that is just sending all the runtime errors", "tokens": [733, 295, 4338, 13106, 11183, 41967, 300, 307, 445, 7750, 439, 264, 34474, 13603], "temperature": 0.0, "avg_logprob": -0.1565143066702537, "compression_ratio": 1.7213740458015268, "no_speech_prob": 8.614543912699446e-05}, {"id": 104, "seek": 59736, "start": 620.64, "end": 625.9200000000001, "text": " that you didn't catch to maybe a monitoring service. And it is added to a log file that", "tokens": [300, 291, 994, 380, 3745, 281, 1310, 257, 11028, 2643, 13, 400, 309, 307, 3869, 281, 257, 3565, 3991, 300], "temperature": 0.0, "avg_logprob": -0.1565143066702537, "compression_ratio": 1.7213740458015268, "no_speech_prob": 8.614543912699446e-05}, {"id": 105, "seek": 62592, "start": 625.92, "end": 630.12, "text": " you are checking like once in a month, looking at a bunch of errors and saying it's not worth", "tokens": [291, 366, 8568, 411, 1564, 294, 257, 1618, 11, 1237, 412, 257, 3840, 295, 13603, 293, 1566, 309, 311, 406, 3163], "temperature": 0.0, "avg_logprob": -0.21137711039760657, "compression_ratio": 1.6407407407407408, "no_speech_prob": 1.98806756088743e-05}, {"id": 106, "seek": 62592, "start": 630.12, "end": 635.04, "text": " my time, so I should move to something else. I don't know if some of you do that, but it", "tokens": [452, 565, 11, 370, 286, 820, 1286, 281, 746, 1646, 13, 286, 500, 380, 458, 498, 512, 295, 291, 360, 300, 11, 457, 309], "temperature": 0.0, "avg_logprob": -0.21137711039760657, "compression_ratio": 1.6407407407407408, "no_speech_prob": 1.98806756088743e-05}, {"id": 107, "seek": 62592, "start": 635.04, "end": 641.56, "text": " happens, right? So it's too bad because we could figure it, figure a way to solve all", "tokens": [2314, 11, 558, 30, 407, 309, 311, 886, 1578, 570, 321, 727, 2573, 309, 11, 2573, 257, 636, 281, 5039, 439], "temperature": 0.0, "avg_logprob": -0.21137711039760657, "compression_ratio": 1.6407407407407408, "no_speech_prob": 1.98806756088743e-05}, {"id": 108, "seek": 62592, "start": 641.56, "end": 647.4799999999999, "text": " these runtime errors. So back to this idea of strong dynamic type checking. How can we", "tokens": [613, 34474, 13603, 13, 407, 646, 281, 341, 1558, 295, 2068, 8546, 2010, 8568, 13, 1012, 393, 321], "temperature": 0.0, "avg_logprob": -0.21137711039760657, "compression_ratio": 1.6407407407407408, "no_speech_prob": 1.98806756088743e-05}, {"id": 109, "seek": 62592, "start": 647.4799999999999, "end": 653.5999999999999, "text": " do that? So I'm just taking to the definition of a strong binding between variable name", "tokens": [360, 300, 30, 407, 286, 478, 445, 1940, 281, 264, 7123, 295, 257, 2068, 17359, 1296, 7006, 1315], "temperature": 0.0, "avg_logprob": -0.21137711039760657, "compression_ratio": 1.6407407407407408, "no_speech_prob": 1.98806756088743e-05}, {"id": 110, "seek": 65360, "start": 653.6, "end": 658.5600000000001, "text": " and a time here. What if we could do this kind of strong binding but at runtime? What", "tokens": [293, 257, 565, 510, 13, 708, 498, 321, 727, 360, 341, 733, 295, 2068, 17359, 457, 412, 34474, 30, 708], "temperature": 0.0, "avg_logprob": -0.18958206176757814, "compression_ratio": 1.7413127413127414, "no_speech_prob": 3.121199188171886e-05}, {"id": 111, "seek": 65360, "start": 658.5600000000001, "end": 664.4, "text": " would it mean? First, it would mean that the type errors that we get would still be runtime", "tokens": [576, 309, 914, 30, 2386, 11, 309, 576, 914, 300, 264, 2010, 13603, 300, 321, 483, 576, 920, 312, 34474], "temperature": 0.0, "avg_logprob": -0.18958206176757814, "compression_ratio": 1.7413127413127414, "no_speech_prob": 3.121199188171886e-05}, {"id": 112, "seek": 65360, "start": 664.4, "end": 669.6, "text": " errors, right? Because it happens at runtime. But at least there will be more explicit and", "tokens": [13603, 11, 558, 30, 1436, 309, 2314, 412, 34474, 13, 583, 412, 1935, 456, 486, 312, 544, 13691, 293], "temperature": 0.0, "avg_logprob": -0.18958206176757814, "compression_ratio": 1.7413127413127414, "no_speech_prob": 3.121199188171886e-05}, {"id": 113, "seek": 65360, "start": 669.6, "end": 674.84, "text": " more catch early. That means that instead of having like undefined is not a function,", "tokens": [544, 3745, 2440, 13, 663, 1355, 300, 2602, 295, 1419, 411, 674, 5666, 2001, 307, 406, 257, 2445, 11], "temperature": 0.0, "avg_logprob": -0.18958206176757814, "compression_ratio": 1.7413127413127414, "no_speech_prob": 3.121199188171886e-05}, {"id": 114, "seek": 65360, "start": 674.84, "end": 679.1600000000001, "text": " you will get an error message like this variable has been from undefined and it was not supposed", "tokens": [291, 486, 483, 364, 6713, 3636, 411, 341, 7006, 575, 668, 490, 674, 5666, 2001, 293, 309, 390, 406, 3442], "temperature": 0.0, "avg_logprob": -0.18958206176757814, "compression_ratio": 1.7413127413127414, "no_speech_prob": 3.121199188171886e-05}, {"id": 115, "seek": 67916, "start": 679.16, "end": 684.12, "text": " to. So instead of pointing to the consequences, it points to the source of the problem. So", "tokens": [281, 13, 407, 2602, 295, 12166, 281, 264, 10098, 11, 309, 2793, 281, 264, 4009, 295, 264, 1154, 13, 407], "temperature": 0.0, "avg_logprob": -0.16239961285457433, "compression_ratio": 1.6755725190839694, "no_speech_prob": 4.222520874463953e-05}, {"id": 116, "seek": 67916, "start": 684.12, "end": 688.64, "text": " that helps a lot to reduce the investigation job that you have to do as a developer when", "tokens": [300, 3665, 257, 688, 281, 5407, 264, 9627, 1691, 300, 291, 362, 281, 360, 382, 257, 10754, 562], "temperature": 0.0, "avg_logprob": -0.16239961285457433, "compression_ratio": 1.6755725190839694, "no_speech_prob": 4.222520874463953e-05}, {"id": 117, "seek": 67916, "start": 688.64, "end": 695.0799999999999, "text": " doing debugging. The second thing is that this strong binding, it should not be just", "tokens": [884, 45592, 13, 440, 1150, 551, 307, 300, 341, 2068, 17359, 11, 309, 820, 406, 312, 445], "temperature": 0.0, "avg_logprob": -0.16239961285457433, "compression_ratio": 1.6755725190839694, "no_speech_prob": 4.222520874463953e-05}, {"id": 118, "seek": 67916, "start": 695.0799999999999, "end": 699.1999999999999, "text": " a one-time validation pass. I'm sure that there are plenty of JavaScript libraries that", "tokens": [257, 472, 12, 3766, 24071, 1320, 13, 286, 478, 988, 300, 456, 366, 7140, 295, 15778, 15148, 300], "temperature": 0.0, "avg_logprob": -0.16239961285457433, "compression_ratio": 1.6755725190839694, "no_speech_prob": 4.222520874463953e-05}, {"id": 119, "seek": 67916, "start": 699.1999999999999, "end": 704.92, "text": " do that. That is, you are throwing a bunch of data to it and it validates, saying true", "tokens": [360, 300, 13, 663, 307, 11, 291, 366, 10238, 257, 3840, 295, 1412, 281, 309, 293, 309, 7363, 1024, 11, 1566, 2074], "temperature": 0.0, "avg_logprob": -0.16239961285457433, "compression_ratio": 1.6755725190839694, "no_speech_prob": 4.222520874463953e-05}, {"id": 120, "seek": 70492, "start": 704.92, "end": 710.12, "text": " or false or just throwing a type error. But we need more than that. We actually need to", "tokens": [420, 7908, 420, 445, 10238, 257, 2010, 6713, 13, 583, 321, 643, 544, 813, 300, 13, 492, 767, 643, 281], "temperature": 0.0, "avg_logprob": -0.1602511451357887, "compression_ratio": 1.6716981132075472, "no_speech_prob": 2.6589743356453255e-05}, {"id": 121, "seek": 70492, "start": 710.12, "end": 716.12, "text": " have this binding. That means the type information needs to live along with your data. So it", "tokens": [362, 341, 17359, 13, 663, 1355, 264, 2010, 1589, 2203, 281, 1621, 2051, 365, 428, 1412, 13, 407, 309], "temperature": 0.0, "avg_logprob": -0.1602511451357887, "compression_ratio": 1.6716981132075472, "no_speech_prob": 2.6589743356453255e-05}, {"id": 122, "seek": 70492, "start": 716.12, "end": 721.0, "text": " should be validated, this type checking thing, on every reassignment or mutation of this", "tokens": [820, 312, 40693, 11, 341, 2010, 8568, 551, 11, 322, 633, 19486, 41134, 420, 27960, 295, 341], "temperature": 0.0, "avg_logprob": -0.1602511451357887, "compression_ratio": 1.6716981132075472, "no_speech_prob": 2.6589743356453255e-05}, {"id": 123, "seek": 70492, "start": 721.0, "end": 728.9599999999999, "text": " data. And finally, the goal of this is to get rid of maybe some silent errors because", "tokens": [1412, 13, 400, 2721, 11, 264, 3387, 295, 341, 307, 281, 483, 3973, 295, 1310, 512, 12784, 13603, 570], "temperature": 0.0, "avg_logprob": -0.1602511451357887, "compression_ratio": 1.6716981132075472, "no_speech_prob": 2.6589743356453255e-05}, {"id": 124, "seek": 70492, "start": 728.9599999999999, "end": 733.52, "text": " we have many mistakes in JavaScript that just are silent. That is, you are not noticing", "tokens": [321, 362, 867, 8038, 294, 15778, 300, 445, 366, 12784, 13, 663, 307, 11, 291, 366, 406, 21814], "temperature": 0.0, "avg_logprob": -0.1602511451357887, "compression_ratio": 1.6716981132075472, "no_speech_prob": 2.6589743356453255e-05}, {"id": 125, "seek": 73352, "start": 733.52, "end": 738.84, "text": " them until it's too late. And it can also make runtime errors maybe more predictable", "tokens": [552, 1826, 309, 311, 886, 3469, 13, 400, 309, 393, 611, 652, 34474, 13603, 1310, 544, 27737], "temperature": 0.0, "avg_logprob": -0.15553014418658087, "compression_ratio": 1.5482456140350878, "no_speech_prob": 4.824840652872808e-05}, {"id": 126, "seek": 73352, "start": 738.84, "end": 746.68, "text": " and so more manageable from a developer's point of view. So this is the main reasoning", "tokens": [293, 370, 544, 38798, 490, 257, 10754, 311, 935, 295, 1910, 13, 407, 341, 307, 264, 2135, 21577], "temperature": 0.0, "avg_logprob": -0.15553014418658087, "compression_ratio": 1.5482456140350878, "no_speech_prob": 4.824840652872808e-05}, {"id": 127, "seek": 73352, "start": 746.68, "end": 752.1999999999999, "text": " I have when I worked on the open source library that I want to present you today, which is", "tokens": [286, 362, 562, 286, 2732, 322, 264, 1269, 4009, 6405, 300, 286, 528, 281, 1974, 291, 965, 11, 597, 307], "temperature": 0.0, "avg_logprob": -0.15553014418658087, "compression_ratio": 1.5482456140350878, "no_speech_prob": 4.824840652872808e-05}, {"id": 128, "seek": 73352, "start": 752.1999999999999, "end": 757.3199999999999, "text": " object model. So definitely not a new project. Actually, I've been working on this for the", "tokens": [2657, 2316, 13, 407, 2138, 406, 257, 777, 1716, 13, 5135, 11, 286, 600, 668, 1364, 322, 341, 337, 264], "temperature": 0.0, "avg_logprob": -0.15553014418658087, "compression_ratio": 1.5482456140350878, "no_speech_prob": 4.824840652872808e-05}, {"id": 129, "seek": 75732, "start": 757.32, "end": 764.8000000000001, "text": " past eight years. So I'm at the version of 4.4.1. That means that I have written the", "tokens": [1791, 3180, 924, 13, 407, 286, 478, 412, 264, 3037, 295, 1017, 13, 19, 13, 16, 13, 663, 1355, 300, 286, 362, 3720, 264], "temperature": 0.0, "avg_logprob": -0.17371583452411726, "compression_ratio": 1.584070796460177, "no_speech_prob": 0.00014747001114301383}, {"id": 130, "seek": 75732, "start": 764.8000000000001, "end": 772.44, "text": " entire thing like four times now. It's obviously the hardest thing I had to code in my life,", "tokens": [2302, 551, 411, 1451, 1413, 586, 13, 467, 311, 2745, 264, 13158, 551, 286, 632, 281, 3089, 294, 452, 993, 11], "temperature": 0.0, "avg_logprob": -0.17371583452411726, "compression_ratio": 1.584070796460177, "no_speech_prob": 0.00014747001114301383}, {"id": 131, "seek": 75732, "start": 772.44, "end": 778.7600000000001, "text": " I would say. It's very complicated, but it works. So I'm glad. And I would say also that", "tokens": [286, 576, 584, 13, 467, 311, 588, 6179, 11, 457, 309, 1985, 13, 407, 286, 478, 5404, 13, 400, 286, 576, 584, 611, 300], "temperature": 0.0, "avg_logprob": -0.17371583452411726, "compression_ratio": 1.584070796460177, "no_speech_prob": 0.00014747001114301383}, {"id": 132, "seek": 75732, "start": 778.7600000000001, "end": 784.0, "text": " it is my most used for real open source project. By use for real, I mean that it is used in", "tokens": [309, 307, 452, 881, 1143, 337, 957, 1269, 4009, 1716, 13, 3146, 764, 337, 957, 11, 286, 914, 300, 309, 307, 1143, 294], "temperature": 0.0, "avg_logprob": -0.17371583452411726, "compression_ratio": 1.584070796460177, "no_speech_prob": 0.00014747001114301383}, {"id": 133, "seek": 78400, "start": 784.0, "end": 790.56, "text": " business projects. So I use it in my professional project. Other people are using it as a fundamental", "tokens": [1606, 4455, 13, 407, 286, 764, 309, 294, 452, 4843, 1716, 13, 5358, 561, 366, 1228, 309, 382, 257, 8088], "temperature": 0.0, "avg_logprob": -0.1775480869204499, "compression_ratio": 1.6026200873362446, "no_speech_prob": 0.00012117880396544933}, {"id": 134, "seek": 78400, "start": 790.56, "end": 794.92, "text": " component of their business project and I receive lots of positive feedback about this", "tokens": [6542, 295, 641, 1606, 1716, 293, 286, 4774, 3195, 295, 3353, 5824, 466, 341], "temperature": 0.0, "avg_logprob": -0.1775480869204499, "compression_ratio": 1.6026200873362446, "no_speech_prob": 0.00012117880396544933}, {"id": 135, "seek": 78400, "start": 794.92, "end": 803.76, "text": " library. You've got an example here. So what is this library doing? So how do you use it?", "tokens": [6405, 13, 509, 600, 658, 364, 1365, 510, 13, 407, 437, 307, 341, 6405, 884, 30, 407, 577, 360, 291, 764, 309, 30], "temperature": 0.0, "avg_logprob": -0.1775480869204499, "compression_ratio": 1.6026200873362446, "no_speech_prob": 0.00012117880396544933}, {"id": 136, "seek": 78400, "start": 803.76, "end": 809.04, "text": " It's pretty simple actually. The first thing you have to do is define the dynamic types,", "tokens": [467, 311, 1238, 2199, 767, 13, 440, 700, 551, 291, 362, 281, 360, 307, 6964, 264, 8546, 3467, 11], "temperature": 0.0, "avg_logprob": -0.1775480869204499, "compression_ratio": 1.6026200873362446, "no_speech_prob": 0.00012117880396544933}, {"id": 137, "seek": 80904, "start": 809.04, "end": 814.0799999999999, "text": " I would say, I would call them models. I explain the difference later. But basically, let's", "tokens": [286, 576, 584, 11, 286, 576, 818, 552, 5245, 13, 286, 2903, 264, 2649, 1780, 13, 583, 1936, 11, 718, 311], "temperature": 0.0, "avg_logprob": -0.2027426180632218, "compression_ratio": 1.6934306569343065, "no_speech_prob": 4.94337291456759e-05}, {"id": 138, "seek": 80904, "start": 814.0799999999999, "end": 819.28, "text": " say you are working on e-commerce application. You can declare an object model for the order,", "tokens": [584, 291, 366, 1364, 322, 308, 12, 26926, 3861, 13, 509, 393, 19710, 364, 2657, 2316, 337, 264, 1668, 11], "temperature": 0.0, "avg_logprob": -0.2027426180632218, "compression_ratio": 1.6934306569343065, "no_speech_prob": 4.94337291456759e-05}, {"id": 139, "seek": 80904, "start": 819.28, "end": 823.56, "text": " for example, the customer order, saying that you have a product which has a name property", "tokens": [337, 1365, 11, 264, 5474, 1668, 11, 1566, 300, 291, 362, 257, 1674, 597, 575, 257, 1315, 4707], "temperature": 0.0, "avg_logprob": -0.2027426180632218, "compression_ratio": 1.6934306569343065, "no_speech_prob": 4.94337291456759e-05}, {"id": 140, "seek": 80904, "start": 823.56, "end": 830.9599999999999, "text": " which is a string, a quantity that is a number, and also an order date. After I've been declared", "tokens": [597, 307, 257, 6798, 11, 257, 11275, 300, 307, 257, 1230, 11, 293, 611, 364, 1668, 4002, 13, 2381, 286, 600, 668, 15489], "temperature": 0.0, "avg_logprob": -0.2027426180632218, "compression_ratio": 1.6934306569343065, "no_speech_prob": 4.94337291456759e-05}, {"id": 141, "seek": 80904, "start": 830.9599999999999, "end": 836.04, "text": " this model, you can now bind it to some data. So this is where you have this strong binding", "tokens": [341, 2316, 11, 291, 393, 586, 14786, 309, 281, 512, 1412, 13, 407, 341, 307, 689, 291, 362, 341, 2068, 17359], "temperature": 0.0, "avg_logprob": -0.2027426180632218, "compression_ratio": 1.6934306569343065, "no_speech_prob": 4.94337291456759e-05}, {"id": 142, "seek": 83604, "start": 836.04, "end": 840.88, "text": " between the type and the variable. Here, I used the constructor pattern, so that means", "tokens": [1296, 264, 2010, 293, 264, 7006, 13, 1692, 11, 286, 1143, 264, 47479, 5102, 11, 370, 300, 1355], "temperature": 0.0, "avg_logprob": -0.1751487694897698, "compression_ratio": 1.7120622568093384, "no_speech_prob": 6.407353066606447e-05}, {"id": 143, "seek": 83604, "start": 840.88, "end": 846.64, "text": " you are calling new order. I think it's probably the most intuitive form of a binding for the", "tokens": [291, 366, 5141, 777, 1668, 13, 286, 519, 309, 311, 1391, 264, 881, 21769, 1254, 295, 257, 17359, 337, 264], "temperature": 0.0, "avg_logprob": -0.1751487694897698, "compression_ratio": 1.7120622568093384, "no_speech_prob": 6.407353066606447e-05}, {"id": 144, "seek": 83604, "start": 846.64, "end": 851.36, "text": " developer. And also, it helps to store the type information on the prototype level of", "tokens": [10754, 13, 400, 611, 11, 309, 3665, 281, 3531, 264, 2010, 1589, 322, 264, 19475, 1496, 295], "temperature": 0.0, "avg_logprob": -0.1751487694897698, "compression_ratio": 1.7120622568093384, "no_speech_prob": 6.407353066606447e-05}, {"id": 145, "seek": 83604, "start": 851.36, "end": 855.68, "text": " the object. So that's how I have this strong binding. We already have a binding between", "tokens": [264, 2657, 13, 407, 300, 311, 577, 286, 362, 341, 2068, 17359, 13, 492, 1217, 362, 257, 17359, 1296], "temperature": 0.0, "avg_logprob": -0.1751487694897698, "compression_ratio": 1.7120622568093384, "no_speech_prob": 6.407353066606447e-05}, {"id": 146, "seek": 83604, "start": 855.68, "end": 861.3199999999999, "text": " objects and prototypes in JavaScript. And after having done that, you get the myorder", "tokens": [6565, 293, 42197, 294, 15778, 13, 400, 934, 1419, 1096, 300, 11, 291, 483, 264, 452, 4687], "temperature": 0.0, "avg_logprob": -0.1751487694897698, "compression_ratio": 1.7120622568093384, "no_speech_prob": 6.407353066606447e-05}, {"id": 147, "seek": 86132, "start": 861.32, "end": 866.6400000000001, "text": " object, which you can manipulate just like you would do with a regular JavaScript object.", "tokens": [2657, 11, 597, 291, 393, 20459, 445, 411, 291, 576, 360, 365, 257, 3890, 15778, 2657, 13], "temperature": 0.0, "avg_logprob": -0.17158757004083372, "compression_ratio": 1.6715867158671587, "no_speech_prob": 0.00011403785174479708}, {"id": 148, "seek": 86132, "start": 866.6400000000001, "end": 872.5200000000001, "text": " But instead, when you are assigning, for example, quantity to Boolean instead of a number, you", "tokens": [583, 2602, 11, 562, 291, 366, 49602, 11, 337, 1365, 11, 11275, 281, 23351, 28499, 2602, 295, 257, 1230, 11, 291], "temperature": 0.0, "avg_logprob": -0.17158757004083372, "compression_ratio": 1.6715867158671587, "no_speech_prob": 0.00011403785174479708}, {"id": 149, "seek": 86132, "start": 872.5200000000001, "end": 877.96, "text": " will get a dynamic type error at runtime with an explicit message saying, expecting product", "tokens": [486, 483, 257, 8546, 2010, 6713, 412, 34474, 365, 364, 13691, 3636, 1566, 11, 9650, 1674], "temperature": 0.0, "avg_logprob": -0.17158757004083372, "compression_ratio": 1.6715867158671587, "no_speech_prob": 0.00011403785174479708}, {"id": 150, "seek": 86132, "start": 877.96, "end": 884.32, "text": " quantity to be number and got Boolean false instead. So because this happens, every time", "tokens": [11275, 281, 312, 1230, 293, 658, 23351, 28499, 7908, 2602, 13, 407, 570, 341, 2314, 11, 633, 565], "temperature": 0.0, "avg_logprob": -0.17158757004083372, "compression_ratio": 1.6715867158671587, "no_speech_prob": 0.00011403785174479708}, {"id": 151, "seek": 86132, "start": 884.32, "end": 889.6400000000001, "text": " you are doing any mutation on an object, it is really easy to quickly find some mistake", "tokens": [291, 366, 884, 604, 27960, 322, 364, 2657, 11, 309, 307, 534, 1858, 281, 2661, 915, 512, 6146], "temperature": 0.0, "avg_logprob": -0.17158757004083372, "compression_ratio": 1.6715867158671587, "no_speech_prob": 0.00011403785174479708}, {"id": 152, "seek": 88964, "start": 889.64, "end": 895.28, "text": " that you are doing as a developer and so improve the debugging experience.", "tokens": [300, 291, 366, 884, 382, 257, 10754, 293, 370, 3470, 264, 45592, 1752, 13], "temperature": 0.0, "avg_logprob": -0.17120825676690965, "compression_ratio": 1.554054054054054, "no_speech_prob": 3.2512634788872674e-05}, {"id": 153, "seek": 88964, "start": 895.28, "end": 902.36, "text": " So that's great, but how does it work? So let's start from a pretty basic example. Here,", "tokens": [407, 300, 311, 869, 11, 457, 577, 775, 309, 589, 30, 407, 718, 311, 722, 490, 257, 1238, 3875, 1365, 13, 1692, 11], "temperature": 0.0, "avg_logprob": -0.17120825676690965, "compression_ratio": 1.554054054054054, "no_speech_prob": 3.2512634788872674e-05}, {"id": 154, "seek": 88964, "start": 902.36, "end": 908.72, "text": " I have a class user having a constructor taking a name and an age. And if you want to validate", "tokens": [286, 362, 257, 1508, 4195, 1419, 257, 47479, 1940, 257, 1315, 293, 364, 3205, 13, 400, 498, 291, 528, 281, 29562], "temperature": 0.0, "avg_logprob": -0.17120825676690965, "compression_ratio": 1.554054054054054, "no_speech_prob": 3.2512634788872674e-05}, {"id": 155, "seek": 88964, "start": 908.72, "end": 913.68, "text": " the parameters that are passed to a function and not rely on static type annotation in", "tokens": [264, 9834, 300, 366, 4678, 281, 257, 2445, 293, 406, 10687, 322, 13437, 2010, 48654, 294], "temperature": 0.0, "avg_logprob": -0.17120825676690965, "compression_ratio": 1.554054054054054, "no_speech_prob": 3.2512634788872674e-05}, {"id": 156, "seek": 91368, "start": 913.68, "end": 921.3599999999999, "text": " JavaScript, that means that you would validate this data at runtime. What you could do is", "tokens": [15778, 11, 300, 1355, 300, 291, 576, 29562, 341, 1412, 412, 34474, 13, 708, 291, 727, 360, 307], "temperature": 0.0, "avg_logprob": -0.23756827197028596, "compression_ratio": 1.6943396226415095, "no_speech_prob": 6.904036126798019e-05}, {"id": 157, "seek": 91368, "start": 921.3599999999999, "end": 925.76, "text": " use these if conditions and check the type of these different variables and throw type", "tokens": [764, 613, 498, 4487, 293, 1520, 264, 2010, 295, 613, 819, 9102, 293, 3507, 2010], "temperature": 0.0, "avg_logprob": -0.23756827197028596, "compression_ratio": 1.6943396226415095, "no_speech_prob": 6.904036126798019e-05}, {"id": 158, "seek": 91368, "start": 925.76, "end": 932.3599999999999, "text": " errors like that. Pretty easy. The problem with that is that it only works in the constructor.", "tokens": [13603, 411, 300, 13, 10693, 1858, 13, 440, 1154, 365, 300, 307, 300, 309, 787, 1985, 294, 264, 47479, 13], "temperature": 0.0, "avg_logprob": -0.23756827197028596, "compression_ratio": 1.6943396226415095, "no_speech_prob": 6.904036126798019e-05}, {"id": 159, "seek": 91368, "start": 932.3599999999999, "end": 936.64, "text": " So maybe you could decide to declare some setters like set name, set age, and have this", "tokens": [407, 1310, 291, 727, 4536, 281, 19710, 512, 992, 1559, 411, 992, 1315, 11, 992, 3205, 11, 293, 362, 341], "temperature": 0.0, "avg_logprob": -0.23756827197028596, "compression_ratio": 1.6943396226415095, "no_speech_prob": 6.904036126798019e-05}, {"id": 160, "seek": 91368, "start": 936.64, "end": 941.64, "text": " validation process on every single attribute, but it's a bit tedious and we can do better", "tokens": [24071, 1399, 322, 633, 2167, 19667, 11, 457, 309, 311, 257, 857, 38284, 293, 321, 393, 360, 1101], "temperature": 0.0, "avg_logprob": -0.23756827197028596, "compression_ratio": 1.6943396226415095, "no_speech_prob": 6.904036126798019e-05}, {"id": 161, "seek": 94164, "start": 941.64, "end": 949.16, "text": " on that. So we can improve this by using a feature of JavaScript, which is the proxy.", "tokens": [322, 300, 13, 407, 321, 393, 3470, 341, 538, 1228, 257, 4111, 295, 15778, 11, 597, 307, 264, 29690, 13], "temperature": 0.0, "avg_logprob": -0.15599587258328212, "compression_ratio": 1.5973451327433628, "no_speech_prob": 4.2851606849581e-05}, {"id": 162, "seek": 94164, "start": 949.16, "end": 954.12, "text": " So I don't know if everyone knows about proxies. This is a feature of JavaScript that has been", "tokens": [407, 286, 500, 380, 458, 498, 1518, 3255, 466, 447, 87, 530, 13, 639, 307, 257, 4111, 295, 15778, 300, 575, 668], "temperature": 0.0, "avg_logprob": -0.15599587258328212, "compression_ratio": 1.5973451327433628, "no_speech_prob": 4.2851606849581e-05}, {"id": 163, "seek": 94164, "start": 954.12, "end": 962.24, "text": " introduced in 2015 as part of Xmascript 6. And proxies are actually really great features,", "tokens": [7268, 294, 7546, 382, 644, 295, 1783, 3799, 5944, 1386, 13, 400, 447, 87, 530, 366, 767, 534, 869, 4122, 11], "temperature": 0.0, "avg_logprob": -0.15599587258328212, "compression_ratio": 1.5973451327433628, "no_speech_prob": 4.2851606849581e-05}, {"id": 164, "seek": 94164, "start": 962.24, "end": 967.8, "text": " really powerful. The way proxy works is that they enable you to intercept some operations", "tokens": [534, 4005, 13, 440, 636, 29690, 1985, 307, 300, 436, 9528, 291, 281, 24700, 512, 7705], "temperature": 0.0, "avg_logprob": -0.15599587258328212, "compression_ratio": 1.5973451327433628, "no_speech_prob": 4.2851606849581e-05}, {"id": 165, "seek": 96780, "start": 967.8, "end": 972.9599999999999, "text": " that are done on some object and react to these operations. So in this example, I just", "tokens": [300, 366, 1096, 322, 512, 2657, 293, 4515, 281, 613, 7705, 13, 407, 294, 341, 1365, 11, 286, 445], "temperature": 0.0, "avg_logprob": -0.14812472697054402, "compression_ratio": 1.6214953271028036, "no_speech_prob": 6.239043432287872e-05}, {"id": 166, "seek": 96780, "start": 972.9599999999999, "end": 978.1999999999999, "text": " use the set trap of the proxy, which means that every time I am reassigning a property,", "tokens": [764, 264, 992, 11487, 295, 264, 29690, 11, 597, 1355, 300, 633, 565, 286, 669, 19486, 9676, 257, 4707, 11], "temperature": 0.0, "avg_logprob": -0.14812472697054402, "compression_ratio": 1.6214953271028036, "no_speech_prob": 6.239043432287872e-05}, {"id": 167, "seek": 96780, "start": 978.1999999999999, "end": 986.5999999999999, "text": " I can execute some custom logic. So I can move my if type of name, different string", "tokens": [286, 393, 14483, 512, 2375, 9952, 13, 407, 286, 393, 1286, 452, 498, 2010, 295, 1315, 11, 819, 6798], "temperature": 0.0, "avg_logprob": -0.14812472697054402, "compression_ratio": 1.6214953271028036, "no_speech_prob": 6.239043432287872e-05}, {"id": 168, "seek": 96780, "start": 986.5999999999999, "end": 995.9599999999999, "text": " and so on into the set trap and be able to detect the different issues. So that's great.", "tokens": [293, 370, 322, 666, 264, 992, 11487, 293, 312, 1075, 281, 5531, 264, 819, 2663, 13, 407, 300, 311, 869, 13], "temperature": 0.0, "avg_logprob": -0.14812472697054402, "compression_ratio": 1.6214953271028036, "no_speech_prob": 6.239043432287872e-05}, {"id": 169, "seek": 99596, "start": 995.96, "end": 1001.5600000000001, "text": " So it works both for the constructor and the future reassignment, the future mutations.", "tokens": [407, 309, 1985, 1293, 337, 264, 47479, 293, 264, 2027, 19486, 41134, 11, 264, 2027, 29243, 13], "temperature": 0.0, "avg_logprob": -0.12489582942082332, "compression_ratio": 1.782258064516129, "no_speech_prob": 7.042314973659813e-05}, {"id": 170, "seek": 99596, "start": 1001.5600000000001, "end": 1009.1600000000001, "text": " What we can do as a first step is try to make a generic function out of this. Like so.", "tokens": [708, 321, 393, 360, 382, 257, 700, 1823, 307, 853, 281, 652, 257, 19577, 2445, 484, 295, 341, 13, 1743, 370, 13], "temperature": 0.0, "avg_logprob": -0.12489582942082332, "compression_ratio": 1.782258064516129, "no_speech_prob": 7.042314973659813e-05}, {"id": 171, "seek": 99596, "start": 1009.1600000000001, "end": 1015.1600000000001, "text": " So now I just move the definition part on this generic type check function argument.", "tokens": [407, 586, 286, 445, 1286, 264, 7123, 644, 322, 341, 19577, 2010, 1520, 2445, 6770, 13], "temperature": 0.0, "avg_logprob": -0.12489582942082332, "compression_ratio": 1.782258064516129, "no_speech_prob": 7.042314973659813e-05}, {"id": 172, "seek": 99596, "start": 1015.1600000000001, "end": 1020.24, "text": " So the type check function takes two arguments. First is the data. Second one is the definition", "tokens": [407, 264, 2010, 1520, 2445, 2516, 732, 12869, 13, 2386, 307, 264, 1412, 13, 5736, 472, 307, 264, 7123], "temperature": 0.0, "avg_logprob": -0.12489582942082332, "compression_ratio": 1.782258064516129, "no_speech_prob": 7.042314973659813e-05}, {"id": 173, "seek": 99596, "start": 1020.24, "end": 1024.24, "text": " or the type if you prefer. So it makes clear that you have this strong binding between", "tokens": [420, 264, 2010, 498, 291, 4382, 13, 407, 309, 1669, 1850, 300, 291, 362, 341, 2068, 17359, 1296], "temperature": 0.0, "avg_logprob": -0.12489582942082332, "compression_ratio": 1.782258064516129, "no_speech_prob": 7.042314973659813e-05}, {"id": 174, "seek": 102424, "start": 1024.24, "end": 1029.0, "text": " objects and types. And as you can see, it is really easy to make a generic function to", "tokens": [6565, 293, 3467, 13, 400, 382, 291, 393, 536, 11, 309, 307, 534, 1858, 281, 652, 257, 19577, 2445, 281], "temperature": 0.0, "avg_logprob": -0.13804155915648073, "compression_ratio": 1.6255707762557077, "no_speech_prob": 5.43711576028727e-05}, {"id": 175, "seek": 102424, "start": 1029.0, "end": 1036.16, "text": " do this kind of stuff. So the type check function that you see here is a very basic version", "tokens": [360, 341, 733, 295, 1507, 13, 407, 264, 2010, 1520, 2445, 300, 291, 536, 510, 307, 257, 588, 3875, 3037], "temperature": 0.0, "avg_logprob": -0.13804155915648073, "compression_ratio": 1.6255707762557077, "no_speech_prob": 5.43711576028727e-05}, {"id": 176, "seek": 102424, "start": 1036.16, "end": 1040.76, "text": " of what object model is. Of course, the library is much more complicated than that. It can", "tokens": [295, 437, 2657, 2316, 307, 13, 2720, 1164, 11, 264, 6405, 307, 709, 544, 6179, 813, 300, 13, 467, 393], "temperature": 0.0, "avg_logprob": -0.13804155915648073, "compression_ratio": 1.6255707762557077, "no_speech_prob": 5.43711576028727e-05}, {"id": 177, "seek": 102424, "start": 1040.76, "end": 1046.48, "text": " cover many other use cases, but you get the idea with this example. So as you can see,", "tokens": [2060, 867, 661, 764, 3331, 11, 457, 291, 483, 264, 1558, 365, 341, 1365, 13, 407, 382, 291, 393, 536, 11], "temperature": 0.0, "avg_logprob": -0.13804155915648073, "compression_ratio": 1.6255707762557077, "no_speech_prob": 5.43711576028727e-05}, {"id": 178, "seek": 104648, "start": 1046.48, "end": 1055.72, "text": " it is really easy to reuse this type check function to apply to many different models.", "tokens": [309, 307, 534, 1858, 281, 26225, 341, 2010, 1520, 2445, 281, 3079, 281, 867, 819, 5245, 13], "temperature": 0.0, "avg_logprob": -0.17694094122909917, "compression_ratio": 1.584070796460177, "no_speech_prob": 2.5320307031506673e-05}, {"id": 179, "seek": 104648, "start": 1055.72, "end": 1061.16, "text": " So why did I call these models and not types? Actually, I wanted to find another word just", "tokens": [407, 983, 630, 286, 818, 613, 5245, 293, 406, 3467, 30, 5135, 11, 286, 1415, 281, 915, 1071, 1349, 445], "temperature": 0.0, "avg_logprob": -0.17694094122909917, "compression_ratio": 1.584070796460177, "no_speech_prob": 2.5320307031506673e-05}, {"id": 180, "seek": 104648, "start": 1061.16, "end": 1065.48, "text": " to make straight that there is a few differences from the types that you know from TypeScript,", "tokens": [281, 652, 2997, 300, 456, 307, 257, 1326, 7300, 490, 264, 3467, 300, 291, 458, 490, 15576, 14237, 11], "temperature": 0.0, "avg_logprob": -0.17694094122909917, "compression_ratio": 1.584070796460177, "no_speech_prob": 2.5320307031506673e-05}, {"id": 181, "seek": 104648, "start": 1065.48, "end": 1071.16, "text": " for example, because everything happens at runtime. This is runtime data validations.", "tokens": [337, 1365, 11, 570, 1203, 2314, 412, 34474, 13, 639, 307, 34474, 1412, 7363, 763, 13], "temperature": 0.0, "avg_logprob": -0.17694094122909917, "compression_ratio": 1.584070796460177, "no_speech_prob": 2.5320307031506673e-05}, {"id": 182, "seek": 107116, "start": 1071.16, "end": 1076.96, "text": " That means that models are more powerful than just the static types. For example, they can", "tokens": [663, 1355, 300, 5245, 366, 544, 4005, 813, 445, 264, 13437, 3467, 13, 1171, 1365, 11, 436, 393], "temperature": 0.0, "avg_logprob": -0.1464391331096272, "compression_ratio": 1.634703196347032, "no_speech_prob": 3.409161217859946e-05}, {"id": 183, "seek": 107116, "start": 1076.96, "end": 1082.3600000000001, "text": " not only check the types, but also the values. Let's say I have a short model which can have", "tokens": [406, 787, 1520, 264, 3467, 11, 457, 611, 264, 4190, 13, 961, 311, 584, 286, 362, 257, 2099, 2316, 597, 393, 362], "temperature": 0.0, "avg_logprob": -0.1464391331096272, "compression_ratio": 1.634703196347032, "no_speech_prob": 3.409161217859946e-05}, {"id": 184, "seek": 107116, "start": 1082.3600000000001, "end": 1088.96, "text": " a size which is either a number or a letter like MSL, Excel, and so on. I could decide", "tokens": [257, 2744, 597, 307, 2139, 257, 1230, 420, 257, 5063, 411, 7395, 43, 11, 19060, 11, 293, 370, 322, 13, 286, 727, 4536], "temperature": 0.0, "avg_logprob": -0.1464391331096272, "compression_ratio": 1.634703196347032, "no_speech_prob": 3.409161217859946e-05}, {"id": 185, "seek": 107116, "start": 1088.96, "end": 1094.64, "text": " to have this kind of type annotation to have both control that it is either a number or", "tokens": [281, 362, 341, 733, 295, 2010, 48654, 281, 362, 1293, 1969, 300, 309, 307, 2139, 257, 1230, 420], "temperature": 0.0, "avg_logprob": -0.1464391331096272, "compression_ratio": 1.634703196347032, "no_speech_prob": 3.409161217859946e-05}, {"id": 186, "seek": 109464, "start": 1094.64, "end": 1101.3200000000002, "text": " a letter M or a string matching this regular expression. I can also have some more complex", "tokens": [257, 5063, 376, 420, 257, 6798, 14324, 341, 3890, 6114, 13, 286, 393, 611, 362, 512, 544, 3997], "temperature": 0.0, "avg_logprob": -0.18465992351910016, "compression_ratio": 1.75390625, "no_speech_prob": 7.651902706129476e-05}, {"id": 187, "seek": 109464, "start": 1101.3200000000002, "end": 1107.0400000000002, "text": " assertions. For example, if I want integers in JavaScript, yeah, integers in JavaScript.", "tokens": [19810, 626, 13, 1171, 1365, 11, 498, 286, 528, 41674, 294, 15778, 11, 1338, 11, 41674, 294, 15778, 13], "temperature": 0.0, "avg_logprob": -0.18465992351910016, "compression_ratio": 1.75390625, "no_speech_prob": 7.651902706129476e-05}, {"id": 188, "seek": 109464, "start": 1107.0400000000002, "end": 1111.68, "text": " So it will be the number in the end because that's how JavaScript handles numbers. It's", "tokens": [407, 309, 486, 312, 264, 1230, 294, 264, 917, 570, 300, 311, 577, 15778, 18722, 3547, 13, 467, 311], "temperature": 0.0, "avg_logprob": -0.18465992351910016, "compression_ratio": 1.75390625, "no_speech_prob": 7.651902706129476e-05}, {"id": 189, "seek": 109464, "start": 1111.68, "end": 1118.3200000000002, "text": " double 64 bits. But I can add another assertion on this number model to say I need to check", "tokens": [3834, 12145, 9239, 13, 583, 286, 393, 909, 1071, 19810, 313, 322, 341, 1230, 2316, 281, 584, 286, 643, 281, 1520], "temperature": 0.0, "avg_logprob": -0.18465992351910016, "compression_ratio": 1.75390625, "no_speech_prob": 7.651902706129476e-05}, {"id": 190, "seek": 109464, "start": 1118.3200000000002, "end": 1122.96, "text": " that it is an integer. And maybe if I want it to be a positive integer, I can add another", "tokens": [300, 309, 307, 364, 24922, 13, 400, 1310, 498, 286, 528, 309, 281, 312, 257, 3353, 24922, 11, 286, 393, 909, 1071], "temperature": 0.0, "avg_logprob": -0.18465992351910016, "compression_ratio": 1.75390625, "no_speech_prob": 7.651902706129476e-05}, {"id": 191, "seek": 112296, "start": 1122.96, "end": 1127.48, "text": " assertion to make sure that it's above zero. So this is the kind of stuff of assertions", "tokens": [19810, 313, 281, 652, 988, 300, 309, 311, 3673, 4018, 13, 407, 341, 307, 264, 733, 295, 1507, 295, 19810, 626], "temperature": 0.0, "avg_logprob": -0.15731486063154917, "compression_ratio": 1.7730263157894737, "no_speech_prob": 5.8671386796049774e-05}, {"id": 192, "seek": 112296, "start": 1127.48, "end": 1131.96, "text": " that you can have. And again, every time you are manipulating this property, for example,", "tokens": [300, 291, 393, 362, 13, 400, 797, 11, 633, 565, 291, 366, 40805, 341, 4707, 11, 337, 1365, 11], "temperature": 0.0, "avg_logprob": -0.15731486063154917, "compression_ratio": 1.7730263157894737, "no_speech_prob": 5.8671386796049774e-05}, {"id": 193, "seek": 112296, "start": 1131.96, "end": 1138.28, "text": " the age of the user, it will check all these assertions automatically. And also the last", "tokens": [264, 3205, 295, 264, 4195, 11, 309, 486, 1520, 439, 613, 19810, 626, 6772, 13, 400, 611, 264, 1036], "temperature": 0.0, "avg_logprob": -0.15731486063154917, "compression_ratio": 1.7730263157894737, "no_speech_prob": 5.8671386796049774e-05}, {"id": 194, "seek": 112296, "start": 1138.28, "end": 1144.0, "text": " difference from models to types is that model validation can affect application logic. Because", "tokens": [2649, 490, 5245, 281, 3467, 307, 300, 2316, 24071, 393, 3345, 3861, 9952, 13, 1436], "temperature": 0.0, "avg_logprob": -0.15731486063154917, "compression_ratio": 1.7730263157894737, "no_speech_prob": 5.8671386796049774e-05}, {"id": 195, "seek": 112296, "start": 1144.0, "end": 1147.92, "text": " it's happening at runtime, that means you need to react to it and have some strategies", "tokens": [309, 311, 2737, 412, 34474, 11, 300, 1355, 291, 643, 281, 4515, 281, 309, 293, 362, 512, 9029], "temperature": 0.0, "avg_logprob": -0.15731486063154917, "compression_ratio": 1.7730263157894737, "no_speech_prob": 5.8671386796049774e-05}, {"id": 196, "seek": 112296, "start": 1147.92, "end": 1152.44, "text": " of how to handle these runtime errors. For example, if you got some error, some type error", "tokens": [295, 577, 281, 4813, 613, 34474, 13603, 13, 1171, 1365, 11, 498, 291, 658, 512, 6713, 11, 512, 2010, 6713], "temperature": 0.0, "avg_logprob": -0.15731486063154917, "compression_ratio": 1.7730263157894737, "no_speech_prob": 5.8671386796049774e-05}, {"id": 197, "seek": 115244, "start": 1152.44, "end": 1158.0800000000002, "text": " on your short model, maybe you just want to cancel the order so that you are making sure", "tokens": [322, 428, 2099, 2316, 11, 1310, 291, 445, 528, 281, 10373, 264, 1668, 370, 300, 291, 366, 1455, 988], "temperature": 0.0, "avg_logprob": -0.11597720781962077, "compression_ratio": 1.6531531531531531, "no_speech_prob": 5.1128088671248406e-05}, {"id": 198, "seek": 115244, "start": 1158.0800000000002, "end": 1166.28, "text": " that everything is happening correctly on your application. So these are the main differences.", "tokens": [300, 1203, 307, 2737, 8944, 322, 428, 3861, 13, 407, 613, 366, 264, 2135, 7300, 13], "temperature": 0.0, "avg_logprob": -0.11597720781962077, "compression_ratio": 1.6531531531531531, "no_speech_prob": 5.1128088671248406e-05}, {"id": 199, "seek": 115244, "start": 1166.28, "end": 1173.04, "text": " So to get a look at the pros and cons of this library, first the pros. You get descriptive", "tokens": [407, 281, 483, 257, 574, 412, 264, 6267, 293, 1014, 295, 341, 6405, 11, 700, 264, 6267, 13, 509, 483, 42585], "temperature": 0.0, "avg_logprob": -0.11597720781962077, "compression_ratio": 1.6531531531531531, "no_speech_prob": 5.1128088671248406e-05}, {"id": 200, "seek": 115244, "start": 1173.04, "end": 1179.04, "text": " error messages. They are pointing to the initial problem, not the consequences. So just that", "tokens": [6713, 7897, 13, 814, 366, 12166, 281, 264, 5883, 1154, 11, 406, 264, 10098, 13, 407, 445, 300], "temperature": 0.0, "avg_logprob": -0.11597720781962077, "compression_ratio": 1.6531531531531531, "no_speech_prob": 5.1128088671248406e-05}, {"id": 201, "seek": 117904, "start": 1179.04, "end": 1183.68, "text": " saves you a lot of time. And it means that you now have this kind of continuous data", "tokens": [19155, 291, 257, 688, 295, 565, 13, 400, 309, 1355, 300, 291, 586, 362, 341, 733, 295, 10957, 1412], "temperature": 0.0, "avg_logprob": -0.1809497911905505, "compression_ratio": 1.6245353159851301, "no_speech_prob": 0.00011524228466441855}, {"id": 202, "seek": 117904, "start": 1183.68, "end": 1188.48, "text": " validation as part of your development process. That means you get faster debugging and more", "tokens": [24071, 382, 644, 295, 428, 3250, 1399, 13, 663, 1355, 291, 483, 4663, 45592, 293, 544], "temperature": 0.0, "avg_logprob": -0.1809497911905505, "compression_ratio": 1.6245353159851301, "no_speech_prob": 0.00011524228466441855}, {"id": 203, "seek": 117904, "start": 1188.48, "end": 1196.28, "text": " reliable applications in the end. Regarding how you manage these runtime errors, because", "tokens": [12924, 5821, 294, 264, 917, 13, 35523, 577, 291, 3067, 613, 34474, 13603, 11, 570], "temperature": 0.0, "avg_logprob": -0.1809497911905505, "compression_ratio": 1.6245353159851301, "no_speech_prob": 0.00011524228466441855}, {"id": 204, "seek": 117904, "start": 1196.28, "end": 1200.28, "text": " you need to do something, right? Not only showing an error message, but maybe doing", "tokens": [291, 643, 281, 360, 746, 11, 558, 30, 1726, 787, 4099, 364, 6713, 3636, 11, 457, 1310, 884], "temperature": 0.0, "avg_logprob": -0.1809497911905505, "compression_ratio": 1.6245353159851301, "no_speech_prob": 0.00011524228466441855}, {"id": 205, "seek": 117904, "start": 1200.28, "end": 1205.2, "text": " some strategies that are planned. You can define some global or maybe per feature, per", "tokens": [512, 9029, 300, 366, 8589, 13, 509, 393, 6964, 512, 4338, 420, 1310, 680, 4111, 11, 680], "temperature": 0.0, "avg_logprob": -0.1809497911905505, "compression_ratio": 1.6245353159851301, "no_speech_prob": 0.00011524228466441855}, {"id": 206, "seek": 120520, "start": 1205.2, "end": 1210.44, "text": " model strategies about how to manage these errors. Maybe some errors can be easily manageable.", "tokens": [2316, 9029, 466, 577, 281, 3067, 613, 13603, 13, 2704, 512, 13603, 393, 312, 3612, 38798, 13], "temperature": 0.0, "avg_logprob": -0.15779890707873423, "compression_ratio": 1.6666666666666667, "no_speech_prob": 3.302571349195205e-05}, {"id": 207, "seek": 120520, "start": 1210.44, "end": 1215.76, "text": " For example, clean up an outdated cache. Or maybe some of them are more complex and then", "tokens": [1171, 1365, 11, 2541, 493, 364, 36313, 19459, 13, 1610, 1310, 512, 295, 552, 366, 544, 3997, 293, 550], "temperature": 0.0, "avg_logprob": -0.15779890707873423, "compression_ratio": 1.6666666666666667, "no_speech_prob": 3.302571349195205e-05}, {"id": 208, "seek": 120520, "start": 1215.76, "end": 1222.76, "text": " you need to maybe log them into a monitoring service. Some of the cons of this library,", "tokens": [291, 643, 281, 1310, 3565, 552, 666, 257, 11028, 2643, 13, 2188, 295, 264, 1014, 295, 341, 6405, 11], "temperature": 0.0, "avg_logprob": -0.15779890707873423, "compression_ratio": 1.6666666666666667, "no_speech_prob": 3.302571349195205e-05}, {"id": 209, "seek": 120520, "start": 1222.76, "end": 1226.8400000000001, "text": " one about performance, of course, because since it's happening at runtime, that means", "tokens": [472, 466, 3389, 11, 295, 1164, 11, 570, 1670, 309, 311, 2737, 412, 34474, 11, 300, 1355], "temperature": 0.0, "avg_logprob": -0.15779890707873423, "compression_ratio": 1.6666666666666667, "no_speech_prob": 3.302571349195205e-05}, {"id": 210, "seek": 120520, "start": 1226.8400000000001, "end": 1231.76, "text": " that it has a cost, a performance cost. Don't worry, it's not too much. But if you are doing", "tokens": [300, 309, 575, 257, 2063, 11, 257, 3389, 2063, 13, 1468, 380, 3292, 11, 309, 311, 406, 886, 709, 13, 583, 498, 291, 366, 884], "temperature": 0.0, "avg_logprob": -0.15779890707873423, "compression_ratio": 1.6666666666666667, "no_speech_prob": 3.302571349195205e-05}, {"id": 211, "seek": 123176, "start": 1231.76, "end": 1237.28, "text": " some heavy mutations, like more than 100 times per second, maybe you should avoid using dynamic", "tokens": [512, 4676, 29243, 11, 411, 544, 813, 2319, 1413, 680, 1150, 11, 1310, 291, 820, 5042, 1228, 8546], "temperature": 0.0, "avg_logprob": -0.16984193403642256, "compression_ratio": 1.5361702127659576, "no_speech_prob": 4.450839333003387e-05}, {"id": 212, "seek": 123176, "start": 1237.28, "end": 1241.52, "text": " type checking for this specific scenario. But most of the times you don't have to do", "tokens": [2010, 8568, 337, 341, 2685, 9005, 13, 583, 881, 295, 264, 1413, 291, 500, 380, 362, 281, 360], "temperature": 0.0, "avg_logprob": -0.16984193403642256, "compression_ratio": 1.5361702127659576, "no_speech_prob": 4.450839333003387e-05}, {"id": 213, "seek": 123176, "start": 1241.52, "end": 1248.04, "text": " this, so it's great. The second problem is that it relies on proxies. So you need support", "tokens": [341, 11, 370, 309, 311, 869, 13, 440, 1150, 1154, 307, 300, 309, 30910, 322, 447, 87, 530, 13, 407, 291, 643, 1406], "temperature": 0.0, "avg_logprob": -0.16984193403642256, "compression_ratio": 1.5361702127659576, "no_speech_prob": 4.450839333003387e-05}, {"id": 214, "seek": 123176, "start": 1248.04, "end": 1254.8, "text": " for it. Today, modern browsers are supporting ES6 proxies very well. But if you have older", "tokens": [337, 309, 13, 2692, 11, 4363, 36069, 366, 7231, 12564, 21, 447, 87, 530, 588, 731, 13, 583, 498, 291, 362, 4906], "temperature": 0.0, "avg_logprob": -0.16984193403642256, "compression_ratio": 1.5361702127659576, "no_speech_prob": 4.450839333003387e-05}, {"id": 215, "seek": 125480, "start": 1254.8, "end": 1263.72, "text": " browsers for some users, this can be an issue. So, which is better? Static type checking", "tokens": [36069, 337, 512, 5022, 11, 341, 393, 312, 364, 2734, 13, 407, 11, 597, 307, 1101, 30, 745, 2399, 2010, 8568], "temperature": 0.0, "avg_logprob": -0.17586898803710938, "compression_ratio": 1.6555555555555554, "no_speech_prob": 3.857877163682133e-05}, {"id": 216, "seek": 125480, "start": 1263.72, "end": 1268.56, "text": " or dynamic type checking? The correct answer is you should use both because they address", "tokens": [420, 8546, 2010, 8568, 30, 440, 3006, 1867, 307, 291, 820, 764, 1293, 570, 436, 2985], "temperature": 0.0, "avg_logprob": -0.17586898803710938, "compression_ratio": 1.6555555555555554, "no_speech_prob": 3.857877163682133e-05}, {"id": 217, "seek": 125480, "start": 1268.56, "end": 1274.08, "text": " different issues. Type script, we saw it. It's awesome. It improves a lot with the developer", "tokens": [819, 2663, 13, 15576, 5755, 11, 321, 1866, 309, 13, 467, 311, 3476, 13, 467, 24771, 257, 688, 365, 264, 10754], "temperature": 0.0, "avg_logprob": -0.17586898803710938, "compression_ratio": 1.6555555555555554, "no_speech_prob": 3.857877163682133e-05}, {"id": 218, "seek": 125480, "start": 1274.08, "end": 1278.6399999999999, "text": " experience. It makes you have a coding base which is reliable and makes sense, which is", "tokens": [1752, 13, 467, 1669, 291, 362, 257, 17720, 3096, 597, 307, 12924, 293, 1669, 2020, 11, 597, 307], "temperature": 0.0, "avg_logprob": -0.17586898803710938, "compression_ratio": 1.6555555555555554, "no_speech_prob": 3.857877163682133e-05}, {"id": 219, "seek": 125480, "start": 1278.6399999999999, "end": 1283.96, "text": " logical. But you should also take care of all the unpredictable parts that are happening", "tokens": [14978, 13, 583, 291, 820, 611, 747, 1127, 295, 439, 264, 31160, 3166, 300, 366, 2737], "temperature": 0.0, "avg_logprob": -0.17586898803710938, "compression_ratio": 1.6555555555555554, "no_speech_prob": 3.857877163682133e-05}, {"id": 220, "seek": 128396, "start": 1283.96, "end": 1289.1200000000001, "text": " at the runtime of your application. So my personal recommendation would be to stick", "tokens": [412, 264, 34474, 295, 428, 3861, 13, 407, 452, 2973, 11879, 576, 312, 281, 2897], "temperature": 0.0, "avg_logprob": -0.1535241961479187, "compression_ratio": 1.568888888888889, "no_speech_prob": 0.00011869343143189326}, {"id": 221, "seek": 128396, "start": 1289.1200000000001, "end": 1294.68, "text": " to TypeScript for the core application logic but also add this object model layer for every", "tokens": [281, 15576, 14237, 337, 264, 4965, 3861, 9952, 457, 611, 909, 341, 2657, 2316, 4583, 337, 633], "temperature": 0.0, "avg_logprob": -0.1535241961479187, "compression_ratio": 1.568888888888889, "no_speech_prob": 0.00011869343143189326}, {"id": 222, "seek": 128396, "start": 1294.68, "end": 1300.44, "text": " external interface that you have to deal with, like the server, user inputs, the local stores", "tokens": [8320, 9226, 300, 291, 362, 281, 2028, 365, 11, 411, 264, 7154, 11, 4195, 15743, 11, 264, 2654, 9512], "temperature": 0.0, "avg_logprob": -0.1535241961479187, "compression_ratio": 1.568888888888889, "no_speech_prob": 0.00011869343143189326}, {"id": 223, "seek": 128396, "start": 1300.44, "end": 1307.3600000000001, "text": " or the browser APIs. And this can lead to a more reliable application. That's all I", "tokens": [420, 264, 11185, 21445, 13, 400, 341, 393, 1477, 281, 257, 544, 12924, 3861, 13, 663, 311, 439, 286], "temperature": 0.0, "avg_logprob": -0.1535241961479187, "compression_ratio": 1.568888888888889, "no_speech_prob": 0.00011869343143189326}, {"id": 224, "seek": 130736, "start": 1307.36, "end": 1318.36, "text": " have for you today. So thank you for listening and I'm taking questions.", "tokens": [362, 337, 291, 965, 13, 407, 1309, 291, 337, 4764, 293, 286, 478, 1940, 1651, 13], "temperature": 0.0, "avg_logprob": -0.22511854625883557, "compression_ratio": 1.3418803418803418, "no_speech_prob": 0.002324427478015423}, {"id": 225, "seek": 130736, "start": 1318.36, "end": 1323.56, "text": " Thank you very much. So, we have time for questions. Who would like to ask the first", "tokens": [1044, 291, 588, 709, 13, 407, 11, 321, 362, 565, 337, 1651, 13, 2102, 576, 411, 281, 1029, 264, 700], "temperature": 0.0, "avg_logprob": -0.22511854625883557, "compression_ratio": 1.3418803418803418, "no_speech_prob": 0.002324427478015423}, {"id": 226, "seek": 132356, "start": 1323.56, "end": 1345.08, "text": " question? My question is, have you ever tried using this library with other libraries for", "tokens": [1168, 30, 1222, 1168, 307, 11, 362, 291, 1562, 3031, 1228, 341, 6405, 365, 661, 15148, 337], "temperature": 0.0, "avg_logprob": -0.2724989028204055, "compression_ratio": 1.1125, "no_speech_prob": 0.0024568962398916483}, {"id": 227, "seek": 134508, "start": 1345.08, "end": 1356.6, "text": " like, as it called, immutable data or for other validation? Have you tried using this library", "tokens": [411, 11, 382, 309, 1219, 11, 3397, 32148, 1412, 420, 337, 661, 24071, 30, 3560, 291, 3031, 1228, 341, 6405], "temperature": 0.0, "avg_logprob": -0.32425920287174964, "compression_ratio": 1.6140350877192982, "no_speech_prob": 0.0007853538263589144}, {"id": 228, "seek": 134508, "start": 1356.6, "end": 1364.9199999999998, "text": " with other libraries for dynamic checking like YAP or for immutable data like EMR or other", "tokens": [365, 661, 15148, 337, 8546, 8568, 411, 398, 4715, 420, 337, 3397, 32148, 1412, 411, 16237, 49, 420, 661], "temperature": 0.0, "avg_logprob": -0.32425920287174964, "compression_ratio": 1.6140350877192982, "no_speech_prob": 0.0007853538263589144}, {"id": 229, "seek": 134508, "start": 1364.9199999999998, "end": 1371.6799999999998, "text": " libraries? Yeah, so immutable should work fine. For other validation libraries, I mean it's", "tokens": [15148, 30, 865, 11, 370, 3397, 32148, 820, 589, 2489, 13, 1171, 661, 24071, 15148, 11, 286, 914, 309, 311], "temperature": 0.0, "avg_logprob": -0.32425920287174964, "compression_ratio": 1.6140350877192982, "no_speech_prob": 0.0007853538263589144}, {"id": 230, "seek": 137168, "start": 1371.68, "end": 1375.8, "text": " kind of the same thing, the same job, so maybe it doesn't work that well and doesn't make", "tokens": [733, 295, 264, 912, 551, 11, 264, 912, 1691, 11, 370, 1310, 309, 1177, 380, 589, 300, 731, 293, 1177, 380, 652], "temperature": 0.0, "avg_logprob": -0.2955824121252283, "compression_ratio": 1.50253807106599, "no_speech_prob": 0.0004280177236068994}, {"id": 231, "seek": 137168, "start": 1375.8, "end": 1380.72, "text": " really sense. But I think it should work perfectly with immutable data structures. So EMR should", "tokens": [534, 2020, 13, 583, 286, 519, 309, 820, 589, 6239, 365, 3397, 32148, 1412, 9227, 13, 407, 16237, 49, 820], "temperature": 0.0, "avg_logprob": -0.2955824121252283, "compression_ratio": 1.50253807106599, "no_speech_prob": 0.0004280177236068994}, {"id": 232, "seek": 137168, "start": 1380.72, "end": 1386.1200000000001, "text": " work fine. Yeah.", "tokens": [589, 2489, 13, 865, 13], "temperature": 0.0, "avg_logprob": -0.2955824121252283, "compression_ratio": 1.50253807106599, "no_speech_prob": 0.0004280177236068994}, {"id": 233, "seek": 137168, "start": 1386.1200000000001, "end": 1399.96, "text": " Hi. Do you think it would be possible to generate the object model, like definitions I don't", "tokens": [2421, 13, 1144, 291, 519, 309, 576, 312, 1944, 281, 8460, 264, 2657, 2316, 11, 411, 21988, 286, 500, 380], "temperature": 0.0, "avg_logprob": -0.2955824121252283, "compression_ratio": 1.50253807106599, "no_speech_prob": 0.0004280177236068994}, {"id": 234, "seek": 139996, "start": 1399.96, "end": 1402.4, "text": " know what's called, object models from TypeScript?", "tokens": [458, 437, 311, 1219, 11, 2657, 5245, 490, 15576, 14237, 30], "temperature": 0.0, "avg_logprob": -0.2303478640894736, "compression_ratio": 1.7422680412371134, "no_speech_prob": 0.00042183243203908205}, {"id": 235, "seek": 139996, "start": 1402.4, "end": 1407.32, "text": " Okay, that's a good question. So actually, you can do the opposite. That means that if", "tokens": [1033, 11, 300, 311, 257, 665, 1168, 13, 407, 767, 11, 291, 393, 360, 264, 6182, 13, 663, 1355, 300, 498], "temperature": 0.0, "avg_logprob": -0.2303478640894736, "compression_ratio": 1.7422680412371134, "no_speech_prob": 0.00042183243203908205}, {"id": 236, "seek": 139996, "start": 1407.32, "end": 1412.3600000000001, "text": " you are using models, it will generate TypeScript types for you. But because this is more than", "tokens": [291, 366, 1228, 5245, 11, 309, 486, 8460, 15576, 14237, 3467, 337, 291, 13, 583, 570, 341, 307, 544, 813], "temperature": 0.0, "avg_logprob": -0.2303478640894736, "compression_ratio": 1.7422680412371134, "no_speech_prob": 0.00042183243203908205}, {"id": 237, "seek": 139996, "start": 1412.3600000000001, "end": 1416.68, "text": " type checking and as you saw, this can affect application logic. That means that we cannot", "tokens": [2010, 8568, 293, 382, 291, 1866, 11, 341, 393, 3345, 3861, 9952, 13, 663, 1355, 300, 321, 2644], "temperature": 0.0, "avg_logprob": -0.2303478640894736, "compression_ratio": 1.7422680412371134, "no_speech_prob": 0.00042183243203908205}, {"id": 238, "seek": 139996, "start": 1416.68, "end": 1421.08, "text": " do this simple conversion. If you use it dynamic type checking, just like you would do with", "tokens": [360, 341, 2199, 14298, 13, 759, 291, 764, 309, 8546, 2010, 8568, 11, 445, 411, 291, 576, 360, 365], "temperature": 0.0, "avg_logprob": -0.2303478640894736, "compression_ratio": 1.7422680412371134, "no_speech_prob": 0.00042183243203908205}, {"id": 239, "seek": 139996, "start": 1421.08, "end": 1427.3600000000001, "text": " TypeScript types, you are just using like 10% of the potential of a library and it wouldn't", "tokens": [15576, 14237, 3467, 11, 291, 366, 445, 1228, 411, 1266, 4, 295, 264, 3995, 295, 257, 6405, 293, 309, 2759, 380], "temperature": 0.0, "avg_logprob": -0.2303478640894736, "compression_ratio": 1.7422680412371134, "no_speech_prob": 0.00042183243203908205}, {"id": 240, "seek": 142736, "start": 1427.36, "end": 1432.9599999999998, "text": " make any sense to me. So you should see the website maybe to have more example of that,", "tokens": [652, 604, 2020, 281, 385, 13, 407, 291, 820, 536, 264, 3144, 1310, 281, 362, 544, 1365, 295, 300, 11], "temperature": 0.0, "avg_logprob": -0.2600770592689514, "compression_ratio": 1.5350877192982457, "no_speech_prob": 0.0002666425134520978}, {"id": 241, "seek": 142736, "start": 1432.9599999999998, "end": 1435.7199999999998, "text": " but yeah, it's a bit more than that.", "tokens": [457, 1338, 11, 309, 311, 257, 857, 544, 813, 300, 13], "temperature": 0.0, "avg_logprob": -0.2600770592689514, "compression_ratio": 1.5350877192982457, "no_speech_prob": 0.0002666425134520978}, {"id": 242, "seek": 142736, "start": 1435.7199999999998, "end": 1441.3999999999999, "text": " Yeah, I see hands. You were there. The next speaker also, could you raise your hand or", "tokens": [865, 11, 286, 536, 2377, 13, 509, 645, 456, 13, 440, 958, 8145, 611, 11, 727, 291, 5300, 428, 1011, 420], "temperature": 0.0, "avg_logprob": -0.2600770592689514, "compression_ratio": 1.5350877192982457, "no_speech_prob": 0.0002666425134520978}, {"id": 243, "seek": 142736, "start": 1441.3999999999999, "end": 1446.6799999999998, "text": " stand up? Okay, so we'll have to contact them.", "tokens": [1463, 493, 30, 1033, 11, 370, 321, 603, 362, 281, 3385, 552, 13], "temperature": 0.0, "avg_logprob": -0.2600770592689514, "compression_ratio": 1.5350877192982457, "no_speech_prob": 0.0002666425134520978}, {"id": 244, "seek": 142736, "start": 1446.6799999999998, "end": 1456.08, "text": " A fantastic idea. Love the library. You mentioned rewriting it four times over eight years.", "tokens": [316, 5456, 1558, 13, 5956, 264, 6405, 13, 509, 2835, 319, 19868, 309, 1451, 1413, 670, 3180, 924, 13], "temperature": 0.0, "avg_logprob": -0.2600770592689514, "compression_ratio": 1.5350877192982457, "no_speech_prob": 0.0002666425134520978}, {"id": 245, "seek": 145608, "start": 1456.08, "end": 1459.32, "text": " How stable would you consider the project to be? How often do breaking changes to the", "tokens": [1012, 8351, 576, 291, 1949, 264, 1716, 281, 312, 30, 1012, 2049, 360, 7697, 2962, 281, 264], "temperature": 0.0, "avg_logprob": -0.24230205889829656, "compression_ratio": 1.5569620253164558, "no_speech_prob": 0.0006891269003972411}, {"id": 246, "seek": 145608, "start": 1459.32, "end": 1461.52, "text": " API get introduced, that kind of thing?", "tokens": [9362, 483, 7268, 11, 300, 733, 295, 551, 30], "temperature": 0.0, "avg_logprob": -0.24230205889829656, "compression_ratio": 1.5569620253164558, "no_speech_prob": 0.0006891269003972411}, {"id": 247, "seek": 145608, "start": 1461.52, "end": 1466.8799999999999, "text": " Yeah, it's true that I've written it four times, but the API never changed. That's one", "tokens": [865, 11, 309, 311, 2074, 300, 286, 600, 3720, 309, 1451, 1413, 11, 457, 264, 9362, 1128, 3105, 13, 663, 311, 472], "temperature": 0.0, "avg_logprob": -0.24230205889829656, "compression_ratio": 1.5569620253164558, "no_speech_prob": 0.0006891269003972411}, {"id": 248, "seek": 145608, "start": 1466.8799999999999, "end": 1471.24, "text": " thing. And also I use it for professional projects. So I would be embarrassed if I had", "tokens": [551, 13, 400, 611, 286, 764, 309, 337, 4843, 4455, 13, 407, 286, 576, 312, 16843, 498, 286, 632], "temperature": 0.0, "avg_logprob": -0.24230205889829656, "compression_ratio": 1.5569620253164558, "no_speech_prob": 0.0006891269003972411}, {"id": 249, "seek": 145608, "start": 1471.24, "end": 1478.6799999999998, "text": " to throw it away, all right? So it's quite stable for many years now.", "tokens": [281, 3507, 309, 1314, 11, 439, 558, 30, 407, 309, 311, 1596, 8351, 337, 867, 924, 586, 13], "temperature": 0.0, "avg_logprob": -0.24230205889829656, "compression_ratio": 1.5569620253164558, "no_speech_prob": 0.0006891269003972411}, {"id": 250, "seek": 147868, "start": 1478.68, "end": 1491.16, "text": " Hello. Thank you for the presentation. And I would like to know whether would you recommend", "tokens": [2425, 13, 1044, 291, 337, 264, 5860, 13, 400, 286, 576, 411, 281, 458, 1968, 576, 291, 2748], "temperature": 0.0, "avg_logprob": -0.235813502109412, "compression_ratio": 1.4516129032258065, "no_speech_prob": 0.0015572456177324057}, {"id": 251, "seek": 147868, "start": 1491.16, "end": 1499.76, "text": " using object model on projects that has not yet TypeScript, only JavaScript. Thank you.", "tokens": [1228, 2657, 2316, 322, 4455, 300, 575, 406, 1939, 15576, 14237, 11, 787, 15778, 13, 1044, 291, 13], "temperature": 0.0, "avg_logprob": -0.235813502109412, "compression_ratio": 1.4516129032258065, "no_speech_prob": 0.0015572456177324057}, {"id": 252, "seek": 147868, "start": 1499.76, "end": 1505.92, "text": " Yeah, I mean, that could be a thing. Although if you are into strong type checking, you're", "tokens": [865, 11, 286, 914, 11, 300, 727, 312, 257, 551, 13, 5780, 498, 291, 366, 666, 2068, 2010, 8568, 11, 291, 434], "temperature": 0.0, "avg_logprob": -0.235813502109412, "compression_ratio": 1.4516129032258065, "no_speech_prob": 0.0015572456177324057}, {"id": 253, "seek": 150592, "start": 1505.92, "end": 1511.48, "text": " probably already using TypeScript. If it's not the case, maybe it's fine. I don't know.", "tokens": [1391, 1217, 1228, 15576, 14237, 13, 759, 309, 311, 406, 264, 1389, 11, 1310, 309, 311, 2489, 13, 286, 500, 380, 458, 13], "temperature": 0.0, "avg_logprob": -0.2611267045996655, "compression_ratio": 1.5728155339805825, "no_speech_prob": 0.0019144430989399552}, {"id": 254, "seek": 150592, "start": 1511.48, "end": 1516.3600000000001, "text": " But yeah, it's totally possible. But most of people are using TypeScript.", "tokens": [583, 1338, 11, 309, 311, 3879, 1944, 13, 583, 881, 295, 561, 366, 1228, 15576, 14237, 13], "temperature": 0.0, "avg_logprob": -0.2611267045996655, "compression_ratio": 1.5728155339805825, "no_speech_prob": 0.0019144430989399552}, {"id": 255, "seek": 150592, "start": 1516.3600000000001, "end": 1521.24, "text": " Thank you very much. We have time still if you have time for another", "tokens": [1044, 291, 588, 709, 13, 492, 362, 565, 920, 498, 291, 362, 565, 337, 1071], "temperature": 0.0, "avg_logprob": -0.2611267045996655, "compression_ratio": 1.5728155339805825, "no_speech_prob": 0.0019144430989399552}, {"id": 256, "seek": 150592, "start": 1521.24, "end": 1529.52, "text": " question. Yeah, you'll have to be loud because people are moving. And if you sit down, please", "tokens": [1168, 13, 865, 11, 291, 603, 362, 281, 312, 6588, 570, 561, 366, 2684, 13, 400, 498, 291, 1394, 760, 11, 1767], "temperature": 0.0, "avg_logprob": -0.2611267045996655, "compression_ratio": 1.5728155339805825, "no_speech_prob": 0.0019144430989399552}, {"id": 257, "seek": 152952, "start": 1529.52, "end": 1538.4, "text": " make sure there is no space because the room is pretty full. Hi. Thank you for your project.", "tokens": [652, 988, 456, 307, 572, 1901, 570, 264, 1808, 307, 1238, 1577, 13, 2421, 13, 1044, 291, 337, 428, 1716, 13], "temperature": 0.0, "avg_logprob": -0.19297150034963348, "compression_ratio": 1.5906735751295338, "no_speech_prob": 0.0019467209931463003}, {"id": 258, "seek": 152952, "start": 1538.4, "end": 1547.08, "text": " So one other approach is using, for example, JSON schemas that then translates to types,", "tokens": [407, 472, 661, 3109, 307, 1228, 11, 337, 1365, 11, 31828, 22627, 296, 300, 550, 28468, 281, 3467, 11], "temperature": 0.0, "avg_logprob": -0.19297150034963348, "compression_ratio": 1.5906735751295338, "no_speech_prob": 0.0019467209931463003}, {"id": 259, "seek": 152952, "start": 1547.08, "end": 1549.2, "text": " should I speak? Sorry, I can't hear you.", "tokens": [820, 286, 1710, 30, 4919, 11, 286, 393, 380, 1568, 291, 13], "temperature": 0.0, "avg_logprob": -0.19297150034963348, "compression_ratio": 1.5906735751295338, "no_speech_prob": 0.0019467209931463003}, {"id": 260, "seek": 152952, "start": 1549.2, "end": 1557.0, "text": " One other approach is using JSON schemas, for example, on the validation side, let's", "tokens": [1485, 661, 3109, 307, 1228, 31828, 22627, 296, 11, 337, 1365, 11, 322, 264, 24071, 1252, 11, 718, 311], "temperature": 0.0, "avg_logprob": -0.19297150034963348, "compression_ratio": 1.5906735751295338, "no_speech_prob": 0.0019467209931463003}, {"id": 261, "seek": 155700, "start": 1557.0, "end": 1565.76, "text": " say, in a controller. And the JSON schema then compiles to the or deduces the TypeScript", "tokens": [584, 11, 294, 257, 10561, 13, 400, 264, 31828, 34078, 550, 715, 4680, 281, 264, 420, 4172, 84, 887, 264, 15576, 14237], "temperature": 0.0, "avg_logprob": -0.1674935560960036, "compression_ratio": 1.446236559139785, "no_speech_prob": 0.0023238768335431814}, {"id": 262, "seek": 155700, "start": 1565.76, "end": 1572.76, "text": " type that the schema defined. So that's one way, for example, to do validation and not", "tokens": [2010, 300, 264, 34078, 7642, 13, 407, 300, 311, 472, 636, 11, 337, 1365, 11, 281, 360, 24071, 293, 406], "temperature": 0.0, "avg_logprob": -0.1674935560960036, "compression_ratio": 1.446236559139785, "no_speech_prob": 0.0023238768335431814}, {"id": 263, "seek": 155700, "start": 1572.76, "end": 1580.68, "text": " have a runtime penalty besides doing the validation itself. Have you considered this approach", "tokens": [362, 257, 34474, 16263, 11868, 884, 264, 24071, 2564, 13, 3560, 291, 4888, 341, 3109], "temperature": 0.0, "avg_logprob": -0.1674935560960036, "compression_ratio": 1.446236559139785, "no_speech_prob": 0.0023238768335431814}, {"id": 264, "seek": 158068, "start": 1580.68, "end": 1588.3600000000001, "text": " for your use case? Yeah, so good question. So you can indeed use", "tokens": [337, 428, 764, 1389, 30, 865, 11, 370, 665, 1168, 13, 407, 291, 393, 6451, 764], "temperature": 0.0, "avg_logprob": -0.17796534583682105, "compression_ratio": 1.5951219512195123, "no_speech_prob": 0.0006548812962137163}, {"id": 265, "seek": 158068, "start": 1588.3600000000001, "end": 1595.6000000000001, "text": " this kind of type declaration. One problem is that, again, if you are sticking to what", "tokens": [341, 733, 295, 2010, 27606, 13, 1485, 1154, 307, 300, 11, 797, 11, 498, 291, 366, 13465, 281, 437], "temperature": 0.0, "avg_logprob": -0.17796534583682105, "compression_ratio": 1.5951219512195123, "no_speech_prob": 0.0006548812962137163}, {"id": 266, "seek": 158068, "start": 1595.6000000000001, "end": 1600.48, "text": " can TypeScript do with static type checking, you are only just using a fraction of what", "tokens": [393, 15576, 14237, 360, 365, 13437, 2010, 8568, 11, 291, 366, 787, 445, 1228, 257, 14135, 295, 437], "temperature": 0.0, "avg_logprob": -0.17796534583682105, "compression_ratio": 1.5951219512195123, "no_speech_prob": 0.0006548812962137163}, {"id": 267, "seek": 158068, "start": 1600.48, "end": 1605.88, "text": " can be done. For example, I told you about custom assertions. I told you about the fact", "tokens": [393, 312, 1096, 13, 1171, 1365, 11, 286, 1907, 291, 466, 2375, 19810, 626, 13, 286, 1907, 291, 466, 264, 1186], "temperature": 0.0, "avg_logprob": -0.17796534583682105, "compression_ratio": 1.5951219512195123, "no_speech_prob": 0.0006548812962137163}, {"id": 268, "seek": 160588, "start": 1605.88, "end": 1610.64, "text": " that you can check values along with the types. So all of these things would not match the", "tokens": [300, 291, 393, 1520, 4190, 2051, 365, 264, 3467, 13, 407, 439, 295, 613, 721, 576, 406, 2995, 264], "temperature": 0.0, "avg_logprob": -0.20226463006467235, "compression_ratio": 1.6056910569105691, "no_speech_prob": 0.00045909234904684126}, {"id": 269, "seek": 160588, "start": 1610.64, "end": 1614.96, "text": " model that you are describing with JSON. So that means we need to have another API for", "tokens": [2316, 300, 291, 366, 16141, 365, 31828, 13, 407, 300, 1355, 321, 643, 281, 362, 1071, 9362, 337], "temperature": 0.0, "avg_logprob": -0.20226463006467235, "compression_ratio": 1.6056910569105691, "no_speech_prob": 0.00045909234904684126}, {"id": 270, "seek": 160588, "start": 1614.96, "end": 1620.5200000000002, "text": " that, and that's why I have the on API for object model.", "tokens": [300, 11, 293, 300, 311, 983, 286, 362, 264, 322, 9362, 337, 2657, 2316, 13], "temperature": 0.0, "avg_logprob": -0.20226463006467235, "compression_ratio": 1.6056910569105691, "no_speech_prob": 0.00045909234904684126}, {"id": 271, "seek": 160588, "start": 1620.5200000000002, "end": 1625.5200000000002, "text": " Another last question, and then please, everybody, squeeze no empty seat. There are a lot of", "tokens": [3996, 1036, 1168, 11, 293, 550, 1767, 11, 2201, 11, 13578, 572, 6707, 6121, 13, 821, 366, 257, 688, 295], "temperature": 0.0, "avg_logprob": -0.20226463006467235, "compression_ratio": 1.6056910569105691, "no_speech_prob": 0.00045909234904684126}, {"id": 272, "seek": 160588, "start": 1625.5200000000002, "end": 1632.2, "text": " people still standing. So JavaScript is executed with V8, and there", "tokens": [561, 920, 4877, 13, 407, 15778, 307, 17577, 365, 691, 23, 11, 293, 456], "temperature": 0.0, "avg_logprob": -0.20226463006467235, "compression_ratio": 1.6056910569105691, "no_speech_prob": 0.00045909234904684126}, {"id": 273, "seek": 163220, "start": 1632.2, "end": 1639.3600000000001, "text": " is a lot of optimization underneath where you have an inlining going on optimization", "tokens": [307, 257, 688, 295, 19618, 7223, 689, 291, 362, 364, 294, 31079, 516, 322, 19618], "temperature": 0.0, "avg_logprob": -0.20039639848001886, "compression_ratio": 1.6210045662100456, "no_speech_prob": 0.0003013992100022733}, {"id": 274, "seek": 163220, "start": 1639.3600000000001, "end": 1645.32, "text": " of the function. When you use proxies, all of that is going to be gone immediately. Like", "tokens": [295, 264, 2445, 13, 1133, 291, 764, 447, 87, 530, 11, 439, 295, 300, 307, 516, 281, 312, 2780, 4258, 13, 1743], "temperature": 0.0, "avg_logprob": -0.20039639848001886, "compression_ratio": 1.6210045662100456, "no_speech_prob": 0.0003013992100022733}, {"id": 275, "seek": 163220, "start": 1645.32, "end": 1651.8, "text": " the performance set is not only when you set something and when you would normally go through", "tokens": [264, 3389, 992, 307, 406, 787, 562, 291, 992, 746, 293, 562, 291, 576, 5646, 352, 807], "temperature": 0.0, "avg_logprob": -0.20039639848001886, "compression_ratio": 1.6210045662100456, "no_speech_prob": 0.0003013992100022733}, {"id": 276, "seek": 163220, "start": 1651.8, "end": 1658.8400000000001, "text": " the proxy. It's not a hook. How's it called again? I forgot the name. Anyhow. Like when", "tokens": [264, 29690, 13, 467, 311, 406, 257, 6328, 13, 1012, 311, 309, 1219, 797, 30, 286, 5298, 264, 1315, 13, 2639, 4286, 13, 1743, 562], "temperature": 0.0, "avg_logprob": -0.20039639848001886, "compression_ratio": 1.6210045662100456, "no_speech_prob": 0.0003013992100022733}, {"id": 277, "seek": 165884, "start": 1658.84, "end": 1664.76, "text": " you have the trigger for it, but also for anything that relies upon that data from that", "tokens": [291, 362, 264, 7875, 337, 309, 11, 457, 611, 337, 1340, 300, 30910, 3564, 300, 1412, 490, 300], "temperature": 0.0, "avg_logprob": -0.19470627006443067, "compression_ratio": 1.5673469387755101, "no_speech_prob": 0.00021420250413939357}, {"id": 278, "seek": 165884, "start": 1664.76, "end": 1671.1599999999999, "text": " point on. So it's going to be a huge performance. I would definitely not recommend this pretty", "tokens": [935, 322, 13, 407, 309, 311, 516, 281, 312, 257, 2603, 3389, 13, 286, 576, 2138, 406, 2748, 341, 1238], "temperature": 0.0, "avg_logprob": -0.19470627006443067, "compression_ratio": 1.5673469387755101, "no_speech_prob": 0.00021420250413939357}, {"id": 279, "seek": 165884, "start": 1671.1599999999999, "end": 1672.1599999999999, "text": " much in production.", "tokens": [709, 294, 4265, 13], "temperature": 0.0, "avg_logprob": -0.19470627006443067, "compression_ratio": 1.5673469387755101, "no_speech_prob": 0.00021420250413939357}, {"id": 280, "seek": 165884, "start": 1672.1599999999999, "end": 1678.28, "text": " Yeah, I talked about the performance issues. One thing is that it's only useful for applying", "tokens": [865, 11, 286, 2825, 466, 264, 3389, 2663, 13, 1485, 551, 307, 300, 309, 311, 787, 4420, 337, 9275], "temperature": 0.0, "avg_logprob": -0.19470627006443067, "compression_ratio": 1.5673469387755101, "no_speech_prob": 0.00021420250413939357}, {"id": 281, "seek": 165884, "start": 1678.28, "end": 1684.6799999999998, "text": " to external interfaces like network request. You can just validate everything related to", "tokens": [281, 8320, 28416, 411, 3209, 5308, 13, 509, 393, 445, 29562, 1203, 4077, 281], "temperature": 0.0, "avg_logprob": -0.19470627006443067, "compression_ratio": 1.5673469387755101, "no_speech_prob": 0.00021420250413939357}, {"id": 282, "seek": 168468, "start": 1684.68, "end": 1688.92, "text": " one request. So the loss of time due to the network request compared to the loss of time", "tokens": [472, 5308, 13, 407, 264, 4470, 295, 565, 3462, 281, 264, 3209, 5308, 5347, 281, 264, 4470, 295, 565], "temperature": 0.0, "avg_logprob": -0.2292721470197042, "compression_ratio": 1.6226415094339623, "no_speech_prob": 0.0013202948030084372}, {"id": 283, "seek": 168468, "start": 1688.92, "end": 1694.3600000000001, "text": " due to proxy, it's acceptable in my opinion.", "tokens": [3462, 281, 29690, 11, 309, 311, 15513, 294, 452, 4800, 13], "temperature": 0.0, "avg_logprob": -0.2292721470197042, "compression_ratio": 1.6226415094339623, "no_speech_prob": 0.0013202948030084372}, {"id": 284, "seek": 168468, "start": 1694.3600000000001, "end": 1699.24, "text": " You can debate after. Don't worry. In his go.", "tokens": [509, 393, 7958, 934, 13, 1468, 380, 3292, 13, 682, 702, 352, 13], "temperature": 0.0, "avg_logprob": -0.2292721470197042, "compression_ratio": 1.6226415094339623, "no_speech_prob": 0.0013202948030084372}, {"id": 285, "seek": 168468, "start": 1699.24, "end": 1703.2, "text": " I mean, I run a bunch of assertions and it takes less than 10 milliseconds. So I don't", "tokens": [286, 914, 11, 286, 1190, 257, 3840, 295, 19810, 626, 293, 309, 2516, 1570, 813, 1266, 34184, 13, 407, 286, 500, 380], "temperature": 0.0, "avg_logprob": -0.2292721470197042, "compression_ratio": 1.6226415094339623, "no_speech_prob": 0.0013202948030084372}, {"id": 286, "seek": 168468, "start": 1703.2, "end": 1706.8400000000001, "text": " think the loss of time is so much trouble. Thank you very much.", "tokens": [519, 264, 4470, 295, 565, 307, 370, 709, 5253, 13, 1044, 291, 588, 709, 13], "temperature": 0.0, "avg_logprob": -0.2292721470197042, "compression_ratio": 1.6226415094339623, "no_speech_prob": 0.0013202948030084372}, {"id": 287, "seek": 170684, "start": 1706.84, "end": 1717.84, "text": " Thanks again.", "tokens": [50364, 2561, 797, 13, 50914], "temperature": 0.0, "avg_logprob": -0.7930433750152588, "compression_ratio": 0.6190476190476191, "no_speech_prob": 0.00016174551274161786}], "language": "en"}