{"text": " Hello. So PGSTATV is, from the name, I think you can understand that it's probably something to do with Postgres. And it is. It is a new Postgres extension and utility pair. So it comes with its own tool that you use outside of Postgres. It's minimalist. We'll get into that in a moment. It only does the thing it's supposed to do and it doesn't touch anything else in the system that it's not supposed to. And the purpose of PGSTATV is time series analysis and visualization. That's the vis part of Postgres internal statistics. That's the stat part. So Postgres internally keeps its own statistics. They are cumulative and dynamic statistics, right? So you get, like, number of buffers written is a cumulative statistic that keeps going up. You also have dynamic statistics like PGSTAT activity that tells you what's happening inside your Postgres server at that moment in time. So if you take snapshots of these statistics internally from within Postgres and you perform time series analysis on them, you can gain insights into how your server is behaving. So this utility that comes with PGSTATV's extension can produce visualizations for selected time ranges on the stored snapshots that are inside the database. So you can, for example, take snapshots of your server every 15 minutes during the course of the day and then analyze it over 24 hours to see what your peak times were and what was happening inside the server at that time. I wouldn't recommend taking snapshots more frequently than a minute. And it's easy to see why. You have too many snapshots. It's harder to see the bigger picture, maybe. So the reason for all of this is you want to track your performance over time and potentially you can perform troubleshooting on why your server is not behaving the way you expect it to and additional tuning. So minimalist, this is a tiny package that is based on the KISS and UNIX philosophies. So keep it simple and sweet, right? And the UNIX philosophy is that it comes with a tool that you can run as a normal Postgres command line tool like P SQL with the same parameters and everything else. And it allows you very simply to create snapshots of the statistics and visualize them. So it's modular. We'll get into the modules in a minute. It's minimal. It's the least amount of code I could write to make this thing work. And it's unobtrusive. So you can take snapshots without affecting any other activity running on your system. And I think that's very important for being able to monitor and analyze in production. So the components are Postgres extension, as we said, and the Python utility that retrieves the stored snapshots from the database and creates simple visualizations with them using matplotlib. The extension is written in plain SQL and PLPG SQL. So there's nothing to put in shared preload libraries. So this means that you can just type create extension and you can start using it without even restarting your server. So create extension PGstatvis is all you need to do. We're working on the packaging now to get it distributed through the PGDG repos, Postgres global development group repositories. And by extension, it will find its way into distributions hopefully soon. The way you install the utility is very simple. You just type pip install PGstatvis. If you tried that this morning, it wouldn't work, but I just uploaded the file so you can try it out. As I said, this is the last minute talk. It's very new. The code is pre-production quality. I would call it alpha code, but you can give it a try for yourself and offer any suggestions or fixes or tell me what I'm doing wrong. Now, the extension can be used by super users, but you don't have to. The only thing that the extension needs is PG monitor role privileges in order to be able to select from the internal Postgres statistics tables. And the usage is dead simple. And to take a snapshot, you just type from within a client, select PGstatvis.snapshot. Now, why is there no underscore there? It's because Postgres doesn't like us naming schemas PG underscore something. That's reserved only for core Postgres. So, extensions are not allowed to do it. So, what does the command line look like? You just pip install PGstatvis and you have the utility and the utility when you ask for help is a normal Postgres utility. You get your database selection, user name, host name part, et cetera, the same way you would connect with any Postgres client. And you've got modules like buff that shows you statistics on the background writer and buffers written to disk, cache hit ratio, checkpoint rate, connections, number of tuples, weights that it found in the server during the snapshot, wall generation and so on. And you can either run analyze which runs all of the modules at once and generates visualizations or you can run just one module if you're only interested in buffers. You can only say run buff. Most importantly, there's a capital D option that you can use to specify the date range in order to visualize only the time range you're interested in. So, like the last 24 hours only. And these are specified, of course, in ISO 8601 format. So, there's no ambiguity in how to type in dates. And it works something like this. You connect to database fof as user Postgres. You give it a date range and it just generates the snapshots and writes the visualizations as PNG to disk. And yes, it has a logo. So, it's complete. The visualizations look something like this. I apologize if the points are a bit too small for you to see. So, as we said, buffers written to disk is a line that keeps going up until stats reset. When the stats get reset, it starts from zero again. So, perhaps this is more useful. This is the buffer write rate in megabytes per second. So, you can see exactly how many buffers your Postgres server was writing to disk at any moment in time. And also, you can analyze what was happening because of the background writer. No? Yes. Thank you. So, you can see here that because this was a test I ran on my laptop with a script that was just inserting rows into the same table. The checkpoint line, which is the orange line, didn't do much because it wasn't scheduled activity taken care of by checkpoints. But you can see that back ends were doing most of the work. And also, you can see that the background writer, which is the green line, didn't get the chance to participate in all this buffer writing because from what we can see from the very low line, its limits were set to low for production. So, you can gain insights into the behavior of your Postgres server like this. Or you can look at connection versus status count. So, you can see how many connections you had coming into your server from clients, how many of them were active, how many of them were idle, how many were idle in transaction, and so on. But you can also see which users were taking up those connections. And I think that's really interesting when you have like an environment that's used by multiple applications so you can know which developers to blame when it all goes south. Weight events. As I was testing this on my laptop and was overflowing it with IO because I was inserting millions of rows into a table, I generated an IO data file read, sorry for the small letters, weight condition. And that was captured by the snapshot that was being taken every 10 seconds or so for this example. So, thank you for listening. The project is going to be live at github.com slash virus slash pgstatvis in a few moments. You can find me on master don. And what the hell? I'll do it right now. So, as we said, this is alpha quality code. Oh, I forgot to say that it doesn't do any scheduling or any maintenance or any partitioning of those internal tables where it keeps the snapshots. So you can delete them by hand. You can schedule the snapshots very easily with any tool you like, like cron or pgcron. But I didn't want to make this a dependency on the extension. So you can just configure it yourself. And I can just go to settings and make it public right now. Cool. Thank you. Any questions? No, okay. Thanks anyway. Thanks. Thanks for doing me.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 12.92, "text": " Hello. So PGSTATV is, from the name, I think you can understand that it's probably something", "tokens": [2425, 13, 407, 40975, 6840, 2218, 53, 307, 11, 490, 264, 1315, 11, 286, 519, 291, 393, 1223, 300, 309, 311, 1391, 746], "temperature": 0.0, "avg_logprob": -0.2604662821843074, "compression_ratio": 1.2877697841726619, "no_speech_prob": 0.2138439118862152}, {"id": 1, "seek": 0, "start": 12.92, "end": 20.88, "text": " to do with Postgres. And it is. It is a new Postgres extension and utility pair. So it", "tokens": [281, 360, 365, 10223, 45189, 13, 400, 309, 307, 13, 467, 307, 257, 777, 10223, 45189, 10320, 293, 14877, 6119, 13, 407, 309], "temperature": 0.0, "avg_logprob": -0.2604662821843074, "compression_ratio": 1.2877697841726619, "no_speech_prob": 0.2138439118862152}, {"id": 2, "seek": 2088, "start": 20.88, "end": 29.799999999999997, "text": " comes with its own tool that you use outside of Postgres. It's minimalist. We'll get into", "tokens": [1487, 365, 1080, 1065, 2290, 300, 291, 764, 2380, 295, 10223, 45189, 13, 467, 311, 50192, 13, 492, 603, 483, 666], "temperature": 0.0, "avg_logprob": -0.12090963787502712, "compression_ratio": 1.5056179775280898, "no_speech_prob": 1.2198735021229368e-05}, {"id": 3, "seek": 2088, "start": 29.799999999999997, "end": 37.08, "text": " that in a moment. It only does the thing it's supposed to do and it doesn't touch anything", "tokens": [300, 294, 257, 1623, 13, 467, 787, 775, 264, 551, 309, 311, 3442, 281, 360, 293, 309, 1177, 380, 2557, 1340], "temperature": 0.0, "avg_logprob": -0.12090963787502712, "compression_ratio": 1.5056179775280898, "no_speech_prob": 1.2198735021229368e-05}, {"id": 4, "seek": 2088, "start": 37.08, "end": 43.480000000000004, "text": " else in the system that it's not supposed to. And the purpose of PGSTATV is time series", "tokens": [1646, 294, 264, 1185, 300, 309, 311, 406, 3442, 281, 13, 400, 264, 4334, 295, 40975, 6840, 2218, 53, 307, 565, 2638], "temperature": 0.0, "avg_logprob": -0.12090963787502712, "compression_ratio": 1.5056179775280898, "no_speech_prob": 1.2198735021229368e-05}, {"id": 5, "seek": 4348, "start": 43.48, "end": 50.279999999999994, "text": " analysis and visualization. That's the vis part of Postgres internal statistics. That's", "tokens": [5215, 293, 25801, 13, 663, 311, 264, 1452, 644, 295, 10223, 45189, 6920, 12523, 13, 663, 311], "temperature": 0.0, "avg_logprob": -0.17345645779468974, "compression_ratio": 1.6477987421383649, "no_speech_prob": 1.6675863662385382e-05}, {"id": 6, "seek": 4348, "start": 50.279999999999994, "end": 62.0, "text": " the stat part. So Postgres internally keeps its own statistics. They are cumulative and", "tokens": [264, 2219, 644, 13, 407, 10223, 45189, 19501, 5965, 1080, 1065, 12523, 13, 814, 366, 38379, 293], "temperature": 0.0, "avg_logprob": -0.17345645779468974, "compression_ratio": 1.6477987421383649, "no_speech_prob": 1.6675863662385382e-05}, {"id": 7, "seek": 4348, "start": 62.0, "end": 68.19999999999999, "text": " dynamic statistics, right? So you get, like, number of buffers written is a cumulative", "tokens": [8546, 12523, 11, 558, 30, 407, 291, 483, 11, 411, 11, 1230, 295, 9204, 433, 3720, 307, 257, 38379], "temperature": 0.0, "avg_logprob": -0.17345645779468974, "compression_ratio": 1.6477987421383649, "no_speech_prob": 1.6675863662385382e-05}, {"id": 8, "seek": 6820, "start": 68.2, "end": 75.56, "text": " statistic that keeps going up. You also have dynamic statistics like PGSTAT activity that", "tokens": [29588, 300, 5965, 516, 493, 13, 509, 611, 362, 8546, 12523, 411, 40975, 6840, 2218, 5191, 300], "temperature": 0.0, "avg_logprob": -0.08886053562164306, "compression_ratio": 1.6061946902654867, "no_speech_prob": 3.1353647500509396e-06}, {"id": 9, "seek": 6820, "start": 75.56, "end": 81.48, "text": " tells you what's happening inside your Postgres server at that moment in time. So if you take", "tokens": [5112, 291, 437, 311, 2737, 1854, 428, 10223, 45189, 7154, 412, 300, 1623, 294, 565, 13, 407, 498, 291, 747], "temperature": 0.0, "avg_logprob": -0.08886053562164306, "compression_ratio": 1.6061946902654867, "no_speech_prob": 3.1353647500509396e-06}, {"id": 10, "seek": 6820, "start": 81.48, "end": 88.28, "text": " snapshots of these statistics internally from within Postgres and you perform time series", "tokens": [19206, 27495, 295, 613, 12523, 19501, 490, 1951, 10223, 45189, 293, 291, 2042, 565, 2638], "temperature": 0.0, "avg_logprob": -0.08886053562164306, "compression_ratio": 1.6061946902654867, "no_speech_prob": 3.1353647500509396e-06}, {"id": 11, "seek": 6820, "start": 88.28, "end": 95.88, "text": " analysis on them, you can gain insights into how your server is behaving. So this utility", "tokens": [5215, 322, 552, 11, 291, 393, 6052, 14310, 666, 577, 428, 7154, 307, 35263, 13, 407, 341, 14877], "temperature": 0.0, "avg_logprob": -0.08886053562164306, "compression_ratio": 1.6061946902654867, "no_speech_prob": 3.1353647500509396e-06}, {"id": 12, "seek": 9588, "start": 95.88, "end": 103.92, "text": " that comes with PGSTATV's extension can produce visualizations for selected time ranges on", "tokens": [300, 1487, 365, 40975, 6840, 2218, 53, 311, 10320, 393, 5258, 5056, 14455, 337, 8209, 565, 22526, 322], "temperature": 0.0, "avg_logprob": -0.08125267028808594, "compression_ratio": 1.5622317596566524, "no_speech_prob": 3.1177511118585244e-05}, {"id": 13, "seek": 9588, "start": 103.92, "end": 111.32, "text": " the stored snapshots that are inside the database. So you can, for example, take snapshots of", "tokens": [264, 12187, 19206, 27495, 300, 366, 1854, 264, 8149, 13, 407, 291, 393, 11, 337, 1365, 11, 747, 19206, 27495, 295], "temperature": 0.0, "avg_logprob": -0.08125267028808594, "compression_ratio": 1.5622317596566524, "no_speech_prob": 3.1177511118585244e-05}, {"id": 14, "seek": 9588, "start": 111.32, "end": 118.88, "text": " your server every 15 minutes during the course of the day and then analyze it over 24 hours", "tokens": [428, 7154, 633, 2119, 2077, 1830, 264, 1164, 295, 264, 786, 293, 550, 12477, 309, 670, 4022, 2496], "temperature": 0.0, "avg_logprob": -0.08125267028808594, "compression_ratio": 1.5622317596566524, "no_speech_prob": 3.1177511118585244e-05}, {"id": 15, "seek": 9588, "start": 118.88, "end": 125.03999999999999, "text": " to see what your peak times were and what was happening inside the server at that time.", "tokens": [281, 536, 437, 428, 10651, 1413, 645, 293, 437, 390, 2737, 1854, 264, 7154, 412, 300, 565, 13], "temperature": 0.0, "avg_logprob": -0.08125267028808594, "compression_ratio": 1.5622317596566524, "no_speech_prob": 3.1177511118585244e-05}, {"id": 16, "seek": 12504, "start": 125.04, "end": 133.4, "text": " I wouldn't recommend taking snapshots more frequently than a minute. And it's easy to", "tokens": [286, 2759, 380, 2748, 1940, 19206, 27495, 544, 10374, 813, 257, 3456, 13, 400, 309, 311, 1858, 281], "temperature": 0.0, "avg_logprob": -0.10029726143342903, "compression_ratio": 1.5580357142857142, "no_speech_prob": 1.4057394764677156e-05}, {"id": 17, "seek": 12504, "start": 133.4, "end": 141.20000000000002, "text": " see why. You have too many snapshots. It's harder to see the bigger picture, maybe. So", "tokens": [536, 983, 13, 509, 362, 886, 867, 19206, 27495, 13, 467, 311, 6081, 281, 536, 264, 3801, 3036, 11, 1310, 13, 407], "temperature": 0.0, "avg_logprob": -0.10029726143342903, "compression_ratio": 1.5580357142857142, "no_speech_prob": 1.4057394764677156e-05}, {"id": 18, "seek": 12504, "start": 141.20000000000002, "end": 148.36, "text": " the reason for all of this is you want to track your performance over time and potentially", "tokens": [264, 1778, 337, 439, 295, 341, 307, 291, 528, 281, 2837, 428, 3389, 670, 565, 293, 7263], "temperature": 0.0, "avg_logprob": -0.10029726143342903, "compression_ratio": 1.5580357142857142, "no_speech_prob": 1.4057394764677156e-05}, {"id": 19, "seek": 12504, "start": 148.36, "end": 153.08, "text": " you can perform troubleshooting on why your server is not behaving the way you expect", "tokens": [291, 393, 2042, 15379, 47011, 322, 983, 428, 7154, 307, 406, 35263, 264, 636, 291, 2066], "temperature": 0.0, "avg_logprob": -0.10029726143342903, "compression_ratio": 1.5580357142857142, "no_speech_prob": 1.4057394764677156e-05}, {"id": 20, "seek": 15308, "start": 153.08, "end": 165.48000000000002, "text": " it to and additional tuning. So minimalist, this is a tiny package that is based on the", "tokens": [309, 281, 293, 4497, 15164, 13, 407, 50192, 11, 341, 307, 257, 5870, 7372, 300, 307, 2361, 322, 264], "temperature": 0.0, "avg_logprob": -0.12005407669964958, "compression_ratio": 1.4942528735632183, "no_speech_prob": 3.6448105674935505e-05}, {"id": 21, "seek": 15308, "start": 165.48000000000002, "end": 175.88000000000002, "text": " KISS and UNIX philosophies. So keep it simple and sweet, right? And the UNIX philosophy", "tokens": [591, 30090, 293, 8229, 21124, 14529, 530, 13, 407, 1066, 309, 2199, 293, 3844, 11, 558, 30, 400, 264, 8229, 21124, 10675], "temperature": 0.0, "avg_logprob": -0.12005407669964958, "compression_ratio": 1.4942528735632183, "no_speech_prob": 3.6448105674935505e-05}, {"id": 22, "seek": 15308, "start": 175.88000000000002, "end": 181.20000000000002, "text": " is that it comes with a tool that you can run as a normal Postgres command line tool", "tokens": [307, 300, 309, 1487, 365, 257, 2290, 300, 291, 393, 1190, 382, 257, 2710, 10223, 45189, 5622, 1622, 2290], "temperature": 0.0, "avg_logprob": -0.12005407669964958, "compression_ratio": 1.4942528735632183, "no_speech_prob": 3.6448105674935505e-05}, {"id": 23, "seek": 18120, "start": 181.2, "end": 189.0, "text": " like P SQL with the same parameters and everything else. And it allows you very simply to create", "tokens": [411, 430, 19200, 365, 264, 912, 9834, 293, 1203, 1646, 13, 400, 309, 4045, 291, 588, 2935, 281, 1884], "temperature": 0.0, "avg_logprob": -0.1161343630622415, "compression_ratio": 1.4623655913978495, "no_speech_prob": 6.799228140152991e-05}, {"id": 24, "seek": 18120, "start": 189.0, "end": 196.28, "text": " snapshots of the statistics and visualize them. So it's modular. We'll get into the modules", "tokens": [19206, 27495, 295, 264, 12523, 293, 23273, 552, 13, 407, 309, 311, 31111, 13, 492, 603, 483, 666, 264, 16679], "temperature": 0.0, "avg_logprob": -0.1161343630622415, "compression_ratio": 1.4623655913978495, "no_speech_prob": 6.799228140152991e-05}, {"id": 25, "seek": 18120, "start": 196.28, "end": 203.16, "text": " in a minute. It's minimal. It's the least amount of code I could write to make this", "tokens": [294, 257, 3456, 13, 467, 311, 13206, 13, 467, 311, 264, 1935, 2372, 295, 3089, 286, 727, 2464, 281, 652, 341], "temperature": 0.0, "avg_logprob": -0.1161343630622415, "compression_ratio": 1.4623655913978495, "no_speech_prob": 6.799228140152991e-05}, {"id": 26, "seek": 20316, "start": 203.16, "end": 211.16, "text": " thing work. And it's unobtrusive. So you can take snapshots without affecting any other", "tokens": [551, 589, 13, 400, 309, 311, 517, 996, 6903, 23053, 13, 407, 291, 393, 747, 19206, 27495, 1553, 17476, 604, 661], "temperature": 0.0, "avg_logprob": -0.09151089051190545, "compression_ratio": 1.5564853556485356, "no_speech_prob": 2.388581560808234e-05}, {"id": 27, "seek": 20316, "start": 211.16, "end": 216.76, "text": " activity running on your system. And I think that's very important for being able to monitor", "tokens": [5191, 2614, 322, 428, 1185, 13, 400, 286, 519, 300, 311, 588, 1021, 337, 885, 1075, 281, 6002], "temperature": 0.0, "avg_logprob": -0.09151089051190545, "compression_ratio": 1.5564853556485356, "no_speech_prob": 2.388581560808234e-05}, {"id": 28, "seek": 20316, "start": 216.76, "end": 223.44, "text": " and analyze in production. So the components are Postgres extension, as we said, and the", "tokens": [293, 12477, 294, 4265, 13, 407, 264, 6677, 366, 10223, 45189, 10320, 11, 382, 321, 848, 11, 293, 264], "temperature": 0.0, "avg_logprob": -0.09151089051190545, "compression_ratio": 1.5564853556485356, "no_speech_prob": 2.388581560808234e-05}, {"id": 29, "seek": 20316, "start": 223.44, "end": 231.12, "text": " Python utility that retrieves the stored snapshots from the database and creates simple visualizations", "tokens": [15329, 14877, 300, 19817, 977, 264, 12187, 19206, 27495, 490, 264, 8149, 293, 7829, 2199, 5056, 14455], "temperature": 0.0, "avg_logprob": -0.09151089051190545, "compression_ratio": 1.5564853556485356, "no_speech_prob": 2.388581560808234e-05}, {"id": 30, "seek": 23112, "start": 231.12, "end": 241.20000000000002, "text": " with them using matplotlib. The extension is written in plain SQL and PLPG SQL. So there's", "tokens": [365, 552, 1228, 3803, 564, 310, 38270, 13, 440, 10320, 307, 3720, 294, 11121, 19200, 293, 6999, 47, 38, 19200, 13, 407, 456, 311], "temperature": 0.0, "avg_logprob": -0.12647776817207906, "compression_ratio": 1.5722543352601157, "no_speech_prob": 2.4656816094648093e-05}, {"id": 31, "seek": 23112, "start": 241.20000000000002, "end": 246.4, "text": " nothing to put in shared preload libraries. So this means that you can just type create", "tokens": [1825, 281, 829, 294, 5507, 659, 2907, 15148, 13, 407, 341, 1355, 300, 291, 393, 445, 2010, 1884], "temperature": 0.0, "avg_logprob": -0.12647776817207906, "compression_ratio": 1.5722543352601157, "no_speech_prob": 2.4656816094648093e-05}, {"id": 32, "seek": 23112, "start": 246.4, "end": 253.8, "text": " extension and you can start using it without even restarting your server. So create extension", "tokens": [10320, 293, 291, 393, 722, 1228, 309, 1553, 754, 21022, 278, 428, 7154, 13, 407, 1884, 10320], "temperature": 0.0, "avg_logprob": -0.12647776817207906, "compression_ratio": 1.5722543352601157, "no_speech_prob": 2.4656816094648093e-05}, {"id": 33, "seek": 25380, "start": 253.8, "end": 261.32, "text": " PGstatvis is all you need to do. We're working on the packaging now to get it distributed", "tokens": [40975, 19435, 4938, 307, 439, 291, 643, 281, 360, 13, 492, 434, 1364, 322, 264, 16836, 586, 281, 483, 309, 12631], "temperature": 0.0, "avg_logprob": -0.15852762858072916, "compression_ratio": 1.5230125523012552, "no_speech_prob": 2.8358794224914163e-05}, {"id": 34, "seek": 25380, "start": 261.32, "end": 270.2, "text": " through the PGDG repos, Postgres global development group repositories. And by extension, it will", "tokens": [807, 264, 40975, 35, 38, 1085, 329, 11, 10223, 45189, 4338, 3250, 1594, 22283, 2083, 13, 400, 538, 10320, 11, 309, 486], "temperature": 0.0, "avg_logprob": -0.15852762858072916, "compression_ratio": 1.5230125523012552, "no_speech_prob": 2.8358794224914163e-05}, {"id": 35, "seek": 25380, "start": 270.2, "end": 276.16, "text": " find its way into distributions hopefully soon. The way you install the utility is very", "tokens": [915, 1080, 636, 666, 37870, 4696, 2321, 13, 440, 636, 291, 3625, 264, 14877, 307, 588], "temperature": 0.0, "avg_logprob": -0.15852762858072916, "compression_ratio": 1.5230125523012552, "no_speech_prob": 2.8358794224914163e-05}, {"id": 36, "seek": 25380, "start": 276.16, "end": 281.64, "text": " simple. You just type pip install PGstatvis. If you tried that this morning, it wouldn't", "tokens": [2199, 13, 509, 445, 2010, 8489, 3625, 40975, 19435, 4938, 13, 759, 291, 3031, 300, 341, 2446, 11, 309, 2759, 380], "temperature": 0.0, "avg_logprob": -0.15852762858072916, "compression_ratio": 1.5230125523012552, "no_speech_prob": 2.8358794224914163e-05}, {"id": 37, "seek": 28164, "start": 281.64, "end": 287.03999999999996, "text": " work, but I just uploaded the file so you can try it out. As I said, this is the last", "tokens": [589, 11, 457, 286, 445, 17135, 264, 3991, 370, 291, 393, 853, 309, 484, 13, 1018, 286, 848, 11, 341, 307, 264, 1036], "temperature": 0.0, "avg_logprob": -0.10048033974387428, "compression_ratio": 1.5299145299145298, "no_speech_prob": 2.246708572783973e-05}, {"id": 38, "seek": 28164, "start": 287.03999999999996, "end": 294.36, "text": " minute talk. It's very new. The code is pre-production quality. I would call it alpha code, but", "tokens": [3456, 751, 13, 467, 311, 588, 777, 13, 440, 3089, 307, 659, 12, 40827, 3125, 13, 286, 576, 818, 309, 8961, 3089, 11, 457], "temperature": 0.0, "avg_logprob": -0.10048033974387428, "compression_ratio": 1.5299145299145298, "no_speech_prob": 2.246708572783973e-05}, {"id": 39, "seek": 28164, "start": 294.36, "end": 302.64, "text": " you can give it a try for yourself and offer any suggestions or fixes or tell me what I'm", "tokens": [291, 393, 976, 309, 257, 853, 337, 1803, 293, 2626, 604, 13396, 420, 32539, 420, 980, 385, 437, 286, 478], "temperature": 0.0, "avg_logprob": -0.10048033974387428, "compression_ratio": 1.5299145299145298, "no_speech_prob": 2.246708572783973e-05}, {"id": 40, "seek": 28164, "start": 302.64, "end": 310.08, "text": " doing wrong. Now, the extension can be used by super users, but you don't have to. The", "tokens": [884, 2085, 13, 823, 11, 264, 10320, 393, 312, 1143, 538, 1687, 5022, 11, 457, 291, 500, 380, 362, 281, 13, 440], "temperature": 0.0, "avg_logprob": -0.10048033974387428, "compression_ratio": 1.5299145299145298, "no_speech_prob": 2.246708572783973e-05}, {"id": 41, "seek": 31008, "start": 310.08, "end": 314.44, "text": " only thing that the extension needs is PG monitor role privileges in order to be able", "tokens": [787, 551, 300, 264, 10320, 2203, 307, 40975, 6002, 3090, 32588, 294, 1668, 281, 312, 1075], "temperature": 0.0, "avg_logprob": -0.12448833205483177, "compression_ratio": 1.5550660792951543, "no_speech_prob": 2.428868720016908e-05}, {"id": 42, "seek": 31008, "start": 314.44, "end": 322.28, "text": " to select from the internal Postgres statistics tables. And the usage is dead simple. And", "tokens": [281, 3048, 490, 264, 6920, 10223, 45189, 12523, 8020, 13, 400, 264, 14924, 307, 3116, 2199, 13, 400], "temperature": 0.0, "avg_logprob": -0.12448833205483177, "compression_ratio": 1.5550660792951543, "no_speech_prob": 2.428868720016908e-05}, {"id": 43, "seek": 31008, "start": 322.28, "end": 329.76, "text": " to take a snapshot, you just type from within a client, select PGstatvis.snapshot. Now, why", "tokens": [281, 747, 257, 30163, 11, 291, 445, 2010, 490, 1951, 257, 6423, 11, 3048, 40975, 19435, 4938, 13, 18860, 2382, 12194, 13, 823, 11, 983], "temperature": 0.0, "avg_logprob": -0.12448833205483177, "compression_ratio": 1.5550660792951543, "no_speech_prob": 2.428868720016908e-05}, {"id": 44, "seek": 31008, "start": 329.76, "end": 336.36, "text": " is there no underscore there? It's because Postgres doesn't like us naming schemas PG", "tokens": [307, 456, 572, 37556, 456, 30, 467, 311, 570, 10223, 45189, 1177, 380, 411, 505, 25290, 22627, 296, 40975], "temperature": 0.0, "avg_logprob": -0.12448833205483177, "compression_ratio": 1.5550660792951543, "no_speech_prob": 2.428868720016908e-05}, {"id": 45, "seek": 33636, "start": 336.36, "end": 340.84000000000003, "text": " underscore something. That's reserved only for core Postgres. So, extensions are not", "tokens": [37556, 746, 13, 663, 311, 24819, 787, 337, 4965, 10223, 45189, 13, 407, 11, 25129, 366, 406], "temperature": 0.0, "avg_logprob": -0.1449321253915851, "compression_ratio": 1.5822222222222222, "no_speech_prob": 1.1656045899144374e-05}, {"id": 46, "seek": 33636, "start": 340.84000000000003, "end": 348.96000000000004, "text": " allowed to do it. So, what does the command line look like? You just pip install PGstatvis", "tokens": [4350, 281, 360, 309, 13, 407, 11, 437, 775, 264, 5622, 1622, 574, 411, 30, 509, 445, 8489, 3625, 40975, 19435, 4938], "temperature": 0.0, "avg_logprob": -0.1449321253915851, "compression_ratio": 1.5822222222222222, "no_speech_prob": 1.1656045899144374e-05}, {"id": 47, "seek": 33636, "start": 348.96000000000004, "end": 356.84000000000003, "text": " and you have the utility and the utility when you ask for help is a normal Postgres utility.", "tokens": [293, 291, 362, 264, 14877, 293, 264, 14877, 562, 291, 1029, 337, 854, 307, 257, 2710, 10223, 45189, 14877, 13], "temperature": 0.0, "avg_logprob": -0.1449321253915851, "compression_ratio": 1.5822222222222222, "no_speech_prob": 1.1656045899144374e-05}, {"id": 48, "seek": 33636, "start": 356.84000000000003, "end": 362.48, "text": " You get your database selection, user name, host name part, et cetera, the same way you", "tokens": [509, 483, 428, 8149, 9450, 11, 4195, 1315, 11, 3975, 1315, 644, 11, 1030, 11458, 11, 264, 912, 636, 291], "temperature": 0.0, "avg_logprob": -0.1449321253915851, "compression_ratio": 1.5822222222222222, "no_speech_prob": 1.1656045899144374e-05}, {"id": 49, "seek": 36248, "start": 362.48, "end": 370.24, "text": " would connect with any Postgres client. And you've got modules like buff that shows you", "tokens": [576, 1745, 365, 604, 10223, 45189, 6423, 13, 400, 291, 600, 658, 16679, 411, 9204, 300, 3110, 291], "temperature": 0.0, "avg_logprob": -0.14974641225424157, "compression_ratio": 1.6160714285714286, "no_speech_prob": 2.7933725505135953e-05}, {"id": 50, "seek": 36248, "start": 370.24, "end": 376.68, "text": " statistics on the background writer and buffers written to disk, cache hit ratio, checkpoint", "tokens": [12523, 322, 264, 3678, 9936, 293, 9204, 433, 3720, 281, 12355, 11, 19459, 2045, 8509, 11, 42269], "temperature": 0.0, "avg_logprob": -0.14974641225424157, "compression_ratio": 1.6160714285714286, "no_speech_prob": 2.7933725505135953e-05}, {"id": 51, "seek": 36248, "start": 376.68, "end": 386.24, "text": " rate, connections, number of tuples, weights that it found in the server during the snapshot,", "tokens": [3314, 11, 9271, 11, 1230, 295, 2604, 2622, 11, 17443, 300, 309, 1352, 294, 264, 7154, 1830, 264, 30163, 11], "temperature": 0.0, "avg_logprob": -0.14974641225424157, "compression_ratio": 1.6160714285714286, "no_speech_prob": 2.7933725505135953e-05}, {"id": 52, "seek": 36248, "start": 386.24, "end": 391.92, "text": " wall generation and so on. And you can either run analyze which runs all of the modules", "tokens": [2929, 5125, 293, 370, 322, 13, 400, 291, 393, 2139, 1190, 12477, 597, 6676, 439, 295, 264, 16679], "temperature": 0.0, "avg_logprob": -0.14974641225424157, "compression_ratio": 1.6160714285714286, "no_speech_prob": 2.7933725505135953e-05}, {"id": 53, "seek": 39192, "start": 391.92, "end": 398.36, "text": " at once and generates visualizations or you can run just one module if you're only interested", "tokens": [412, 1564, 293, 23815, 5056, 14455, 420, 291, 393, 1190, 445, 472, 10088, 498, 291, 434, 787, 3102], "temperature": 0.0, "avg_logprob": -0.09046576962326512, "compression_ratio": 1.6, "no_speech_prob": 2.6663126845960505e-05}, {"id": 54, "seek": 39192, "start": 398.36, "end": 408.72, "text": " in buffers. You can only say run buff. Most importantly, there's a capital D option that", "tokens": [294, 9204, 433, 13, 509, 393, 787, 584, 1190, 9204, 13, 4534, 8906, 11, 456, 311, 257, 4238, 413, 3614, 300], "temperature": 0.0, "avg_logprob": -0.09046576962326512, "compression_ratio": 1.6, "no_speech_prob": 2.6663126845960505e-05}, {"id": 55, "seek": 39192, "start": 408.72, "end": 415.64, "text": " you can use to specify the date range in order to visualize only the time range you're interested", "tokens": [291, 393, 764, 281, 16500, 264, 4002, 3613, 294, 1668, 281, 23273, 787, 264, 565, 3613, 291, 434, 3102], "temperature": 0.0, "avg_logprob": -0.09046576962326512, "compression_ratio": 1.6, "no_speech_prob": 2.6663126845960505e-05}, {"id": 56, "seek": 41564, "start": 415.64, "end": 423.12, "text": " in. So, like the last 24 hours only. And these are specified, of course, in ISO 8601 format.", "tokens": [294, 13, 407, 11, 411, 264, 1036, 4022, 2496, 787, 13, 400, 613, 366, 22206, 11, 295, 1164, 11, 294, 25042, 1649, 4550, 16, 7877, 13], "temperature": 0.0, "avg_logprob": -0.1681717046101888, "compression_ratio": 1.4157894736842105, "no_speech_prob": 9.366687663714401e-06}, {"id": 57, "seek": 41564, "start": 423.12, "end": 429.88, "text": " So, there's no ambiguity in how to type in dates. And it works something like this.", "tokens": [407, 11, 456, 311, 572, 46519, 294, 577, 281, 2010, 294, 11691, 13, 400, 309, 1985, 746, 411, 341, 13], "temperature": 0.0, "avg_logprob": -0.1681717046101888, "compression_ratio": 1.4157894736842105, "no_speech_prob": 9.366687663714401e-06}, {"id": 58, "seek": 41564, "start": 429.88, "end": 437.03999999999996, "text": " You connect to database fof as user Postgres. You give it a date range and it just generates", "tokens": [509, 1745, 281, 8149, 726, 69, 382, 4195, 10223, 45189, 13, 509, 976, 309, 257, 4002, 3613, 293, 309, 445, 23815], "temperature": 0.0, "avg_logprob": -0.1681717046101888, "compression_ratio": 1.4157894736842105, "no_speech_prob": 9.366687663714401e-06}, {"id": 59, "seek": 43704, "start": 437.04, "end": 447.28000000000003, "text": " the snapshots and writes the visualizations as PNG to disk. And yes, it has a logo. So,", "tokens": [264, 19206, 27495, 293, 13657, 264, 5056, 14455, 382, 430, 30237, 281, 12355, 13, 400, 2086, 11, 309, 575, 257, 9699, 13, 407, 11], "temperature": 0.0, "avg_logprob": -0.10730874169733107, "compression_ratio": 1.5848214285714286, "no_speech_prob": 7.525917226303136e-06}, {"id": 60, "seek": 43704, "start": 447.28000000000003, "end": 453.24, "text": " it's complete. The visualizations look something like this. I apologize if the points are a", "tokens": [309, 311, 3566, 13, 440, 5056, 14455, 574, 746, 411, 341, 13, 286, 12328, 498, 264, 2793, 366, 257], "temperature": 0.0, "avg_logprob": -0.10730874169733107, "compression_ratio": 1.5848214285714286, "no_speech_prob": 7.525917226303136e-06}, {"id": 61, "seek": 43704, "start": 453.24, "end": 459.44, "text": " bit too small for you to see. So, as we said, buffers written to disk is a line that keeps", "tokens": [857, 886, 1359, 337, 291, 281, 536, 13, 407, 11, 382, 321, 848, 11, 9204, 433, 3720, 281, 12355, 307, 257, 1622, 300, 5965], "temperature": 0.0, "avg_logprob": -0.10730874169733107, "compression_ratio": 1.5848214285714286, "no_speech_prob": 7.525917226303136e-06}, {"id": 62, "seek": 43704, "start": 459.44, "end": 466.52000000000004, "text": " going up until stats reset. When the stats get reset, it starts from zero again. So,", "tokens": [516, 493, 1826, 18152, 14322, 13, 1133, 264, 18152, 483, 14322, 11, 309, 3719, 490, 4018, 797, 13, 407, 11], "temperature": 0.0, "avg_logprob": -0.10730874169733107, "compression_ratio": 1.5848214285714286, "no_speech_prob": 7.525917226303136e-06}, {"id": 63, "seek": 46652, "start": 466.52, "end": 472.68, "text": " perhaps this is more useful. This is the buffer write rate in megabytes per second. So, you", "tokens": [4317, 341, 307, 544, 4420, 13, 639, 307, 264, 21762, 2464, 3314, 294, 10816, 24538, 680, 1150, 13, 407, 11, 291], "temperature": 0.0, "avg_logprob": -0.16608383472149188, "compression_ratio": 1.467032967032967, "no_speech_prob": 0.0002889815950766206}, {"id": 64, "seek": 46652, "start": 472.68, "end": 477.76, "text": " can see exactly how many buffers your Postgres server was writing to disk at any moment in", "tokens": [393, 536, 2293, 577, 867, 9204, 433, 428, 10223, 45189, 7154, 390, 3579, 281, 12355, 412, 604, 1623, 294], "temperature": 0.0, "avg_logprob": -0.16608383472149188, "compression_ratio": 1.467032967032967, "no_speech_prob": 0.0002889815950766206}, {"id": 65, "seek": 46652, "start": 477.76, "end": 482.28, "text": " time. And also, you can analyze what was happening because of the background writer.", "tokens": [565, 13, 400, 611, 11, 291, 393, 12477, 437, 390, 2737, 570, 295, 264, 3678, 9936, 13], "temperature": 0.0, "avg_logprob": -0.16608383472149188, "compression_ratio": 1.467032967032967, "no_speech_prob": 0.0002889815950766206}, {"id": 66, "seek": 48228, "start": 482.28, "end": 504.52, "text": " No? Yes. Thank you. So, you can see here that because this was a test I ran on my laptop", "tokens": [883, 30, 1079, 13, 1044, 291, 13, 407, 11, 291, 393, 536, 510, 300, 570, 341, 390, 257, 1500, 286, 5872, 322, 452, 10732], "temperature": 0.0, "avg_logprob": -0.17705283846173966, "compression_ratio": 1.0476190476190477, "no_speech_prob": 0.00022627570433542132}, {"id": 67, "seek": 50452, "start": 504.52, "end": 512.72, "text": " with a script that was just inserting rows into the same table. The checkpoint line,", "tokens": [365, 257, 5755, 300, 390, 445, 46567, 13241, 666, 264, 912, 3199, 13, 440, 42269, 1622, 11], "temperature": 0.0, "avg_logprob": -0.128617197968239, "compression_ratio": 1.6859903381642511, "no_speech_prob": 3.8786740333307534e-05}, {"id": 68, "seek": 50452, "start": 512.72, "end": 518.12, "text": " which is the orange line, didn't do much because it wasn't scheduled activity taken", "tokens": [597, 307, 264, 7671, 1622, 11, 994, 380, 360, 709, 570, 309, 2067, 380, 15678, 5191, 2726], "temperature": 0.0, "avg_logprob": -0.128617197968239, "compression_ratio": 1.6859903381642511, "no_speech_prob": 3.8786740333307534e-05}, {"id": 69, "seek": 50452, "start": 518.12, "end": 524.4, "text": " care of by checkpoints. But you can see that back ends were doing most of the work. And", "tokens": [1127, 295, 538, 1520, 20552, 13, 583, 291, 393, 536, 300, 646, 5314, 645, 884, 881, 295, 264, 589, 13, 400], "temperature": 0.0, "avg_logprob": -0.128617197968239, "compression_ratio": 1.6859903381642511, "no_speech_prob": 3.8786740333307534e-05}, {"id": 70, "seek": 50452, "start": 524.4, "end": 529.16, "text": " also, you can see that the background writer, which is the green line, didn't get the chance", "tokens": [611, 11, 291, 393, 536, 300, 264, 3678, 9936, 11, 597, 307, 264, 3092, 1622, 11, 994, 380, 483, 264, 2931], "temperature": 0.0, "avg_logprob": -0.128617197968239, "compression_ratio": 1.6859903381642511, "no_speech_prob": 3.8786740333307534e-05}, {"id": 71, "seek": 52916, "start": 529.16, "end": 535.8, "text": " to participate in all this buffer writing because from what we can see from the very", "tokens": [281, 8197, 294, 439, 341, 21762, 3579, 570, 490, 437, 321, 393, 536, 490, 264, 588], "temperature": 0.0, "avg_logprob": -0.12613182757274213, "compression_ratio": 1.669811320754717, "no_speech_prob": 2.1427569663501345e-05}, {"id": 72, "seek": 52916, "start": 535.8, "end": 544.64, "text": " low line, its limits were set to low for production. So, you can gain insights into the behavior", "tokens": [2295, 1622, 11, 1080, 10406, 645, 992, 281, 2295, 337, 4265, 13, 407, 11, 291, 393, 6052, 14310, 666, 264, 5223], "temperature": 0.0, "avg_logprob": -0.12613182757274213, "compression_ratio": 1.669811320754717, "no_speech_prob": 2.1427569663501345e-05}, {"id": 73, "seek": 52916, "start": 544.64, "end": 551.56, "text": " of your Postgres server like this. Or you can look at connection versus status count.", "tokens": [295, 428, 10223, 45189, 7154, 411, 341, 13, 1610, 291, 393, 574, 412, 4984, 5717, 6558, 1207, 13], "temperature": 0.0, "avg_logprob": -0.12613182757274213, "compression_ratio": 1.669811320754717, "no_speech_prob": 2.1427569663501345e-05}, {"id": 74, "seek": 52916, "start": 551.56, "end": 556.4, "text": " So, you can see how many connections you had coming into your server from clients, how", "tokens": [407, 11, 291, 393, 536, 577, 867, 9271, 291, 632, 1348, 666, 428, 7154, 490, 6982, 11, 577], "temperature": 0.0, "avg_logprob": -0.12613182757274213, "compression_ratio": 1.669811320754717, "no_speech_prob": 2.1427569663501345e-05}, {"id": 75, "seek": 55640, "start": 556.4, "end": 561.52, "text": " many of them were active, how many of them were idle, how many were idle in transaction,", "tokens": [867, 295, 552, 645, 4967, 11, 577, 867, 295, 552, 645, 30650, 11, 577, 867, 645, 30650, 294, 14425, 11], "temperature": 0.0, "avg_logprob": -0.1000753912595239, "compression_ratio": 1.6796875, "no_speech_prob": 2.7082973247161135e-05}, {"id": 76, "seek": 55640, "start": 561.52, "end": 568.84, "text": " and so on. But you can also see which users were taking up those connections. And I think", "tokens": [293, 370, 322, 13, 583, 291, 393, 611, 536, 597, 5022, 645, 1940, 493, 729, 9271, 13, 400, 286, 519], "temperature": 0.0, "avg_logprob": -0.1000753912595239, "compression_ratio": 1.6796875, "no_speech_prob": 2.7082973247161135e-05}, {"id": 77, "seek": 55640, "start": 568.84, "end": 573.56, "text": " that's really interesting when you have like an environment that's used by multiple applications", "tokens": [300, 311, 534, 1880, 562, 291, 362, 411, 364, 2823, 300, 311, 1143, 538, 3866, 5821], "temperature": 0.0, "avg_logprob": -0.1000753912595239, "compression_ratio": 1.6796875, "no_speech_prob": 2.7082973247161135e-05}, {"id": 78, "seek": 55640, "start": 573.56, "end": 578.4399999999999, "text": " so you can know which developers to blame when it all goes south.", "tokens": [370, 291, 393, 458, 597, 8849, 281, 10127, 562, 309, 439, 1709, 7377, 13], "temperature": 0.0, "avg_logprob": -0.1000753912595239, "compression_ratio": 1.6796875, "no_speech_prob": 2.7082973247161135e-05}, {"id": 79, "seek": 55640, "start": 578.4399999999999, "end": 585.16, "text": " Weight events. As I was testing this on my laptop and was overflowing it with IO because", "tokens": [44464, 3931, 13, 1018, 286, 390, 4997, 341, 322, 452, 10732, 293, 390, 670, 43955, 309, 365, 39839, 570], "temperature": 0.0, "avg_logprob": -0.1000753912595239, "compression_ratio": 1.6796875, "no_speech_prob": 2.7082973247161135e-05}, {"id": 80, "seek": 58516, "start": 585.16, "end": 594.4, "text": " I was inserting millions of rows into a table, I generated an IO data file read, sorry for", "tokens": [286, 390, 46567, 6803, 295, 13241, 666, 257, 3199, 11, 286, 10833, 364, 39839, 1412, 3991, 1401, 11, 2597, 337], "temperature": 0.0, "avg_logprob": -0.11584246708796575, "compression_ratio": 1.456989247311828, "no_speech_prob": 3.422995359869674e-05}, {"id": 81, "seek": 58516, "start": 594.4, "end": 600.3199999999999, "text": " the small letters, weight condition. And that was captured by the snapshot that was being", "tokens": [264, 1359, 7825, 11, 3364, 4188, 13, 400, 300, 390, 11828, 538, 264, 30163, 300, 390, 885], "temperature": 0.0, "avg_logprob": -0.11584246708796575, "compression_ratio": 1.456989247311828, "no_speech_prob": 3.422995359869674e-05}, {"id": 82, "seek": 58516, "start": 600.3199999999999, "end": 609.0799999999999, "text": " taken every 10 seconds or so for this example. So, thank you for listening. The project is", "tokens": [2726, 633, 1266, 3949, 420, 370, 337, 341, 1365, 13, 407, 11, 1309, 291, 337, 4764, 13, 440, 1716, 307], "temperature": 0.0, "avg_logprob": -0.11584246708796575, "compression_ratio": 1.456989247311828, "no_speech_prob": 3.422995359869674e-05}, {"id": 83, "seek": 60908, "start": 609.08, "end": 617.36, "text": " going to be live at github.com slash virus slash pgstatvis in a few moments. You can find", "tokens": [516, 281, 312, 1621, 412, 290, 355, 836, 13, 1112, 17330, 5752, 17330, 280, 70, 19435, 4938, 294, 257, 1326, 6065, 13, 509, 393, 915], "temperature": 0.0, "avg_logprob": -0.2032151099963066, "compression_ratio": 1.394736842105263, "no_speech_prob": 3.424416354391724e-05}, {"id": 84, "seek": 60908, "start": 617.36, "end": 628.84, "text": " me on master don. And what the hell? I'll do it right now. So, as we said, this is alpha", "tokens": [385, 322, 4505, 500, 13, 400, 437, 264, 4921, 30, 286, 603, 360, 309, 558, 586, 13, 407, 11, 382, 321, 848, 11, 341, 307, 8961], "temperature": 0.0, "avg_logprob": -0.2032151099963066, "compression_ratio": 1.394736842105263, "no_speech_prob": 3.424416354391724e-05}, {"id": 85, "seek": 60908, "start": 628.84, "end": 636.12, "text": " quality code. Oh, I forgot to say that it doesn't do any scheduling or any maintenance", "tokens": [3125, 3089, 13, 876, 11, 286, 5298, 281, 584, 300, 309, 1177, 380, 360, 604, 29055, 420, 604, 11258], "temperature": 0.0, "avg_logprob": -0.2032151099963066, "compression_ratio": 1.394736842105263, "no_speech_prob": 3.424416354391724e-05}, {"id": 86, "seek": 63612, "start": 636.12, "end": 643.16, "text": " or any partitioning of those internal tables where it keeps the snapshots. So you can delete", "tokens": [420, 604, 24808, 278, 295, 729, 6920, 8020, 689, 309, 5965, 264, 19206, 27495, 13, 407, 291, 393, 12097], "temperature": 0.0, "avg_logprob": -0.15291600831797425, "compression_ratio": 1.5084745762711864, "no_speech_prob": 6.196126196300611e-05}, {"id": 87, "seek": 63612, "start": 643.16, "end": 653.32, "text": " them by hand. You can schedule the snapshots very easily with any tool you like, like cron", "tokens": [552, 538, 1011, 13, 509, 393, 7567, 264, 19206, 27495, 588, 3612, 365, 604, 2290, 291, 411, 11, 411, 941, 266], "temperature": 0.0, "avg_logprob": -0.15291600831797425, "compression_ratio": 1.5084745762711864, "no_speech_prob": 6.196126196300611e-05}, {"id": 88, "seek": 63612, "start": 653.32, "end": 659.16, "text": " or pgcron. But I didn't want to make this a dependency on the extension. So you can", "tokens": [420, 280, 70, 66, 2044, 13, 583, 286, 994, 380, 528, 281, 652, 341, 257, 33621, 322, 264, 10320, 13, 407, 291, 393], "temperature": 0.0, "avg_logprob": -0.15291600831797425, "compression_ratio": 1.5084745762711864, "no_speech_prob": 6.196126196300611e-05}, {"id": 89, "seek": 65916, "start": 659.16, "end": 675.64, "text": " just configure it yourself. And I can just go to settings and make it public right now.", "tokens": [445, 22162, 309, 1803, 13, 400, 286, 393, 445, 352, 281, 6257, 293, 652, 309, 1908, 558, 586, 13], "temperature": 0.0, "avg_logprob": -0.2571808566217837, "compression_ratio": 1.0609756097560976, "no_speech_prob": 4.7543344408040866e-05}, {"id": 90, "seek": 67564, "start": 675.64, "end": 705.56, "text": " Cool. Thank you. Any questions? No, okay.", "tokens": [8561, 13, 1044, 291, 13, 2639, 1651, 30, 883, 11, 1392, 13], "temperature": 0.0, "avg_logprob": -0.5293372869491577, "compression_ratio": 0.8367346938775511, "no_speech_prob": 0.010338491760194302}, {"id": 91, "seek": 70556, "start": 705.56, "end": 710.2399999999999, "text": " Thanks anyway. Thanks. Thanks for doing me.", "tokens": [50364, 2561, 4033, 13, 2561, 13, 2561, 337, 884, 385, 13, 50598], "temperature": 0.0, "avg_logprob": -0.35637840857872594, "compression_ratio": 1.048780487804878, "no_speech_prob": 0.00442015053704381}], "language": "en"}