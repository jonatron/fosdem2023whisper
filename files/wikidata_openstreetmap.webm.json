{"text": " So, hello. I'm Edward, and I'm going to be talking about some tools that I've been building for adding links between OpenStreetMap and Wikidata. I've been working on these for a few years. This is all a hobbyist project. I'm not being paid to work on this, but I thought I'd come here and share with you some of the work that I've been doing. So, I'm going to use as an example to talk about the software that I'm building, this building which is in Brussels, the Royal Palace of Brussels. It's in the city centre. So, you can see here, this is it in two different systems. You've got OpenStreetMap and you've got Wikidata, both showing the same building. So, I'll describe OpenStreetMap just for anyone who's not familiar with it. It's a collaborative map. I've been going since 2004, covers the whole world, and anyone can come in and edit the map. It's got revision history. You know, it works a lot like Wikipedia, but for maps. So, within OpenStreetMap, you've got three types of objects, nodes, ways and relations, increasing complexity. And each of those objects can have tags. Tags are pairs of keys and values. I've got some examples here for my example in Brussels. And the tags are not controlled by the software. You can put anything you want in, but it won't get rendered on the map unless it's one of the standard tags that gets used on OpenStreetMap. So, there's a community process for discussing, you know, how things should be tagged in OpenStreetMap, and then it gets documented on the OpenStreetMap wiki. So, everything in OpenStreetMap can be uniquely identified by the type and the ID. Like the ID on its own isn't enough. There's nodes and ways that have got the same ID. You have to have the type as well. So, in this example, the Royal Palace, you can see it's a relation. It's a complex polygon. You can see there's holes in the middle of the building, so you can't represent it as a way. And you can see there it's got an ID as well. So, what about the other system I'm talking about? Wiki data. So, wiki data is part of the Wikimedia Foundation, like the same people that run Wikipedia. And it's a wiki for structured data. It's newer than OpenStreetMap 2012. It launched, and it's big. Like, it's got 102 million items now. And for comparison, English Wikipedia has 6.6 million articles. Like, English Wikipedia is the biggest Wikipedia. And most of those articles have a wiki data item as well. But then there's a lot more data, a lot more items in wiki data than there are articles in English Wikipedia. So, if I take my example of the Royal Palace of Brussels, and you look it up on English Wikipedia, you can see there's a link in the sidebar that will take you to the wiki data item. And you click that link, you end up on the, this is the wiki data item for the Royal Palace. I'll talk you through some of the pieces on this page. So, you've got, down the side, the site links. These are links to Wikipedia articles in different languages. Like, part of the reason for the distance of wiki data is to store these, they call them inter-language links. They used to be stored in Wikipedia and had to be maintained across all the different languages. So, if there was a new article written in a new language, every existing article in one of the existing languages had to be updated with these links. So, much better to centralize them and store them in wiki data instead. All the bits and pieces you get on this page, you get a label, description and aliases. So, by default, when I look at wiki data, I just see them in English because that's the language I speak. But I can click the link to show me in more languages and you can see that there's names of the thing available in lots of languages and descriptions and so on. The other main part of this page you see is the list of statements. So, statements are a bit like tags in OpenStreetMap, but they're more controlled by the software. You can't just make up a property. You have to use ones that are already in the system. And again, there's a community process in wiki data for determining new properties. And the other big difference is that there's different data types. Like in OpenStreetMap, everything is a string, but wiki data has different data types of values. Here you can see there's an image and there's also a link to another item used as values in the statements. So the interesting in terms of maps is wiki data has got coordinate locations. There's almost 10 million items with coordinates. So those are the kinds of things that we're interested in and will probably be on OpenStreetMap as well. And there is a property for storing geo-shapes in wiki data, but it's quite new and it's not used so much. There's only 29,000 odd items with a geo-shape. So, you know, it's mostly about the coordinates. So the thing that I'm interested in is adding links between the systems. So if we have another look at OpenStreetMap, I've got highlighted here one of the tags for the palace and it's the wiki data tag and it's got a wiki data QID. This is the unique identifier for the wiki data item. So now the two systems are linked. Like if you visit this object on OpenStreetMap, then the user interface has a hyperlink that will take you to the same thing on wiki data. So why do I want to add links between wiki data and OpenStreetMap? Well, it makes the data in OpenStreetMap a lot more useful. Like wiki data tends to have labels in more languages. Like if you want the name of a thing in a different language, you can get it from wiki data. You can link to the wiki preview articles. You get images from commons and identifiers from other catalogs, data catalogs. So there's wiki media commons is the wiki media location for storing photos of things. So we get loads of photos of our building and we also get lots of identifiers in wiki data. So you can think of wiki data as a bit like the Rosetta Stone of linking different data catalogs. It makes sense to store all this information in one place. So why not use wiki data as that place for storing this kind of info? So this is a good thing. We want to add links. The other thing that you get is wiki data gets access to the shapes of things, the polygon outline of the building, which otherwise it wouldn't have without a link. So adding these links by hand is kind of laborious and time consuming. So better to write some software to do it instead. So the software I've written, I'm calling it awl places and the web address is osm.wiki.data.link. So this is what the software looks like when you visit it. It asks you for a place name where you want to search for some matches. So you can put in the name of your town, somewhere you're familiar with and can check that the matches are valid. So I've done a search and I've found the place where the Royal Palace is located. And this is the page you see. You've got a map with some blue pins. And these blue pins represent wiki data items that the software has found something that matches OpenStreetMap. So if I scroll down this page, you can see some example matches. So I show you various bits of data that come from wiki data and wikipedia to help you try and identify if these matches are valid. Like sometimes the software doesn't get it right and will give you an invalid match. So it's important to look through this list and check that all the matches are correct. And to help you with that, I show you the first paragraph from the wikipedia article and I show you any images that come from wiki data. You've got the wiki data description there. The paragraphs I show you, I'll talk later about how it decides which languages to use for showing those. But it supports various languages. And then it shows you some of the details from OpenStreetMap just so you can compare and make sure that they match. So if I click on one of those, then it will zoom in on the map and it shows you the polygon outline of the thing. You can see the red pin there is the selected thing. So that looks like a pretty good match. It's probably the same thing. So we can go ahead and save that. So we're interested in saving these matches to OpenStreetMap. So the software has a button that lets us log in via OpenStreetMap by OAuth. Just put in username and password and log in. And then you come back to the confirmation page where you just see the same list again but kind of abbreviated. These are things that I've checked and I've said yes, these are valid matches and I want to save them. You can put a change comment. So everything gets saved together as one change set like it goes in as a single edit. And the change comment on the change set is generated automatically based on the location but you can change it if you want to. So I'll carry on with describing the software and I'll show you some more features that I've built. So I've added a type filter like at the top here you can see it's a type filter and there's a list of different types of things that it's found that are possible matches. So it's got statues and buildings. I can tick a sculpture to say I just want sculptures. And then when I scroll down it will just show me things that it thinks are sculptures. So I can focus on one particular type of thing. Sometimes when you put in the name of a town you might get 200 matches and it's a bit overwhelming to do them all in one go. So it's useful to do them bit by bit just specific types that you're interested in. And then when I go to the save page it generates a change comment that's based on the type filter that you've selected. So here it just says add wiki data tags to sculptures in this area. So I'm just going to talk about how it determines what is a match. So if we have a look at one of these examples this is a sculpture. So if we have a look at the same thing on wiki data you can see that there's a statement in wiki data which is the instance of statement. So this is saying that this thing is a sculpture. So we can click through and have a look at the sculpture page. This is the wiki data item for the concept of a sculpture. And then if we scroll down this page we get a wiki data property which is for OpenStreetMap tag or key. So there's actually two values here and the second value is uninteresting like it's shown in red because it's a deprecated value like it's a kind of old value that used to be used in OpenStreetMap and it's being documented in wiki data. So the interesting one is the top one which is tag colon artwork underscore type of sculpture. So the information is stored in wiki data about what tags are used in OpenStreetMap to describe things. So using this information we can say that these two things are the same type of entity. So when it comes to matching things I'm looking for the coordinates to match like the two things and the two systems have to be close to each other. They're not necessarily a perfect match but within like 50 meters or something. And the entity type has to be the same like I just described. And then I'm also looking for a matching name or street address or identifier. So I pull names from all over the place in both systems like in wiki data there's a bunch of different fields or rather in OpenStreetMap there's a bunch of different fields where names can be stored and I look at all of those and then in wiki data there's different places to get the names. I look at the labels, wiki data, the aliases, the names of any wikipedia articles. I look at the file name of any images that are in wiki data just to get as much, you know, many possible names that I can use for matching. And then I normalize the names a lot so I lowercase them and I remove stop words and process them a lot to try and get as many name matches as I can. And then similarly with street addresses. So there's street addresses in OpenStreetMap and wiki data which I compare and the software also looks for street addresses in the first paragraph of wikipedia articles. And then in terms of matching identifiers there's lots of standardized OpenStreetMap tags for different identifiers and then there's also properties in wiki data for those same identifiers. So if, you know, I've got a railway station that's got the same station code in OpenStreetMap and wiki data I can be pretty sure that it's the same thing that I'm matching so I can be confident about that match. So one of the things I'm not using at the moment is the wikipedia tags which appear in OpenStreetMap. Like before wiki data came along there was lots of wikipedia tags added to OpenStreetMap and they're not completely consistent in their formatting for how they link to wikipedia and sometimes they're wrong. So, you know, I've left the work for now working on trying to match up using wikipedia tags for somebody else to have a look at. But I've been waiting for a few years now and no one has so I might have to have a go at this. So just in case anyone's interested in the technology behind this, the software is written in Python with Flask. I'm using Postgres as my database and then on the front end, you know, various bits of JavaScript. I'm not really a front end developer but, you know, I'm muddling my way through and it seems to be working quite well. I'm using a bunch of APIs to get this data. So in terms of searching for places to look for matches, I use the OpenStreetMap nominatum API and then to grab more data I use the overview pass API and then on the wiki data side, I do a lot of sparkle queries against the wiki data query service and I use the wiki data media wiki API to get the details of the wiki data items. So there's a bunch of things that don't work in my system at the moment. One of them is tunnels. Like I designed the software with the assumption that there would be a kind of one-to-one mapping between a thing in OpenStreetMap and a thing in wiki data and that doesn't work for tunnels because tunnels tend to get represented as two ways in OpenStreetMap where as in wiki data there'll be a single item. And so, you know, my assumption was wrong and I need to change my software to say that you can add the wiki data identifier to ways in OpenStreetMap but I haven't done that yet. Incidentally, we don't have the same problem with bridges. Like the way that bridges get represented in OpenStreetMap is they are often two ways but then there's a relation across the whole bridge that represents the bridge itself. And tunnels, there isn't a relation for representing the whole concept of the tunnel. So that's another possible approach. Maybe OpenStreetMap should change and start mapping the tunnels with a relation that contains the two ways, you know, for storing wiki data tags and any other information about the tunnel that is the same across both ways. So, another thing that I don't support are rivers because they are linear relations and my software that I'm using to import data from OpenStreetMap I'm using OSM to PGSQL and it can't handle linear relations. It just, you know, expects relations to be polygons. So at the moment rivers don't work in the system. And then similarly for tram stops. Tram stops are kind of complex objects in OpenStreetMap. You've got, you know, stop positions of where the tram stops on either side of the road which are no single points and they're collected together into a relation and that isn't supported properly by OSM to PGSQL. So I can't handle tram stops properly. I'm going to talk about a few more features that are in the software. So again, this is the center of Brussels and I've got the language selector. So the software has figured out all the languages that get used for the labels of things and the OpenStreetMap objects that are in this area. You know, unsurprisingly for Brussels the most popular languages are French and then Dutch and English is the third most popular. Interestingly we've got Latin at the bottom there. There's 22 items that have got labels in Latin in wiki data. But so by default this page is opened in French and you can see the type filter is appearing in French but I can't read French very well so if I want to change it to Dutch I can reorder these languages by drag and drop or I can click on move to top and you can see the type filter is now switched into being in Dutch or if I want it in English then I can move English to the top of the list and it will show me the type filter in English, English labels and descriptions. And if I scroll down the page you can see that this is the page appearing in French. You've got titles in French and the extracts from wikipedia in French or again I can change it into Dutch if I want or I can have it in English. And this works without reloading the page. You just change the order that you prefer the languages to appear in and it does it all on the client and switches it over. So some statistics for you. People are using this tool. Well first of all there's more and more wiki data tags appearing in OpenStreetMap so not all of them are coming from my software. You know there's other people figuring out how to add wiki data tags to OpenStreetMap. So here's some more stats. 26% of the wiki data tags in OpenStreetMap were added using this tool and we're up to 400 people and there's been 23,000 change sets and we're getting close to 700,000 wiki data tags added. So I'm going to talk about the licensing. Wiki data is CC0 or public domain. You can do anything you want with wiki data and OpenStreetMap uses the open database license which is a license that was pretty much written for OpenStreetMap. So you can't copy any data from OpenStreetMap into wiki data because you'd be re-licensing it CC0 which is not allowed. But even more than just the licenses being different the intellectual property jurisdictions are different. So OpenStreetMap asserts database rights. Like the argument is that it's a lot of effort to go around collecting all this information and putting it in OpenStreetMap and they want to protect that whereas wiki data is part of the wiki media foundation which uses US intellectual property rules and so under US law facts are not copyrighted, not protected rather in law. So the two things don't mesh that well but it's fine because I'm not copying any data between the systems. I'm just adding links between them. Like in some cases it might be nice if we could tidy up the data in one system based on the other but I'm not doing that and there's you've got to think carefully about the intellectual property rules before you try and do that. And so also just while we're talking about licenses my software is GPL and code is on GitHub it's all open source. Anyone can have a look at the software behind it. So an important aspect for being able to add these links between the systems is to have stable identifiers and for a long time OpenStreetMap has talked about the identifiers not being stable and sometimes say a railway station might get mapped as a single point and then later on somebody comes along and traces the outline of the building and so it changes from being a node into a way or a relation and the identifier will have changed. So they aren't stable identifiers for concepts in OpenStreetMap. So the thinking is that makes it difficult to link into OpenStreetMap because the identifiers might change and there's been discussions within the OpenStreetMap community of having a permanent ID and the discussions have been going on since 2017 and they haven't come to a conclusion. There's been an argument that maybe the right thing to use in terms of stable identifiers would be wiki data IDs, just say anything that's important enough to need a stable identifier is probably on wiki data and so you could use the wiki data ID as a permanent ID. But another way to look at it is in reality most of the world is mapped now on OpenStreetMap and the IDs aren't changing that much. Things tend to be mapped as polygons like outlines of buildings and people aren't coming along and making changes that are destructive in destroying the IDs. So maybe the IDs that are in OpenStreetMap already, the IDs that I talked about earlier, maybe they're stable enough and maybe it's okay to just link to those and not worry about them changing. Whereas we've got wiki data on the other hand and wiki data was designed always to have stable identifiers. That was a big part I think of the initial approach to wiki data. Wikipedia identifies things by article title and over time the article titles can change and then things get moved around and so they don't have long-term stable IDs and so the wiki data QIDs was an approach that gave you stable IDs. But it turns out that they're not completely stable. There's also redirects appearing in wiki data. Like with some of the work I've been doing, I find a lot of duplicates in wiki data. Things have been imported from different sources and say for example I found a lot of duplicate churches in wiki data. So when I go and I merge the churches, then the ID that represents one of those churches will change. So I've got on the slide here there's 10,000 OpenStreetMap objects that point to a redirect in wiki data and somebody needs to go through and resolve those redirects and fix OpenStreetMap. I will probably do that at some point if no one else does. So a recent change to wiki data is that there's a new property called OpenStreetMapElement and that is for storing OpenStreetMap IDs. So now it is possible to add the links in both directions. We can have links from wiki data to OpenStreetMap which we never used to be able to have. So I need to change my software to start adding these links in. When you save things at the moment it just uploads into OpenStreetMap it should be uploading them to wiki data as well. But to do that I need to make the user login to both systems which is possible but it will break the flow of it. So I am going to try and do a demo. Let's see. So this is the software I'm describing and I can say I want it in English. And you can see the type filter there and if I scroll down it shows matches that weren't very good at the start. So it's got some difficulty with this match and it can't handle it so we scroll past those. And here's the first match that the system can handle and if I click on it then it shows you the match. I can click toggle OSM tags. This is showing all of the tags from OpenStreetMap. The green ones are ones where it's found a match that's using those to figure out what the match is. I'll show you some more. Here's another one. You can see it appearing on the map. If I think this is not a correct match I can click here and it's deselected it. So I've got a whole pile of matches here. I've checked these ahead of time. They're all good. So I scroll to the bottom and I can say add tags to OpenStreetMap and this is the confirmation page that I was talking about. So I can hit save and the software goes through and it's saving my matches. So it has done it and I can say view my change set and you get to see my change set on OpenStreetMap. I can scroll down and you can see these are all the things I've edited. So nice and quick to go through and edit OpenStreetMap. I've just got another example. Another bit of Brussels. I can change to English. Say I want squares and then if I scroll down it will just show me some matches that haven't worked. So scroll past those. Here's some squares that the software has managed to match up. And these all look like good matches. I've checked these before so I can scroll to the bottom. There's another one and I can say add to save to OpenStreetMap and it's in the change comment it's put the word squares. So I can hit save and that is working to edit OpenStreetMap. I'll go back to the presentation. So that was my existing software. That's been running for a few years. People have been using that and I've been working on a new version of the software that I'm calling OwlMap. This is what OwlMap looks like. So when you open this you go straight to a map. It tries to guess where you are, locate you based on your IP address and then it shows you this interface much more map-based rather than like a list of things. You see the red pins are where there isn't a match already. Green pins are where there is a match and the yellow pins are OpenStreetMap things. So you can see some of them have a line between the green pin and the yellow pin. That's showing you which, you know, the green pin is a Wikipedia item that matches a thing on OpenStreetMap which is the yellow pin and there's a line between them. And you've got a filter at the side where you can filter on different item types. This is an example where I've selected one of the pins. I've clicked on a pin and it changes the color slightly and it shows you some details. You get to see the photo and bits and pieces from Wikidata. And then underneath it shows you a list of possible matches. It just says, you know, this is a building. Here's some other buildings nearby. And I can see the street addresses on here and, you know, the nearest building. The street address matches. But in actual fact, there's two street addresses on there. And if I scroll down this list, I can see that there's two buildings next to each other that both match this warehouse. So for some reason Wikidata is representing it as a single item whereas OpenStreetMap has got two separate objects. But this version of the software supports it. So I tick the boxes next to them and then I can hit save and it'll add the Wikidata tag to them. So this bit of software I'm still working on. It's live but it keeps breaking so I'm not really advertising for people to use it. I need to do some more work on it. And in fact, I think I need some help. You know, I'm just a hobbyist and I'm running out of time to work on this stuff. So I don't know if anyone knows how I can get some help with this, whether, you know, there's someone out there who wants to pay for this work or whether I can find volunteers to help me. I don't know. It's all a bit tricky like trying to work out managing people to work on this. So yeah, that's the software built. And I guess, has anyone got any questions? If you have a question, please raise your hand so I can see you all there. I'm coming. Thank you, Edward, for that. Hi, I'm Siebrandt. I'm a volunteer at Wikimedia. Wikimedia has a service called Wikimedia Cloud Services where you can get free compute resources. Oh, where you can get free compute resources. I would highly recommend that you look into that. So like the machine I'm running some of this stuff on is 60 gigabytes of RAM and two terabytes of disk. Would I be able to get that much from Cloud Services? I would highly recommend that you talk to someone there as you may be having a project that's quite valuable to the Wikimedia movement. I'm sure that someone will try to help you. Thank you for your contributions and for the talk. Have you considered interfacing or linking with OSMOS? It's a quality assurance project. It's a quality assurance project. It's a model where you see alerts on the mob, dangling ways, et cetera. I think it's somewhat extended and it has an existing user base. Maybe you could benefit from that. I haven't looked at this. I will write you later. Thank you. Hello. I have two remarks. First of all, I'm the maker of MapComplete which also has an entomology team to link Wikidata to Straits so we can work together on that. And then second, a small remark on the adding an ID of OpenStreetMap to Wikidata. That's a bit of a flow approach because IDs aren't very stable in OpenStreetMap. Say that a new park is opened, I place a point where the park is and then a few days later someone else passes by and says, oh, we have aerial imagery now, throws the outline as a polygon and then removes the alt point. That means that the link would be broken in Wikidata. I mean, I guess we just have to deal with that. We can have software that looks for these broken links. Maybe it would be nice if OpenStreetMap could add redirects like Wikidata has. Yeah, except that it's way more difficult than that because, for example, sometimes you have a big street and then you have properties which are different for parts of the street and then the street gets split into three parts. So then suddenly you'd have to redirect to three different parts. Do you think that it's a mistake to add OpenStreetMap IDs to Wikidata then? Yes, basically. It doesn't make sense at first glance but technically it will break down over time. So it's better to add a link to OpenStreetMap to Wikidata and then look it up reversely because the editing tools will keep track of the Wikidata link. So if the roads get split into multiple pieces, every single piece of the road will get a backlink to the Wikidata item. Yeah, you might have a good point. But let's have a discussion after the questions. Hi Ed, thanks for sharing the new software. It looks great. So I was fascinated by the example where you showed a modern one potential match and I just wondered does your software have a role to play in improving the quality of the data by cross-referencing between the two sides? I think it can improve the quality. Like I say, when I run this I find duplicates in Wikidata that are difficult to identify from just Wikidata itself. I feel like the coordinates that are in Wikidata don't get much use. Like for a long time you didn't even see the map appearing, the Wikidata pages, and then a lot of the coordinates were wrong. People transpose digits. Since the map is visible, people are more likely to check their data. The fact that the two systems exist, you can cross-reference them and find errors. Yes. I'm wondering how relevant it is now based upon the question just a moment ago. But I was wondering can you search Wikidata for a lot long window and find all objects within it when you're adding data to OpenStreetMap? So underneath I'm doing Sparkle queries to Wikidata, and Wikidata Sparkle queries do support coordinate bounding boxes. I can say you can write your own query in Sparkle that will give you all the churches within a given bounding box. I demoed two separate systems that should really be combined into one, and the old system doesn't support bounding boxes. It's all based on place polygons. You have to say, show me things that are in Brussels. You can't say, show me things within this rectangle. And the new system is more bounding box based in that you see the map and it just shows you all the matches that are in the rectangle that's visible on the screen. I'm not sure if that answers your question. It doesn't think. It's very valuable what you've done. Thanks. Any other questions? Raise your hand. Hi. Thank you for your talk. I had a question about the OpenStreetMap tags that are in Wikidata. I think you showed this in one of your slides. How often are these tags uploaded from OpenStreetMap, and does it pose any problem with the license compatibility issues that you talked about? I think you mean the property for OpenStreetMap tag or key. Things like I showed the palace type. Is that right? Is that the one you're thinking of? There's a few properties in Wikidata. Yes, the OSM tag, like the structure one. I don't think there's any problem in terms of the intellectual property. It's kept pretty up to date. People invent a new tag to use on OpenStreetMap, and then they go and find the matching Wikidata item and add the tag to it. And some unofficial tags that are used on OpenStreetMap, the information is in Wikidata. So it's pretty current, I think. So similar question from my side. Nice presentation. You explained the licenses. Nicely when you said that you cannot copy data from the OpenStreetMap to Wikidata, but what about the other way around? So that's an interesting question. And the OpenStreetMap community is a bit suspicious of the information that's in Wikidata. Like, there's a feeling, you know, where did the coordinates come from? Were they just copied from Google Maps? Like, do people look up a thing on Google Maps, find the coordinates, put the coordinates into Wikidata? And then does that make Wikidata a derived work of Google Maps? And so, you know, it's probably fine to copy any data from Wikidata into OpenStreetMap. You know, if you want to copy a name in a different language, you know, that's probably fine. But my software doesn't do that. I just add the links. And, you know, once the links are there, it's easier for somebody else to come along and find these things and copy the data over if they want. So my question is, does the software do the requests, the API requests on the back end on your hosted service, or is it the client, the user that will do the browser will do the API requests? I showed two versions. The old, you know, the more established version is using the Nominatum API to find things. And then it's using the Overpass API to grab lots of map data. And then they use the OpenStreetMap API to push the changes you make to upload the Wikidata tags back into OpenStreetMap. And the new system I built maintains a full mirror of the OpenStreetMap data just to make things faster. So I'm not using APIs for downloading data with that one. I just use the API for saving the changes. Does that answer your question? Yeah, partly. But does the request to fetch data from the Wikidata, does that go from your servers? Do your servers fetch data? It is all going from my server, yeah. It's not from the client browser. It's going. Like, I do a lot of pre-processing before I show you the list of paid matches, and then I store them all in the database. So when you load the list of matches for a place, it's not doing any queries either on the server or the client with the APIs. It's all stored in the database. I mean, that's a problem. The matches get stale. There's a refresh button that you can hit, and it will go off and rerun the matcher and get fresh data from OpenStreetMap and Wikidata. Yeah, okay, thanks. There was a question here? No? Okay, so I'll be back on the other side. Hi, I'm Valerio from Milano, and thank you so much for this tool. Again, thank you for the person who mentioned the possibility to host this tool on the Wikimedia Foundation infrastructure, because it would be really, really nice to propose this on the Wikimedia Fabricator, and I would be interested in discovering how the discussion will go. Second thing, you asked how to found your development. I think you can just contact your local Wikimedia chapter that maybe they provide microgrants or something like that. In my local community, some volunteers often in one week can obtain microgrants to develop small tools or to boost some activities. Maybe this can be interesting if they are useful for the university to produce OpenStreet software and Libre content. One feedback for the user interface, it's not clear to me how to contribute on just one element. If I have one minute, if I want to visit the tool and connect just one item, because I'm 100% sure about that item, so I just want to save on that contribution and be kidnapped, I don't know. So this maybe can be useful if it's not already possible. The two approaches for that, if you click on the title of an item, it takes you to a page where you can just edit a single item. Okay, wonderful. At the top of the page there's an uncheck all tick box, and then you can just tick the box next to one thing and scroll to the bottom and hit save. Both of those will work for adding a single Wikidata tag. Okay, thank you. And thanks for your comment about contacting my local Wikimedia chapter, that's a good idea. Last thing, can you repeat sorry, why do you need two terabytes of data to have this working? Thank you so much. The open stream app database is big. The Earth is big and I keep a whole copy of it to make things fast. And so it's probably 1.6 terabytes to store all of the open stream app data. I think that's time up. So thank you. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 10.44, "text": " So, hello. I'm Edward, and I'm going to be talking about some tools that I've been building", "tokens": [407, 11, 7751, 13, 286, 478, 18456, 11, 293, 286, 478, 516, 281, 312, 1417, 466, 512, 3873, 300, 286, 600, 668, 2390], "temperature": 0.0, "avg_logprob": -0.16548946380615234, "compression_ratio": 1.5871559633027523, "no_speech_prob": 0.3422527313232422}, {"id": 1, "seek": 0, "start": 10.44, "end": 15.72, "text": " for adding links between OpenStreetMap and Wikidata. I've been working on these for a", "tokens": [337, 5127, 6123, 1296, 7238, 50, 3599, 302, 44, 569, 293, 23377, 327, 3274, 13, 286, 600, 668, 1364, 322, 613, 337, 257], "temperature": 0.0, "avg_logprob": -0.16548946380615234, "compression_ratio": 1.5871559633027523, "no_speech_prob": 0.3422527313232422}, {"id": 2, "seek": 0, "start": 15.72, "end": 22.96, "text": " few years. This is all a hobbyist project. I'm not being paid to work on this, but I", "tokens": [1326, 924, 13, 639, 307, 439, 257, 18240, 468, 1716, 13, 286, 478, 406, 885, 4835, 281, 589, 322, 341, 11, 457, 286], "temperature": 0.0, "avg_logprob": -0.16548946380615234, "compression_ratio": 1.5871559633027523, "no_speech_prob": 0.3422527313232422}, {"id": 3, "seek": 0, "start": 22.96, "end": 28.0, "text": " thought I'd come here and share with you some of the work that I've been doing. So,", "tokens": [1194, 286, 1116, 808, 510, 293, 2073, 365, 291, 512, 295, 264, 589, 300, 286, 600, 668, 884, 13, 407, 11], "temperature": 0.0, "avg_logprob": -0.16548946380615234, "compression_ratio": 1.5871559633027523, "no_speech_prob": 0.3422527313232422}, {"id": 4, "seek": 2800, "start": 28.0, "end": 33.4, "text": " I'm going to use as an example to talk about the software that I'm building, this building", "tokens": [286, 478, 516, 281, 764, 382, 364, 1365, 281, 751, 466, 264, 4722, 300, 286, 478, 2390, 11, 341, 2390], "temperature": 0.0, "avg_logprob": -0.12237759590148926, "compression_ratio": 1.5682819383259912, "no_speech_prob": 0.0004546928103081882}, {"id": 5, "seek": 2800, "start": 33.4, "end": 40.56, "text": " which is in Brussels, the Royal Palace of Brussels. It's in the city centre. So, you", "tokens": [597, 307, 294, 38717, 11, 264, 12717, 19121, 295, 38717, 13, 467, 311, 294, 264, 2307, 10093, 13, 407, 11, 291], "temperature": 0.0, "avg_logprob": -0.12237759590148926, "compression_ratio": 1.5682819383259912, "no_speech_prob": 0.0004546928103081882}, {"id": 6, "seek": 2800, "start": 40.56, "end": 47.32, "text": " can see here, this is it in two different systems. You've got OpenStreetMap and you've", "tokens": [393, 536, 510, 11, 341, 307, 309, 294, 732, 819, 3652, 13, 509, 600, 658, 7238, 50, 3599, 302, 44, 569, 293, 291, 600], "temperature": 0.0, "avg_logprob": -0.12237759590148926, "compression_ratio": 1.5682819383259912, "no_speech_prob": 0.0004546928103081882}, {"id": 7, "seek": 2800, "start": 47.32, "end": 56.72, "text": " got Wikidata, both showing the same building. So, I'll describe OpenStreetMap just for anyone", "tokens": [658, 23377, 327, 3274, 11, 1293, 4099, 264, 912, 2390, 13, 407, 11, 286, 603, 6786, 7238, 50, 3599, 302, 44, 569, 445, 337, 2878], "temperature": 0.0, "avg_logprob": -0.12237759590148926, "compression_ratio": 1.5682819383259912, "no_speech_prob": 0.0004546928103081882}, {"id": 8, "seek": 5672, "start": 56.72, "end": 63.8, "text": " who's not familiar with it. It's a collaborative map. I've been going since 2004, covers the", "tokens": [567, 311, 406, 4963, 365, 309, 13, 467, 311, 257, 16555, 4471, 13, 286, 600, 668, 516, 1670, 15817, 11, 10538, 264], "temperature": 0.0, "avg_logprob": -0.12189399421989143, "compression_ratio": 1.3897435897435897, "no_speech_prob": 0.00016085394599940628}, {"id": 9, "seek": 5672, "start": 63.8, "end": 70.24, "text": " whole world, and anyone can come in and edit the map. It's got revision history. You know,", "tokens": [1379, 1002, 11, 293, 2878, 393, 808, 294, 293, 8129, 264, 4471, 13, 467, 311, 658, 34218, 2503, 13, 509, 458, 11], "temperature": 0.0, "avg_logprob": -0.12189399421989143, "compression_ratio": 1.3897435897435897, "no_speech_prob": 0.00016085394599940628}, {"id": 10, "seek": 5672, "start": 70.24, "end": 77.52, "text": " it works a lot like Wikipedia, but for maps. So, within OpenStreetMap, you've got three", "tokens": [309, 1985, 257, 688, 411, 28999, 11, 457, 337, 11317, 13, 407, 11, 1951, 7238, 50, 3599, 302, 44, 569, 11, 291, 600, 658, 1045], "temperature": 0.0, "avg_logprob": -0.12189399421989143, "compression_ratio": 1.3897435897435897, "no_speech_prob": 0.00016085394599940628}, {"id": 11, "seek": 7752, "start": 77.52, "end": 87.39999999999999, "text": " types of objects, nodes, ways and relations, increasing complexity. And each of those objects", "tokens": [3467, 295, 6565, 11, 13891, 11, 2098, 293, 2299, 11, 5662, 14024, 13, 400, 1184, 295, 729, 6565], "temperature": 0.0, "avg_logprob": -0.15034893883599176, "compression_ratio": 1.328358208955224, "no_speech_prob": 0.00012630526907742023}, {"id": 12, "seek": 7752, "start": 87.39999999999999, "end": 102.64, "text": " can have tags. Tags are pairs of keys and values. I've got some examples here for my", "tokens": [393, 362, 18632, 13, 11204, 82, 366, 15494, 295, 9317, 293, 4190, 13, 286, 600, 658, 512, 5110, 510, 337, 452], "temperature": 0.0, "avg_logprob": -0.15034893883599176, "compression_ratio": 1.328358208955224, "no_speech_prob": 0.00012630526907742023}, {"id": 13, "seek": 10264, "start": 102.64, "end": 108.0, "text": " example in Brussels. And the tags are not controlled by the software. You can put anything", "tokens": [1365, 294, 38717, 13, 400, 264, 18632, 366, 406, 10164, 538, 264, 4722, 13, 509, 393, 829, 1340], "temperature": 0.0, "avg_logprob": -0.1177651376435251, "compression_ratio": 1.6205357142857142, "no_speech_prob": 0.00011870910384459421}, {"id": 14, "seek": 10264, "start": 108.0, "end": 114.24, "text": " you want in, but it won't get rendered on the map unless it's one of the standard tags", "tokens": [291, 528, 294, 11, 457, 309, 1582, 380, 483, 28748, 322, 264, 4471, 5969, 309, 311, 472, 295, 264, 3832, 18632], "temperature": 0.0, "avg_logprob": -0.1177651376435251, "compression_ratio": 1.6205357142857142, "no_speech_prob": 0.00011870910384459421}, {"id": 15, "seek": 10264, "start": 114.24, "end": 119.76, "text": " that gets used on OpenStreetMap. So, there's a community process for discussing, you know,", "tokens": [300, 2170, 1143, 322, 7238, 50, 3599, 302, 44, 569, 13, 407, 11, 456, 311, 257, 1768, 1399, 337, 10850, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.1177651376435251, "compression_ratio": 1.6205357142857142, "no_speech_prob": 0.00011870910384459421}, {"id": 16, "seek": 10264, "start": 119.76, "end": 125.28, "text": " how things should be tagged in OpenStreetMap, and then it gets documented on the OpenStreetMap", "tokens": [577, 721, 820, 312, 40239, 294, 7238, 50, 3599, 302, 44, 569, 11, 293, 550, 309, 2170, 23007, 322, 264, 7238, 50, 3599, 302, 44, 569], "temperature": 0.0, "avg_logprob": -0.1177651376435251, "compression_ratio": 1.6205357142857142, "no_speech_prob": 0.00011870910384459421}, {"id": 17, "seek": 12528, "start": 125.28, "end": 133.0, "text": " wiki. So, everything in OpenStreetMap can be uniquely identified by the type and the", "tokens": [261, 9850, 13, 407, 11, 1203, 294, 7238, 50, 3599, 302, 44, 569, 393, 312, 31474, 9234, 538, 264, 2010, 293, 264], "temperature": 0.0, "avg_logprob": -0.13555217511726148, "compression_ratio": 1.5753424657534247, "no_speech_prob": 0.00017519462562631816}, {"id": 18, "seek": 12528, "start": 133.0, "end": 139.24, "text": " ID. Like the ID on its own isn't enough. There's nodes and ways that have got the same", "tokens": [7348, 13, 1743, 264, 7348, 322, 1080, 1065, 1943, 380, 1547, 13, 821, 311, 13891, 293, 2098, 300, 362, 658, 264, 912], "temperature": 0.0, "avg_logprob": -0.13555217511726148, "compression_ratio": 1.5753424657534247, "no_speech_prob": 0.00017519462562631816}, {"id": 19, "seek": 12528, "start": 139.24, "end": 145.4, "text": " ID. You have to have the type as well. So, in this example, the Royal Palace, you can", "tokens": [7348, 13, 509, 362, 281, 362, 264, 2010, 382, 731, 13, 407, 11, 294, 341, 1365, 11, 264, 12717, 19121, 11, 291, 393], "temperature": 0.0, "avg_logprob": -0.13555217511726148, "compression_ratio": 1.5753424657534247, "no_speech_prob": 0.00017519462562631816}, {"id": 20, "seek": 12528, "start": 145.4, "end": 151.12, "text": " see it's a relation. It's a complex polygon. You can see there's holes in the middle of", "tokens": [536, 309, 311, 257, 9721, 13, 467, 311, 257, 3997, 48242, 13, 509, 393, 536, 456, 311, 8118, 294, 264, 2808, 295], "temperature": 0.0, "avg_logprob": -0.13555217511726148, "compression_ratio": 1.5753424657534247, "no_speech_prob": 0.00017519462562631816}, {"id": 21, "seek": 15112, "start": 151.12, "end": 155.64000000000001, "text": " the building, so you can't represent it as a way. And you can see there it's got an", "tokens": [264, 2390, 11, 370, 291, 393, 380, 2906, 309, 382, 257, 636, 13, 400, 291, 393, 536, 456, 309, 311, 658, 364], "temperature": 0.0, "avg_logprob": -0.18283973693847655, "compression_ratio": 1.5087719298245614, "no_speech_prob": 0.00016375997802242637}, {"id": 22, "seek": 15112, "start": 155.64000000000001, "end": 164.44, "text": " ID as well. So, what about the other system I'm talking about? Wiki data. So, wiki data", "tokens": [7348, 382, 731, 13, 407, 11, 437, 466, 264, 661, 1185, 286, 478, 1417, 466, 30, 343, 9850, 1412, 13, 407, 11, 261, 9850, 1412], "temperature": 0.0, "avg_logprob": -0.18283973693847655, "compression_ratio": 1.5087719298245614, "no_speech_prob": 0.00016375997802242637}, {"id": 23, "seek": 15112, "start": 164.44, "end": 175.04000000000002, "text": " is part of the Wikimedia Foundation, like the same people that run Wikipedia. And it's", "tokens": [307, 644, 295, 264, 23377, 332, 14212, 10335, 11, 411, 264, 912, 561, 300, 1190, 28999, 13, 400, 309, 311], "temperature": 0.0, "avg_logprob": -0.18283973693847655, "compression_ratio": 1.5087719298245614, "no_speech_prob": 0.00016375997802242637}, {"id": 24, "seek": 17504, "start": 175.04, "end": 182.23999999999998, "text": " a wiki for structured data. It's newer than OpenStreetMap 2012. It launched, and it's", "tokens": [257, 261, 9850, 337, 18519, 1412, 13, 467, 311, 17628, 813, 7238, 50, 3599, 302, 44, 569, 9125, 13, 467, 8730, 11, 293, 309, 311], "temperature": 0.0, "avg_logprob": -0.1621091365814209, "compression_ratio": 1.610091743119266, "no_speech_prob": 0.0001888861443148926}, {"id": 25, "seek": 17504, "start": 182.23999999999998, "end": 188.07999999999998, "text": " big. Like, it's got 102 million items now. And for comparison, English Wikipedia has", "tokens": [955, 13, 1743, 11, 309, 311, 658, 45937, 2459, 4754, 586, 13, 400, 337, 9660, 11, 3669, 28999, 575], "temperature": 0.0, "avg_logprob": -0.1621091365814209, "compression_ratio": 1.610091743119266, "no_speech_prob": 0.0001888861443148926}, {"id": 26, "seek": 17504, "start": 188.07999999999998, "end": 193.56, "text": " 6.6 million articles. Like, English Wikipedia is the biggest Wikipedia. And most of those", "tokens": [1386, 13, 21, 2459, 11290, 13, 1743, 11, 3669, 28999, 307, 264, 3880, 28999, 13, 400, 881, 295, 729], "temperature": 0.0, "avg_logprob": -0.1621091365814209, "compression_ratio": 1.610091743119266, "no_speech_prob": 0.0001888861443148926}, {"id": 27, "seek": 17504, "start": 193.56, "end": 199.92, "text": " articles have a wiki data item as well. But then there's a lot more data, a lot more items", "tokens": [11290, 362, 257, 261, 9850, 1412, 3174, 382, 731, 13, 583, 550, 456, 311, 257, 688, 544, 1412, 11, 257, 688, 544, 4754], "temperature": 0.0, "avg_logprob": -0.1621091365814209, "compression_ratio": 1.610091743119266, "no_speech_prob": 0.0001888861443148926}, {"id": 28, "seek": 19992, "start": 199.92, "end": 208.44, "text": " in wiki data than there are articles in English Wikipedia. So, if I take my example of the", "tokens": [294, 261, 9850, 1412, 813, 456, 366, 11290, 294, 3669, 28999, 13, 407, 11, 498, 286, 747, 452, 1365, 295, 264], "temperature": 0.0, "avg_logprob": -0.11365007360776265, "compression_ratio": 1.7450980392156863, "no_speech_prob": 0.000112374902528245}, {"id": 29, "seek": 19992, "start": 208.44, "end": 212.6, "text": " Royal Palace of Brussels, and you look it up on English Wikipedia, you can see there's", "tokens": [12717, 19121, 295, 38717, 11, 293, 291, 574, 309, 493, 322, 3669, 28999, 11, 291, 393, 536, 456, 311], "temperature": 0.0, "avg_logprob": -0.11365007360776265, "compression_ratio": 1.7450980392156863, "no_speech_prob": 0.000112374902528245}, {"id": 30, "seek": 19992, "start": 212.6, "end": 218.88, "text": " a link in the sidebar that will take you to the wiki data item. And you click that link,", "tokens": [257, 2113, 294, 264, 1252, 5356, 300, 486, 747, 291, 281, 264, 261, 9850, 1412, 3174, 13, 400, 291, 2052, 300, 2113, 11], "temperature": 0.0, "avg_logprob": -0.11365007360776265, "compression_ratio": 1.7450980392156863, "no_speech_prob": 0.000112374902528245}, {"id": 31, "seek": 19992, "start": 218.88, "end": 226.0, "text": " you end up on the, this is the wiki data item for the Royal Palace. I'll talk you through", "tokens": [291, 917, 493, 322, 264, 11, 341, 307, 264, 261, 9850, 1412, 3174, 337, 264, 12717, 19121, 13, 286, 603, 751, 291, 807], "temperature": 0.0, "avg_logprob": -0.11365007360776265, "compression_ratio": 1.7450980392156863, "no_speech_prob": 0.000112374902528245}, {"id": 32, "seek": 22600, "start": 226.0, "end": 232.12, "text": " some of the pieces on this page. So, you've got, down the side, the site links. These", "tokens": [512, 295, 264, 3755, 322, 341, 3028, 13, 407, 11, 291, 600, 658, 11, 760, 264, 1252, 11, 264, 3621, 6123, 13, 1981], "temperature": 0.0, "avg_logprob": -0.16216847101847331, "compression_ratio": 1.7365853658536585, "no_speech_prob": 0.0001625376899028197}, {"id": 33, "seek": 22600, "start": 232.12, "end": 239.44, "text": " are links to Wikipedia articles in different languages. Like, part of the reason for the", "tokens": [366, 6123, 281, 28999, 11290, 294, 819, 8650, 13, 1743, 11, 644, 295, 264, 1778, 337, 264], "temperature": 0.0, "avg_logprob": -0.16216847101847331, "compression_ratio": 1.7365853658536585, "no_speech_prob": 0.0001625376899028197}, {"id": 34, "seek": 22600, "start": 239.44, "end": 247.24, "text": " distance of wiki data is to store these, they call them inter-language links. They used", "tokens": [4560, 295, 261, 9850, 1412, 307, 281, 3531, 613, 11, 436, 818, 552, 728, 12, 25241, 20473, 6123, 13, 814, 1143], "temperature": 0.0, "avg_logprob": -0.16216847101847331, "compression_ratio": 1.7365853658536585, "no_speech_prob": 0.0001625376899028197}, {"id": 35, "seek": 22600, "start": 247.24, "end": 253.32, "text": " to be stored in Wikipedia and had to be maintained across all the different languages. So, if", "tokens": [281, 312, 12187, 294, 28999, 293, 632, 281, 312, 17578, 2108, 439, 264, 819, 8650, 13, 407, 11, 498], "temperature": 0.0, "avg_logprob": -0.16216847101847331, "compression_ratio": 1.7365853658536585, "no_speech_prob": 0.0001625376899028197}, {"id": 36, "seek": 25332, "start": 253.32, "end": 260.32, "text": " there was a new article written in a new language, every existing article in one of the existing", "tokens": [456, 390, 257, 777, 7222, 3720, 294, 257, 777, 2856, 11, 633, 6741, 7222, 294, 472, 295, 264, 6741], "temperature": 0.0, "avg_logprob": -0.13673647830360813, "compression_ratio": 1.6787330316742082, "no_speech_prob": 0.00016038029571063817}, {"id": 37, "seek": 25332, "start": 260.32, "end": 264.8, "text": " languages had to be updated with these links. So, much better to centralize them and store", "tokens": [8650, 632, 281, 312, 10588, 365, 613, 6123, 13, 407, 11, 709, 1101, 281, 5777, 1125, 552, 293, 3531], "temperature": 0.0, "avg_logprob": -0.13673647830360813, "compression_ratio": 1.6787330316742082, "no_speech_prob": 0.00016038029571063817}, {"id": 38, "seek": 25332, "start": 264.8, "end": 272.84, "text": " them in wiki data instead. All the bits and pieces you get on this page, you get a label,", "tokens": [552, 294, 261, 9850, 1412, 2602, 13, 1057, 264, 9239, 293, 3755, 291, 483, 322, 341, 3028, 11, 291, 483, 257, 7645, 11], "temperature": 0.0, "avg_logprob": -0.13673647830360813, "compression_ratio": 1.6787330316742082, "no_speech_prob": 0.00016038029571063817}, {"id": 39, "seek": 25332, "start": 272.84, "end": 280.2, "text": " description and aliases. So, by default, when I look at wiki data, I just see them in English", "tokens": [3855, 293, 10198, 1957, 13, 407, 11, 538, 7576, 11, 562, 286, 574, 412, 261, 9850, 1412, 11, 286, 445, 536, 552, 294, 3669], "temperature": 0.0, "avg_logprob": -0.13673647830360813, "compression_ratio": 1.6787330316742082, "no_speech_prob": 0.00016038029571063817}, {"id": 40, "seek": 28020, "start": 280.2, "end": 286.88, "text": " because that's the language I speak. But I can click the link to show me in more languages", "tokens": [570, 300, 311, 264, 2856, 286, 1710, 13, 583, 286, 393, 2052, 264, 2113, 281, 855, 385, 294, 544, 8650], "temperature": 0.0, "avg_logprob": -0.13417598765383484, "compression_ratio": 1.6457399103139014, "no_speech_prob": 0.00021804458810947835}, {"id": 41, "seek": 28020, "start": 286.88, "end": 294.0, "text": " and you can see that there's names of the thing available in lots of languages and descriptions", "tokens": [293, 291, 393, 536, 300, 456, 311, 5288, 295, 264, 551, 2435, 294, 3195, 295, 8650, 293, 24406], "temperature": 0.0, "avg_logprob": -0.13417598765383484, "compression_ratio": 1.6457399103139014, "no_speech_prob": 0.00021804458810947835}, {"id": 42, "seek": 28020, "start": 294.0, "end": 303.0, "text": " and so on. The other main part of this page you see is the list of statements. So, statements", "tokens": [293, 370, 322, 13, 440, 661, 2135, 644, 295, 341, 3028, 291, 536, 307, 264, 1329, 295, 12363, 13, 407, 11, 12363], "temperature": 0.0, "avg_logprob": -0.13417598765383484, "compression_ratio": 1.6457399103139014, "no_speech_prob": 0.00021804458810947835}, {"id": 43, "seek": 28020, "start": 303.0, "end": 307.12, "text": " are a bit like tags in OpenStreetMap, but they're more controlled by the software. You", "tokens": [366, 257, 857, 411, 18632, 294, 7238, 50, 3599, 302, 44, 569, 11, 457, 436, 434, 544, 10164, 538, 264, 4722, 13, 509], "temperature": 0.0, "avg_logprob": -0.13417598765383484, "compression_ratio": 1.6457399103139014, "no_speech_prob": 0.00021804458810947835}, {"id": 44, "seek": 30712, "start": 307.12, "end": 314.76, "text": " can't just make up a property. You have to use ones that are already in the system. And", "tokens": [393, 380, 445, 652, 493, 257, 4707, 13, 509, 362, 281, 764, 2306, 300, 366, 1217, 294, 264, 1185, 13, 400], "temperature": 0.0, "avg_logprob": -0.1323453882238367, "compression_ratio": 1.655813953488372, "no_speech_prob": 0.0002058671962004155}, {"id": 45, "seek": 30712, "start": 314.76, "end": 320.2, "text": " again, there's a community process in wiki data for determining new properties. And the", "tokens": [797, 11, 456, 311, 257, 1768, 1399, 294, 261, 9850, 1412, 337, 23751, 777, 7221, 13, 400, 264], "temperature": 0.0, "avg_logprob": -0.1323453882238367, "compression_ratio": 1.655813953488372, "no_speech_prob": 0.0002058671962004155}, {"id": 46, "seek": 30712, "start": 320.2, "end": 325.2, "text": " other big difference is that there's different data types. Like in OpenStreetMap, everything", "tokens": [661, 955, 2649, 307, 300, 456, 311, 819, 1412, 3467, 13, 1743, 294, 7238, 50, 3599, 302, 44, 569, 11, 1203], "temperature": 0.0, "avg_logprob": -0.1323453882238367, "compression_ratio": 1.655813953488372, "no_speech_prob": 0.0002058671962004155}, {"id": 47, "seek": 30712, "start": 325.2, "end": 330.36, "text": " is a string, but wiki data has different data types of values. Here you can see there's", "tokens": [307, 257, 6798, 11, 457, 261, 9850, 1412, 575, 819, 1412, 3467, 295, 4190, 13, 1692, 291, 393, 536, 456, 311], "temperature": 0.0, "avg_logprob": -0.1323453882238367, "compression_ratio": 1.655813953488372, "no_speech_prob": 0.0002058671962004155}, {"id": 48, "seek": 33036, "start": 330.36, "end": 338.36, "text": " an image and there's also a link to another item used as values in the statements.", "tokens": [364, 3256, 293, 456, 311, 611, 257, 2113, 281, 1071, 3174, 1143, 382, 4190, 294, 264, 12363, 13], "temperature": 0.0, "avg_logprob": -0.1377633338750795, "compression_ratio": 1.6, "no_speech_prob": 0.0003198536578565836}, {"id": 49, "seek": 33036, "start": 338.36, "end": 344.44, "text": " So the interesting in terms of maps is wiki data has got coordinate locations. There's", "tokens": [407, 264, 1880, 294, 2115, 295, 11317, 307, 261, 9850, 1412, 575, 658, 15670, 9253, 13, 821, 311], "temperature": 0.0, "avg_logprob": -0.1377633338750795, "compression_ratio": 1.6, "no_speech_prob": 0.0003198536578565836}, {"id": 50, "seek": 33036, "start": 344.44, "end": 350.40000000000003, "text": " almost 10 million items with coordinates. So those are the kinds of things that we're", "tokens": [1920, 1266, 2459, 4754, 365, 21056, 13, 407, 729, 366, 264, 3685, 295, 721, 300, 321, 434], "temperature": 0.0, "avg_logprob": -0.1377633338750795, "compression_ratio": 1.6, "no_speech_prob": 0.0003198536578565836}, {"id": 51, "seek": 33036, "start": 350.40000000000003, "end": 358.28000000000003, "text": " interested in and will probably be on OpenStreetMap as well. And there is a property for storing", "tokens": [3102, 294, 293, 486, 1391, 312, 322, 7238, 50, 3599, 302, 44, 569, 382, 731, 13, 400, 456, 307, 257, 4707, 337, 26085], "temperature": 0.0, "avg_logprob": -0.1377633338750795, "compression_ratio": 1.6, "no_speech_prob": 0.0003198536578565836}, {"id": 52, "seek": 35828, "start": 358.28, "end": 365.2, "text": " geo-shapes in wiki data, but it's quite new and it's not used so much. There's only 29,000", "tokens": [43198, 12, 2716, 569, 279, 294, 261, 9850, 1412, 11, 457, 309, 311, 1596, 777, 293, 309, 311, 406, 1143, 370, 709, 13, 821, 311, 787, 9413, 11, 1360], "temperature": 0.0, "avg_logprob": -0.16745464618389422, "compression_ratio": 1.4555555555555555, "no_speech_prob": 0.00019186417921446264}, {"id": 53, "seek": 35828, "start": 365.2, "end": 375.15999999999997, "text": " odd items with a geo-shape. So, you know, it's mostly about the coordinates. So the", "tokens": [7401, 4754, 365, 257, 43198, 12, 82, 42406, 13, 407, 11, 291, 458, 11, 309, 311, 5240, 466, 264, 21056, 13, 407, 264], "temperature": 0.0, "avg_logprob": -0.16745464618389422, "compression_ratio": 1.4555555555555555, "no_speech_prob": 0.00019186417921446264}, {"id": 54, "seek": 35828, "start": 375.15999999999997, "end": 379.96, "text": " thing that I'm interested in is adding links between the systems. So if we have another", "tokens": [551, 300, 286, 478, 3102, 294, 307, 5127, 6123, 1296, 264, 3652, 13, 407, 498, 321, 362, 1071], "temperature": 0.0, "avg_logprob": -0.16745464618389422, "compression_ratio": 1.4555555555555555, "no_speech_prob": 0.00019186417921446264}, {"id": 55, "seek": 37996, "start": 379.96, "end": 388.68, "text": " look at OpenStreetMap, I've got highlighted here one of the tags for the palace and it's", "tokens": [574, 412, 7238, 50, 3599, 302, 44, 569, 11, 286, 600, 658, 17173, 510, 472, 295, 264, 18632, 337, 264, 15207, 293, 309, 311], "temperature": 0.0, "avg_logprob": -0.14252026488141314, "compression_ratio": 1.5689655172413792, "no_speech_prob": 0.00010578871297184378}, {"id": 56, "seek": 37996, "start": 388.68, "end": 396.44, "text": " the wiki data tag and it's got a wiki data QID. This is the unique identifier for the", "tokens": [264, 261, 9850, 1412, 6162, 293, 309, 311, 658, 257, 261, 9850, 1412, 1249, 2777, 13, 639, 307, 264, 3845, 45690, 337, 264], "temperature": 0.0, "avg_logprob": -0.14252026488141314, "compression_ratio": 1.5689655172413792, "no_speech_prob": 0.00010578871297184378}, {"id": 57, "seek": 37996, "start": 396.44, "end": 405.24, "text": " wiki data item. So now the two systems are linked. Like if you visit this object on OpenStreetMap,", "tokens": [261, 9850, 1412, 3174, 13, 407, 586, 264, 732, 3652, 366, 9408, 13, 1743, 498, 291, 3441, 341, 2657, 322, 7238, 50, 3599, 302, 44, 569, 11], "temperature": 0.0, "avg_logprob": -0.14252026488141314, "compression_ratio": 1.5689655172413792, "no_speech_prob": 0.00010578871297184378}, {"id": 58, "seek": 40524, "start": 405.24, "end": 413.04, "text": " then the user interface has a hyperlink that will take you to the same thing on wiki data.", "tokens": [550, 264, 4195, 9226, 575, 257, 9848, 22473, 300, 486, 747, 291, 281, 264, 912, 551, 322, 261, 9850, 1412, 13], "temperature": 0.0, "avg_logprob": -0.1107794911253686, "compression_ratio": 1.662037037037037, "no_speech_prob": 7.609502063132823e-05}, {"id": 59, "seek": 40524, "start": 413.04, "end": 420.04, "text": " So why do I want to add links between wiki data and OpenStreetMap? Well, it makes the", "tokens": [407, 983, 360, 286, 528, 281, 909, 6123, 1296, 261, 9850, 1412, 293, 7238, 50, 3599, 302, 44, 569, 30, 1042, 11, 309, 1669, 264], "temperature": 0.0, "avg_logprob": -0.1107794911253686, "compression_ratio": 1.662037037037037, "no_speech_prob": 7.609502063132823e-05}, {"id": 60, "seek": 40524, "start": 420.04, "end": 428.68, "text": " data in OpenStreetMap a lot more useful. Like wiki data tends to have labels in more languages.", "tokens": [1412, 294, 7238, 50, 3599, 302, 44, 569, 257, 688, 544, 4420, 13, 1743, 261, 9850, 1412, 12258, 281, 362, 16949, 294, 544, 8650, 13], "temperature": 0.0, "avg_logprob": -0.1107794911253686, "compression_ratio": 1.662037037037037, "no_speech_prob": 7.609502063132823e-05}, {"id": 61, "seek": 40524, "start": 428.68, "end": 432.52, "text": " Like if you want the name of a thing in a different language, you can get it from wiki", "tokens": [1743, 498, 291, 528, 264, 1315, 295, 257, 551, 294, 257, 819, 2856, 11, 291, 393, 483, 309, 490, 261, 9850], "temperature": 0.0, "avg_logprob": -0.1107794911253686, "compression_ratio": 1.662037037037037, "no_speech_prob": 7.609502063132823e-05}, {"id": 62, "seek": 43252, "start": 432.52, "end": 442.03999999999996, "text": " data. You can link to the wiki preview articles. You get images from commons and identifiers", "tokens": [1412, 13, 509, 393, 2113, 281, 264, 261, 9850, 14281, 11290, 13, 509, 483, 5267, 490, 800, 892, 293, 2473, 23463], "temperature": 0.0, "avg_logprob": -0.17022730598986988, "compression_ratio": 1.6545454545454545, "no_speech_prob": 8.505552250426263e-05}, {"id": 63, "seek": 43252, "start": 442.03999999999996, "end": 449.64, "text": " from other catalogs, data catalogs. So there's wiki media commons is the wiki media location", "tokens": [490, 661, 19746, 82, 11, 1412, 19746, 82, 13, 407, 456, 311, 261, 9850, 3021, 800, 892, 307, 264, 261, 9850, 3021, 4914], "temperature": 0.0, "avg_logprob": -0.17022730598986988, "compression_ratio": 1.6545454545454545, "no_speech_prob": 8.505552250426263e-05}, {"id": 64, "seek": 43252, "start": 449.64, "end": 456.96, "text": " for storing photos of things. So we get loads of photos of our building and we also get", "tokens": [337, 26085, 5787, 295, 721, 13, 407, 321, 483, 12668, 295, 5787, 295, 527, 2390, 293, 321, 611, 483], "temperature": 0.0, "avg_logprob": -0.17022730598986988, "compression_ratio": 1.6545454545454545, "no_speech_prob": 8.505552250426263e-05}, {"id": 65, "seek": 45696, "start": 456.96, "end": 463.56, "text": " lots of identifiers in wiki data. So you can think of wiki data as a bit like the Rosetta", "tokens": [3195, 295, 2473, 23463, 294, 261, 9850, 1412, 13, 407, 291, 393, 519, 295, 261, 9850, 1412, 382, 257, 857, 411, 264, 11144, 16593], "temperature": 0.0, "avg_logprob": -0.11896527067143867, "compression_ratio": 1.6941747572815533, "no_speech_prob": 4.722226003650576e-05}, {"id": 66, "seek": 45696, "start": 463.56, "end": 472.03999999999996, "text": " Stone of linking different data catalogs. It makes sense to store all this information", "tokens": [15012, 295, 25775, 819, 1412, 19746, 82, 13, 467, 1669, 2020, 281, 3531, 439, 341, 1589], "temperature": 0.0, "avg_logprob": -0.11896527067143867, "compression_ratio": 1.6941747572815533, "no_speech_prob": 4.722226003650576e-05}, {"id": 67, "seek": 45696, "start": 472.03999999999996, "end": 479.96, "text": " in one place. So why not use wiki data as that place for storing this kind of info?", "tokens": [294, 472, 1081, 13, 407, 983, 406, 764, 261, 9850, 1412, 382, 300, 1081, 337, 26085, 341, 733, 295, 13614, 30], "temperature": 0.0, "avg_logprob": -0.11896527067143867, "compression_ratio": 1.6941747572815533, "no_speech_prob": 4.722226003650576e-05}, {"id": 68, "seek": 45696, "start": 479.96, "end": 486.03999999999996, "text": " So this is a good thing. We want to add links. The other thing that you get is wiki data", "tokens": [407, 341, 307, 257, 665, 551, 13, 492, 528, 281, 909, 6123, 13, 440, 661, 551, 300, 291, 483, 307, 261, 9850, 1412], "temperature": 0.0, "avg_logprob": -0.11896527067143867, "compression_ratio": 1.6941747572815533, "no_speech_prob": 4.722226003650576e-05}, {"id": 69, "seek": 48604, "start": 486.04, "end": 492.52000000000004, "text": " gets access to the shapes of things, the polygon outline of the building, which otherwise", "tokens": [2170, 2105, 281, 264, 10854, 295, 721, 11, 264, 48242, 16387, 295, 264, 2390, 11, 597, 5911], "temperature": 0.0, "avg_logprob": -0.1587411273609508, "compression_ratio": 1.5222222222222221, "no_speech_prob": 0.00014055304927751422}, {"id": 70, "seek": 48604, "start": 492.52000000000004, "end": 500.08000000000004, "text": " it wouldn't have without a link. So adding these links by hand is kind of laborious and", "tokens": [309, 2759, 380, 362, 1553, 257, 2113, 13, 407, 5127, 613, 6123, 538, 1011, 307, 733, 295, 5938, 851, 293], "temperature": 0.0, "avg_logprob": -0.1587411273609508, "compression_ratio": 1.5222222222222221, "no_speech_prob": 0.00014055304927751422}, {"id": 71, "seek": 48604, "start": 500.08000000000004, "end": 507.28000000000003, "text": " time consuming. So better to write some software to do it instead. So the software I've written,", "tokens": [565, 19867, 13, 407, 1101, 281, 2464, 512, 4722, 281, 360, 309, 2602, 13, 407, 264, 4722, 286, 600, 3720, 11], "temperature": 0.0, "avg_logprob": -0.1587411273609508, "compression_ratio": 1.5222222222222221, "no_speech_prob": 0.00014055304927751422}, {"id": 72, "seek": 50728, "start": 507.28, "end": 518.52, "text": " I'm calling it awl places and the web address is osm.wiki.data.link. So this is what the", "tokens": [286, 478, 5141, 309, 1714, 75, 3190, 293, 264, 3670, 2985, 307, 3003, 76, 13, 86, 9850, 13, 67, 3274, 13, 22473, 13, 407, 341, 307, 437, 264], "temperature": 0.0, "avg_logprob": -0.15788626352945964, "compression_ratio": 1.5375722543352601, "no_speech_prob": 4.813308987650089e-05}, {"id": 73, "seek": 50728, "start": 518.52, "end": 524.6, "text": " software looks like when you visit it. It asks you for a place name where you want to", "tokens": [4722, 1542, 411, 562, 291, 3441, 309, 13, 467, 8962, 291, 337, 257, 1081, 1315, 689, 291, 528, 281], "temperature": 0.0, "avg_logprob": -0.15788626352945964, "compression_ratio": 1.5375722543352601, "no_speech_prob": 4.813308987650089e-05}, {"id": 74, "seek": 50728, "start": 524.6, "end": 530.1999999999999, "text": " search for some matches. So you can put in the name of your town, somewhere you're familiar", "tokens": [3164, 337, 512, 10676, 13, 407, 291, 393, 829, 294, 264, 1315, 295, 428, 3954, 11, 4079, 291, 434, 4963], "temperature": 0.0, "avg_logprob": -0.15788626352945964, "compression_ratio": 1.5375722543352601, "no_speech_prob": 4.813308987650089e-05}, {"id": 75, "seek": 53020, "start": 530.2, "end": 539.36, "text": " with and can check that the matches are valid. So I've done a search and I've found the place", "tokens": [365, 293, 393, 1520, 300, 264, 10676, 366, 7363, 13, 407, 286, 600, 1096, 257, 3164, 293, 286, 600, 1352, 264, 1081], "temperature": 0.0, "avg_logprob": -0.13712621771770975, "compression_ratio": 1.5340909090909092, "no_speech_prob": 3.521688631735742e-05}, {"id": 76, "seek": 53020, "start": 539.36, "end": 546.2, "text": " where the Royal Palace is located. And this is the page you see. You've got a map with", "tokens": [689, 264, 12717, 19121, 307, 6870, 13, 400, 341, 307, 264, 3028, 291, 536, 13, 509, 600, 658, 257, 4471, 365], "temperature": 0.0, "avg_logprob": -0.13712621771770975, "compression_ratio": 1.5340909090909092, "no_speech_prob": 3.521688631735742e-05}, {"id": 77, "seek": 53020, "start": 546.2, "end": 553.44, "text": " some blue pins. And these blue pins represent wiki data items that the software has found", "tokens": [512, 3344, 16392, 13, 400, 613, 3344, 16392, 2906, 261, 9850, 1412, 4754, 300, 264, 4722, 575, 1352], "temperature": 0.0, "avg_logprob": -0.13712621771770975, "compression_ratio": 1.5340909090909092, "no_speech_prob": 3.521688631735742e-05}, {"id": 78, "seek": 55344, "start": 553.44, "end": 560.6400000000001, "text": " something that matches OpenStreetMap. So if I scroll down this page, you can see some", "tokens": [746, 300, 10676, 7238, 50, 3599, 302, 44, 569, 13, 407, 498, 286, 11369, 760, 341, 3028, 11, 291, 393, 536, 512], "temperature": 0.0, "avg_logprob": -0.1006314937884991, "compression_ratio": 1.6233183856502242, "no_speech_prob": 8.597224950790405e-05}, {"id": 79, "seek": 55344, "start": 560.6400000000001, "end": 570.8800000000001, "text": " example matches. So I show you various bits of data that come from wiki data and wikipedia", "tokens": [1365, 10676, 13, 407, 286, 855, 291, 3683, 9239, 295, 1412, 300, 808, 490, 261, 9850, 1412, 293, 261, 1035, 26633], "temperature": 0.0, "avg_logprob": -0.1006314937884991, "compression_ratio": 1.6233183856502242, "no_speech_prob": 8.597224950790405e-05}, {"id": 80, "seek": 55344, "start": 570.8800000000001, "end": 576.6800000000001, "text": " to help you try and identify if these matches are valid. Like sometimes the software doesn't", "tokens": [281, 854, 291, 853, 293, 5876, 498, 613, 10676, 366, 7363, 13, 1743, 2171, 264, 4722, 1177, 380], "temperature": 0.0, "avg_logprob": -0.1006314937884991, "compression_ratio": 1.6233183856502242, "no_speech_prob": 8.597224950790405e-05}, {"id": 81, "seek": 55344, "start": 576.6800000000001, "end": 582.6, "text": " get it right and will give you an invalid match. So it's important to look through this list", "tokens": [483, 309, 558, 293, 486, 976, 291, 364, 34702, 2995, 13, 407, 309, 311, 1021, 281, 574, 807, 341, 1329], "temperature": 0.0, "avg_logprob": -0.1006314937884991, "compression_ratio": 1.6233183856502242, "no_speech_prob": 8.597224950790405e-05}, {"id": 82, "seek": 58260, "start": 582.6, "end": 590.24, "text": " and check that all the matches are correct. And to help you with that, I show you the", "tokens": [293, 1520, 300, 439, 264, 10676, 366, 3006, 13, 400, 281, 854, 291, 365, 300, 11, 286, 855, 291, 264], "temperature": 0.0, "avg_logprob": -0.12903628629796646, "compression_ratio": 1.572289156626506, "no_speech_prob": 6.869410572107881e-05}, {"id": 83, "seek": 58260, "start": 590.24, "end": 598.12, "text": " first paragraph from the wikipedia article and I show you any images that come from wiki", "tokens": [700, 18865, 490, 264, 261, 1035, 26633, 7222, 293, 286, 855, 291, 604, 5267, 300, 808, 490, 261, 9850], "temperature": 0.0, "avg_logprob": -0.12903628629796646, "compression_ratio": 1.572289156626506, "no_speech_prob": 6.869410572107881e-05}, {"id": 84, "seek": 58260, "start": 598.12, "end": 606.5600000000001, "text": " data. You've got the wiki data description there. The paragraphs I show you, I'll talk", "tokens": [1412, 13, 509, 600, 658, 264, 261, 9850, 1412, 3855, 456, 13, 440, 48910, 286, 855, 291, 11, 286, 603, 751], "temperature": 0.0, "avg_logprob": -0.12903628629796646, "compression_ratio": 1.572289156626506, "no_speech_prob": 6.869410572107881e-05}, {"id": 85, "seek": 60656, "start": 606.56, "end": 614.9599999999999, "text": " later about how it decides which languages to use for showing those. But it supports", "tokens": [1780, 466, 577, 309, 14898, 597, 8650, 281, 764, 337, 4099, 729, 13, 583, 309, 9346], "temperature": 0.0, "avg_logprob": -0.12216954761081272, "compression_ratio": 1.5972850678733033, "no_speech_prob": 0.00010826219659065828}, {"id": 86, "seek": 60656, "start": 614.9599999999999, "end": 621.56, "text": " various languages. And then it shows you some of the details from OpenStreetMap just so", "tokens": [3683, 8650, 13, 400, 550, 309, 3110, 291, 512, 295, 264, 4365, 490, 7238, 50, 3599, 302, 44, 569, 445, 370], "temperature": 0.0, "avg_logprob": -0.12216954761081272, "compression_ratio": 1.5972850678733033, "no_speech_prob": 0.00010826219659065828}, {"id": 87, "seek": 60656, "start": 621.56, "end": 628.4, "text": " you can compare and make sure that they match. So if I click on one of those, then it will", "tokens": [291, 393, 6794, 293, 652, 988, 300, 436, 2995, 13, 407, 498, 286, 2052, 322, 472, 295, 729, 11, 550, 309, 486], "temperature": 0.0, "avg_logprob": -0.12216954761081272, "compression_ratio": 1.5972850678733033, "no_speech_prob": 0.00010826219659065828}, {"id": 88, "seek": 60656, "start": 628.4, "end": 636.3199999999999, "text": " zoom in on the map and it shows you the polygon outline of the thing. You can see the red", "tokens": [8863, 294, 322, 264, 4471, 293, 309, 3110, 291, 264, 48242, 16387, 295, 264, 551, 13, 509, 393, 536, 264, 2182], "temperature": 0.0, "avg_logprob": -0.12216954761081272, "compression_ratio": 1.5972850678733033, "no_speech_prob": 0.00010826219659065828}, {"id": 89, "seek": 63632, "start": 636.32, "end": 641.2800000000001, "text": " pin there is the selected thing. So that looks like a pretty good match. It's probably the", "tokens": [5447, 456, 307, 264, 8209, 551, 13, 407, 300, 1542, 411, 257, 1238, 665, 2995, 13, 467, 311, 1391, 264], "temperature": 0.0, "avg_logprob": -0.13914906248754386, "compression_ratio": 1.6396396396396395, "no_speech_prob": 0.0001811709807952866}, {"id": 90, "seek": 63632, "start": 641.2800000000001, "end": 647.6, "text": " same thing. So we can go ahead and save that. So we're interested in saving these matches", "tokens": [912, 551, 13, 407, 321, 393, 352, 2286, 293, 3155, 300, 13, 407, 321, 434, 3102, 294, 6816, 613, 10676], "temperature": 0.0, "avg_logprob": -0.13914906248754386, "compression_ratio": 1.6396396396396395, "no_speech_prob": 0.0001811709807952866}, {"id": 91, "seek": 63632, "start": 647.6, "end": 655.8000000000001, "text": " to OpenStreetMap. So the software has a button that lets us log in via OpenStreetMap by OAuth.", "tokens": [281, 7238, 50, 3599, 302, 44, 569, 13, 407, 264, 4722, 575, 257, 2960, 300, 6653, 505, 3565, 294, 5766, 7238, 50, 3599, 302, 44, 569, 538, 48424, 2910, 13], "temperature": 0.0, "avg_logprob": -0.13914906248754386, "compression_ratio": 1.6396396396396395, "no_speech_prob": 0.0001811709807952866}, {"id": 92, "seek": 63632, "start": 655.8000000000001, "end": 661.6, "text": " Just put in username and password and log in. And then you come back to the confirmation", "tokens": [1449, 829, 294, 30351, 293, 11524, 293, 3565, 294, 13, 400, 550, 291, 808, 646, 281, 264, 21871], "temperature": 0.0, "avg_logprob": -0.13914906248754386, "compression_ratio": 1.6396396396396395, "no_speech_prob": 0.0001811709807952866}, {"id": 93, "seek": 66160, "start": 661.6, "end": 668.0, "text": " page where you just see the same list again but kind of abbreviated. These are things", "tokens": [3028, 689, 291, 445, 536, 264, 912, 1329, 797, 457, 733, 295, 35839, 770, 13, 1981, 366, 721], "temperature": 0.0, "avg_logprob": -0.13514170927159927, "compression_ratio": 1.6359447004608294, "no_speech_prob": 0.0003590758133213967}, {"id": 94, "seek": 66160, "start": 668.0, "end": 673.52, "text": " that I've checked and I've said yes, these are valid matches and I want to save them.", "tokens": [300, 286, 600, 10033, 293, 286, 600, 848, 2086, 11, 613, 366, 7363, 10676, 293, 286, 528, 281, 3155, 552, 13], "temperature": 0.0, "avg_logprob": -0.13514170927159927, "compression_ratio": 1.6359447004608294, "no_speech_prob": 0.0003590758133213967}, {"id": 95, "seek": 66160, "start": 673.52, "end": 678.52, "text": " You can put a change comment. So everything gets saved together as one change set like", "tokens": [509, 393, 829, 257, 1319, 2871, 13, 407, 1203, 2170, 6624, 1214, 382, 472, 1319, 992, 411], "temperature": 0.0, "avg_logprob": -0.13514170927159927, "compression_ratio": 1.6359447004608294, "no_speech_prob": 0.0003590758133213967}, {"id": 96, "seek": 66160, "start": 678.52, "end": 686.32, "text": " it goes in as a single edit. And the change comment on the change set is generated automatically", "tokens": [309, 1709, 294, 382, 257, 2167, 8129, 13, 400, 264, 1319, 2871, 322, 264, 1319, 992, 307, 10833, 6772], "temperature": 0.0, "avg_logprob": -0.13514170927159927, "compression_ratio": 1.6359447004608294, "no_speech_prob": 0.0003590758133213967}, {"id": 97, "seek": 68632, "start": 686.32, "end": 695.0, "text": " based on the location but you can change it if you want to. So I'll carry on with describing", "tokens": [2361, 322, 264, 4914, 457, 291, 393, 1319, 309, 498, 291, 528, 281, 13, 407, 286, 603, 3985, 322, 365, 16141], "temperature": 0.0, "avg_logprob": -0.1369870768653022, "compression_ratio": 1.6104651162790697, "no_speech_prob": 0.00015941515448503196}, {"id": 98, "seek": 68632, "start": 695.0, "end": 700.72, "text": " the software and I'll show you some more features that I've built. So I've added a type filter", "tokens": [264, 4722, 293, 286, 603, 855, 291, 512, 544, 4122, 300, 286, 600, 3094, 13, 407, 286, 600, 3869, 257, 2010, 6608], "temperature": 0.0, "avg_logprob": -0.1369870768653022, "compression_ratio": 1.6104651162790697, "no_speech_prob": 0.00015941515448503196}, {"id": 99, "seek": 68632, "start": 700.72, "end": 707.24, "text": " like at the top here you can see it's a type filter and there's a list of different types", "tokens": [411, 412, 264, 1192, 510, 291, 393, 536, 309, 311, 257, 2010, 6608, 293, 456, 311, 257, 1329, 295, 819, 3467], "temperature": 0.0, "avg_logprob": -0.1369870768653022, "compression_ratio": 1.6104651162790697, "no_speech_prob": 0.00015941515448503196}, {"id": 100, "seek": 70724, "start": 707.24, "end": 717.28, "text": " of things that it's found that are possible matches. So it's got statues and buildings.", "tokens": [295, 721, 300, 309, 311, 1352, 300, 366, 1944, 10676, 13, 407, 309, 311, 658, 29480, 293, 7446, 13], "temperature": 0.0, "avg_logprob": -0.201677605509758, "compression_ratio": 1.6012269938650308, "no_speech_prob": 9.108513040700927e-05}, {"id": 101, "seek": 70724, "start": 717.28, "end": 723.76, "text": " I can tick a sculpture to say I just want sculptures. And then when I scroll down it", "tokens": [286, 393, 5204, 257, 22972, 281, 584, 286, 445, 528, 37544, 13, 400, 550, 562, 286, 11369, 760, 309], "temperature": 0.0, "avg_logprob": -0.201677605509758, "compression_ratio": 1.6012269938650308, "no_speech_prob": 9.108513040700927e-05}, {"id": 102, "seek": 70724, "start": 723.76, "end": 730.32, "text": " will just show me things that it thinks are sculptures. So I can focus on one particular", "tokens": [486, 445, 855, 385, 721, 300, 309, 7309, 366, 37544, 13, 407, 286, 393, 1879, 322, 472, 1729], "temperature": 0.0, "avg_logprob": -0.201677605509758, "compression_ratio": 1.6012269938650308, "no_speech_prob": 9.108513040700927e-05}, {"id": 103, "seek": 73032, "start": 730.32, "end": 737.2800000000001, "text": " type of thing. Sometimes when you put in the name of a town you might get 200 matches and", "tokens": [2010, 295, 551, 13, 4803, 562, 291, 829, 294, 264, 1315, 295, 257, 3954, 291, 1062, 483, 2331, 10676, 293], "temperature": 0.0, "avg_logprob": -0.11703552669949002, "compression_ratio": 1.610091743119266, "no_speech_prob": 3.159835614496842e-05}, {"id": 104, "seek": 73032, "start": 737.2800000000001, "end": 744.2800000000001, "text": " it's a bit overwhelming to do them all in one go. So it's useful to do them bit by bit", "tokens": [309, 311, 257, 857, 13373, 281, 360, 552, 439, 294, 472, 352, 13, 407, 309, 311, 4420, 281, 360, 552, 857, 538, 857], "temperature": 0.0, "avg_logprob": -0.11703552669949002, "compression_ratio": 1.610091743119266, "no_speech_prob": 3.159835614496842e-05}, {"id": 105, "seek": 73032, "start": 744.2800000000001, "end": 751.2800000000001, "text": " just specific types that you're interested in. And then when I go to the save page it", "tokens": [445, 2685, 3467, 300, 291, 434, 3102, 294, 13, 400, 550, 562, 286, 352, 281, 264, 3155, 3028, 309], "temperature": 0.0, "avg_logprob": -0.11703552669949002, "compression_ratio": 1.610091743119266, "no_speech_prob": 3.159835614496842e-05}, {"id": 106, "seek": 73032, "start": 751.2800000000001, "end": 756.48, "text": " generates a change comment that's based on the type filter that you've selected. So here", "tokens": [23815, 257, 1319, 2871, 300, 311, 2361, 322, 264, 2010, 6608, 300, 291, 600, 8209, 13, 407, 510], "temperature": 0.0, "avg_logprob": -0.11703552669949002, "compression_ratio": 1.610091743119266, "no_speech_prob": 3.159835614496842e-05}, {"id": 107, "seek": 75648, "start": 756.48, "end": 766.2, "text": " it just says add wiki data tags to sculptures in this area. So I'm just going to talk about", "tokens": [309, 445, 1619, 909, 261, 9850, 1412, 18632, 281, 37544, 294, 341, 1859, 13, 407, 286, 478, 445, 516, 281, 751, 466], "temperature": 0.0, "avg_logprob": -0.14618347786568306, "compression_ratio": 1.6666666666666667, "no_speech_prob": 7.070495485095307e-05}, {"id": 108, "seek": 75648, "start": 766.2, "end": 774.84, "text": " how it determines what is a match. So if we have a look at one of these examples this", "tokens": [577, 309, 24799, 437, 307, 257, 2995, 13, 407, 498, 321, 362, 257, 574, 412, 472, 295, 613, 5110, 341], "temperature": 0.0, "avg_logprob": -0.14618347786568306, "compression_ratio": 1.6666666666666667, "no_speech_prob": 7.070495485095307e-05}, {"id": 109, "seek": 75648, "start": 774.84, "end": 783.04, "text": " is a sculpture. So if we have a look at the same thing on wiki data you can see that there's", "tokens": [307, 257, 22972, 13, 407, 498, 321, 362, 257, 574, 412, 264, 912, 551, 322, 261, 9850, 1412, 291, 393, 536, 300, 456, 311], "temperature": 0.0, "avg_logprob": -0.14618347786568306, "compression_ratio": 1.6666666666666667, "no_speech_prob": 7.070495485095307e-05}, {"id": 110, "seek": 78304, "start": 783.04, "end": 788.28, "text": " a statement in wiki data which is the instance of statement. So this is saying that this", "tokens": [257, 5629, 294, 261, 9850, 1412, 597, 307, 264, 5197, 295, 5629, 13, 407, 341, 307, 1566, 300, 341], "temperature": 0.0, "avg_logprob": -0.10920198639826988, "compression_ratio": 1.65, "no_speech_prob": 0.00010553370520938188}, {"id": 111, "seek": 78304, "start": 788.28, "end": 796.56, "text": " thing is a sculpture. So we can click through and have a look at the sculpture page. This", "tokens": [551, 307, 257, 22972, 13, 407, 321, 393, 2052, 807, 293, 362, 257, 574, 412, 264, 22972, 3028, 13, 639], "temperature": 0.0, "avg_logprob": -0.10920198639826988, "compression_ratio": 1.65, "no_speech_prob": 0.00010553370520938188}, {"id": 112, "seek": 78304, "start": 796.56, "end": 804.68, "text": " is the wiki data item for the concept of a sculpture. And then if we scroll down this", "tokens": [307, 264, 261, 9850, 1412, 3174, 337, 264, 3410, 295, 257, 22972, 13, 400, 550, 498, 321, 11369, 760, 341], "temperature": 0.0, "avg_logprob": -0.10920198639826988, "compression_ratio": 1.65, "no_speech_prob": 0.00010553370520938188}, {"id": 113, "seek": 80468, "start": 804.68, "end": 814.7199999999999, "text": " page we get a wiki data property which is for OpenStreetMap tag or key. So there's actually", "tokens": [3028, 321, 483, 257, 261, 9850, 1412, 4707, 597, 307, 337, 7238, 50, 3599, 302, 44, 569, 6162, 420, 2141, 13, 407, 456, 311, 767], "temperature": 0.0, "avg_logprob": -0.12200330285465016, "compression_ratio": 1.776190476190476, "no_speech_prob": 0.00013106198457535356}, {"id": 114, "seek": 80468, "start": 814.7199999999999, "end": 821.56, "text": " two values here and the second value is uninteresting like it's shown in red because it's a deprecated", "tokens": [732, 4190, 510, 293, 264, 1150, 2158, 307, 49234, 8714, 411, 309, 311, 4898, 294, 2182, 570, 309, 311, 257, 1367, 13867, 770], "temperature": 0.0, "avg_logprob": -0.12200330285465016, "compression_ratio": 1.776190476190476, "no_speech_prob": 0.00013106198457535356}, {"id": 115, "seek": 80468, "start": 821.56, "end": 826.7199999999999, "text": " value like it's a kind of old value that used to be used in OpenStreetMap and it's being", "tokens": [2158, 411, 309, 311, 257, 733, 295, 1331, 2158, 300, 1143, 281, 312, 1143, 294, 7238, 50, 3599, 302, 44, 569, 293, 309, 311, 885], "temperature": 0.0, "avg_logprob": -0.12200330285465016, "compression_ratio": 1.776190476190476, "no_speech_prob": 0.00013106198457535356}, {"id": 116, "seek": 80468, "start": 826.7199999999999, "end": 834.3599999999999, "text": " documented in wiki data. So the interesting one is the top one which is tag colon artwork", "tokens": [23007, 294, 261, 9850, 1412, 13, 407, 264, 1880, 472, 307, 264, 1192, 472, 597, 307, 6162, 8255, 15829], "temperature": 0.0, "avg_logprob": -0.12200330285465016, "compression_ratio": 1.776190476190476, "no_speech_prob": 0.00013106198457535356}, {"id": 117, "seek": 83436, "start": 834.36, "end": 844.28, "text": " underscore type of sculpture. So the information is stored in wiki data about what tags are", "tokens": [37556, 2010, 295, 22972, 13, 407, 264, 1589, 307, 12187, 294, 261, 9850, 1412, 466, 437, 18632, 366], "temperature": 0.0, "avg_logprob": -0.12531118681936554, "compression_ratio": 1.563953488372093, "no_speech_prob": 0.00014877277135383338}, {"id": 118, "seek": 83436, "start": 844.28, "end": 850.8000000000001, "text": " used in OpenStreetMap to describe things. So using this information we can say that these", "tokens": [1143, 294, 7238, 50, 3599, 302, 44, 569, 281, 6786, 721, 13, 407, 1228, 341, 1589, 321, 393, 584, 300, 613], "temperature": 0.0, "avg_logprob": -0.12531118681936554, "compression_ratio": 1.563953488372093, "no_speech_prob": 0.00014877277135383338}, {"id": 119, "seek": 83436, "start": 850.8000000000001, "end": 858.64, "text": " two things are the same type of entity. So when it comes to matching things I'm looking", "tokens": [732, 721, 366, 264, 912, 2010, 295, 13977, 13, 407, 562, 309, 1487, 281, 14324, 721, 286, 478, 1237], "temperature": 0.0, "avg_logprob": -0.12531118681936554, "compression_ratio": 1.563953488372093, "no_speech_prob": 0.00014877277135383338}, {"id": 120, "seek": 85864, "start": 858.64, "end": 864.88, "text": " for the coordinates to match like the two things and the two systems have to be close", "tokens": [337, 264, 21056, 281, 2995, 411, 264, 732, 721, 293, 264, 732, 3652, 362, 281, 312, 1998], "temperature": 0.0, "avg_logprob": -0.12229265168655751, "compression_ratio": 1.6322869955156951, "no_speech_prob": 6.180007039802149e-05}, {"id": 121, "seek": 85864, "start": 864.88, "end": 873.56, "text": " to each other. They're not necessarily a perfect match but within like 50 meters or something.", "tokens": [281, 1184, 661, 13, 814, 434, 406, 4725, 257, 2176, 2995, 457, 1951, 411, 2625, 8146, 420, 746, 13], "temperature": 0.0, "avg_logprob": -0.12229265168655751, "compression_ratio": 1.6322869955156951, "no_speech_prob": 6.180007039802149e-05}, {"id": 122, "seek": 85864, "start": 873.56, "end": 878.36, "text": " And the entity type has to be the same like I just described. And then I'm also looking", "tokens": [400, 264, 13977, 2010, 575, 281, 312, 264, 912, 411, 286, 445, 7619, 13, 400, 550, 286, 478, 611, 1237], "temperature": 0.0, "avg_logprob": -0.12229265168655751, "compression_ratio": 1.6322869955156951, "no_speech_prob": 6.180007039802149e-05}, {"id": 123, "seek": 85864, "start": 878.36, "end": 887.4, "text": " for a matching name or street address or identifier. So I pull names from all over the place in", "tokens": [337, 257, 14324, 1315, 420, 4838, 2985, 420, 45690, 13, 407, 286, 2235, 5288, 490, 439, 670, 264, 1081, 294], "temperature": 0.0, "avg_logprob": -0.12229265168655751, "compression_ratio": 1.6322869955156951, "no_speech_prob": 6.180007039802149e-05}, {"id": 124, "seek": 88740, "start": 887.4, "end": 894.04, "text": " both systems like in wiki data there's a bunch of different fields or rather in OpenStreetMap", "tokens": [1293, 3652, 411, 294, 261, 9850, 1412, 456, 311, 257, 3840, 295, 819, 7909, 420, 2831, 294, 7238, 50, 3599, 302, 44, 569], "temperature": 0.0, "avg_logprob": -0.1412347254126963, "compression_ratio": 1.967914438502674, "no_speech_prob": 0.00015452905790880322}, {"id": 125, "seek": 88740, "start": 894.04, "end": 899.9599999999999, "text": " there's a bunch of different fields where names can be stored and I look at all of those", "tokens": [456, 311, 257, 3840, 295, 819, 7909, 689, 5288, 393, 312, 12187, 293, 286, 574, 412, 439, 295, 729], "temperature": 0.0, "avg_logprob": -0.1412347254126963, "compression_ratio": 1.967914438502674, "no_speech_prob": 0.00015452905790880322}, {"id": 126, "seek": 88740, "start": 899.9599999999999, "end": 906.3199999999999, "text": " and then in wiki data there's different places to get the names. I look at the labels, wiki", "tokens": [293, 550, 294, 261, 9850, 1412, 456, 311, 819, 3190, 281, 483, 264, 5288, 13, 286, 574, 412, 264, 16949, 11, 261, 9850], "temperature": 0.0, "avg_logprob": -0.1412347254126963, "compression_ratio": 1.967914438502674, "no_speech_prob": 0.00015452905790880322}, {"id": 127, "seek": 88740, "start": 906.3199999999999, "end": 914.36, "text": " data, the aliases, the names of any wikipedia articles. I look at the file name of any images", "tokens": [1412, 11, 264, 10198, 1957, 11, 264, 5288, 295, 604, 261, 1035, 26633, 11290, 13, 286, 574, 412, 264, 3991, 1315, 295, 604, 5267], "temperature": 0.0, "avg_logprob": -0.1412347254126963, "compression_ratio": 1.967914438502674, "no_speech_prob": 0.00015452905790880322}, {"id": 128, "seek": 91436, "start": 914.36, "end": 921.0, "text": " that are in wiki data just to get as much, you know, many possible names that I can use", "tokens": [300, 366, 294, 261, 9850, 1412, 445, 281, 483, 382, 709, 11, 291, 458, 11, 867, 1944, 5288, 300, 286, 393, 764], "temperature": 0.0, "avg_logprob": -0.14264176555515565, "compression_ratio": 1.688073394495413, "no_speech_prob": 0.00011668892693705857}, {"id": 129, "seek": 91436, "start": 921.0, "end": 925.6, "text": " for matching. And then I normalize the names a lot so I lowercase them and I remove stop", "tokens": [337, 14324, 13, 400, 550, 286, 2710, 1125, 264, 5288, 257, 688, 370, 286, 3126, 9765, 552, 293, 286, 4159, 1590], "temperature": 0.0, "avg_logprob": -0.14264176555515565, "compression_ratio": 1.688073394495413, "no_speech_prob": 0.00011668892693705857}, {"id": 130, "seek": 91436, "start": 925.6, "end": 934.48, "text": " words and process them a lot to try and get as many name matches as I can. And then similarly", "tokens": [2283, 293, 1399, 552, 257, 688, 281, 853, 293, 483, 382, 867, 1315, 10676, 382, 286, 393, 13, 400, 550, 14138], "temperature": 0.0, "avg_logprob": -0.14264176555515565, "compression_ratio": 1.688073394495413, "no_speech_prob": 0.00011668892693705857}, {"id": 131, "seek": 91436, "start": 934.48, "end": 940.84, "text": " with street addresses. So there's street addresses in OpenStreetMap and wiki data which I compare", "tokens": [365, 4838, 16862, 13, 407, 456, 311, 4838, 16862, 294, 7238, 50, 3599, 302, 44, 569, 293, 261, 9850, 1412, 597, 286, 6794], "temperature": 0.0, "avg_logprob": -0.14264176555515565, "compression_ratio": 1.688073394495413, "no_speech_prob": 0.00011668892693705857}, {"id": 132, "seek": 94084, "start": 940.84, "end": 949.4, "text": " and the software also looks for street addresses in the first paragraph of wikipedia articles.", "tokens": [293, 264, 4722, 611, 1542, 337, 4838, 16862, 294, 264, 700, 18865, 295, 261, 1035, 26633, 11290, 13], "temperature": 0.0, "avg_logprob": -0.12972375479611484, "compression_ratio": 1.6697247706422018, "no_speech_prob": 6.061337990104221e-05}, {"id": 133, "seek": 94084, "start": 949.4, "end": 956.52, "text": " And then in terms of matching identifiers there's lots of standardized OpenStreetMap", "tokens": [400, 550, 294, 2115, 295, 14324, 2473, 23463, 456, 311, 3195, 295, 31677, 7238, 50, 3599, 302, 44, 569], "temperature": 0.0, "avg_logprob": -0.12972375479611484, "compression_ratio": 1.6697247706422018, "no_speech_prob": 6.061337990104221e-05}, {"id": 134, "seek": 94084, "start": 956.52, "end": 964.2800000000001, "text": " tags for different identifiers and then there's also properties in wiki data for those same", "tokens": [18632, 337, 819, 2473, 23463, 293, 550, 456, 311, 611, 7221, 294, 261, 9850, 1412, 337, 729, 912], "temperature": 0.0, "avg_logprob": -0.12972375479611484, "compression_ratio": 1.6697247706422018, "no_speech_prob": 6.061337990104221e-05}, {"id": 135, "seek": 94084, "start": 964.2800000000001, "end": 969.2, "text": " identifiers. So if, you know, I've got a railway station that's got the same station code in", "tokens": [2473, 23463, 13, 407, 498, 11, 291, 458, 11, 286, 600, 658, 257, 25812, 5214, 300, 311, 658, 264, 912, 5214, 3089, 294], "temperature": 0.0, "avg_logprob": -0.12972375479611484, "compression_ratio": 1.6697247706422018, "no_speech_prob": 6.061337990104221e-05}, {"id": 136, "seek": 96920, "start": 969.2, "end": 974.44, "text": " OpenStreetMap and wiki data I can be pretty sure that it's the same thing that I'm matching", "tokens": [7238, 50, 3599, 302, 44, 569, 293, 261, 9850, 1412, 286, 393, 312, 1238, 988, 300, 309, 311, 264, 912, 551, 300, 286, 478, 14324], "temperature": 0.0, "avg_logprob": -0.08962310865087417, "compression_ratio": 1.7655502392344498, "no_speech_prob": 0.00024502689484506845}, {"id": 137, "seek": 96920, "start": 974.44, "end": 980.72, "text": " so I can be confident about that match. So one of the things I'm not using at the moment", "tokens": [370, 286, 393, 312, 6679, 466, 300, 2995, 13, 407, 472, 295, 264, 721, 286, 478, 406, 1228, 412, 264, 1623], "temperature": 0.0, "avg_logprob": -0.08962310865087417, "compression_ratio": 1.7655502392344498, "no_speech_prob": 0.00024502689484506845}, {"id": 138, "seek": 96920, "start": 980.72, "end": 988.44, "text": " is the wikipedia tags which appear in OpenStreetMap. Like before wiki data came along there was", "tokens": [307, 264, 261, 1035, 26633, 18632, 597, 4204, 294, 7238, 50, 3599, 302, 44, 569, 13, 1743, 949, 261, 9850, 1412, 1361, 2051, 456, 390], "temperature": 0.0, "avg_logprob": -0.08962310865087417, "compression_ratio": 1.7655502392344498, "no_speech_prob": 0.00024502689484506845}, {"id": 139, "seek": 96920, "start": 988.44, "end": 996.6400000000001, "text": " lots of wikipedia tags added to OpenStreetMap and they're not completely consistent in their", "tokens": [3195, 295, 261, 1035, 26633, 18632, 3869, 281, 7238, 50, 3599, 302, 44, 569, 293, 436, 434, 406, 2584, 8398, 294, 641], "temperature": 0.0, "avg_logprob": -0.08962310865087417, "compression_ratio": 1.7655502392344498, "no_speech_prob": 0.00024502689484506845}, {"id": 140, "seek": 99664, "start": 996.64, "end": 1004.3199999999999, "text": " formatting for how they link to wikipedia and sometimes they're wrong. So, you know, I've", "tokens": [39366, 337, 577, 436, 2113, 281, 261, 1035, 26633, 293, 2171, 436, 434, 2085, 13, 407, 11, 291, 458, 11, 286, 600], "temperature": 0.0, "avg_logprob": -0.1251573460076445, "compression_ratio": 1.6210045662100456, "no_speech_prob": 0.00019954735762439668}, {"id": 141, "seek": 99664, "start": 1004.3199999999999, "end": 1010.64, "text": " left the work for now working on trying to match up using wikipedia tags for somebody", "tokens": [1411, 264, 589, 337, 586, 1364, 322, 1382, 281, 2995, 493, 1228, 261, 1035, 26633, 18632, 337, 2618], "temperature": 0.0, "avg_logprob": -0.1251573460076445, "compression_ratio": 1.6210045662100456, "no_speech_prob": 0.00019954735762439668}, {"id": 142, "seek": 99664, "start": 1010.64, "end": 1017.16, "text": " else to have a look at. But I've been waiting for a few years now and no one has so I might", "tokens": [1646, 281, 362, 257, 574, 412, 13, 583, 286, 600, 668, 3806, 337, 257, 1326, 924, 586, 293, 572, 472, 575, 370, 286, 1062], "temperature": 0.0, "avg_logprob": -0.1251573460076445, "compression_ratio": 1.6210045662100456, "no_speech_prob": 0.00019954735762439668}, {"id": 143, "seek": 99664, "start": 1017.16, "end": 1025.6, "text": " have to have a go at this. So just in case anyone's interested in the technology behind", "tokens": [362, 281, 362, 257, 352, 412, 341, 13, 407, 445, 294, 1389, 2878, 311, 3102, 294, 264, 2899, 2261], "temperature": 0.0, "avg_logprob": -0.1251573460076445, "compression_ratio": 1.6210045662100456, "no_speech_prob": 0.00019954735762439668}, {"id": 144, "seek": 102560, "start": 1025.6, "end": 1035.24, "text": " this, the software is written in Python with Flask. I'm using Postgres as my database and", "tokens": [341, 11, 264, 4722, 307, 3720, 294, 15329, 365, 3235, 3863, 13, 286, 478, 1228, 10223, 45189, 382, 452, 8149, 293], "temperature": 0.0, "avg_logprob": -0.18258508954729352, "compression_ratio": 1.4692737430167597, "no_speech_prob": 7.896686292951927e-05}, {"id": 145, "seek": 102560, "start": 1035.24, "end": 1041.1999999999998, "text": " then on the front end, you know, various bits of JavaScript. I'm not really a front end", "tokens": [550, 322, 264, 1868, 917, 11, 291, 458, 11, 3683, 9239, 295, 15778, 13, 286, 478, 406, 534, 257, 1868, 917], "temperature": 0.0, "avg_logprob": -0.18258508954729352, "compression_ratio": 1.4692737430167597, "no_speech_prob": 7.896686292951927e-05}, {"id": 146, "seek": 102560, "start": 1041.1999999999998, "end": 1047.28, "text": " developer but, you know, I'm muddling my way through and it seems to be working quite", "tokens": [10754, 457, 11, 291, 458, 11, 286, 478, 8933, 35543, 452, 636, 807, 293, 309, 2544, 281, 312, 1364, 1596], "temperature": 0.0, "avg_logprob": -0.18258508954729352, "compression_ratio": 1.4692737430167597, "no_speech_prob": 7.896686292951927e-05}, {"id": 147, "seek": 104728, "start": 1047.28, "end": 1055.96, "text": " well. I'm using a bunch of APIs to get this data. So in terms of searching for places", "tokens": [731, 13, 286, 478, 1228, 257, 3840, 295, 21445, 281, 483, 341, 1412, 13, 407, 294, 2115, 295, 10808, 337, 3190], "temperature": 0.0, "avg_logprob": -0.1277913950910472, "compression_ratio": 1.6926829268292682, "no_speech_prob": 5.147952833794989e-05}, {"id": 148, "seek": 104728, "start": 1055.96, "end": 1062.32, "text": " to look for matches, I use the OpenStreetMap nominatum API and then to grab more data I", "tokens": [281, 574, 337, 10676, 11, 286, 764, 264, 7238, 50, 3599, 302, 44, 569, 5369, 259, 267, 449, 9362, 293, 550, 281, 4444, 544, 1412, 286], "temperature": 0.0, "avg_logprob": -0.1277913950910472, "compression_ratio": 1.6926829268292682, "no_speech_prob": 5.147952833794989e-05}, {"id": 149, "seek": 104728, "start": 1062.32, "end": 1068.84, "text": " use the overview pass API and then on the wiki data side, I do a lot of sparkle queries", "tokens": [764, 264, 12492, 1320, 9362, 293, 550, 322, 264, 261, 9850, 1412, 1252, 11, 286, 360, 257, 688, 295, 48558, 24109], "temperature": 0.0, "avg_logprob": -0.1277913950910472, "compression_ratio": 1.6926829268292682, "no_speech_prob": 5.147952833794989e-05}, {"id": 150, "seek": 104728, "start": 1068.84, "end": 1076.72, "text": " against the wiki data query service and I use the wiki data media wiki API to get the", "tokens": [1970, 264, 261, 9850, 1412, 14581, 2643, 293, 286, 764, 264, 261, 9850, 1412, 3021, 261, 9850, 9362, 281, 483, 264], "temperature": 0.0, "avg_logprob": -0.1277913950910472, "compression_ratio": 1.6926829268292682, "no_speech_prob": 5.147952833794989e-05}, {"id": 151, "seek": 107672, "start": 1076.72, "end": 1083.4, "text": " details of the wiki data items. So there's a bunch of things that don't work in my system", "tokens": [4365, 295, 264, 261, 9850, 1412, 4754, 13, 407, 456, 311, 257, 3840, 295, 721, 300, 500, 380, 589, 294, 452, 1185], "temperature": 0.0, "avg_logprob": -0.10338123895788706, "compression_ratio": 1.6807511737089202, "no_speech_prob": 9.461550507694483e-05}, {"id": 152, "seek": 107672, "start": 1083.4, "end": 1090.88, "text": " at the moment. One of them is tunnels. Like I designed the software with the assumption", "tokens": [412, 264, 1623, 13, 1485, 295, 552, 307, 30804, 13, 1743, 286, 4761, 264, 4722, 365, 264, 15302], "temperature": 0.0, "avg_logprob": -0.10338123895788706, "compression_ratio": 1.6807511737089202, "no_speech_prob": 9.461550507694483e-05}, {"id": 153, "seek": 107672, "start": 1090.88, "end": 1096.1200000000001, "text": " that there would be a kind of one-to-one mapping between a thing in OpenStreetMap and", "tokens": [300, 456, 576, 312, 257, 733, 295, 472, 12, 1353, 12, 546, 18350, 1296, 257, 551, 294, 7238, 50, 3599, 302, 44, 569, 293], "temperature": 0.0, "avg_logprob": -0.10338123895788706, "compression_ratio": 1.6807511737089202, "no_speech_prob": 9.461550507694483e-05}, {"id": 154, "seek": 107672, "start": 1096.1200000000001, "end": 1102.64, "text": " a thing in wiki data and that doesn't work for tunnels because tunnels tend to get represented", "tokens": [257, 551, 294, 261, 9850, 1412, 293, 300, 1177, 380, 589, 337, 30804, 570, 30804, 3928, 281, 483, 10379], "temperature": 0.0, "avg_logprob": -0.10338123895788706, "compression_ratio": 1.6807511737089202, "no_speech_prob": 9.461550507694483e-05}, {"id": 155, "seek": 110264, "start": 1102.64, "end": 1109.6000000000001, "text": " as two ways in OpenStreetMap where as in wiki data there'll be a single item. And so, you", "tokens": [382, 732, 2098, 294, 7238, 50, 3599, 302, 44, 569, 689, 382, 294, 261, 9850, 1412, 456, 603, 312, 257, 2167, 3174, 13, 400, 370, 11, 291], "temperature": 0.0, "avg_logprob": -0.1818008905724634, "compression_ratio": 1.5371428571428571, "no_speech_prob": 5.8214893215335906e-05}, {"id": 156, "seek": 110264, "start": 1109.6000000000001, "end": 1115.16, "text": " know, my assumption was wrong and I need to change my software to say that you can add", "tokens": [458, 11, 452, 15302, 390, 2085, 293, 286, 643, 281, 1319, 452, 4722, 281, 584, 300, 291, 393, 909], "temperature": 0.0, "avg_logprob": -0.1818008905724634, "compression_ratio": 1.5371428571428571, "no_speech_prob": 5.8214893215335906e-05}, {"id": 157, "seek": 110264, "start": 1115.16, "end": 1129.24, "text": " the wiki data identifier to ways in OpenStreetMap but I haven't done that yet. Incidentally,", "tokens": [264, 261, 9850, 1412, 45690, 281, 2098, 294, 7238, 50, 3599, 302, 44, 569, 457, 286, 2378, 380, 1096, 300, 1939, 13, 7779, 36578, 11], "temperature": 0.0, "avg_logprob": -0.1818008905724634, "compression_ratio": 1.5371428571428571, "no_speech_prob": 5.8214893215335906e-05}, {"id": 158, "seek": 112924, "start": 1129.24, "end": 1133.6, "text": " we don't have the same problem with bridges. Like the way that bridges get represented", "tokens": [321, 500, 380, 362, 264, 912, 1154, 365, 21114, 13, 1743, 264, 636, 300, 21114, 483, 10379], "temperature": 0.0, "avg_logprob": -0.1568454379127139, "compression_ratio": 1.8360655737704918, "no_speech_prob": 6.843130540801212e-05}, {"id": 159, "seek": 112924, "start": 1133.6, "end": 1138.28, "text": " in OpenStreetMap is they are often two ways but then there's a relation across the whole", "tokens": [294, 7238, 50, 3599, 302, 44, 569, 307, 436, 366, 2049, 732, 2098, 457, 550, 456, 311, 257, 9721, 2108, 264, 1379], "temperature": 0.0, "avg_logprob": -0.1568454379127139, "compression_ratio": 1.8360655737704918, "no_speech_prob": 6.843130540801212e-05}, {"id": 160, "seek": 112924, "start": 1138.28, "end": 1146.92, "text": " bridge that represents the bridge itself. And tunnels, there isn't a relation for representing", "tokens": [7283, 300, 8855, 264, 7283, 2564, 13, 400, 30804, 11, 456, 1943, 380, 257, 9721, 337, 13460], "temperature": 0.0, "avg_logprob": -0.1568454379127139, "compression_ratio": 1.8360655737704918, "no_speech_prob": 6.843130540801212e-05}, {"id": 161, "seek": 112924, "start": 1146.92, "end": 1152.16, "text": " the whole concept of the tunnel. So that's another possible approach. Maybe OpenStreetMap", "tokens": [264, 1379, 3410, 295, 264, 13186, 13, 407, 300, 311, 1071, 1944, 3109, 13, 2704, 7238, 50, 3599, 302, 44, 569], "temperature": 0.0, "avg_logprob": -0.1568454379127139, "compression_ratio": 1.8360655737704918, "no_speech_prob": 6.843130540801212e-05}, {"id": 162, "seek": 112924, "start": 1152.16, "end": 1158.72, "text": " should change and start mapping the tunnels with a relation that contains the two ways,", "tokens": [820, 1319, 293, 722, 18350, 264, 30804, 365, 257, 9721, 300, 8306, 264, 732, 2098, 11], "temperature": 0.0, "avg_logprob": -0.1568454379127139, "compression_ratio": 1.8360655737704918, "no_speech_prob": 6.843130540801212e-05}, {"id": 163, "seek": 115872, "start": 1158.72, "end": 1163.8, "text": " you know, for storing wiki data tags and any other information about the tunnel that", "tokens": [291, 458, 11, 337, 26085, 261, 9850, 1412, 18632, 293, 604, 661, 1589, 466, 264, 13186, 300], "temperature": 0.0, "avg_logprob": -0.1319466790000161, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.0001569414889672771}, {"id": 164, "seek": 115872, "start": 1163.8, "end": 1173.72, "text": " is the same across both ways. So, another thing that I don't support are rivers because", "tokens": [307, 264, 912, 2108, 1293, 2098, 13, 407, 11, 1071, 551, 300, 286, 500, 380, 1406, 366, 18361, 570], "temperature": 0.0, "avg_logprob": -0.1319466790000161, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.0001569414889672771}, {"id": 165, "seek": 115872, "start": 1173.72, "end": 1179.72, "text": " they are linear relations and my software that I'm using to import data from OpenStreetMap", "tokens": [436, 366, 8213, 2299, 293, 452, 4722, 300, 286, 478, 1228, 281, 974, 1412, 490, 7238, 50, 3599, 302, 44, 569], "temperature": 0.0, "avg_logprob": -0.1319466790000161, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.0001569414889672771}, {"id": 166, "seek": 115872, "start": 1179.72, "end": 1187.0, "text": " I'm using OSM to PGSQL and it can't handle linear relations. It just, you know, expects", "tokens": [286, 478, 1228, 12731, 44, 281, 430, 24446, 13695, 293, 309, 393, 380, 4813, 8213, 2299, 13, 467, 445, 11, 291, 458, 11, 33280], "temperature": 0.0, "avg_logprob": -0.1319466790000161, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.0001569414889672771}, {"id": 167, "seek": 118700, "start": 1187.0, "end": 1193.28, "text": " relations to be polygons. So at the moment rivers don't work in the system. And then", "tokens": [2299, 281, 312, 6754, 70, 892, 13, 407, 412, 264, 1623, 18361, 500, 380, 589, 294, 264, 1185, 13, 400, 550], "temperature": 0.0, "avg_logprob": -0.15309977001614042, "compression_ratio": 1.5594713656387664, "no_speech_prob": 0.00025055836886167526}, {"id": 168, "seek": 118700, "start": 1193.28, "end": 1199.04, "text": " similarly for tram stops. Tram stops are kind of complex objects in OpenStreetMap. You've", "tokens": [14138, 337, 25749, 10094, 13, 1765, 335, 10094, 366, 733, 295, 3997, 6565, 294, 7238, 50, 3599, 302, 44, 569, 13, 509, 600], "temperature": 0.0, "avg_logprob": -0.15309977001614042, "compression_ratio": 1.5594713656387664, "no_speech_prob": 0.00025055836886167526}, {"id": 169, "seek": 118700, "start": 1199.04, "end": 1204.0, "text": " got, you know, stop positions of where the tram stops on either side of the road which", "tokens": [658, 11, 291, 458, 11, 1590, 8432, 295, 689, 264, 25749, 10094, 322, 2139, 1252, 295, 264, 3060, 597], "temperature": 0.0, "avg_logprob": -0.15309977001614042, "compression_ratio": 1.5594713656387664, "no_speech_prob": 0.00025055836886167526}, {"id": 170, "seek": 118700, "start": 1204.0, "end": 1211.92, "text": " are no single points and they're collected together into a relation and that isn't supported", "tokens": [366, 572, 2167, 2793, 293, 436, 434, 11087, 1214, 666, 257, 9721, 293, 300, 1943, 380, 8104], "temperature": 0.0, "avg_logprob": -0.15309977001614042, "compression_ratio": 1.5594713656387664, "no_speech_prob": 0.00025055836886167526}, {"id": 171, "seek": 121192, "start": 1211.92, "end": 1222.1200000000001, "text": " properly by OSM to PGSQL. So I can't handle tram stops properly. I'm going to talk about", "tokens": [6108, 538, 12731, 44, 281, 430, 24446, 13695, 13, 407, 286, 393, 380, 4813, 25749, 10094, 6108, 13, 286, 478, 516, 281, 751, 466], "temperature": 0.0, "avg_logprob": -0.11577744551107917, "compression_ratio": 1.5083798882681565, "no_speech_prob": 7.310146611416712e-05}, {"id": 172, "seek": 121192, "start": 1222.1200000000001, "end": 1230.5600000000002, "text": " a few more features that are in the software. So again, this is the center of Brussels and", "tokens": [257, 1326, 544, 4122, 300, 366, 294, 264, 4722, 13, 407, 797, 11, 341, 307, 264, 3056, 295, 38717, 293], "temperature": 0.0, "avg_logprob": -0.11577744551107917, "compression_ratio": 1.5083798882681565, "no_speech_prob": 7.310146611416712e-05}, {"id": 173, "seek": 121192, "start": 1230.5600000000002, "end": 1236.16, "text": " I've got the language selector. So the software has figured out all the languages that get", "tokens": [286, 600, 658, 264, 2856, 23264, 1672, 13, 407, 264, 4722, 575, 8932, 484, 439, 264, 8650, 300, 483], "temperature": 0.0, "avg_logprob": -0.11577744551107917, "compression_ratio": 1.5083798882681565, "no_speech_prob": 7.310146611416712e-05}, {"id": 174, "seek": 123616, "start": 1236.16, "end": 1247.3600000000001, "text": " used for the labels of things and the OpenStreetMap objects that are in this area. You know, unsurprisingly", "tokens": [1143, 337, 264, 16949, 295, 721, 293, 264, 7238, 50, 3599, 302, 44, 569, 6565, 300, 366, 294, 341, 1859, 13, 509, 458, 11, 2693, 374, 34408], "temperature": 0.0, "avg_logprob": -0.1631659908571105, "compression_ratio": 1.484375, "no_speech_prob": 0.0002697519084904343}, {"id": 175, "seek": 123616, "start": 1247.3600000000001, "end": 1254.52, "text": " for Brussels the most popular languages are French and then Dutch and English is the third", "tokens": [337, 38717, 264, 881, 3743, 8650, 366, 5522, 293, 550, 15719, 293, 3669, 307, 264, 2636], "temperature": 0.0, "avg_logprob": -0.1631659908571105, "compression_ratio": 1.484375, "no_speech_prob": 0.0002697519084904343}, {"id": 176, "seek": 123616, "start": 1254.52, "end": 1261.1200000000001, "text": " most popular. Interestingly we've got Latin at the bottom there. There's 22 items that", "tokens": [881, 3743, 13, 30564, 321, 600, 658, 10803, 412, 264, 2767, 456, 13, 821, 311, 5853, 4754, 300], "temperature": 0.0, "avg_logprob": -0.1631659908571105, "compression_ratio": 1.484375, "no_speech_prob": 0.0002697519084904343}, {"id": 177, "seek": 126112, "start": 1261.12, "end": 1269.4399999999998, "text": " have got labels in Latin in wiki data. But so by default this page is opened in French", "tokens": [362, 658, 16949, 294, 10803, 294, 261, 9850, 1412, 13, 583, 370, 538, 7576, 341, 3028, 307, 5625, 294, 5522], "temperature": 0.0, "avg_logprob": -0.12355758878919813, "compression_ratio": 1.6985645933014355, "no_speech_prob": 0.0001532045571366325}, {"id": 178, "seek": 126112, "start": 1269.4399999999998, "end": 1275.84, "text": " and you can see the type filter is appearing in French but I can't read French very well", "tokens": [293, 291, 393, 536, 264, 2010, 6608, 307, 19870, 294, 5522, 457, 286, 393, 380, 1401, 5522, 588, 731], "temperature": 0.0, "avg_logprob": -0.12355758878919813, "compression_ratio": 1.6985645933014355, "no_speech_prob": 0.0001532045571366325}, {"id": 179, "seek": 126112, "start": 1275.84, "end": 1283.6799999999998, "text": " so if I want to change it to Dutch I can reorder these languages by drag and drop or I can", "tokens": [370, 498, 286, 528, 281, 1319, 309, 281, 15719, 286, 393, 319, 4687, 613, 8650, 538, 5286, 293, 3270, 420, 286, 393], "temperature": 0.0, "avg_logprob": -0.12355758878919813, "compression_ratio": 1.6985645933014355, "no_speech_prob": 0.0001532045571366325}, {"id": 180, "seek": 126112, "start": 1283.6799999999998, "end": 1290.04, "text": " click on move to top and you can see the type filter is now switched into being in Dutch", "tokens": [2052, 322, 1286, 281, 1192, 293, 291, 393, 536, 264, 2010, 6608, 307, 586, 16858, 666, 885, 294, 15719], "temperature": 0.0, "avg_logprob": -0.12355758878919813, "compression_ratio": 1.6985645933014355, "no_speech_prob": 0.0001532045571366325}, {"id": 181, "seek": 129004, "start": 1290.04, "end": 1296.44, "text": " or if I want it in English then I can move English to the top of the list and it will", "tokens": [420, 498, 286, 528, 309, 294, 3669, 550, 286, 393, 1286, 3669, 281, 264, 1192, 295, 264, 1329, 293, 309, 486], "temperature": 0.0, "avg_logprob": -0.1587387720743815, "compression_ratio": 1.674757281553398, "no_speech_prob": 0.00020380863861646503}, {"id": 182, "seek": 129004, "start": 1296.44, "end": 1302.28, "text": " show me the type filter in English, English labels and descriptions. And if I scroll down", "tokens": [855, 385, 264, 2010, 6608, 294, 3669, 11, 3669, 16949, 293, 24406, 13, 400, 498, 286, 11369, 760], "temperature": 0.0, "avg_logprob": -0.1587387720743815, "compression_ratio": 1.674757281553398, "no_speech_prob": 0.00020380863861646503}, {"id": 183, "seek": 129004, "start": 1302.28, "end": 1308.48, "text": " the page you can see that this is the page appearing in French. You've got titles in", "tokens": [264, 3028, 291, 393, 536, 300, 341, 307, 264, 3028, 19870, 294, 5522, 13, 509, 600, 658, 12992, 294], "temperature": 0.0, "avg_logprob": -0.1587387720743815, "compression_ratio": 1.674757281553398, "no_speech_prob": 0.00020380863861646503}, {"id": 184, "seek": 129004, "start": 1308.48, "end": 1315.6399999999999, "text": " French and the extracts from wikipedia in French or again I can change it into Dutch", "tokens": [5522, 293, 264, 8947, 82, 490, 261, 1035, 26633, 294, 5522, 420, 797, 286, 393, 1319, 309, 666, 15719], "temperature": 0.0, "avg_logprob": -0.1587387720743815, "compression_ratio": 1.674757281553398, "no_speech_prob": 0.00020380863861646503}, {"id": 185, "seek": 131564, "start": 1315.64, "end": 1321.72, "text": " if I want or I can have it in English. And this works without reloading the page. You", "tokens": [498, 286, 528, 420, 286, 393, 362, 309, 294, 3669, 13, 400, 341, 1985, 1553, 25628, 278, 264, 3028, 13, 509], "temperature": 0.0, "avg_logprob": -0.16122830167729804, "compression_ratio": 1.553648068669528, "no_speech_prob": 0.0001309765939367935}, {"id": 186, "seek": 131564, "start": 1321.72, "end": 1328.68, "text": " just change the order that you prefer the languages to appear in and it does it all on the client", "tokens": [445, 1319, 264, 1668, 300, 291, 4382, 264, 8650, 281, 4204, 294, 293, 309, 775, 309, 439, 322, 264, 6423], "temperature": 0.0, "avg_logprob": -0.16122830167729804, "compression_ratio": 1.553648068669528, "no_speech_prob": 0.0001309765939367935}, {"id": 187, "seek": 131564, "start": 1328.68, "end": 1338.16, "text": " and switches it over. So some statistics for you. People are using this tool. Well first", "tokens": [293, 19458, 309, 670, 13, 407, 512, 12523, 337, 291, 13, 3432, 366, 1228, 341, 2290, 13, 1042, 700], "temperature": 0.0, "avg_logprob": -0.16122830167729804, "compression_ratio": 1.553648068669528, "no_speech_prob": 0.0001309765939367935}, {"id": 188, "seek": 131564, "start": 1338.16, "end": 1344.8400000000001, "text": " of all there's more and more wiki data tags appearing in OpenStreetMap so not all of them", "tokens": [295, 439, 456, 311, 544, 293, 544, 261, 9850, 1412, 18632, 19870, 294, 7238, 50, 3599, 302, 44, 569, 370, 406, 439, 295, 552], "temperature": 0.0, "avg_logprob": -0.16122830167729804, "compression_ratio": 1.553648068669528, "no_speech_prob": 0.0001309765939367935}, {"id": 189, "seek": 134484, "start": 1344.84, "end": 1350.8, "text": " are coming from my software. You know there's other people figuring out how to add wiki data", "tokens": [366, 1348, 490, 452, 4722, 13, 509, 458, 456, 311, 661, 561, 15213, 484, 577, 281, 909, 261, 9850, 1412], "temperature": 0.0, "avg_logprob": -0.1430977447123467, "compression_ratio": 1.5340909090909092, "no_speech_prob": 0.00016221601981669664}, {"id": 190, "seek": 134484, "start": 1350.8, "end": 1361.12, "text": " tags to OpenStreetMap. So here's some more stats. 26% of the wiki data tags in OpenStreetMap", "tokens": [18632, 281, 7238, 50, 3599, 302, 44, 569, 13, 407, 510, 311, 512, 544, 18152, 13, 7551, 4, 295, 264, 261, 9850, 1412, 18632, 294, 7238, 50, 3599, 302, 44, 569], "temperature": 0.0, "avg_logprob": -0.1430977447123467, "compression_ratio": 1.5340909090909092, "no_speech_prob": 0.00016221601981669664}, {"id": 191, "seek": 134484, "start": 1361.12, "end": 1368.6, "text": " were added using this tool and we're up to 400 people and there's been 23,000 change", "tokens": [645, 3869, 1228, 341, 2290, 293, 321, 434, 493, 281, 8423, 561, 293, 456, 311, 668, 6673, 11, 1360, 1319], "temperature": 0.0, "avg_logprob": -0.1430977447123467, "compression_ratio": 1.5340909090909092, "no_speech_prob": 0.00016221601981669664}, {"id": 192, "seek": 136860, "start": 1368.6, "end": 1377.48, "text": " sets and we're getting close to 700,000 wiki data tags added. So I'm going to talk about", "tokens": [6352, 293, 321, 434, 1242, 1998, 281, 15204, 11, 1360, 261, 9850, 1412, 18632, 3869, 13, 407, 286, 478, 516, 281, 751, 466], "temperature": 0.0, "avg_logprob": -0.1237480640411377, "compression_ratio": 1.463276836158192, "no_speech_prob": 0.00010863332136068493}, {"id": 193, "seek": 136860, "start": 1377.48, "end": 1386.9199999999998, "text": " the licensing. Wiki data is CC0 or public domain. You can do anything you want with", "tokens": [264, 29759, 13, 343, 9850, 1412, 307, 12630, 15, 420, 1908, 9274, 13, 509, 393, 360, 1340, 291, 528, 365], "temperature": 0.0, "avg_logprob": -0.1237480640411377, "compression_ratio": 1.463276836158192, "no_speech_prob": 0.00010863332136068493}, {"id": 194, "seek": 136860, "start": 1386.9199999999998, "end": 1392.7199999999998, "text": " wiki data and OpenStreetMap uses the open database license which is a license that was", "tokens": [261, 9850, 1412, 293, 7238, 50, 3599, 302, 44, 569, 4960, 264, 1269, 8149, 10476, 597, 307, 257, 10476, 300, 390], "temperature": 0.0, "avg_logprob": -0.1237480640411377, "compression_ratio": 1.463276836158192, "no_speech_prob": 0.00010863332136068493}, {"id": 195, "seek": 139272, "start": 1392.72, "end": 1401.24, "text": " pretty much written for OpenStreetMap. So you can't copy any data from OpenStreetMap", "tokens": [1238, 709, 3720, 337, 7238, 50, 3599, 302, 44, 569, 13, 407, 291, 393, 380, 5055, 604, 1412, 490, 7238, 50, 3599, 302, 44, 569], "temperature": 0.0, "avg_logprob": -0.1218082549724173, "compression_ratio": 1.5638766519823788, "no_speech_prob": 8.458760567009449e-05}, {"id": 196, "seek": 139272, "start": 1401.24, "end": 1409.1200000000001, "text": " into wiki data because you'd be re-licensing it CC0 which is not allowed. But even more", "tokens": [666, 261, 9850, 1412, 570, 291, 1116, 312, 319, 12, 1050, 22481, 309, 12630, 15, 597, 307, 406, 4350, 13, 583, 754, 544], "temperature": 0.0, "avg_logprob": -0.1218082549724173, "compression_ratio": 1.5638766519823788, "no_speech_prob": 8.458760567009449e-05}, {"id": 197, "seek": 139272, "start": 1409.1200000000001, "end": 1416.1200000000001, "text": " than just the licenses being different the intellectual property jurisdictions are different.", "tokens": [813, 445, 264, 32821, 885, 819, 264, 12576, 4707, 37958, 366, 819, 13], "temperature": 0.0, "avg_logprob": -0.1218082549724173, "compression_ratio": 1.5638766519823788, "no_speech_prob": 8.458760567009449e-05}, {"id": 198, "seek": 139272, "start": 1416.1200000000001, "end": 1422.48, "text": " So OpenStreetMap asserts database rights. Like the argument is that it's a lot of effort", "tokens": [407, 7238, 50, 3599, 302, 44, 569, 19810, 82, 8149, 4601, 13, 1743, 264, 6770, 307, 300, 309, 311, 257, 688, 295, 4630], "temperature": 0.0, "avg_logprob": -0.1218082549724173, "compression_ratio": 1.5638766519823788, "no_speech_prob": 8.458760567009449e-05}, {"id": 199, "seek": 142248, "start": 1422.48, "end": 1427.72, "text": " to go around collecting all this information and putting it in OpenStreetMap and they want", "tokens": [281, 352, 926, 12510, 439, 341, 1589, 293, 3372, 309, 294, 7238, 50, 3599, 302, 44, 569, 293, 436, 528], "temperature": 0.0, "avg_logprob": -0.11367242280827013, "compression_ratio": 1.5822222222222222, "no_speech_prob": 0.00012271327432245016}, {"id": 200, "seek": 142248, "start": 1427.72, "end": 1435.48, "text": " to protect that whereas wiki data is part of the wiki media foundation which uses US", "tokens": [281, 2371, 300, 9735, 261, 9850, 1412, 307, 644, 295, 264, 261, 9850, 3021, 7030, 597, 4960, 2546], "temperature": 0.0, "avg_logprob": -0.11367242280827013, "compression_ratio": 1.5822222222222222, "no_speech_prob": 0.00012271327432245016}, {"id": 201, "seek": 142248, "start": 1435.48, "end": 1442.44, "text": " intellectual property rules and so under US law facts are not copyrighted, not protected", "tokens": [12576, 4707, 4474, 293, 370, 833, 2546, 2101, 9130, 366, 406, 17996, 292, 11, 406, 10594], "temperature": 0.0, "avg_logprob": -0.11367242280827013, "compression_ratio": 1.5822222222222222, "no_speech_prob": 0.00012271327432245016}, {"id": 202, "seek": 142248, "start": 1442.44, "end": 1451.44, "text": " rather in law. So the two things don't mesh that well but it's fine because I'm not copying", "tokens": [2831, 294, 2101, 13, 407, 264, 732, 721, 500, 380, 17407, 300, 731, 457, 309, 311, 2489, 570, 286, 478, 406, 27976], "temperature": 0.0, "avg_logprob": -0.11367242280827013, "compression_ratio": 1.5822222222222222, "no_speech_prob": 0.00012271327432245016}, {"id": 203, "seek": 145144, "start": 1451.44, "end": 1457.24, "text": " any data between the systems. I'm just adding links between them. Like in some cases it", "tokens": [604, 1412, 1296, 264, 3652, 13, 286, 478, 445, 5127, 6123, 1296, 552, 13, 1743, 294, 512, 3331, 309], "temperature": 0.0, "avg_logprob": -0.1485068570999872, "compression_ratio": 1.5936073059360731, "no_speech_prob": 0.00011735744192264974}, {"id": 204, "seek": 145144, "start": 1457.24, "end": 1464.88, "text": " might be nice if we could tidy up the data in one system based on the other but I'm", "tokens": [1062, 312, 1481, 498, 321, 727, 34646, 493, 264, 1412, 294, 472, 1185, 2361, 322, 264, 661, 457, 286, 478], "temperature": 0.0, "avg_logprob": -0.1485068570999872, "compression_ratio": 1.5936073059360731, "no_speech_prob": 0.00011735744192264974}, {"id": 205, "seek": 145144, "start": 1464.88, "end": 1470.4, "text": " not doing that and there's you've got to think carefully about the intellectual property", "tokens": [406, 884, 300, 293, 456, 311, 291, 600, 658, 281, 519, 7500, 466, 264, 12576, 4707], "temperature": 0.0, "avg_logprob": -0.1485068570999872, "compression_ratio": 1.5936073059360731, "no_speech_prob": 0.00011735744192264974}, {"id": 206, "seek": 145144, "start": 1470.4, "end": 1478.64, "text": " rules before you try and do that. And so also just while we're talking about licenses my", "tokens": [4474, 949, 291, 853, 293, 360, 300, 13, 400, 370, 611, 445, 1339, 321, 434, 1417, 466, 32821, 452], "temperature": 0.0, "avg_logprob": -0.1485068570999872, "compression_ratio": 1.5936073059360731, "no_speech_prob": 0.00011735744192264974}, {"id": 207, "seek": 147864, "start": 1478.64, "end": 1483.68, "text": " software is GPL and code is on GitHub it's all open source. Anyone can have a look at", "tokens": [4722, 307, 460, 21593, 293, 3089, 307, 322, 23331, 309, 311, 439, 1269, 4009, 13, 14643, 393, 362, 257, 574, 412], "temperature": 0.0, "avg_logprob": -0.19461905066646748, "compression_ratio": 1.441988950276243, "no_speech_prob": 0.00018590575200505555}, {"id": 208, "seek": 147864, "start": 1483.68, "end": 1491.68, "text": " the software behind it. So an important aspect for being able to add these links between", "tokens": [264, 4722, 2261, 309, 13, 407, 364, 1021, 4171, 337, 885, 1075, 281, 909, 613, 6123, 1296], "temperature": 0.0, "avg_logprob": -0.19461905066646748, "compression_ratio": 1.441988950276243, "no_speech_prob": 0.00018590575200505555}, {"id": 209, "seek": 147864, "start": 1491.68, "end": 1499.76, "text": " the systems is to have stable identifiers and for a long time OpenStreetMap has talked", "tokens": [264, 3652, 307, 281, 362, 8351, 2473, 23463, 293, 337, 257, 938, 565, 7238, 50, 3599, 302, 44, 569, 575, 2825], "temperature": 0.0, "avg_logprob": -0.19461905066646748, "compression_ratio": 1.441988950276243, "no_speech_prob": 0.00018590575200505555}, {"id": 210, "seek": 149976, "start": 1499.76, "end": 1508.32, "text": " about the identifiers not being stable and sometimes say a railway station might get", "tokens": [466, 264, 2473, 23463, 406, 885, 8351, 293, 2171, 584, 257, 25812, 5214, 1062, 483], "temperature": 0.0, "avg_logprob": -0.10828375412245929, "compression_ratio": 1.6583850931677018, "no_speech_prob": 4.9371687055099756e-05}, {"id": 211, "seek": 149976, "start": 1508.32, "end": 1515.24, "text": " mapped as a single point and then later on somebody comes along and traces the outline", "tokens": [33318, 382, 257, 2167, 935, 293, 550, 1780, 322, 2618, 1487, 2051, 293, 26076, 264, 16387], "temperature": 0.0, "avg_logprob": -0.10828375412245929, "compression_ratio": 1.6583850931677018, "no_speech_prob": 4.9371687055099756e-05}, {"id": 212, "seek": 149976, "start": 1515.24, "end": 1523.24, "text": " of the building and so it changes from being a node into a way or a relation and the identifier", "tokens": [295, 264, 2390, 293, 370, 309, 2962, 490, 885, 257, 9984, 666, 257, 636, 420, 257, 9721, 293, 264, 45690], "temperature": 0.0, "avg_logprob": -0.10828375412245929, "compression_ratio": 1.6583850931677018, "no_speech_prob": 4.9371687055099756e-05}, {"id": 213, "seek": 152324, "start": 1523.24, "end": 1534.92, "text": " will have changed. So they aren't stable identifiers for concepts in OpenStreetMap. So the thinking", "tokens": [486, 362, 3105, 13, 407, 436, 3212, 380, 8351, 2473, 23463, 337, 10392, 294, 7238, 50, 3599, 302, 44, 569, 13, 407, 264, 1953], "temperature": 0.0, "avg_logprob": -0.16031722499899667, "compression_ratio": 1.6033519553072626, "no_speech_prob": 0.0001712216471787542}, {"id": 214, "seek": 152324, "start": 1534.92, "end": 1542.68, "text": " is that makes it difficult to link into OpenStreetMap because the identifiers might change and", "tokens": [307, 300, 1669, 309, 2252, 281, 2113, 666, 7238, 50, 3599, 302, 44, 569, 570, 264, 2473, 23463, 1062, 1319, 293], "temperature": 0.0, "avg_logprob": -0.16031722499899667, "compression_ratio": 1.6033519553072626, "no_speech_prob": 0.0001712216471787542}, {"id": 215, "seek": 152324, "start": 1542.68, "end": 1549.72, "text": " there's been discussions within the OpenStreetMap community of having a permanent ID and the", "tokens": [456, 311, 668, 11088, 1951, 264, 7238, 50, 3599, 302, 44, 569, 1768, 295, 1419, 257, 10996, 7348, 293, 264], "temperature": 0.0, "avg_logprob": -0.16031722499899667, "compression_ratio": 1.6033519553072626, "no_speech_prob": 0.0001712216471787542}, {"id": 216, "seek": 154972, "start": 1549.72, "end": 1555.84, "text": " discussions have been going on since 2017 and they haven't come to a conclusion. There's", "tokens": [11088, 362, 668, 516, 322, 1670, 6591, 293, 436, 2378, 380, 808, 281, 257, 10063, 13, 821, 311], "temperature": 0.0, "avg_logprob": -0.16014307807473577, "compression_ratio": 1.583710407239819, "no_speech_prob": 0.00011226396600250155}, {"id": 217, "seek": 154972, "start": 1555.84, "end": 1560.92, "text": " been an argument that maybe the right thing to use in terms of stable identifiers would", "tokens": [668, 364, 6770, 300, 1310, 264, 558, 551, 281, 764, 294, 2115, 295, 8351, 2473, 23463, 576], "temperature": 0.0, "avg_logprob": -0.16014307807473577, "compression_ratio": 1.583710407239819, "no_speech_prob": 0.00011226396600250155}, {"id": 218, "seek": 154972, "start": 1560.92, "end": 1567.48, "text": " be wiki data IDs, just say anything that's important enough to need a stable identifier", "tokens": [312, 261, 9850, 1412, 48212, 11, 445, 584, 1340, 300, 311, 1021, 1547, 281, 643, 257, 8351, 45690], "temperature": 0.0, "avg_logprob": -0.16014307807473577, "compression_ratio": 1.583710407239819, "no_speech_prob": 0.00011226396600250155}, {"id": 219, "seek": 154972, "start": 1567.48, "end": 1574.08, "text": " is probably on wiki data and so you could use the wiki data ID as a permanent ID. But", "tokens": [307, 1391, 322, 261, 9850, 1412, 293, 370, 291, 727, 764, 264, 261, 9850, 1412, 7348, 382, 257, 10996, 7348, 13, 583], "temperature": 0.0, "avg_logprob": -0.16014307807473577, "compression_ratio": 1.583710407239819, "no_speech_prob": 0.00011226396600250155}, {"id": 220, "seek": 157408, "start": 1574.08, "end": 1579.6799999999998, "text": " another way to look at it is in reality most of the world is mapped now on OpenStreetMap", "tokens": [1071, 636, 281, 574, 412, 309, 307, 294, 4103, 881, 295, 264, 1002, 307, 33318, 586, 322, 7238, 50, 3599, 302, 44, 569], "temperature": 0.0, "avg_logprob": -0.12029074562920464, "compression_ratio": 1.674641148325359, "no_speech_prob": 0.00011128301412099972}, {"id": 221, "seek": 157408, "start": 1579.6799999999998, "end": 1588.48, "text": " and the IDs aren't changing that much. Things tend to be mapped as polygons like outlines", "tokens": [293, 264, 48212, 3212, 380, 4473, 300, 709, 13, 9514, 3928, 281, 312, 33318, 382, 6754, 70, 892, 411, 40125], "temperature": 0.0, "avg_logprob": -0.12029074562920464, "compression_ratio": 1.674641148325359, "no_speech_prob": 0.00011128301412099972}, {"id": 222, "seek": 157408, "start": 1588.48, "end": 1592.72, "text": " of buildings and people aren't coming along and making changes that are destructive in", "tokens": [295, 7446, 293, 561, 3212, 380, 1348, 2051, 293, 1455, 2962, 300, 366, 26960, 294], "temperature": 0.0, "avg_logprob": -0.12029074562920464, "compression_ratio": 1.674641148325359, "no_speech_prob": 0.00011128301412099972}, {"id": 223, "seek": 157408, "start": 1592.72, "end": 1598.24, "text": " destroying the IDs. So maybe the IDs that are in OpenStreetMap already, the IDs that", "tokens": [19926, 264, 48212, 13, 407, 1310, 264, 48212, 300, 366, 294, 7238, 50, 3599, 302, 44, 569, 1217, 11, 264, 48212, 300], "temperature": 0.0, "avg_logprob": -0.12029074562920464, "compression_ratio": 1.674641148325359, "no_speech_prob": 0.00011128301412099972}, {"id": 224, "seek": 159824, "start": 1598.24, "end": 1604.2, "text": " I talked about earlier, maybe they're stable enough and maybe it's okay to just link to", "tokens": [286, 2825, 466, 3071, 11, 1310, 436, 434, 8351, 1547, 293, 1310, 309, 311, 1392, 281, 445, 2113, 281], "temperature": 0.0, "avg_logprob": -0.14301342683679918, "compression_ratio": 1.640552995391705, "no_speech_prob": 0.00011807033297372982}, {"id": 225, "seek": 159824, "start": 1604.2, "end": 1611.64, "text": " those and not worry about them changing. Whereas we've got wiki data on the other hand and", "tokens": [729, 293, 406, 3292, 466, 552, 4473, 13, 13813, 321, 600, 658, 261, 9850, 1412, 322, 264, 661, 1011, 293], "temperature": 0.0, "avg_logprob": -0.14301342683679918, "compression_ratio": 1.640552995391705, "no_speech_prob": 0.00011807033297372982}, {"id": 226, "seek": 159824, "start": 1611.64, "end": 1617.64, "text": " wiki data was designed always to have stable identifiers. That was a big part I think of", "tokens": [261, 9850, 1412, 390, 4761, 1009, 281, 362, 8351, 2473, 23463, 13, 663, 390, 257, 955, 644, 286, 519, 295], "temperature": 0.0, "avg_logprob": -0.14301342683679918, "compression_ratio": 1.640552995391705, "no_speech_prob": 0.00011807033297372982}, {"id": 227, "seek": 159824, "start": 1617.64, "end": 1627.44, "text": " the initial approach to wiki data. Wikipedia identifies things by article title and over", "tokens": [264, 5883, 3109, 281, 261, 9850, 1412, 13, 28999, 34597, 721, 538, 7222, 4876, 293, 670], "temperature": 0.0, "avg_logprob": -0.14301342683679918, "compression_ratio": 1.640552995391705, "no_speech_prob": 0.00011807033297372982}, {"id": 228, "seek": 162744, "start": 1627.44, "end": 1634.0, "text": " time the article titles can change and then things get moved around and so they don't", "tokens": [565, 264, 7222, 12992, 393, 1319, 293, 550, 721, 483, 4259, 926, 293, 370, 436, 500, 380], "temperature": 0.0, "avg_logprob": -0.13740958338198456, "compression_ratio": 1.5619469026548674, "no_speech_prob": 5.9156132920179516e-05}, {"id": 229, "seek": 162744, "start": 1634.0, "end": 1642.0, "text": " have long-term stable IDs and so the wiki data QIDs was an approach that gave you stable", "tokens": [362, 938, 12, 7039, 8351, 48212, 293, 370, 264, 261, 9850, 1412, 1249, 2777, 82, 390, 364, 3109, 300, 2729, 291, 8351], "temperature": 0.0, "avg_logprob": -0.13740958338198456, "compression_ratio": 1.5619469026548674, "no_speech_prob": 5.9156132920179516e-05}, {"id": 230, "seek": 162744, "start": 1642.0, "end": 1647.72, "text": " IDs. But it turns out that they're not completely stable. There's also redirects appearing in", "tokens": [48212, 13, 583, 309, 4523, 484, 300, 436, 434, 406, 2584, 8351, 13, 821, 311, 611, 29066, 82, 19870, 294], "temperature": 0.0, "avg_logprob": -0.13740958338198456, "compression_ratio": 1.5619469026548674, "no_speech_prob": 5.9156132920179516e-05}, {"id": 231, "seek": 162744, "start": 1647.72, "end": 1652.8400000000001, "text": " wiki data. Like with some of the work I've been doing, I find a lot of duplicates in", "tokens": [261, 9850, 1412, 13, 1743, 365, 512, 295, 264, 589, 286, 600, 668, 884, 11, 286, 915, 257, 688, 295, 17154, 1024, 294], "temperature": 0.0, "avg_logprob": -0.13740958338198456, "compression_ratio": 1.5619469026548674, "no_speech_prob": 5.9156132920179516e-05}, {"id": 232, "seek": 165284, "start": 1652.84, "end": 1658.28, "text": " wiki data. Things have been imported from different sources and say for example I found", "tokens": [261, 9850, 1412, 13, 9514, 362, 668, 25524, 490, 819, 7139, 293, 584, 337, 1365, 286, 1352], "temperature": 0.0, "avg_logprob": -0.18310912205622745, "compression_ratio": 1.5, "no_speech_prob": 0.00012498196156229824}, {"id": 233, "seek": 165284, "start": 1658.28, "end": 1666.04, "text": " a lot of duplicate churches in wiki data. So when I go and I merge the churches, then", "tokens": [257, 688, 295, 23976, 15381, 294, 261, 9850, 1412, 13, 407, 562, 286, 352, 293, 286, 22183, 264, 15381, 11, 550], "temperature": 0.0, "avg_logprob": -0.18310912205622745, "compression_ratio": 1.5, "no_speech_prob": 0.00012498196156229824}, {"id": 234, "seek": 165284, "start": 1666.04, "end": 1675.3999999999999, "text": " the ID that represents one of those churches will change. So I've got on the slide here", "tokens": [264, 7348, 300, 8855, 472, 295, 729, 15381, 486, 1319, 13, 407, 286, 600, 658, 322, 264, 4137, 510], "temperature": 0.0, "avg_logprob": -0.18310912205622745, "compression_ratio": 1.5, "no_speech_prob": 0.00012498196156229824}, {"id": 235, "seek": 167540, "start": 1675.4, "end": 1683.92, "text": " there's 10,000 OpenStreetMap objects that point to a redirect in wiki data and somebody", "tokens": [456, 311, 1266, 11, 1360, 7238, 50, 3599, 302, 44, 569, 6565, 300, 935, 281, 257, 29066, 294, 261, 9850, 1412, 293, 2618], "temperature": 0.0, "avg_logprob": -0.13088723500569663, "compression_ratio": 1.5406976744186047, "no_speech_prob": 8.846956916386262e-05}, {"id": 236, "seek": 167540, "start": 1683.92, "end": 1691.8000000000002, "text": " needs to go through and resolve those redirects and fix OpenStreetMap. I will probably do", "tokens": [2203, 281, 352, 807, 293, 14151, 729, 29066, 82, 293, 3191, 7238, 50, 3599, 302, 44, 569, 13, 286, 486, 1391, 360], "temperature": 0.0, "avg_logprob": -0.13088723500569663, "compression_ratio": 1.5406976744186047, "no_speech_prob": 8.846956916386262e-05}, {"id": 237, "seek": 167540, "start": 1691.8000000000002, "end": 1700.48, "text": " that at some point if no one else does. So a recent change to wiki data is that there's", "tokens": [300, 412, 512, 935, 498, 572, 472, 1646, 775, 13, 407, 257, 5162, 1319, 281, 261, 9850, 1412, 307, 300, 456, 311], "temperature": 0.0, "avg_logprob": -0.13088723500569663, "compression_ratio": 1.5406976744186047, "no_speech_prob": 8.846956916386262e-05}, {"id": 238, "seek": 170048, "start": 1700.48, "end": 1708.92, "text": " a new property called OpenStreetMapElement and that is for storing OpenStreetMap IDs.", "tokens": [257, 777, 4707, 1219, 7238, 50, 3599, 302, 44, 569, 36, 3054, 293, 300, 307, 337, 26085, 7238, 50, 3599, 302, 44, 569, 48212, 13], "temperature": 0.0, "avg_logprob": -0.06893614360264369, "compression_ratio": 1.5389221556886228, "no_speech_prob": 0.00014491927868220955}, {"id": 239, "seek": 170048, "start": 1708.92, "end": 1717.3600000000001, "text": " So now it is possible to add the links in both directions. We can have links from wiki", "tokens": [407, 586, 309, 307, 1944, 281, 909, 264, 6123, 294, 1293, 11095, 13, 492, 393, 362, 6123, 490, 261, 9850], "temperature": 0.0, "avg_logprob": -0.06893614360264369, "compression_ratio": 1.5389221556886228, "no_speech_prob": 0.00014491927868220955}, {"id": 240, "seek": 170048, "start": 1717.3600000000001, "end": 1724.28, "text": " data to OpenStreetMap which we never used to be able to have. So I need to change my", "tokens": [1412, 281, 7238, 50, 3599, 302, 44, 569, 597, 321, 1128, 1143, 281, 312, 1075, 281, 362, 13, 407, 286, 643, 281, 1319, 452], "temperature": 0.0, "avg_logprob": -0.06893614360264369, "compression_ratio": 1.5389221556886228, "no_speech_prob": 0.00014491927868220955}, {"id": 241, "seek": 172428, "start": 1724.28, "end": 1731.2, "text": " software to start adding these links in. When you save things at the moment it just uploads", "tokens": [4722, 281, 722, 5127, 613, 6123, 294, 13, 1133, 291, 3155, 721, 412, 264, 1623, 309, 445, 48611], "temperature": 0.0, "avg_logprob": -0.15901609028086944, "compression_ratio": 1.4777777777777779, "no_speech_prob": 0.00011086103768320754}, {"id": 242, "seek": 172428, "start": 1731.2, "end": 1737.52, "text": " into OpenStreetMap it should be uploading them to wiki data as well. But to do that", "tokens": [666, 7238, 50, 3599, 302, 44, 569, 309, 820, 312, 27301, 552, 281, 261, 9850, 1412, 382, 731, 13, 583, 281, 360, 300], "temperature": 0.0, "avg_logprob": -0.15901609028086944, "compression_ratio": 1.4777777777777779, "no_speech_prob": 0.00011086103768320754}, {"id": 243, "seek": 172428, "start": 1737.52, "end": 1744.92, "text": " I need to make the user login to both systems which is possible but it will break the flow", "tokens": [286, 643, 281, 652, 264, 4195, 24276, 281, 1293, 3652, 597, 307, 1944, 457, 309, 486, 1821, 264, 3095], "temperature": 0.0, "avg_logprob": -0.15901609028086944, "compression_ratio": 1.4777777777777779, "no_speech_prob": 0.00011086103768320754}, {"id": 244, "seek": 174492, "start": 1744.92, "end": 1772.92, "text": " of it. So I am going to try and do a demo. Let's see. So this is the software I'm describing", "tokens": [295, 309, 13, 407, 286, 669, 516, 281, 853, 293, 360, 257, 10723, 13, 961, 311, 536, 13, 407, 341, 307, 264, 4722, 286, 478, 16141], "temperature": 0.0, "avg_logprob": -0.15660851796468098, "compression_ratio": 1.0952380952380953, "no_speech_prob": 0.00036206861841492355}, {"id": 245, "seek": 177292, "start": 1772.92, "end": 1780.3600000000001, "text": " and I can say I want it in English. And you can see the type filter there and if I scroll", "tokens": [293, 286, 393, 584, 286, 528, 309, 294, 3669, 13, 400, 291, 393, 536, 264, 2010, 6608, 456, 293, 498, 286, 11369], "temperature": 0.0, "avg_logprob": -0.1692856636600218, "compression_ratio": 1.5174418604651163, "no_speech_prob": 0.0004976332420483232}, {"id": 246, "seek": 177292, "start": 1780.3600000000001, "end": 1786.0, "text": " down it shows matches that weren't very good at the start. So it's got some difficulty", "tokens": [760, 309, 3110, 10676, 300, 4999, 380, 588, 665, 412, 264, 722, 13, 407, 309, 311, 658, 512, 10360], "temperature": 0.0, "avg_logprob": -0.1692856636600218, "compression_ratio": 1.5174418604651163, "no_speech_prob": 0.0004976332420483232}, {"id": 247, "seek": 177292, "start": 1786.0, "end": 1791.72, "text": " with this match and it can't handle it so we scroll past those. And here's the first", "tokens": [365, 341, 2995, 293, 309, 393, 380, 4813, 309, 370, 321, 11369, 1791, 729, 13, 400, 510, 311, 264, 700], "temperature": 0.0, "avg_logprob": -0.1692856636600218, "compression_ratio": 1.5174418604651163, "no_speech_prob": 0.0004976332420483232}, {"id": 248, "seek": 179172, "start": 1791.72, "end": 1804.4, "text": " match that the system can handle and if I click on it then it shows you the match. I", "tokens": [2995, 300, 264, 1185, 393, 4813, 293, 498, 286, 2052, 322, 309, 550, 309, 3110, 291, 264, 2995, 13, 286], "temperature": 0.0, "avg_logprob": -0.1445401954650879, "compression_ratio": 1.384, "no_speech_prob": 0.00013544896501116455}, {"id": 249, "seek": 179172, "start": 1804.4, "end": 1816.3600000000001, "text": " can click toggle OSM tags. This is showing all of the tags from OpenStreetMap. The green", "tokens": [393, 2052, 31225, 12731, 44, 18632, 13, 639, 307, 4099, 439, 295, 264, 18632, 490, 7238, 50, 3599, 302, 44, 569, 13, 440, 3092], "temperature": 0.0, "avg_logprob": -0.1445401954650879, "compression_ratio": 1.384, "no_speech_prob": 0.00013544896501116455}, {"id": 250, "seek": 181636, "start": 1816.36, "end": 1825.4399999999998, "text": " ones are ones where it's found a match that's using those to figure out what the match is.", "tokens": [2306, 366, 2306, 689, 309, 311, 1352, 257, 2995, 300, 311, 1228, 729, 281, 2573, 484, 437, 264, 2995, 307, 13], "temperature": 0.0, "avg_logprob": -0.1698353416041324, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.00019628195150289685}, {"id": 251, "seek": 181636, "start": 1825.4399999999998, "end": 1831.32, "text": " I'll show you some more. Here's another one. You can see it appearing on the map. If I", "tokens": [286, 603, 855, 291, 512, 544, 13, 1692, 311, 1071, 472, 13, 509, 393, 536, 309, 19870, 322, 264, 4471, 13, 759, 286], "temperature": 0.0, "avg_logprob": -0.1698353416041324, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.00019628195150289685}, {"id": 252, "seek": 181636, "start": 1831.32, "end": 1841.6399999999999, "text": " think this is not a correct match I can click here and it's deselected it. So I've got a", "tokens": [519, 341, 307, 406, 257, 3006, 2995, 286, 393, 2052, 510, 293, 309, 311, 730, 14664, 292, 309, 13, 407, 286, 600, 658, 257], "temperature": 0.0, "avg_logprob": -0.1698353416041324, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.00019628195150289685}, {"id": 253, "seek": 184164, "start": 1841.64, "end": 1847.16, "text": " whole pile of matches here. I've checked these ahead of time. They're all good. So I scroll", "tokens": [1379, 14375, 295, 10676, 510, 13, 286, 600, 10033, 613, 2286, 295, 565, 13, 814, 434, 439, 665, 13, 407, 286, 11369], "temperature": 0.0, "avg_logprob": -0.18723799052991366, "compression_ratio": 1.5026455026455026, "no_speech_prob": 0.00023206486366689205}, {"id": 254, "seek": 184164, "start": 1847.16, "end": 1855.2, "text": " to the bottom and I can say add tags to OpenStreetMap and this is the confirmation page that I was", "tokens": [281, 264, 2767, 293, 286, 393, 584, 909, 18632, 281, 7238, 50, 3599, 302, 44, 569, 293, 341, 307, 264, 21871, 3028, 300, 286, 390], "temperature": 0.0, "avg_logprob": -0.18723799052991366, "compression_ratio": 1.5026455026455026, "no_speech_prob": 0.00023206486366689205}, {"id": 255, "seek": 184164, "start": 1855.2, "end": 1869.3200000000002, "text": " talking about. So I can hit save and the software goes through and it's saving my matches. So", "tokens": [1417, 466, 13, 407, 286, 393, 2045, 3155, 293, 264, 4722, 1709, 807, 293, 309, 311, 6816, 452, 10676, 13, 407], "temperature": 0.0, "avg_logprob": -0.18723799052991366, "compression_ratio": 1.5026455026455026, "no_speech_prob": 0.00023206486366689205}, {"id": 256, "seek": 186932, "start": 1869.32, "end": 1878.32, "text": " it has done it and I can say view my change set and you get to see my change set on OpenStreetMap.", "tokens": [309, 575, 1096, 309, 293, 286, 393, 584, 1910, 452, 1319, 992, 293, 291, 483, 281, 536, 452, 1319, 992, 322, 7238, 50, 3599, 302, 44, 569, 13], "temperature": 0.0, "avg_logprob": -0.17945336428555575, "compression_ratio": 1.4461538461538461, "no_speech_prob": 0.00023768639948684722}, {"id": 257, "seek": 186932, "start": 1878.32, "end": 1887.3999999999999, "text": " I can scroll down and you can see these are all the things I've edited. So nice and quick", "tokens": [286, 393, 11369, 760, 293, 291, 393, 536, 613, 366, 439, 264, 721, 286, 600, 23016, 13, 407, 1481, 293, 1702], "temperature": 0.0, "avg_logprob": -0.17945336428555575, "compression_ratio": 1.4461538461538461, "no_speech_prob": 0.00023768639948684722}, {"id": 258, "seek": 188740, "start": 1887.4, "end": 1899.96, "text": " to go through and edit OpenStreetMap. I've just got another example. Another bit of Brussels.", "tokens": [281, 352, 807, 293, 8129, 7238, 50, 3599, 302, 44, 569, 13, 286, 600, 445, 658, 1071, 1365, 13, 3996, 857, 295, 38717, 13], "temperature": 0.0, "avg_logprob": -0.22997352600097656, "compression_ratio": 1.3021582733812949, "no_speech_prob": 7.119212386896834e-05}, {"id": 259, "seek": 188740, "start": 1899.96, "end": 1911.0, "text": " I can change to English. Say I want squares and then if I scroll down it will just show", "tokens": [286, 393, 1319, 281, 3669, 13, 6463, 286, 528, 19368, 293, 550, 498, 286, 11369, 760, 309, 486, 445, 855], "temperature": 0.0, "avg_logprob": -0.22997352600097656, "compression_ratio": 1.3021582733812949, "no_speech_prob": 7.119212386896834e-05}, {"id": 260, "seek": 191100, "start": 1911.0, "end": 1919.8, "text": " me some matches that haven't worked. So scroll past those. Here's some squares that the software", "tokens": [385, 512, 10676, 300, 2378, 380, 2732, 13, 407, 11369, 1791, 729, 13, 1692, 311, 512, 19368, 300, 264, 4722], "temperature": 0.0, "avg_logprob": -0.14568533962720062, "compression_ratio": 1.532967032967033, "no_speech_prob": 0.00013383370242081583}, {"id": 261, "seek": 191100, "start": 1919.8, "end": 1929.08, "text": " has managed to match up. And these all look like good matches. I've checked these before", "tokens": [575, 6453, 281, 2995, 493, 13, 400, 613, 439, 574, 411, 665, 10676, 13, 286, 600, 10033, 613, 949], "temperature": 0.0, "avg_logprob": -0.14568533962720062, "compression_ratio": 1.532967032967033, "no_speech_prob": 0.00013383370242081583}, {"id": 262, "seek": 191100, "start": 1929.08, "end": 1938.56, "text": " so I can scroll to the bottom. There's another one and I can say add to save to OpenStreetMap", "tokens": [370, 286, 393, 11369, 281, 264, 2767, 13, 821, 311, 1071, 472, 293, 286, 393, 584, 909, 281, 3155, 281, 7238, 50, 3599, 302, 44, 569], "temperature": 0.0, "avg_logprob": -0.14568533962720062, "compression_ratio": 1.532967032967033, "no_speech_prob": 0.00013383370242081583}, {"id": 263, "seek": 193856, "start": 1938.56, "end": 1948.76, "text": " and it's in the change comment it's put the word squares. So I can hit save and that is", "tokens": [293, 309, 311, 294, 264, 1319, 2871, 309, 311, 829, 264, 1349, 19368, 13, 407, 286, 393, 2045, 3155, 293, 300, 307], "temperature": 0.0, "avg_logprob": -0.1506456479634324, "compression_ratio": 1.4804469273743017, "no_speech_prob": 6.400270649464801e-05}, {"id": 264, "seek": 193856, "start": 1948.76, "end": 1960.56, "text": " working to edit OpenStreetMap. I'll go back to the presentation. So that was my existing", "tokens": [1364, 281, 8129, 7238, 50, 3599, 302, 44, 569, 13, 286, 603, 352, 646, 281, 264, 5860, 13, 407, 300, 390, 452, 6741], "temperature": 0.0, "avg_logprob": -0.1506456479634324, "compression_ratio": 1.4804469273743017, "no_speech_prob": 6.400270649464801e-05}, {"id": 265, "seek": 193856, "start": 1960.56, "end": 1964.12, "text": " software. That's been running for a few years. People have been using that and I've been", "tokens": [4722, 13, 663, 311, 668, 2614, 337, 257, 1326, 924, 13, 3432, 362, 668, 1228, 300, 293, 286, 600, 668], "temperature": 0.0, "avg_logprob": -0.1506456479634324, "compression_ratio": 1.4804469273743017, "no_speech_prob": 6.400270649464801e-05}, {"id": 266, "seek": 196412, "start": 1964.12, "end": 1970.7199999999998, "text": " working on a new version of the software that I'm calling OwlMap. This is what OwlMap looks", "tokens": [1364, 322, 257, 777, 3037, 295, 264, 4722, 300, 286, 478, 5141, 12773, 75, 44, 569, 13, 639, 307, 437, 12773, 75, 44, 569, 1542], "temperature": 0.0, "avg_logprob": -0.1998791436891298, "compression_ratio": 1.4972375690607735, "no_speech_prob": 0.00013954717724118382}, {"id": 267, "seek": 196412, "start": 1970.7199999999998, "end": 1978.8799999999999, "text": " like. So when you open this you go straight to a map. It tries to guess where you are,", "tokens": [411, 13, 407, 562, 291, 1269, 341, 291, 352, 2997, 281, 257, 4471, 13, 467, 9898, 281, 2041, 689, 291, 366, 11], "temperature": 0.0, "avg_logprob": -0.1998791436891298, "compression_ratio": 1.4972375690607735, "no_speech_prob": 0.00013954717724118382}, {"id": 268, "seek": 196412, "start": 1978.8799999999999, "end": 1986.36, "text": " locate you based on your IP address and then it shows you this interface much more map-based", "tokens": [22370, 291, 2361, 322, 428, 8671, 2985, 293, 550, 309, 3110, 291, 341, 9226, 709, 544, 4471, 12, 6032], "temperature": 0.0, "avg_logprob": -0.1998791436891298, "compression_ratio": 1.4972375690607735, "no_speech_prob": 0.00013954717724118382}, {"id": 269, "seek": 198636, "start": 1986.36, "end": 1994.8799999999999, "text": " rather than like a list of things. You see the red pins are where there isn't a match", "tokens": [2831, 813, 411, 257, 1329, 295, 721, 13, 509, 536, 264, 2182, 16392, 366, 689, 456, 1943, 380, 257, 2995], "temperature": 0.0, "avg_logprob": -0.14225069681803384, "compression_ratio": 1.8217821782178218, "no_speech_prob": 7.044763333396986e-05}, {"id": 270, "seek": 198636, "start": 1994.8799999999999, "end": 2001.84, "text": " already. Green pins are where there is a match and the yellow pins are OpenStreetMap things.", "tokens": [1217, 13, 6969, 16392, 366, 689, 456, 307, 257, 2995, 293, 264, 5566, 16392, 366, 7238, 50, 3599, 302, 44, 569, 721, 13], "temperature": 0.0, "avg_logprob": -0.14225069681803384, "compression_ratio": 1.8217821782178218, "no_speech_prob": 7.044763333396986e-05}, {"id": 271, "seek": 198636, "start": 2001.84, "end": 2008.0, "text": " So you can see some of them have a line between the green pin and the yellow pin. That's showing", "tokens": [407, 291, 393, 536, 512, 295, 552, 362, 257, 1622, 1296, 264, 3092, 5447, 293, 264, 5566, 5447, 13, 663, 311, 4099], "temperature": 0.0, "avg_logprob": -0.14225069681803384, "compression_ratio": 1.8217821782178218, "no_speech_prob": 7.044763333396986e-05}, {"id": 272, "seek": 198636, "start": 2008.0, "end": 2016.08, "text": " you which, you know, the green pin is a Wikipedia item that matches a thing on OpenStreetMap", "tokens": [291, 597, 11, 291, 458, 11, 264, 3092, 5447, 307, 257, 28999, 3174, 300, 10676, 257, 551, 322, 7238, 50, 3599, 302, 44, 569], "temperature": 0.0, "avg_logprob": -0.14225069681803384, "compression_ratio": 1.8217821782178218, "no_speech_prob": 7.044763333396986e-05}, {"id": 273, "seek": 201608, "start": 2016.08, "end": 2021.04, "text": " which is the yellow pin and there's a line between them. And you've got a filter at the", "tokens": [597, 307, 264, 5566, 5447, 293, 456, 311, 257, 1622, 1296, 552, 13, 400, 291, 600, 658, 257, 6608, 412, 264], "temperature": 0.0, "avg_logprob": -0.11070916482380458, "compression_ratio": 1.6833976833976834, "no_speech_prob": 0.00010835307330125943}, {"id": 274, "seek": 201608, "start": 2021.04, "end": 2028.56, "text": " side where you can filter on different item types. This is an example where I've selected", "tokens": [1252, 689, 291, 393, 6608, 322, 819, 3174, 3467, 13, 639, 307, 364, 1365, 689, 286, 600, 8209], "temperature": 0.0, "avg_logprob": -0.11070916482380458, "compression_ratio": 1.6833976833976834, "no_speech_prob": 0.00010835307330125943}, {"id": 275, "seek": 201608, "start": 2028.56, "end": 2034.04, "text": " one of the pins. I've clicked on a pin and it changes the color slightly and it shows", "tokens": [472, 295, 264, 16392, 13, 286, 600, 23370, 322, 257, 5447, 293, 309, 2962, 264, 2017, 4748, 293, 309, 3110], "temperature": 0.0, "avg_logprob": -0.11070916482380458, "compression_ratio": 1.6833976833976834, "no_speech_prob": 0.00010835307330125943}, {"id": 276, "seek": 201608, "start": 2034.04, "end": 2040.0, "text": " you some details. You get to see the photo and bits and pieces from Wikidata. And then", "tokens": [291, 512, 4365, 13, 509, 483, 281, 536, 264, 5052, 293, 9239, 293, 3755, 490, 23377, 327, 3274, 13, 400, 550], "temperature": 0.0, "avg_logprob": -0.11070916482380458, "compression_ratio": 1.6833976833976834, "no_speech_prob": 0.00010835307330125943}, {"id": 277, "seek": 201608, "start": 2040.0, "end": 2045.0, "text": " underneath it shows you a list of possible matches. It just says, you know, this is a", "tokens": [7223, 309, 3110, 291, 257, 1329, 295, 1944, 10676, 13, 467, 445, 1619, 11, 291, 458, 11, 341, 307, 257], "temperature": 0.0, "avg_logprob": -0.11070916482380458, "compression_ratio": 1.6833976833976834, "no_speech_prob": 0.00010835307330125943}, {"id": 278, "seek": 204500, "start": 2045.0, "end": 2052.12, "text": " building. Here's some other buildings nearby. And I can see the street addresses on here", "tokens": [2390, 13, 1692, 311, 512, 661, 7446, 11184, 13, 400, 286, 393, 536, 264, 4838, 16862, 322, 510], "temperature": 0.0, "avg_logprob": -0.16558577797629617, "compression_ratio": 1.791044776119403, "no_speech_prob": 0.00022149161668494344}, {"id": 279, "seek": 204500, "start": 2052.12, "end": 2058.04, "text": " and, you know, the nearest building. The street address matches. But in actual fact, there's", "tokens": [293, 11, 291, 458, 11, 264, 23831, 2390, 13, 440, 4838, 2985, 10676, 13, 583, 294, 3539, 1186, 11, 456, 311], "temperature": 0.0, "avg_logprob": -0.16558577797629617, "compression_ratio": 1.791044776119403, "no_speech_prob": 0.00022149161668494344}, {"id": 280, "seek": 204500, "start": 2058.04, "end": 2064.2, "text": " two street addresses on there. And if I scroll down this list, I can see that there's two", "tokens": [732, 4838, 16862, 322, 456, 13, 400, 498, 286, 11369, 760, 341, 1329, 11, 286, 393, 536, 300, 456, 311, 732], "temperature": 0.0, "avg_logprob": -0.16558577797629617, "compression_ratio": 1.791044776119403, "no_speech_prob": 0.00022149161668494344}, {"id": 281, "seek": 204500, "start": 2064.2, "end": 2069.92, "text": " buildings next to each other that both match this warehouse. So for some reason Wikidata", "tokens": [7446, 958, 281, 1184, 661, 300, 1293, 2995, 341, 22244, 13, 407, 337, 512, 1778, 23377, 327, 3274], "temperature": 0.0, "avg_logprob": -0.16558577797629617, "compression_ratio": 1.791044776119403, "no_speech_prob": 0.00022149161668494344}, {"id": 282, "seek": 206992, "start": 2069.92, "end": 2075.76, "text": " is representing it as a single item whereas OpenStreetMap has got two separate objects.", "tokens": [307, 13460, 309, 382, 257, 2167, 3174, 9735, 7238, 50, 3599, 302, 44, 569, 575, 658, 732, 4994, 6565, 13], "temperature": 0.0, "avg_logprob": -0.14192522090414297, "compression_ratio": 1.5644444444444445, "no_speech_prob": 0.00018159540195483714}, {"id": 283, "seek": 206992, "start": 2075.76, "end": 2080.96, "text": " But this version of the software supports it. So I tick the boxes next to them and then", "tokens": [583, 341, 3037, 295, 264, 4722, 9346, 309, 13, 407, 286, 5204, 264, 9002, 958, 281, 552, 293, 550], "temperature": 0.0, "avg_logprob": -0.14192522090414297, "compression_ratio": 1.5644444444444445, "no_speech_prob": 0.00018159540195483714}, {"id": 284, "seek": 206992, "start": 2080.96, "end": 2088.84, "text": " I can hit save and it'll add the Wikidata tag to them. So this bit of software I'm still", "tokens": [286, 393, 2045, 3155, 293, 309, 603, 909, 264, 23377, 327, 3274, 6162, 281, 552, 13, 407, 341, 857, 295, 4722, 286, 478, 920], "temperature": 0.0, "avg_logprob": -0.14192522090414297, "compression_ratio": 1.5644444444444445, "no_speech_prob": 0.00018159540195483714}, {"id": 285, "seek": 206992, "start": 2088.84, "end": 2095.64, "text": " working on. It's live but it keeps breaking so I'm not really advertising for people to", "tokens": [1364, 322, 13, 467, 311, 1621, 457, 309, 5965, 7697, 370, 286, 478, 406, 534, 13097, 337, 561, 281], "temperature": 0.0, "avg_logprob": -0.14192522090414297, "compression_ratio": 1.5644444444444445, "no_speech_prob": 0.00018159540195483714}, {"id": 286, "seek": 209564, "start": 2095.64, "end": 2106.7999999999997, "text": " use it. I need to do some more work on it. And in fact, I think I need some help. You", "tokens": [764, 309, 13, 286, 643, 281, 360, 512, 544, 589, 322, 309, 13, 400, 294, 1186, 11, 286, 519, 286, 643, 512, 854, 13, 509], "temperature": 0.0, "avg_logprob": -0.13008700745015206, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.00017268994997721165}, {"id": 287, "seek": 209564, "start": 2106.7999999999997, "end": 2112.12, "text": " know, I'm just a hobbyist and I'm running out of time to work on this stuff. So I don't", "tokens": [458, 11, 286, 478, 445, 257, 18240, 468, 293, 286, 478, 2614, 484, 295, 565, 281, 589, 322, 341, 1507, 13, 407, 286, 500, 380], "temperature": 0.0, "avg_logprob": -0.13008700745015206, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.00017268994997721165}, {"id": 288, "seek": 209564, "start": 2112.12, "end": 2118.7999999999997, "text": " know if anyone knows how I can get some help with this, whether, you know, there's someone", "tokens": [458, 498, 2878, 3255, 577, 286, 393, 483, 512, 854, 365, 341, 11, 1968, 11, 291, 458, 11, 456, 311, 1580], "temperature": 0.0, "avg_logprob": -0.13008700745015206, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.00017268994997721165}, {"id": 289, "seek": 211880, "start": 2118.8, "end": 2126.7200000000003, "text": " out there who wants to pay for this work or whether I can find volunteers to help me.", "tokens": [484, 456, 567, 2738, 281, 1689, 337, 341, 589, 420, 1968, 286, 393, 915, 14352, 281, 854, 385, 13], "temperature": 0.0, "avg_logprob": -0.11442897717158, "compression_ratio": 1.4126984126984128, "no_speech_prob": 8.523251744918525e-05}, {"id": 290, "seek": 211880, "start": 2126.7200000000003, "end": 2136.7200000000003, "text": " I don't know. It's all a bit tricky like trying to work out managing people to work on this.", "tokens": [286, 500, 380, 458, 13, 467, 311, 439, 257, 857, 12414, 411, 1382, 281, 589, 484, 11642, 561, 281, 589, 322, 341, 13], "temperature": 0.0, "avg_logprob": -0.11442897717158, "compression_ratio": 1.4126984126984128, "no_speech_prob": 8.523251744918525e-05}, {"id": 291, "seek": 213672, "start": 2136.72, "end": 2153.3599999999997, "text": " So yeah, that's the software built. And I guess, has anyone got any questions?", "tokens": [407, 1338, 11, 300, 311, 264, 4722, 3094, 13, 400, 286, 2041, 11, 575, 2878, 658, 604, 1651, 30], "temperature": 0.0, "avg_logprob": -0.2820246323295262, "compression_ratio": 0.975, "no_speech_prob": 0.00040378584526479244}, {"id": 292, "seek": 215336, "start": 2153.36, "end": 2181.1200000000003, "text": " If you have a question, please raise your hand so I can see you all there. I'm coming.", "tokens": [759, 291, 362, 257, 1168, 11, 1767, 5300, 428, 1011, 370, 286, 393, 536, 291, 439, 456, 13, 286, 478, 1348, 13], "temperature": 0.0, "avg_logprob": -0.15858806096590483, "compression_ratio": 1.048780487804878, "no_speech_prob": 0.010234497487545013}, {"id": 293, "seek": 218112, "start": 2181.12, "end": 2186.96, "text": " Thank you, Edward, for that. Hi, I'm Siebrandt. I'm a volunteer at Wikimedia. Wikimedia has", "tokens": [1044, 291, 11, 18456, 11, 337, 300, 13, 2421, 11, 286, 478, 3559, 30476, 83, 13, 286, 478, 257, 13835, 412, 23377, 332, 14212, 13, 23377, 332, 14212, 575], "temperature": 0.0, "avg_logprob": -0.21657412539246262, "compression_ratio": 1.6221198156682028, "no_speech_prob": 0.004645344335585833}, {"id": 294, "seek": 218112, "start": 2186.96, "end": 2194.56, "text": " a service called Wikimedia Cloud Services where you can get free compute resources.", "tokens": [257, 2643, 1219, 23377, 332, 14212, 8061, 12124, 689, 291, 393, 483, 1737, 14722, 3593, 13], "temperature": 0.0, "avg_logprob": -0.21657412539246262, "compression_ratio": 1.6221198156682028, "no_speech_prob": 0.004645344335585833}, {"id": 295, "seek": 218112, "start": 2194.56, "end": 2200.52, "text": " Oh, where you can get free compute resources. I would highly recommend that you look into", "tokens": [876, 11, 689, 291, 393, 483, 1737, 14722, 3593, 13, 286, 576, 5405, 2748, 300, 291, 574, 666], "temperature": 0.0, "avg_logprob": -0.21657412539246262, "compression_ratio": 1.6221198156682028, "no_speech_prob": 0.004645344335585833}, {"id": 296, "seek": 218112, "start": 2200.52, "end": 2206.92, "text": " that. So like the machine I'm running some of this stuff on is 60 gigabytes of RAM and", "tokens": [300, 13, 407, 411, 264, 3479, 286, 478, 2614, 512, 295, 341, 1507, 322, 307, 4060, 42741, 295, 14561, 293], "temperature": 0.0, "avg_logprob": -0.21657412539246262, "compression_ratio": 1.6221198156682028, "no_speech_prob": 0.004645344335585833}, {"id": 297, "seek": 220692, "start": 2206.92, "end": 2214.0, "text": " two terabytes of disk. Would I be able to get that much from Cloud Services?", "tokens": [732, 1796, 24538, 295, 12355, 13, 6068, 286, 312, 1075, 281, 483, 300, 709, 490, 8061, 12124, 30], "temperature": 0.0, "avg_logprob": -0.18122633420504056, "compression_ratio": 1.4628571428571429, "no_speech_prob": 0.0008086813613772392}, {"id": 298, "seek": 220692, "start": 2214.0, "end": 2221.56, "text": " I would highly recommend that you talk to someone there as you may be having a project", "tokens": [286, 576, 5405, 2748, 300, 291, 751, 281, 1580, 456, 382, 291, 815, 312, 1419, 257, 1716], "temperature": 0.0, "avg_logprob": -0.18122633420504056, "compression_ratio": 1.4628571428571429, "no_speech_prob": 0.0008086813613772392}, {"id": 299, "seek": 220692, "start": 2221.56, "end": 2228.0, "text": " that's quite valuable to the Wikimedia movement. I'm sure that someone will try to help you.", "tokens": [300, 311, 1596, 8263, 281, 264, 23377, 332, 14212, 3963, 13, 286, 478, 988, 300, 1580, 486, 853, 281, 854, 291, 13], "temperature": 0.0, "avg_logprob": -0.18122633420504056, "compression_ratio": 1.4628571428571429, "no_speech_prob": 0.0008086813613772392}, {"id": 300, "seek": 222800, "start": 2228.0, "end": 2250.12, "text": " Thank you for your contributions and for the talk. Have you considered interfacing or linking", "tokens": [1044, 291, 337, 428, 15725, 293, 337, 264, 751, 13, 3560, 291, 4888, 14510, 5615, 420, 25775], "temperature": 0.0, "avg_logprob": -0.31638054620651973, "compression_ratio": 1.1071428571428572, "no_speech_prob": 0.00653649028390646}, {"id": 301, "seek": 225012, "start": 2250.12, "end": 2269.04, "text": " with OSMOS? It's a quality assurance project. It's a quality assurance project. It's a", "tokens": [365, 12731, 44, 4367, 30, 467, 311, 257, 3125, 32189, 1716, 13, 467, 311, 257, 3125, 32189, 1716, 13, 467, 311, 257], "temperature": 0.0, "avg_logprob": -0.42004933724036586, "compression_ratio": 1.5636363636363637, "no_speech_prob": 0.012571598403155804}, {"id": 302, "seek": 226904, "start": 2269.04, "end": 2279.44, "text": " model where you see alerts on the mob, dangling ways, et cetera. I think it's somewhat extended", "tokens": [2316, 689, 291, 536, 28061, 322, 264, 4298, 11, 21892, 1688, 2098, 11, 1030, 11458, 13, 286, 519, 309, 311, 8344, 10913], "temperature": 0.0, "avg_logprob": -0.29555584987004596, "compression_ratio": 1.3430656934306568, "no_speech_prob": 0.004018865991383791}, {"id": 303, "seek": 226904, "start": 2279.44, "end": 2288.44, "text": " and it has an existing user base. Maybe you could benefit from that. I haven't looked at", "tokens": [293, 309, 575, 364, 6741, 4195, 3096, 13, 2704, 291, 727, 5121, 490, 300, 13, 286, 2378, 380, 2956, 412], "temperature": 0.0, "avg_logprob": -0.29555584987004596, "compression_ratio": 1.3430656934306568, "no_speech_prob": 0.004018865991383791}, {"id": 304, "seek": 228844, "start": 2288.44, "end": 2301.96, "text": " this. I will write you later. Thank you. Hello. I have two remarks. First of all, I'm the", "tokens": [341, 13, 286, 486, 2464, 291, 1780, 13, 1044, 291, 13, 2425, 13, 286, 362, 732, 19151, 13, 2386, 295, 439, 11, 286, 478, 264], "temperature": 0.0, "avg_logprob": -0.24243573789243344, "compression_ratio": 1.4196891191709844, "no_speech_prob": 0.0029675497207790613}, {"id": 305, "seek": 228844, "start": 2301.96, "end": 2309.64, "text": " maker of MapComplete which also has an entomology team to link Wikidata to Straits so we can", "tokens": [17127, 295, 22053, 14627, 17220, 597, 611, 575, 364, 948, 298, 1793, 1469, 281, 2113, 23377, 327, 3274, 281, 12875, 1208, 370, 321, 393], "temperature": 0.0, "avg_logprob": -0.24243573789243344, "compression_ratio": 1.4196891191709844, "no_speech_prob": 0.0029675497207790613}, {"id": 306, "seek": 228844, "start": 2309.64, "end": 2317.32, "text": " work together on that. And then second, a small remark on the adding an ID of OpenStreetMap", "tokens": [589, 1214, 322, 300, 13, 400, 550, 1150, 11, 257, 1359, 7942, 322, 264, 5127, 364, 7348, 295, 7238, 50, 3599, 302, 44, 569], "temperature": 0.0, "avg_logprob": -0.24243573789243344, "compression_ratio": 1.4196891191709844, "no_speech_prob": 0.0029675497207790613}, {"id": 307, "seek": 231732, "start": 2317.32, "end": 2323.76, "text": " to Wikidata. That's a bit of a flow approach because IDs aren't very stable in OpenStreetMap.", "tokens": [281, 23377, 327, 3274, 13, 663, 311, 257, 857, 295, 257, 3095, 3109, 570, 48212, 3212, 380, 588, 8351, 294, 7238, 50, 3599, 302, 44, 569, 13], "temperature": 0.0, "avg_logprob": -0.17360506057739258, "compression_ratio": 1.5683760683760684, "no_speech_prob": 0.002215521177276969}, {"id": 308, "seek": 231732, "start": 2323.76, "end": 2330.76, "text": " Say that a new park is opened, I place a point where the park is and then a few days later", "tokens": [6463, 300, 257, 777, 3884, 307, 5625, 11, 286, 1081, 257, 935, 689, 264, 3884, 307, 293, 550, 257, 1326, 1708, 1780], "temperature": 0.0, "avg_logprob": -0.17360506057739258, "compression_ratio": 1.5683760683760684, "no_speech_prob": 0.002215521177276969}, {"id": 309, "seek": 231732, "start": 2330.76, "end": 2336.4, "text": " someone else passes by and says, oh, we have aerial imagery now, throws the outline as a", "tokens": [1580, 1646, 11335, 538, 293, 1619, 11, 1954, 11, 321, 362, 31026, 24340, 586, 11, 19251, 264, 16387, 382, 257], "temperature": 0.0, "avg_logprob": -0.17360506057739258, "compression_ratio": 1.5683760683760684, "no_speech_prob": 0.002215521177276969}, {"id": 310, "seek": 231732, "start": 2336.4, "end": 2344.2400000000002, "text": " polygon and then removes the alt point. That means that the link would be broken in Wikidata.", "tokens": [48242, 293, 550, 30445, 264, 4955, 935, 13, 663, 1355, 300, 264, 2113, 576, 312, 5463, 294, 23377, 327, 3274, 13], "temperature": 0.0, "avg_logprob": -0.17360506057739258, "compression_ratio": 1.5683760683760684, "no_speech_prob": 0.002215521177276969}, {"id": 311, "seek": 234424, "start": 2344.24, "end": 2348.7999999999997, "text": " I mean, I guess we just have to deal with that. We can have software that looks for", "tokens": [286, 914, 11, 286, 2041, 321, 445, 362, 281, 2028, 365, 300, 13, 492, 393, 362, 4722, 300, 1542, 337], "temperature": 0.0, "avg_logprob": -0.1655439674307447, "compression_ratio": 1.6528301886792454, "no_speech_prob": 0.0005414031911641359}, {"id": 312, "seek": 234424, "start": 2348.7999999999997, "end": 2354.72, "text": " these broken links. Maybe it would be nice if OpenStreetMap could add redirects like", "tokens": [613, 5463, 6123, 13, 2704, 309, 576, 312, 1481, 498, 7238, 50, 3599, 302, 44, 569, 727, 909, 29066, 82, 411], "temperature": 0.0, "avg_logprob": -0.1655439674307447, "compression_ratio": 1.6528301886792454, "no_speech_prob": 0.0005414031911641359}, {"id": 313, "seek": 234424, "start": 2354.72, "end": 2361.8399999999997, "text": " Wikidata has. Yeah, except that it's way more difficult than that because, for example,", "tokens": [23377, 327, 3274, 575, 13, 865, 11, 3993, 300, 309, 311, 636, 544, 2252, 813, 300, 570, 11, 337, 1365, 11], "temperature": 0.0, "avg_logprob": -0.1655439674307447, "compression_ratio": 1.6528301886792454, "no_speech_prob": 0.0005414031911641359}, {"id": 314, "seek": 234424, "start": 2361.8399999999997, "end": 2366.52, "text": " sometimes you have a big street and then you have properties which are different for parts", "tokens": [2171, 291, 362, 257, 955, 4838, 293, 550, 291, 362, 7221, 597, 366, 819, 337, 3166], "temperature": 0.0, "avg_logprob": -0.1655439674307447, "compression_ratio": 1.6528301886792454, "no_speech_prob": 0.0005414031911641359}, {"id": 315, "seek": 234424, "start": 2366.52, "end": 2370.72, "text": " of the street and then the street gets split into three parts. So then suddenly you'd have", "tokens": [295, 264, 4838, 293, 550, 264, 4838, 2170, 7472, 666, 1045, 3166, 13, 407, 550, 5800, 291, 1116, 362], "temperature": 0.0, "avg_logprob": -0.1655439674307447, "compression_ratio": 1.6528301886792454, "no_speech_prob": 0.0005414031911641359}, {"id": 316, "seek": 237072, "start": 2370.72, "end": 2380.72, "text": " to redirect to three different parts. Do you think that it's a mistake to add OpenStreetMap", "tokens": [281, 29066, 281, 1045, 819, 3166, 13, 1144, 291, 519, 300, 309, 311, 257, 6146, 281, 909, 7238, 50, 3599, 302, 44, 569], "temperature": 0.0, "avg_logprob": -0.12692808493589744, "compression_ratio": 1.4728260869565217, "no_speech_prob": 0.0005590639193542302}, {"id": 317, "seek": 237072, "start": 2380.72, "end": 2391.0, "text": " IDs to Wikidata then? Yes, basically. It doesn't make sense at first glance but technically", "tokens": [48212, 281, 23377, 327, 3274, 550, 30, 1079, 11, 1936, 13, 467, 1177, 380, 652, 2020, 412, 700, 21094, 457, 12120], "temperature": 0.0, "avg_logprob": -0.12692808493589744, "compression_ratio": 1.4728260869565217, "no_speech_prob": 0.0005590639193542302}, {"id": 318, "seek": 237072, "start": 2391.0, "end": 2397.8399999999997, "text": " it will break down over time. So it's better to add a link to OpenStreetMap to Wikidata", "tokens": [309, 486, 1821, 760, 670, 565, 13, 407, 309, 311, 1101, 281, 909, 257, 2113, 281, 7238, 50, 3599, 302, 44, 569, 281, 23377, 327, 3274], "temperature": 0.0, "avg_logprob": -0.12692808493589744, "compression_ratio": 1.4728260869565217, "no_speech_prob": 0.0005590639193542302}, {"id": 319, "seek": 239784, "start": 2397.84, "end": 2406.2400000000002, "text": " and then look it up reversely because the editing tools will keep track of the Wikidata", "tokens": [293, 550, 574, 309, 493, 14582, 736, 570, 264, 10000, 3873, 486, 1066, 2837, 295, 264, 23377, 327, 3274], "temperature": 0.0, "avg_logprob": -0.18754400525774276, "compression_ratio": 1.543859649122807, "no_speech_prob": 0.001299857976846397}, {"id": 320, "seek": 239784, "start": 2406.2400000000002, "end": 2410.92, "text": " link. So if the roads get split into multiple pieces, every single piece of the road will", "tokens": [2113, 13, 407, 498, 264, 11344, 483, 7472, 666, 3866, 3755, 11, 633, 2167, 2522, 295, 264, 3060, 486], "temperature": 0.0, "avg_logprob": -0.18754400525774276, "compression_ratio": 1.543859649122807, "no_speech_prob": 0.001299857976846397}, {"id": 321, "seek": 239784, "start": 2410.92, "end": 2417.32, "text": " get a backlink to the Wikidata item. Yeah, you might have a good point. But let's have", "tokens": [483, 257, 646, 22473, 281, 264, 23377, 327, 3274, 3174, 13, 865, 11, 291, 1062, 362, 257, 665, 935, 13, 583, 718, 311, 362], "temperature": 0.0, "avg_logprob": -0.18754400525774276, "compression_ratio": 1.543859649122807, "no_speech_prob": 0.001299857976846397}, {"id": 322, "seek": 241732, "start": 2417.32, "end": 2437.56, "text": " a discussion after the questions. Hi Ed, thanks for sharing the new software. It looks great.", "tokens": [257, 5017, 934, 264, 1651, 13, 2421, 3977, 11, 3231, 337, 5414, 264, 777, 4722, 13, 467, 1542, 869, 13], "temperature": 0.0, "avg_logprob": -0.24363602039425872, "compression_ratio": 1.3235294117647058, "no_speech_prob": 0.0006296576466411352}, {"id": 323, "seek": 241732, "start": 2437.56, "end": 2444.56, "text": " So I was fascinated by the example where you showed a modern one potential match and I", "tokens": [407, 286, 390, 24597, 538, 264, 1365, 689, 291, 4712, 257, 4363, 472, 3995, 2995, 293, 286], "temperature": 0.0, "avg_logprob": -0.24363602039425872, "compression_ratio": 1.3235294117647058, "no_speech_prob": 0.0006296576466411352}, {"id": 324, "seek": 244456, "start": 2444.56, "end": 2451.2, "text": " just wondered does your software have a role to play in improving the quality of the data", "tokens": [445, 17055, 775, 428, 4722, 362, 257, 3090, 281, 862, 294, 11470, 264, 3125, 295, 264, 1412], "temperature": 0.0, "avg_logprob": -0.14196861183250342, "compression_ratio": 1.6018099547511313, "no_speech_prob": 0.00035047956043854356}, {"id": 325, "seek": 244456, "start": 2451.2, "end": 2456.7599999999998, "text": " by cross-referencing between the two sides? I think it can improve the quality. Like I", "tokens": [538, 3278, 12, 265, 612, 13644, 1296, 264, 732, 4881, 30, 286, 519, 309, 393, 3470, 264, 3125, 13, 1743, 286], "temperature": 0.0, "avg_logprob": -0.14196861183250342, "compression_ratio": 1.6018099547511313, "no_speech_prob": 0.00035047956043854356}, {"id": 326, "seek": 244456, "start": 2456.7599999999998, "end": 2464.12, "text": " say, when I run this I find duplicates in Wikidata that are difficult to identify from", "tokens": [584, 11, 562, 286, 1190, 341, 286, 915, 17154, 1024, 294, 23377, 327, 3274, 300, 366, 2252, 281, 5876, 490], "temperature": 0.0, "avg_logprob": -0.14196861183250342, "compression_ratio": 1.6018099547511313, "no_speech_prob": 0.00035047956043854356}, {"id": 327, "seek": 244456, "start": 2464.12, "end": 2471.52, "text": " just Wikidata itself. I feel like the coordinates that are in Wikidata don't get much use.", "tokens": [445, 23377, 327, 3274, 2564, 13, 286, 841, 411, 264, 21056, 300, 366, 294, 23377, 327, 3274, 500, 380, 483, 709, 764, 13], "temperature": 0.0, "avg_logprob": -0.14196861183250342, "compression_ratio": 1.6018099547511313, "no_speech_prob": 0.00035047956043854356}, {"id": 328, "seek": 247152, "start": 2471.52, "end": 2477.64, "text": " Like for a long time you didn't even see the map appearing, the Wikidata pages, and then", "tokens": [1743, 337, 257, 938, 565, 291, 994, 380, 754, 536, 264, 4471, 19870, 11, 264, 23377, 327, 3274, 7183, 11, 293, 550], "temperature": 0.0, "avg_logprob": -0.1821584132180285, "compression_ratio": 1.456043956043956, "no_speech_prob": 0.0008771680877543986}, {"id": 329, "seek": 247152, "start": 2477.64, "end": 2485.08, "text": " a lot of the coordinates were wrong. People transpose digits. Since the map is visible,", "tokens": [257, 688, 295, 264, 21056, 645, 2085, 13, 3432, 25167, 27011, 13, 4162, 264, 4471, 307, 8974, 11], "temperature": 0.0, "avg_logprob": -0.1821584132180285, "compression_ratio": 1.456043956043956, "no_speech_prob": 0.0008771680877543986}, {"id": 330, "seek": 247152, "start": 2485.08, "end": 2494.52, "text": " people are more likely to check their data. The fact that the two systems exist, you can", "tokens": [561, 366, 544, 3700, 281, 1520, 641, 1412, 13, 440, 1186, 300, 264, 732, 3652, 2514, 11, 291, 393], "temperature": 0.0, "avg_logprob": -0.1821584132180285, "compression_ratio": 1.456043956043956, "no_speech_prob": 0.0008771680877543986}, {"id": 331, "seek": 249452, "start": 2494.52, "end": 2505.36, "text": " cross-reference them and find errors. Yes. I'm wondering how relevant it is now based", "tokens": [3278, 12, 265, 5158, 552, 293, 915, 13603, 13, 1079, 13, 286, 478, 6359, 577, 7340, 309, 307, 586, 2361], "temperature": 0.0, "avg_logprob": -0.16747771671840123, "compression_ratio": 1.403225806451613, "no_speech_prob": 0.0005400337977334857}, {"id": 332, "seek": 249452, "start": 2505.36, "end": 2511.64, "text": " upon the question just a moment ago. But I was wondering can you search Wikidata for", "tokens": [3564, 264, 1168, 445, 257, 1623, 2057, 13, 583, 286, 390, 6359, 393, 291, 3164, 23377, 327, 3274, 337], "temperature": 0.0, "avg_logprob": -0.16747771671840123, "compression_ratio": 1.403225806451613, "no_speech_prob": 0.0005400337977334857}, {"id": 333, "seek": 249452, "start": 2511.64, "end": 2520.4, "text": " a lot long window and find all objects within it when you're adding data to OpenStreetMap?", "tokens": [257, 688, 938, 4910, 293, 915, 439, 6565, 1951, 309, 562, 291, 434, 5127, 1412, 281, 7238, 50, 3599, 302, 44, 569, 30], "temperature": 0.0, "avg_logprob": -0.16747771671840123, "compression_ratio": 1.403225806451613, "no_speech_prob": 0.0005400337977334857}, {"id": 334, "seek": 252040, "start": 2520.4, "end": 2527.28, "text": " So underneath I'm doing Sparkle queries to Wikidata, and Wikidata Sparkle queries", "tokens": [407, 7223, 286, 478, 884, 23424, 306, 24109, 281, 23377, 327, 3274, 11, 293, 23377, 327, 3274, 23424, 306, 24109], "temperature": 0.0, "avg_logprob": -0.12053709251936091, "compression_ratio": 1.6941747572815533, "no_speech_prob": 0.00011949220788665116}, {"id": 335, "seek": 252040, "start": 2527.28, "end": 2535.64, "text": " do support coordinate bounding boxes. I can say you can write your own query in Sparkle", "tokens": [360, 1406, 15670, 5472, 278, 9002, 13, 286, 393, 584, 291, 393, 2464, 428, 1065, 14581, 294, 23424, 306], "temperature": 0.0, "avg_logprob": -0.12053709251936091, "compression_ratio": 1.6941747572815533, "no_speech_prob": 0.00011949220788665116}, {"id": 336, "seek": 252040, "start": 2535.64, "end": 2542.84, "text": " that will give you all the churches within a given bounding box. I demoed two separate", "tokens": [300, 486, 976, 291, 439, 264, 15381, 1951, 257, 2212, 5472, 278, 2424, 13, 286, 10723, 292, 732, 4994], "temperature": 0.0, "avg_logprob": -0.12053709251936091, "compression_ratio": 1.6941747572815533, "no_speech_prob": 0.00011949220788665116}, {"id": 337, "seek": 252040, "start": 2542.84, "end": 2548.12, "text": " systems that should really be combined into one, and the old system doesn't support bounding", "tokens": [3652, 300, 820, 534, 312, 9354, 666, 472, 11, 293, 264, 1331, 1185, 1177, 380, 1406, 5472, 278], "temperature": 0.0, "avg_logprob": -0.12053709251936091, "compression_ratio": 1.6941747572815533, "no_speech_prob": 0.00011949220788665116}, {"id": 338, "seek": 254812, "start": 2548.12, "end": 2554.64, "text": " boxes. It's all based on place polygons. You have to say, show me things that are in Brussels.", "tokens": [9002, 13, 467, 311, 439, 2361, 322, 1081, 6754, 70, 892, 13, 509, 362, 281, 584, 11, 855, 385, 721, 300, 366, 294, 38717, 13], "temperature": 0.0, "avg_logprob": -0.16344583162697413, "compression_ratio": 1.7067307692307692, "no_speech_prob": 0.0009551324183121324}, {"id": 339, "seek": 254812, "start": 2554.64, "end": 2561.56, "text": " You can't say, show me things within this rectangle. And the new system is more bounding", "tokens": [509, 393, 380, 584, 11, 855, 385, 721, 1951, 341, 21930, 13, 400, 264, 777, 1185, 307, 544, 5472, 278], "temperature": 0.0, "avg_logprob": -0.16344583162697413, "compression_ratio": 1.7067307692307692, "no_speech_prob": 0.0009551324183121324}, {"id": 340, "seek": 254812, "start": 2561.56, "end": 2565.64, "text": " box based in that you see the map and it just shows you all the matches that are in the", "tokens": [2424, 2361, 294, 300, 291, 536, 264, 4471, 293, 309, 445, 3110, 291, 439, 264, 10676, 300, 366, 294, 264], "temperature": 0.0, "avg_logprob": -0.16344583162697413, "compression_ratio": 1.7067307692307692, "no_speech_prob": 0.0009551324183121324}, {"id": 341, "seek": 254812, "start": 2565.64, "end": 2571.56, "text": " rectangle that's visible on the screen. I'm not sure if that answers your question.", "tokens": [21930, 300, 311, 8974, 322, 264, 2568, 13, 286, 478, 406, 988, 498, 300, 6338, 428, 1168, 13], "temperature": 0.0, "avg_logprob": -0.16344583162697413, "compression_ratio": 1.7067307692307692, "no_speech_prob": 0.0009551324183121324}, {"id": 342, "seek": 257156, "start": 2571.56, "end": 2582.4, "text": " It doesn't think. It's very valuable what you've done. Thanks.", "tokens": [467, 1177, 380, 519, 13, 467, 311, 588, 8263, 437, 291, 600, 1096, 13, 2561, 13], "temperature": 0.0, "avg_logprob": -0.2194400394664091, "compression_ratio": 1.4171779141104295, "no_speech_prob": 0.0013789015356451273}, {"id": 343, "seek": 257156, "start": 2582.4, "end": 2593.72, "text": " Any other questions? Raise your hand. Hi. Thank you for your talk. I had a question", "tokens": [2639, 661, 1651, 30, 30062, 428, 1011, 13, 2421, 13, 1044, 291, 337, 428, 751, 13, 286, 632, 257, 1168], "temperature": 0.0, "avg_logprob": -0.2194400394664091, "compression_ratio": 1.4171779141104295, "no_speech_prob": 0.0013789015356451273}, {"id": 344, "seek": 257156, "start": 2593.72, "end": 2600.64, "text": " about the OpenStreetMap tags that are in Wikidata. I think you showed this in one of", "tokens": [466, 264, 7238, 50, 3599, 302, 44, 569, 18632, 300, 366, 294, 23377, 327, 3274, 13, 286, 519, 291, 4712, 341, 294, 472, 295], "temperature": 0.0, "avg_logprob": -0.2194400394664091, "compression_ratio": 1.4171779141104295, "no_speech_prob": 0.0013789015356451273}, {"id": 345, "seek": 260064, "start": 2600.64, "end": 2608.2799999999997, "text": " your slides. How often are these tags uploaded from OpenStreetMap, and does it pose any problem", "tokens": [428, 9788, 13, 1012, 2049, 366, 613, 18632, 17135, 490, 7238, 50, 3599, 302, 44, 569, 11, 293, 775, 309, 10774, 604, 1154], "temperature": 0.0, "avg_logprob": -0.19794378175840274, "compression_ratio": 1.5244444444444445, "no_speech_prob": 0.0010672705247998238}, {"id": 346, "seek": 260064, "start": 2608.2799999999997, "end": 2612.16, "text": " with the license compatibility issues that you talked about?", "tokens": [365, 264, 10476, 34237, 2663, 300, 291, 2825, 466, 30], "temperature": 0.0, "avg_logprob": -0.19794378175840274, "compression_ratio": 1.5244444444444445, "no_speech_prob": 0.0010672705247998238}, {"id": 347, "seek": 260064, "start": 2612.16, "end": 2620.0, "text": " I think you mean the property for OpenStreetMap tag or key. Things like I showed the palace", "tokens": [286, 519, 291, 914, 264, 4707, 337, 7238, 50, 3599, 302, 44, 569, 6162, 420, 2141, 13, 9514, 411, 286, 4712, 264, 15207], "temperature": 0.0, "avg_logprob": -0.19794378175840274, "compression_ratio": 1.5244444444444445, "no_speech_prob": 0.0010672705247998238}, {"id": 348, "seek": 260064, "start": 2620.0, "end": 2625.92, "text": " type. Is that right? Is that the one you're thinking of? There's a few properties in Wikidata.", "tokens": [2010, 13, 1119, 300, 558, 30, 1119, 300, 264, 472, 291, 434, 1953, 295, 30, 821, 311, 257, 1326, 7221, 294, 23377, 327, 3274, 13], "temperature": 0.0, "avg_logprob": -0.19794378175840274, "compression_ratio": 1.5244444444444445, "no_speech_prob": 0.0010672705247998238}, {"id": 349, "seek": 262592, "start": 2625.92, "end": 2631.48, "text": " Yes, the OSM tag, like the structure one. I don't think there's any problem in terms", "tokens": [1079, 11, 264, 12731, 44, 6162, 11, 411, 264, 3877, 472, 13, 286, 500, 380, 519, 456, 311, 604, 1154, 294, 2115], "temperature": 0.0, "avg_logprob": -0.1472123803444279, "compression_ratio": 1.59375, "no_speech_prob": 0.0008322381181642413}, {"id": 350, "seek": 262592, "start": 2631.48, "end": 2640.2000000000003, "text": " of the intellectual property. It's kept pretty up to date. People invent a new tag to use", "tokens": [295, 264, 12576, 4707, 13, 467, 311, 4305, 1238, 493, 281, 4002, 13, 3432, 7962, 257, 777, 6162, 281, 764], "temperature": 0.0, "avg_logprob": -0.1472123803444279, "compression_ratio": 1.59375, "no_speech_prob": 0.0008322381181642413}, {"id": 351, "seek": 262592, "start": 2640.2000000000003, "end": 2646.04, "text": " on OpenStreetMap, and then they go and find the matching Wikidata item and add the tag", "tokens": [322, 7238, 50, 3599, 302, 44, 569, 11, 293, 550, 436, 352, 293, 915, 264, 14324, 23377, 327, 3274, 3174, 293, 909, 264, 6162], "temperature": 0.0, "avg_logprob": -0.1472123803444279, "compression_ratio": 1.59375, "no_speech_prob": 0.0008322381181642413}, {"id": 352, "seek": 262592, "start": 2646.04, "end": 2654.16, "text": " to it. And some unofficial tags that are used on OpenStreetMap, the information is in Wikidata.", "tokens": [281, 309, 13, 400, 512, 8526, 37661, 18632, 300, 366, 1143, 322, 7238, 50, 3599, 302, 44, 569, 11, 264, 1589, 307, 294, 23377, 327, 3274, 13], "temperature": 0.0, "avg_logprob": -0.1472123803444279, "compression_ratio": 1.59375, "no_speech_prob": 0.0008322381181642413}, {"id": 353, "seek": 265416, "start": 2654.16, "end": 2659.92, "text": " So it's pretty current, I think.", "tokens": [407, 309, 311, 1238, 2190, 11, 286, 519, 13], "temperature": 0.0, "avg_logprob": -0.21014303448556484, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.0008543358417227864}, {"id": 354, "seek": 265416, "start": 2659.92, "end": 2667.6, "text": " So similar question from my side. Nice presentation. You explained the licenses. Nicely when you", "tokens": [407, 2531, 1168, 490, 452, 1252, 13, 5490, 5860, 13, 509, 8825, 264, 32821, 13, 14776, 736, 562, 291], "temperature": 0.0, "avg_logprob": -0.21014303448556484, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.0008543358417227864}, {"id": 355, "seek": 265416, "start": 2667.6, "end": 2673.92, "text": " said that you cannot copy data from the OpenStreetMap to Wikidata, but what about the other way", "tokens": [848, 300, 291, 2644, 5055, 1412, 490, 264, 7238, 50, 3599, 302, 44, 569, 281, 23377, 327, 3274, 11, 457, 437, 466, 264, 661, 636], "temperature": 0.0, "avg_logprob": -0.21014303448556484, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.0008543358417227864}, {"id": 356, "seek": 265416, "start": 2673.92, "end": 2675.72, "text": " around?", "tokens": [926, 30], "temperature": 0.0, "avg_logprob": -0.21014303448556484, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.0008543358417227864}, {"id": 357, "seek": 265416, "start": 2675.72, "end": 2681.3599999999997, "text": " So that's an interesting question. And the OpenStreetMap community is a bit suspicious", "tokens": [407, 300, 311, 364, 1880, 1168, 13, 400, 264, 7238, 50, 3599, 302, 44, 569, 1768, 307, 257, 857, 17931], "temperature": 0.0, "avg_logprob": -0.21014303448556484, "compression_ratio": 1.5238095238095237, "no_speech_prob": 0.0008543358417227864}, {"id": 358, "seek": 268136, "start": 2681.36, "end": 2685.8, "text": " of the information that's in Wikidata. Like, there's a feeling, you know, where did the", "tokens": [295, 264, 1589, 300, 311, 294, 23377, 327, 3274, 13, 1743, 11, 456, 311, 257, 2633, 11, 291, 458, 11, 689, 630, 264], "temperature": 0.0, "avg_logprob": -0.12150207642586, "compression_ratio": 1.7376237623762376, "no_speech_prob": 0.00016870335093699396}, {"id": 359, "seek": 268136, "start": 2685.8, "end": 2692.6800000000003, "text": " coordinates come from? Were they just copied from Google Maps? Like, do people look up", "tokens": [21056, 808, 490, 30, 12448, 436, 445, 25365, 490, 3329, 28978, 30, 1743, 11, 360, 561, 574, 493], "temperature": 0.0, "avg_logprob": -0.12150207642586, "compression_ratio": 1.7376237623762376, "no_speech_prob": 0.00016870335093699396}, {"id": 360, "seek": 268136, "start": 2692.6800000000003, "end": 2698.1600000000003, "text": " a thing on Google Maps, find the coordinates, put the coordinates into Wikidata? And then", "tokens": [257, 551, 322, 3329, 28978, 11, 915, 264, 21056, 11, 829, 264, 21056, 666, 23377, 327, 3274, 30, 400, 550], "temperature": 0.0, "avg_logprob": -0.12150207642586, "compression_ratio": 1.7376237623762376, "no_speech_prob": 0.00016870335093699396}, {"id": 361, "seek": 268136, "start": 2698.1600000000003, "end": 2704.88, "text": " does that make Wikidata a derived work of Google Maps? And so, you know, it's probably", "tokens": [775, 300, 652, 23377, 327, 3274, 257, 18949, 589, 295, 3329, 28978, 30, 400, 370, 11, 291, 458, 11, 309, 311, 1391], "temperature": 0.0, "avg_logprob": -0.12150207642586, "compression_ratio": 1.7376237623762376, "no_speech_prob": 0.00016870335093699396}, {"id": 362, "seek": 270488, "start": 2704.88, "end": 2713.84, "text": " fine to copy any data from Wikidata into OpenStreetMap. You know, if you want to copy a name in", "tokens": [2489, 281, 5055, 604, 1412, 490, 23377, 327, 3274, 666, 7238, 50, 3599, 302, 44, 569, 13, 509, 458, 11, 498, 291, 528, 281, 5055, 257, 1315, 294], "temperature": 0.0, "avg_logprob": -0.10365249201194528, "compression_ratio": 1.5818181818181818, "no_speech_prob": 0.00037481237086467445}, {"id": 363, "seek": 270488, "start": 2713.84, "end": 2719.6, "text": " a different language, you know, that's probably fine. But my software doesn't do that. I just", "tokens": [257, 819, 2856, 11, 291, 458, 11, 300, 311, 1391, 2489, 13, 583, 452, 4722, 1177, 380, 360, 300, 13, 286, 445], "temperature": 0.0, "avg_logprob": -0.10365249201194528, "compression_ratio": 1.5818181818181818, "no_speech_prob": 0.00037481237086467445}, {"id": 364, "seek": 270488, "start": 2719.6, "end": 2723.7200000000003, "text": " add the links. And, you know, once the links are there, it's easier for somebody else", "tokens": [909, 264, 6123, 13, 400, 11, 291, 458, 11, 1564, 264, 6123, 366, 456, 11, 309, 311, 3571, 337, 2618, 1646], "temperature": 0.0, "avg_logprob": -0.10365249201194528, "compression_ratio": 1.5818181818181818, "no_speech_prob": 0.00037481237086467445}, {"id": 365, "seek": 270488, "start": 2723.7200000000003, "end": 2731.32, "text": " to come along and find these things and copy the data over if they want.", "tokens": [281, 808, 2051, 293, 915, 613, 721, 293, 5055, 264, 1412, 670, 498, 436, 528, 13], "temperature": 0.0, "avg_logprob": -0.10365249201194528, "compression_ratio": 1.5818181818181818, "no_speech_prob": 0.00037481237086467445}, {"id": 366, "seek": 273132, "start": 2731.32, "end": 2737.96, "text": " So my question is, does the software do the requests, the API requests on the back end", "tokens": [407, 452, 1168, 307, 11, 775, 264, 4722, 360, 264, 12475, 11, 264, 9362, 12475, 322, 264, 646, 917], "temperature": 0.0, "avg_logprob": -0.1822713017463684, "compression_ratio": 1.6837209302325582, "no_speech_prob": 0.000458982220152393}, {"id": 367, "seek": 273132, "start": 2737.96, "end": 2745.36, "text": " on your hosted service, or is it the client, the user that will do the browser will do", "tokens": [322, 428, 19204, 2643, 11, 420, 307, 309, 264, 6423, 11, 264, 4195, 300, 486, 360, 264, 11185, 486, 360], "temperature": 0.0, "avg_logprob": -0.1822713017463684, "compression_ratio": 1.6837209302325582, "no_speech_prob": 0.000458982220152393}, {"id": 368, "seek": 273132, "start": 2745.36, "end": 2746.84, "text": " the API requests?", "tokens": [264, 9362, 12475, 30], "temperature": 0.0, "avg_logprob": -0.1822713017463684, "compression_ratio": 1.6837209302325582, "no_speech_prob": 0.000458982220152393}, {"id": 369, "seek": 273132, "start": 2746.84, "end": 2752.84, "text": " I showed two versions. The old, you know, the more established version is using the", "tokens": [286, 4712, 732, 9606, 13, 440, 1331, 11, 291, 458, 11, 264, 544, 7545, 3037, 307, 1228, 264], "temperature": 0.0, "avg_logprob": -0.1822713017463684, "compression_ratio": 1.6837209302325582, "no_speech_prob": 0.000458982220152393}, {"id": 370, "seek": 273132, "start": 2752.84, "end": 2758.76, "text": " Nominatum API to find things. And then it's using the Overpass API to grab lots of map", "tokens": [426, 6981, 267, 449, 9362, 281, 915, 721, 13, 400, 550, 309, 311, 1228, 264, 4886, 9216, 9362, 281, 4444, 3195, 295, 4471], "temperature": 0.0, "avg_logprob": -0.1822713017463684, "compression_ratio": 1.6837209302325582, "no_speech_prob": 0.000458982220152393}, {"id": 371, "seek": 275876, "start": 2758.76, "end": 2765.0800000000004, "text": " data. And then they use the OpenStreetMap API to push the changes you make to upload", "tokens": [1412, 13, 400, 550, 436, 764, 264, 7238, 50, 3599, 302, 44, 569, 9362, 281, 2944, 264, 2962, 291, 652, 281, 6580], "temperature": 0.0, "avg_logprob": -0.11277664408964269, "compression_ratio": 1.6367713004484306, "no_speech_prob": 0.0003379422705620527}, {"id": 372, "seek": 275876, "start": 2765.0800000000004, "end": 2772.44, "text": " the Wikidata tags back into OpenStreetMap. And the new system I built maintains a full", "tokens": [264, 23377, 327, 3274, 18632, 646, 666, 7238, 50, 3599, 302, 44, 569, 13, 400, 264, 777, 1185, 286, 3094, 33385, 257, 1577], "temperature": 0.0, "avg_logprob": -0.11277664408964269, "compression_ratio": 1.6367713004484306, "no_speech_prob": 0.0003379422705620527}, {"id": 373, "seek": 275876, "start": 2772.44, "end": 2782.28, "text": " mirror of the OpenStreetMap data just to make things faster. So I'm not using APIs for downloading", "tokens": [8013, 295, 264, 7238, 50, 3599, 302, 44, 569, 1412, 445, 281, 652, 721, 4663, 13, 407, 286, 478, 406, 1228, 21445, 337, 32529], "temperature": 0.0, "avg_logprob": -0.11277664408964269, "compression_ratio": 1.6367713004484306, "no_speech_prob": 0.0003379422705620527}, {"id": 374, "seek": 275876, "start": 2782.28, "end": 2787.0400000000004, "text": " data with that one. I just use the API for saving the changes. Does that answer your", "tokens": [1412, 365, 300, 472, 13, 286, 445, 764, 264, 9362, 337, 6816, 264, 2962, 13, 4402, 300, 1867, 428], "temperature": 0.0, "avg_logprob": -0.11277664408964269, "compression_ratio": 1.6367713004484306, "no_speech_prob": 0.0003379422705620527}, {"id": 375, "seek": 275876, "start": 2787.0400000000004, "end": 2788.0400000000004, "text": " question?", "tokens": [1168, 30], "temperature": 0.0, "avg_logprob": -0.11277664408964269, "compression_ratio": 1.6367713004484306, "no_speech_prob": 0.0003379422705620527}, {"id": 376, "seek": 278804, "start": 2788.04, "end": 2796.0, "text": " Yeah, partly. But does the request to fetch data from the Wikidata, does that go from", "tokens": [865, 11, 17031, 13, 583, 775, 264, 5308, 281, 23673, 1412, 490, 264, 23377, 327, 3274, 11, 775, 300, 352, 490], "temperature": 0.0, "avg_logprob": -0.22144277380147112, "compression_ratio": 1.7017543859649122, "no_speech_prob": 0.0005820172373205423}, {"id": 377, "seek": 278804, "start": 2796.0, "end": 2799.8, "text": " your servers? Do your servers fetch data?", "tokens": [428, 15909, 30, 1144, 428, 15909, 23673, 1412, 30], "temperature": 0.0, "avg_logprob": -0.22144277380147112, "compression_ratio": 1.7017543859649122, "no_speech_prob": 0.0005820172373205423}, {"id": 378, "seek": 278804, "start": 2799.8, "end": 2805.88, "text": " It is all going from my server, yeah. It's not from the client browser. It's going. Like,", "tokens": [467, 307, 439, 516, 490, 452, 7154, 11, 1338, 13, 467, 311, 406, 490, 264, 6423, 11185, 13, 467, 311, 516, 13, 1743, 11], "temperature": 0.0, "avg_logprob": -0.22144277380147112, "compression_ratio": 1.7017543859649122, "no_speech_prob": 0.0005820172373205423}, {"id": 379, "seek": 278804, "start": 2805.88, "end": 2811.6, "text": " I do a lot of pre-processing before I show you the list of paid matches, and then I", "tokens": [286, 360, 257, 688, 295, 659, 12, 41075, 278, 949, 286, 855, 291, 264, 1329, 295, 4835, 10676, 11, 293, 550, 286], "temperature": 0.0, "avg_logprob": -0.22144277380147112, "compression_ratio": 1.7017543859649122, "no_speech_prob": 0.0005820172373205423}, {"id": 380, "seek": 278804, "start": 2811.6, "end": 2817.0, "text": " store them all in the database. So when you load the list of matches for a place, it's", "tokens": [3531, 552, 439, 294, 264, 8149, 13, 407, 562, 291, 3677, 264, 1329, 295, 10676, 337, 257, 1081, 11, 309, 311], "temperature": 0.0, "avg_logprob": -0.22144277380147112, "compression_ratio": 1.7017543859649122, "no_speech_prob": 0.0005820172373205423}, {"id": 381, "seek": 281700, "start": 2817.0, "end": 2822.88, "text": " not doing any queries either on the server or the client with the APIs. It's all stored", "tokens": [406, 884, 604, 24109, 2139, 322, 264, 7154, 420, 264, 6423, 365, 264, 21445, 13, 467, 311, 439, 12187], "temperature": 0.0, "avg_logprob": -0.2106908497057463, "compression_ratio": 1.594142259414226, "no_speech_prob": 0.00010060535714728758}, {"id": 382, "seek": 281700, "start": 2822.88, "end": 2828.28, "text": " in the database. I mean, that's a problem. The matches get stale. There's a refresh", "tokens": [294, 264, 8149, 13, 286, 914, 11, 300, 311, 257, 1154, 13, 440, 10676, 483, 342, 1220, 13, 821, 311, 257, 15134], "temperature": 0.0, "avg_logprob": -0.2106908497057463, "compression_ratio": 1.594142259414226, "no_speech_prob": 0.00010060535714728758}, {"id": 383, "seek": 281700, "start": 2828.28, "end": 2833.48, "text": " button that you can hit, and it will go off and rerun the matcher and get fresh data from", "tokens": [2960, 300, 291, 393, 2045, 11, 293, 309, 486, 352, 766, 293, 43819, 409, 264, 2995, 260, 293, 483, 4451, 1412, 490], "temperature": 0.0, "avg_logprob": -0.2106908497057463, "compression_ratio": 1.594142259414226, "no_speech_prob": 0.00010060535714728758}, {"id": 384, "seek": 281700, "start": 2833.48, "end": 2835.0, "text": " OpenStreetMap and Wikidata.", "tokens": [7238, 50, 3599, 302, 44, 569, 293, 23377, 327, 3274, 13], "temperature": 0.0, "avg_logprob": -0.2106908497057463, "compression_ratio": 1.594142259414226, "no_speech_prob": 0.00010060535714728758}, {"id": 385, "seek": 281700, "start": 2835.0, "end": 2837.0, "text": " Yeah, okay, thanks.", "tokens": [865, 11, 1392, 11, 3231, 13], "temperature": 0.0, "avg_logprob": -0.2106908497057463, "compression_ratio": 1.594142259414226, "no_speech_prob": 0.00010060535714728758}, {"id": 386, "seek": 281700, "start": 2837.0, "end": 2844.0, "text": " There was a question here? No? Okay, so I'll be back on the other side.", "tokens": [821, 390, 257, 1168, 510, 30, 883, 30, 1033, 11, 370, 286, 603, 312, 646, 322, 264, 661, 1252, 13], "temperature": 0.0, "avg_logprob": -0.2106908497057463, "compression_ratio": 1.594142259414226, "no_speech_prob": 0.00010060535714728758}, {"id": 387, "seek": 284400, "start": 2844.0, "end": 2863.0, "text": " Hi, I'm Valerio from Milano, and thank you so much for this tool. Again, thank you for", "tokens": [2421, 11, 286, 478, 7188, 260, 1004, 490, 7036, 3730, 11, 293, 1309, 291, 370, 709, 337, 341, 2290, 13, 3764, 11, 1309, 291, 337], "temperature": 0.0, "avg_logprob": -0.1496841231388832, "compression_ratio": 1.5502958579881656, "no_speech_prob": 0.011126503348350525}, {"id": 388, "seek": 284400, "start": 2863.0, "end": 2868.48, "text": " the person who mentioned the possibility to host this tool on the Wikimedia Foundation", "tokens": [264, 954, 567, 2835, 264, 7959, 281, 3975, 341, 2290, 322, 264, 23377, 332, 14212, 10335], "temperature": 0.0, "avg_logprob": -0.1496841231388832, "compression_ratio": 1.5502958579881656, "no_speech_prob": 0.011126503348350525}, {"id": 389, "seek": 284400, "start": 2868.48, "end": 2873.76, "text": " infrastructure, because it would be really, really nice to propose this on the Wikimedia", "tokens": [6896, 11, 570, 309, 576, 312, 534, 11, 534, 1481, 281, 17421, 341, 322, 264, 23377, 332, 14212], "temperature": 0.0, "avg_logprob": -0.1496841231388832, "compression_ratio": 1.5502958579881656, "no_speech_prob": 0.011126503348350525}, {"id": 390, "seek": 287376, "start": 2873.76, "end": 2881.76, "text": " Fabricator, and I would be interested in discovering how the discussion will go. Second thing,", "tokens": [17440, 1341, 1639, 11, 293, 286, 576, 312, 3102, 294, 24773, 577, 264, 5017, 486, 352, 13, 5736, 551, 11], "temperature": 0.0, "avg_logprob": -0.21263741885914522, "compression_ratio": 1.6, "no_speech_prob": 0.0014367441181093454}, {"id": 391, "seek": 287376, "start": 2881.76, "end": 2888.28, "text": " you asked how to found your development. I think you can just contact your local Wikimedia", "tokens": [291, 2351, 577, 281, 1352, 428, 3250, 13, 286, 519, 291, 393, 445, 3385, 428, 2654, 23377, 332, 14212], "temperature": 0.0, "avg_logprob": -0.21263741885914522, "compression_ratio": 1.6, "no_speech_prob": 0.0014367441181093454}, {"id": 392, "seek": 287376, "start": 2888.28, "end": 2895.28, "text": " chapter that maybe they provide microgrants or something like that. In my local community,", "tokens": [7187, 300, 1310, 436, 2893, 4532, 861, 1719, 420, 746, 411, 300, 13, 682, 452, 2654, 1768, 11], "temperature": 0.0, "avg_logprob": -0.21263741885914522, "compression_ratio": 1.6, "no_speech_prob": 0.0014367441181093454}, {"id": 393, "seek": 287376, "start": 2895.28, "end": 2901.96, "text": " some volunteers often in one week can obtain microgrants to develop small tools or to boost", "tokens": [512, 14352, 2049, 294, 472, 1243, 393, 12701, 4532, 861, 1719, 281, 1499, 1359, 3873, 420, 281, 9194], "temperature": 0.0, "avg_logprob": -0.21263741885914522, "compression_ratio": 1.6, "no_speech_prob": 0.0014367441181093454}, {"id": 394, "seek": 290196, "start": 2901.96, "end": 2910.2400000000002, "text": " some activities. Maybe this can be interesting if they are useful for the university to produce", "tokens": [512, 5354, 13, 2704, 341, 393, 312, 1880, 498, 436, 366, 4420, 337, 264, 5454, 281, 5258], "temperature": 0.0, "avg_logprob": -0.24282010396321616, "compression_ratio": 1.453551912568306, "no_speech_prob": 0.0017061266116797924}, {"id": 395, "seek": 290196, "start": 2910.2400000000002, "end": 2917.32, "text": " OpenStreet software and Libre content. One feedback for the user interface, it's not", "tokens": [7238, 50, 3599, 302, 4722, 293, 15834, 265, 2701, 13, 1485, 5824, 337, 264, 4195, 9226, 11, 309, 311, 406], "temperature": 0.0, "avg_logprob": -0.24282010396321616, "compression_ratio": 1.453551912568306, "no_speech_prob": 0.0017061266116797924}, {"id": 396, "seek": 290196, "start": 2917.32, "end": 2925.6, "text": " clear to me how to contribute on just one element. If I have one minute, if I want to", "tokens": [1850, 281, 385, 577, 281, 10586, 322, 445, 472, 4478, 13, 759, 286, 362, 472, 3456, 11, 498, 286, 528, 281], "temperature": 0.0, "avg_logprob": -0.24282010396321616, "compression_ratio": 1.453551912568306, "no_speech_prob": 0.0017061266116797924}, {"id": 397, "seek": 292560, "start": 2925.6, "end": 2933.04, "text": " visit the tool and connect just one item, because I'm 100% sure about that item, so", "tokens": [3441, 264, 2290, 293, 1745, 445, 472, 3174, 11, 570, 286, 478, 2319, 4, 988, 466, 300, 3174, 11, 370], "temperature": 0.0, "avg_logprob": -0.2167524610246931, "compression_ratio": 1.5520361990950227, "no_speech_prob": 0.0008877601940184832}, {"id": 398, "seek": 292560, "start": 2933.04, "end": 2940.52, "text": " I just want to save on that contribution and be kidnapped, I don't know. So this maybe", "tokens": [286, 445, 528, 281, 3155, 322, 300, 13150, 293, 312, 29300, 11, 286, 500, 380, 458, 13, 407, 341, 1310], "temperature": 0.0, "avg_logprob": -0.2167524610246931, "compression_ratio": 1.5520361990950227, "no_speech_prob": 0.0008877601940184832}, {"id": 399, "seek": 292560, "start": 2940.52, "end": 2946.2, "text": " can be useful if it's not already possible. The two approaches for that, if you click", "tokens": [393, 312, 4420, 498, 309, 311, 406, 1217, 1944, 13, 440, 732, 11587, 337, 300, 11, 498, 291, 2052], "temperature": 0.0, "avg_logprob": -0.2167524610246931, "compression_ratio": 1.5520361990950227, "no_speech_prob": 0.0008877601940184832}, {"id": 400, "seek": 292560, "start": 2946.2, "end": 2951.08, "text": " on the title of an item, it takes you to a page where you can just edit a single item.", "tokens": [322, 264, 4876, 295, 364, 3174, 11, 309, 2516, 291, 281, 257, 3028, 689, 291, 393, 445, 8129, 257, 2167, 3174, 13], "temperature": 0.0, "avg_logprob": -0.2167524610246931, "compression_ratio": 1.5520361990950227, "no_speech_prob": 0.0008877601940184832}, {"id": 401, "seek": 295108, "start": 2951.08, "end": 2957.2, "text": " Okay, wonderful. At the top of the page there's an uncheck all tick box, and then you can", "tokens": [1033, 11, 3715, 13, 1711, 264, 1192, 295, 264, 3028, 456, 311, 364, 46672, 439, 5204, 2424, 11, 293, 550, 291, 393], "temperature": 0.0, "avg_logprob": -0.2341300883191697, "compression_ratio": 1.5955555555555556, "no_speech_prob": 0.0007838818710297346}, {"id": 402, "seek": 295108, "start": 2957.2, "end": 2963.08, "text": " just tick the box next to one thing and scroll to the bottom and hit save. Both of those", "tokens": [445, 5204, 264, 2424, 958, 281, 472, 551, 293, 11369, 281, 264, 2767, 293, 2045, 3155, 13, 6767, 295, 729], "temperature": 0.0, "avg_logprob": -0.2341300883191697, "compression_ratio": 1.5955555555555556, "no_speech_prob": 0.0007838818710297346}, {"id": 403, "seek": 295108, "start": 2963.08, "end": 2968.4, "text": " will work for adding a single Wikidata tag. Okay, thank you. And thanks for your comment", "tokens": [486, 589, 337, 5127, 257, 2167, 23377, 327, 3274, 6162, 13, 1033, 11, 1309, 291, 13, 400, 3231, 337, 428, 2871], "temperature": 0.0, "avg_logprob": -0.2341300883191697, "compression_ratio": 1.5955555555555556, "no_speech_prob": 0.0007838818710297346}, {"id": 404, "seek": 295108, "start": 2968.4, "end": 2974.2, "text": " about contacting my local Wikimedia chapter, that's a good idea. Last thing, can you repeat", "tokens": [466, 41482, 452, 2654, 23377, 332, 14212, 7187, 11, 300, 311, 257, 665, 1558, 13, 5264, 551, 11, 393, 291, 7149], "temperature": 0.0, "avg_logprob": -0.2341300883191697, "compression_ratio": 1.5955555555555556, "no_speech_prob": 0.0007838818710297346}, {"id": 405, "seek": 297420, "start": 2974.2, "end": 2981.2, "text": " sorry, why do you need two terabytes of data to have this working? Thank you so much. The", "tokens": [2597, 11, 983, 360, 291, 643, 732, 1796, 24538, 295, 1412, 281, 362, 341, 1364, 30, 1044, 291, 370, 709, 13, 440], "temperature": 0.0, "avg_logprob": -0.2481251793938714, "compression_ratio": 1.5344827586206897, "no_speech_prob": 0.0007839088211767375}, {"id": 406, "seek": 297420, "start": 2981.2, "end": 2988.08, "text": " open stream app database is big. The Earth is big and I keep a whole copy of it to make", "tokens": [1269, 4309, 724, 8149, 307, 955, 13, 440, 4755, 307, 955, 293, 286, 1066, 257, 1379, 5055, 295, 309, 281, 652], "temperature": 0.0, "avg_logprob": -0.2481251793938714, "compression_ratio": 1.5344827586206897, "no_speech_prob": 0.0007839088211767375}, {"id": 407, "seek": 297420, "start": 2988.08, "end": 2996.3199999999997, "text": " things fast. And so it's probably 1.6 terabytes to store all of the open stream app data.", "tokens": [721, 2370, 13, 400, 370, 309, 311, 1391, 502, 13, 21, 1796, 24538, 281, 3531, 439, 295, 264, 1269, 4309, 724, 1412, 13], "temperature": 0.0, "avg_logprob": -0.2481251793938714, "compression_ratio": 1.5344827586206897, "no_speech_prob": 0.0007839088211767375}, {"id": 408, "seek": 299632, "start": 2996.32, "end": 3003.32, "text": " I think that's time up. So thank you. Thank you.", "tokens": [50364, 286, 519, 300, 311, 565, 493, 13, 407, 1309, 291, 13, 1044, 291, 13, 50714], "temperature": 0.0, "avg_logprob": -0.24384459327248967, "compression_ratio": 1.0909090909090908, "no_speech_prob": 0.0009058654541149735}], "language": "en"}