{"text": " So the thing about QuestDB, apart from being open source, we want people to know us because we try to be very performant, but specifically in small machines. It, like, perform very well in 120 CPUs and 200 gigs of RAM, it's okay. Performing very well in 4 CPUs and 16 of RAM, 16 gigs is more difficult. So that we try to optimize for that. Actually in the past, we were optimizing for the larger instance use case and then we realized not everybody has, like, a super large instance at home, so, you know, we try to be better at that. We also try to be very good with developer experience, that you get performance out of the box. There are many things you can tweak in QuestDB, you know, in every other database, every other system, lots of configuration, the, I don't know, the memory, page size, the buffers and what not, which CPUs do what, blah, blah, blah, blah. By default, if you don't touch anything, which will perform well. And then if you have expert tolerance, you might fine tune. But we try hard to make developer experience as simple, and that's why we choose SQL also for querying data. So another time series database, make the trade off. We want to perform. We need to use a different language, which is cool because, you know, that's, I get it. We choose SQL because we want the developers to have an easy way learning QuestDB. For ingesting data, you can use SQL, but we also offer a different protocol, which is faster. That's why we have collecting libraries, so you don't have to go low level to be performant. But that's the idea. And we are open source, very proud about being open source. But why we are building another database? There are a lot of databases. If you walk around first, then you're going to read research about every type of database out there. And just today here, I saw MongoDB, I saw Clickhouse, there's someone about Postgres, there's someone about SQL, about MariaDB. Why you need another database, another open source database? Well, because different data looks different and can have different problems. And in our case, we are specialized on time series. We don't do anything else. I mean, if you try to use QuestDB for full text search analytics, we are truly the worst database ever for that. If you try to use QuestDB for geospatial queries, we support some geospatial themes kind of a bit. We have a specific data type about geohasses, so we have a type about that. But we are not good for geospatial unless it is part of time series plus geo. That's kind of the idea. So we specialize only on time series analytics, on data which is changing over time and you want to monitor and track those changes. That's the idea. We are not good for anything else. If you try to use QuestDB for everything, boy, what a disappointment we are going to be. But if you try for time series database, this will be one of the good ones. That's kind of the idea. And that's why we are building QuestDB, because there are a lot of time series data out there. And how do you know if you have a time series tool and I have to hear a lot of things. I want to just read a couple of them. But basically, if most of the time you are reading data on a slice of time, tell me which energy consumption I have over the last minute. Tell me how is the nuclear reactor doing in the past 10 microseconds. Tell me what is the conversion for this user in the past week. Let me know for all the data, I have a moving vehicle, which was the last position I saw it and which was the sensor in this particular point in time. So if you have that, time series can be interesting. So with time series, you have all that type of problems. Data tends to be inserting faster than it reads. Databases, historically, have been optimized for reads. They try every trick in the book for making read super fast. When you insert data, you need to define indexes and they are going to index by many different things and they keep caching memory for a lot of things and blah, blah, blah, blah. So reading is the key thing, because usually you read data much more than you write. But also in time series databases, we can support heavy reads on top of that, but we need to support heavy inserts and keep performance of that. We don't use indexes. The performance you're going to see today is with no indexes. We don't need them. We don't want them, because having an index slowed down in gestion. It's a luxury we cannot have. So we have some kind of indexing, but we don't have indexes, not as you know them. That's kind of the idea here. So it's slightly different. You have data that you are writing very often, that data is going to grow, and it can grow fast. And you need to have some way of loading or deleting that data. On a traditional database, you just don't say, oh, I have, I don't know, I'm Amazon and I'm getting users. It's like, oh, I already have a million users, a million one, I'm going to delete the old users. You don't do that. I mean, sometimes you do, but you don't do that. You don't really do that on your databases. On time series database, almost all of them have some mechanism to deal with historical data and do something with that. In our case, you can amount partitions, you can amount to cheaper storage, those kind of things. But we have the commands and it is designed for that kind of thing. That kind of the idea. Many other things about how you have a time series storyline, but that kind of the idea. But better than me just telling you, I'm going to show you some queries on top of demo data sets. I'm going to get the feeling why a time series database might be interesting and then we're going to details about the ingesting data and about all those things. That's in sound good so far, yeah? Do you have any questions? I'm happy to take them during the talk, by the way, not only at the end. So we have a live demo, demo.questdbe.io, which is running on a large machine on AWS. We don't need all the power, but since it's like, you know, open to the public. Again, we have a few different data sets. There is one. You are in a big data room, so you are truly familiar with the taxi rise, New York City taxi rise data set. It's the, and the city of New York has a data set, which is very cool for machine learning and for big data, which is taxi rides in the city of New York. When the ride started, when it finished, also the coordinate and a few things like the tip and the amount of the fare, how many people, blah, blah, blah. So we took that open data set and we just put it here on questdbe, a few years of the data set. Yes, you know, a lot of columns here. So let me just show you how big this is. This is, right now, is the size okay or maybe not? Maybe I have to make it a bit, first this a bit bigger and then, okay. So it's 1.6 billion rows, which is not huge. I mean, if you have a relational database, 1.6 billion rows, they don't, relational databases today, they are great. But 1.6 billion rows is like, yeah, I couldn't work with that, I'm not super comfortable. For us, it's cute. It's like, I mean, it's a data set which is respectable but not really huge, but 1.60 billion rows. And now, what if I want to do something like, for example, I don't know, I want to calculate the average of whichever, this for example, this number, I want to average the fair amount over 1.6 billion trips. How long you will expect your database to take to go do a full scan over 1.6 billion rows and compute the average, no indexes, no anything. How long would you say, more or less, ballpark, 1.6 billion rows, no one? How is the size in gigabytes, megabytes? I don't know for the whole data set, but this is a double, I mean, I really just know, it's big, it's big. When you download the CSV, it's CSV, it's about 600 megabytes and you have several of those. It's in the, you know, it's largesse. But anyway, well, actually it was slower than I thought. It took, usually it takes half a second, this time it took 0.6 seconds. I know it's slow, I know, but it's with a reason, sort of that. But I told you, I told you, we are trying to see this database, we are super slow for other things. This is not a time series query, did you see any timestamp here, I didn't see anything. This is just a full scan, we parallelize, we read data and we are slow. We take almost over half a second to go over only 1.6 billion rows, unforgivable, sort of that. But there with me here, no, that's the thing, I mean, I'm kind of half kidding but not really. But wait until I put a time dimension, now yes, I want only, for example, I want only one year of data and I'm going to just also add another computation because I know that it's just counting data which is super fast. So I'm going to add another computation, so I'm going to count the data and only for 2016 and this is better, this is already 100 milliseconds because we are going only over a few rows, we are going only about, yeah, it's only 146 million rows, this is much more manageable, so only 140 million rows, that's better. So we can go actually very fast on this and then if you keep going down, oh no, I want only one month of data which is, I don't know, still, yeah, 12 million rows, so a month of data is 60 milliseconds, for one day of data, of course, is way faster, this is already 50 milliseconds, if I go to one specific hour, a minute, it should be, you know, kind of, not much faster because, oh yeah, it's under one millisecond actually, thank you for that, but still, like, you know, we have partitions, so basically one thing we do, we only go to the partition where the data is stored, so we only attack that part of the data, but that's kind of the thing, for when you have like that time component, we are quite fast, oh, fairly fast, that's kind of the beauty for a time-serious database, and we can do also interesting, other interesting things, if I go to the same table and I show you what this looks like, you can see that for the same second, I have many trips because this is New York, baby, and in New York, you know, the city that never sleeps, you can't get back in every corner, you get rich when you land in New York, I spent there one year, it's not like that, anyway, so in every particular second, even at midnight, you have always a few trips at least, okay, so actually you could do that, we could do something like, I want to know the, I want to, if I want to do something like, give me the date time and how many trips are ending where this date time is in, for example, June 21st, city, what are you doing there, man? I didn't even know I had city here, okay, so, I don't know, for example, in this particular minute, in one particular day, I want to sample in one second interval and know how many trips I have for every particular second, so that's another thing you can do in a time series database, rather than grouping by columns that you can also do, you can group by time, you call this sample by, so we can sample by any, we go from microsecond to year, I guess, microsecond to year, so you can group by microsecond, millisecond, second, year, day, whatever, so in this case, I'm saying, okay, in this particular second, I have six trips and five trips and blah, blah, blah, you get the idea, yeah, so something I wanted to show you, which is another cool one, it's, I have this data set with several trips every second, I have another data set, also with data from Manhattan, is the weather data set, so maybe it will be interesting to know, to join those two data sets, it will be cool to know the weather that I had for a particular trip, because maybe that gives me some insight, I don't know, the challenge is this data set, of course, is real life, it's a different open data set, it's not at the same resolution, we don't have weather changes every second, in my hometown sometimes that happens, and when I was living in London that was crazy, but in real life, we don't measure, we don't store weather changes every second, in this particular data set, we have about two or three records every hour, so now if I want to join a data set with sub-second resolution, a data set with sub-hour resolution, and I want to do a join, if I want to do it in other databases, I could do it, it will take me a while, then I will think I have it and I wouldn't, and then it will be like, yeah, this makes sense, or not really, and a week later I will be crying, I don't know, I don't know, so you know, I should know, so one thing, one cool thing we have here, we have a demo set, it's an example, I'm going to move on to another thing really quickly, because otherwise, but this one I really like, we have a special type of join, which we call an ask of join, which basically does this, I'm going to select the data from the table I told you already for one particular day in time, and then I'm going to do what we call an ask of join, which basically says, this table has a time stamp, we call it the designated time stamp, you design which is the column, you have several, so we have the designated time stamp in one, designated time stamp in the other, joined by the ones that are closer to each other, in this case, ask of means the one which is exactly the same, or immediately before me, the one which is closer to me, what happened before, we have also the one strictly before me cannot be the same, but that's the idea, so in this case for joining two different data sets, I can just do that, also I'm going to add here the time stamp for the other table, so it's clear, so if I run this query, now here I can see for each record on the New York taxi rides, I'm always getting the same time stamp in the weather data set, because I have only one entry every 40 or 45 minutes, if I move to a different point in the day to this day, but instead of at 12, at 12.55 for example, I should see already the time matching to a different entry on this table, but that's it, I have different resolutions, I don't care which one, we join by time, because we're about time, that's kind of the idea, that's what I'm trying to say, I have more interesting queries, but maybe for a different day, so that's the first thing. So I told you, okay, now you get the idea why tensile is kind of interesting, the kind of things we can do, down sampling, all those things, machine learning is very important, you have data maybe every second, and then you want to do a forecasting, and it doesn't make sense to train a model with every second data in many cases, maybe you want to down sample to 15 minutes intervals, with this trick you can do it easily, so that's kind of the idea. So I was speaking about ingesting data, so ingesting over one million times per second on a single instance, it's interesting, but ingesting over one million records per second on a single instance, it's easy actually, I could just write to a file, a pending line, and that will be it, the interesting bit is actually being able to ingest data while you are able to query data in real time, the same data you ingested, that's the trick, because just ingesting, I mean, you put it there and you're like, why ingesting a million records, when you think about it, it's like, well, wait, but how long I have to wait to query the data, and when I can, so the idea is you can query the data at the same time, all benchmarks are lies, of course, on the same benchmark that I'm going to tell you, other people will tell you the contrary, and I'm totally fine with that, but a couple of years ago we published an article saying, hey, we can ingest now at 1.4 million, the slides are linked already on the first page, by the way, thank you, so we, our CTO posted about, you know, how we were ingesting 1.4 million records per second, these records were, they have like 20 columns, 10 dimensions, 10 strings, and 10 metrics, 10 numbers, so, you know, we could ingest records of 20 columns with 10 strings and 10 numbers, 1.4 million records per second while running queries, which is the other bit, so we were able to scan over 4 million, 4 billion records per second, you know, at the same time in relatively small machines, relatively small, so that's kind of the, the idea, okay, and these benchmarks, we didn't write it, it was, there is a benchmark specifically for 10 series databases, as I told you earlier, if you load data in QuestDB, you can load relational data into QuestDB, and you can run queries, you try to run a conventional benchmark on QuestDB, it's going to be super slow, so we are not designed for full text search, we are not designed for, you know, just operations, reading individual records, or doing updating data, we are not designed for that, we can do it, but we are not designed for that, so there is, and also there are 10 series databases, so in FluxDB, another open source database, created this benchmark, the TSBS benchmark, which is specifically about 10 series databases, so the queries and the ingestion patterns matches what you would expect from a 10 series database, now it's maintained by time scale, which is another open source database on top of Postgres, and we have our own, you know, there is an adapter for running that on top of QuestDB, and with that benchmark, it's with the one that we are getting those results, so with that particular benchmark, it's the one giving the results, so you know, your mileage might vary, also depending on the hardware, if you try to run the benchmark in the cloud, it's going to be slower, always, because in the cloud, by default, you use on AWS, you use CVS, on WorldCloud, you use the attached storage, it's networking storage, it has latency, because they are not local disk, they are super cool, but they are not local, it's going to be always slower, you want to get this on WorldCloud or on AWS, you can do it, you have to use NVME disk, which are local disk, which are attached to the instance, but they disappear when you close the instance, but with those disks, you will be getting the same benchmark, so hardware is also important with the benchmark, but that's the idea, you know, that's how we did it, and before, I tell you a bit about the technical decisions, that I will not have super time, but I want to show you how we are doing this in gestion, so let me just, if I can move this out of the way, so this is a scripting goal, I don't know any goal at all, but I know to run this, so another developer advocate, I mean, I couldn't tell you that I know a lot of goals, but I have no idea, so goal lang is a language, so yeah, we have, I've been told it's pretty cool, so we have this library or package or whatever they call it in Go, which is our official package, cargo or whatever, I don't know, so this is my missing languages here, thank you, so yeah, this is our theme, I'm connecting to local host to the default port in QuestDB, I'm going to be simulating data, so I'm simulating IoT data, and I'm going to be outputting a device type, it can be red or blue or green or yellow, I'm going to be outputting duration, latitude, longitude, speed, and time stamp in nanoseconds, and I'm going to do this in chunks of, in batches of 50,000 records, I'm going to do this 200 times, 50,000 records, 200 times, 10 million records, I'm going to be inserting 10 million records on a device, on a table that doesn't exist, QuestDB will create it automatically when it starts receiving data, so if I run this scripting goal, which run doing go run, well don't go, so go run, it's ingesting data, it should take less than 10 seconds because we are ingesting 10 million, and that's finished, so let me just go to my local host here, let me just select, select how many records did we ingest it for, I have to refresh the tables, okay, how many records I ingested, 10 million records, that's good, can you tell me the interval, so I can see what happened here, sampled by one second, and it's telling me, yeah, you know, in the first second only half a million, because we, we then started at the top of the second, it was probably at second or something, but after that, one million, one million, one million, ten, one, you see, you see the idea, okay, that's not too bad, I can do this slightly better, I can run this script actually twice ingesting in the same instant to two different tables, so now, if I refresh, I should see I have two tables, not only one, so I have two tables here, same hardware and everything, if I run again, I'm going to select only the last 10 rows, so we only see the latest run, so you can see it's just lower now, I was actually ingesting to two tables, so I'm ingesting only 700,000 per second, something like that, but if I go to the same time to the other table, I can just do a union, if I go to the other table here, you should see that at the same time in the, oh yeah, I cannot apply limit here, sorry, in a union, so I should see that, you know, even if I was going slower, the other table was reading data, and in this format you cannot see it very well, but we can do something I told you earlier, I can just rather than do a join, I can just do something like, as of join, the first query with the second, so I should be able to do this, now I have, in the first run, we were running only one instance of sending data, and this one is the one in which I was running two, so you can see, for this particular second, we were ingesting 700,000 records in one, 700,000 records in the other same time, so about 1.4 something million in total because we're in different tables, out of the box, if I configure the writers and how many threads I have for processing things, I can get it slightly faster than this, okay, but that's good enough, on a local, M1 laptop SSD, it's fast, but that's the idea, okay, so that's the one million there, I was not lying, I was just, you know, telling you things, I have only a few minutes, but that's cool, how we got here, first, we can do a lot of assumptions about the data, this is time-serious, so we know people usually want to get not individual rows, but computations over rows, we know people mostly want to group by things that are in the data, like strings, like the country name or the device name or the brand or whatever, so instead of storing strings, we have a special symbol, which is called a special type, which is called a symbol, if you give me a string, we convert into a number and we do look up automatically those things, so we can make a lot of assumptions because we hyper-specialize on one particular use case, we optimize storage, we don't use indexes because we store everything always in incremental order per partition, if we get data out of order, we have to regret the partitions, but we don't need indexes because we always have the data physically in order, so we can scan super quickly back and forth, that's kind of the idea, we also parallelize as much as we can using different things, this is written in Java and it's from scratch, you will see some databases which I love, like MongoDB, excellent database for content, they have a time-serious module, we use the same MongoDB collections for doing time-series, they cannot be as fast because they are using exactly what they are using for content, it's very convenient, I can do everything, but same thing with other engines that are built on top of other things, we don't have any dependencies, everything is built for scratch, actually we are writing some of the libraries in Java like strings and loggers and so on to avoid conversions, there are things that we don't use, so we don't use them, we have libraries for strings, we have libraries for memory management, we have libraries for absolutely everything, they are written in our own version, we had our own Justintine compiler because the original Justintine compiler in Java was not performed enough for some of the parallelization inquiries wanted to do, so we wrote everything, our Java is kind of weird, Jeremy can tell you more about that, it's super weird Java, but it's still Java, that's kind of the idea, we even route our own input output functions, that's kind of a thing, why? Because we can get nanoseconds faster, this is log4j, log4j, we don't speak about log4j, but this is awesome, but you know this is log4j, j for log4j, and this is the nanoseconds, the operations you can do in each nanosecond, so with log4j, login, integer, you can do 82 operations per nanosecond, we can do 800 operations per nanosecond, which is, do you have to go down to the nanosecond, if you are doing a CRUT application, probably not, it really depends what you are building, that's kind of why we are writing things from scratch, so basically the approach of QuestDB to performance, you know this, this is like, I don't know who you are, but I don't know you, but I will find you and I will kill you, that's kind of the same approach I see on QuestDB team, they are like, I don't know, we can get faster at some obscure thing here, so that's kind of the idea, and we try to be a good team player, Jeremy here has contributed himself, only alone, the connectors for KafkaConnet, connectors for Apache Flink, so we try to integrate with the rest of the ecosystem, we love it if you try QuestDB, you are open source geeks, you like, we have stars, we like you have stars, please contribute, please start on GitHub if you like it, we have a contributor to the Slack channel, we are quite friendly, we are fast, we work with interesting problems, if you like interesting problems, if you like weird Java, we would love to have you here, so thank you very much, and I can take any questions outside. Oh, one question for the chat, thank you, yeah, yeah, yeah, yeah, it's a, someone was asking, is QuestDB can work with GPS data, yes, you can work with GPS data, we have doubles that we can use for that, we don't have a lot of geospatial functions, we have geohashes, which basically allow you to define in which, at different resolutions, in which square in the world something is, so if you are talking about finding where a point is in the world, at a particular point in time, QuestDB is very cool, if you need to do other things, we support some math libraries, calls and all those things to do your own calculations, but yeah, it can be used for GPS, and some people are, a lot of people are actually doing asset tracking with QuestDB, thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 10.44, "text": " So the thing about QuestDB, apart from being open source, we want people to know us because", "tokens": [407, 264, 551, 466, 8800, 27735, 11, 4936, 490, 885, 1269, 4009, 11, 321, 528, 561, 281, 458, 505, 570], "temperature": 0.0, "avg_logprob": -0.2692712829226539, "compression_ratio": 1.4519230769230769, "no_speech_prob": 0.2246098667383194}, {"id": 1, "seek": 0, "start": 10.44, "end": 13.96, "text": " we try to be very performant, but specifically in small machines.", "tokens": [321, 853, 281, 312, 588, 2042, 394, 11, 457, 4682, 294, 1359, 8379, 13], "temperature": 0.0, "avg_logprob": -0.2692712829226539, "compression_ratio": 1.4519230769230769, "no_speech_prob": 0.2246098667383194}, {"id": 2, "seek": 0, "start": 13.96, "end": 23.6, "text": " It, like, perform very well in 120 CPUs and 200 gigs of RAM, it's okay.", "tokens": [467, 11, 411, 11, 2042, 588, 731, 294, 10411, 13199, 82, 293, 2331, 34586, 295, 14561, 11, 309, 311, 1392, 13], "temperature": 0.0, "avg_logprob": -0.2692712829226539, "compression_ratio": 1.4519230769230769, "no_speech_prob": 0.2246098667383194}, {"id": 3, "seek": 0, "start": 23.6, "end": 29.2, "text": " Performing very well in 4 CPUs and 16 of RAM, 16 gigs is more difficult.", "tokens": [19351, 278, 588, 731, 294, 1017, 13199, 82, 293, 3165, 295, 14561, 11, 3165, 34586, 307, 544, 2252, 13], "temperature": 0.0, "avg_logprob": -0.2692712829226539, "compression_ratio": 1.4519230769230769, "no_speech_prob": 0.2246098667383194}, {"id": 4, "seek": 2920, "start": 29.2, "end": 31.8, "text": " So that we try to optimize for that.", "tokens": [407, 300, 321, 853, 281, 19719, 337, 300, 13], "temperature": 0.0, "avg_logprob": -0.20619311862521703, "compression_ratio": 1.7322033898305085, "no_speech_prob": 0.0004177364462520927}, {"id": 5, "seek": 2920, "start": 31.8, "end": 37.32, "text": " Actually in the past, we were optimizing for the larger instance use case and then we realized", "tokens": [5135, 294, 264, 1791, 11, 321, 645, 40425, 337, 264, 4833, 5197, 764, 1389, 293, 550, 321, 5334], "temperature": 0.0, "avg_logprob": -0.20619311862521703, "compression_ratio": 1.7322033898305085, "no_speech_prob": 0.0004177364462520927}, {"id": 6, "seek": 2920, "start": 37.32, "end": 41.12, "text": " not everybody has, like, a super large instance at home, so, you know, we try to be better", "tokens": [406, 2201, 575, 11, 411, 11, 257, 1687, 2416, 5197, 412, 1280, 11, 370, 11, 291, 458, 11, 321, 853, 281, 312, 1101], "temperature": 0.0, "avg_logprob": -0.20619311862521703, "compression_ratio": 1.7322033898305085, "no_speech_prob": 0.0004177364462520927}, {"id": 7, "seek": 2920, "start": 41.12, "end": 42.12, "text": " at that.", "tokens": [412, 300, 13], "temperature": 0.0, "avg_logprob": -0.20619311862521703, "compression_ratio": 1.7322033898305085, "no_speech_prob": 0.0004177364462520927}, {"id": 8, "seek": 2920, "start": 42.12, "end": 46.56, "text": " We also try to be very good with developer experience, that you get performance out of", "tokens": [492, 611, 853, 281, 312, 588, 665, 365, 10754, 1752, 11, 300, 291, 483, 3389, 484, 295], "temperature": 0.0, "avg_logprob": -0.20619311862521703, "compression_ratio": 1.7322033898305085, "no_speech_prob": 0.0004177364462520927}, {"id": 9, "seek": 2920, "start": 46.56, "end": 47.56, "text": " the box.", "tokens": [264, 2424, 13], "temperature": 0.0, "avg_logprob": -0.20619311862521703, "compression_ratio": 1.7322033898305085, "no_speech_prob": 0.0004177364462520927}, {"id": 10, "seek": 2920, "start": 47.56, "end": 51.519999999999996, "text": " There are many things you can tweak in QuestDB, you know, in every other database, every other", "tokens": [821, 366, 867, 721, 291, 393, 29879, 294, 8800, 27735, 11, 291, 458, 11, 294, 633, 661, 8149, 11, 633, 661], "temperature": 0.0, "avg_logprob": -0.20619311862521703, "compression_ratio": 1.7322033898305085, "no_speech_prob": 0.0004177364462520927}, {"id": 11, "seek": 2920, "start": 51.519999999999996, "end": 59.0, "text": " system, lots of configuration, the, I don't know, the memory, page size, the buffers and", "tokens": [1185, 11, 3195, 295, 11694, 11, 264, 11, 286, 500, 380, 458, 11, 264, 4675, 11, 3028, 2744, 11, 264, 9204, 433, 293], "temperature": 0.0, "avg_logprob": -0.20619311862521703, "compression_ratio": 1.7322033898305085, "no_speech_prob": 0.0004177364462520927}, {"id": 12, "seek": 5900, "start": 59.0, "end": 62.08, "text": " what not, which CPUs do what, blah, blah, blah, blah.", "tokens": [437, 406, 11, 597, 13199, 82, 360, 437, 11, 12288, 11, 12288, 11, 12288, 11, 12288, 13], "temperature": 0.0, "avg_logprob": -0.22717712039039248, "compression_ratio": 1.6386861313868613, "no_speech_prob": 9.720930393086746e-05}, {"id": 13, "seek": 5900, "start": 62.08, "end": 65.32, "text": " By default, if you don't touch anything, which will perform well.", "tokens": [3146, 7576, 11, 498, 291, 500, 380, 2557, 1340, 11, 597, 486, 2042, 731, 13], "temperature": 0.0, "avg_logprob": -0.22717712039039248, "compression_ratio": 1.6386861313868613, "no_speech_prob": 9.720930393086746e-05}, {"id": 14, "seek": 5900, "start": 65.32, "end": 68.28, "text": " And then if you have expert tolerance, you might fine tune.", "tokens": [400, 550, 498, 291, 362, 5844, 23368, 11, 291, 1062, 2489, 10864, 13], "temperature": 0.0, "avg_logprob": -0.22717712039039248, "compression_ratio": 1.6386861313868613, "no_speech_prob": 9.720930393086746e-05}, {"id": 15, "seek": 5900, "start": 68.28, "end": 75.0, "text": " But we try hard to make developer experience as simple, and that's why we choose SQL also", "tokens": [583, 321, 853, 1152, 281, 652, 10754, 1752, 382, 2199, 11, 293, 300, 311, 983, 321, 2826, 19200, 611], "temperature": 0.0, "avg_logprob": -0.22717712039039248, "compression_ratio": 1.6386861313868613, "no_speech_prob": 9.720930393086746e-05}, {"id": 16, "seek": 5900, "start": 75.0, "end": 76.0, "text": " for querying data.", "tokens": [337, 7083, 1840, 1412, 13], "temperature": 0.0, "avg_logprob": -0.22717712039039248, "compression_ratio": 1.6386861313868613, "no_speech_prob": 9.720930393086746e-05}, {"id": 17, "seek": 5900, "start": 76.0, "end": 80.2, "text": " So another time series database, make the trade off.", "tokens": [407, 1071, 565, 2638, 8149, 11, 652, 264, 4923, 766, 13], "temperature": 0.0, "avg_logprob": -0.22717712039039248, "compression_ratio": 1.6386861313868613, "no_speech_prob": 9.720930393086746e-05}, {"id": 18, "seek": 5900, "start": 80.2, "end": 81.2, "text": " We want to perform.", "tokens": [492, 528, 281, 2042, 13], "temperature": 0.0, "avg_logprob": -0.22717712039039248, "compression_ratio": 1.6386861313868613, "no_speech_prob": 9.720930393086746e-05}, {"id": 19, "seek": 5900, "start": 81.2, "end": 86.24000000000001, "text": " We need to use a different language, which is cool because, you know, that's, I get it.", "tokens": [492, 643, 281, 764, 257, 819, 2856, 11, 597, 307, 1627, 570, 11, 291, 458, 11, 300, 311, 11, 286, 483, 309, 13], "temperature": 0.0, "avg_logprob": -0.22717712039039248, "compression_ratio": 1.6386861313868613, "no_speech_prob": 9.720930393086746e-05}, {"id": 20, "seek": 8624, "start": 86.24, "end": 91.88, "text": " We choose SQL because we want the developers to have an easy way learning QuestDB.", "tokens": [492, 2826, 19200, 570, 321, 528, 264, 8849, 281, 362, 364, 1858, 636, 2539, 8800, 27735, 13], "temperature": 0.0, "avg_logprob": -0.20920792178831238, "compression_ratio": 1.6762820512820513, "no_speech_prob": 0.00019903903012163937}, {"id": 21, "seek": 8624, "start": 91.88, "end": 95.56, "text": " For ingesting data, you can use SQL, but we also offer a different protocol, which", "tokens": [1171, 3957, 8714, 1412, 11, 291, 393, 764, 19200, 11, 457, 321, 611, 2626, 257, 819, 10336, 11, 597], "temperature": 0.0, "avg_logprob": -0.20920792178831238, "compression_ratio": 1.6762820512820513, "no_speech_prob": 0.00019903903012163937}, {"id": 22, "seek": 8624, "start": 95.56, "end": 96.56, "text": " is faster.", "tokens": [307, 4663, 13], "temperature": 0.0, "avg_logprob": -0.20920792178831238, "compression_ratio": 1.6762820512820513, "no_speech_prob": 0.00019903903012163937}, {"id": 23, "seek": 8624, "start": 96.56, "end": 101.0, "text": " That's why we have collecting libraries, so you don't have to go low level to be performant.", "tokens": [663, 311, 983, 321, 362, 12510, 15148, 11, 370, 291, 500, 380, 362, 281, 352, 2295, 1496, 281, 312, 2042, 394, 13], "temperature": 0.0, "avg_logprob": -0.20920792178831238, "compression_ratio": 1.6762820512820513, "no_speech_prob": 0.00019903903012163937}, {"id": 24, "seek": 8624, "start": 101.0, "end": 102.0, "text": " But that's the idea.", "tokens": [583, 300, 311, 264, 1558, 13], "temperature": 0.0, "avg_logprob": -0.20920792178831238, "compression_ratio": 1.6762820512820513, "no_speech_prob": 0.00019903903012163937}, {"id": 25, "seek": 8624, "start": 102.0, "end": 104.44, "text": " And we are open source, very proud about being open source.", "tokens": [400, 321, 366, 1269, 4009, 11, 588, 4570, 466, 885, 1269, 4009, 13], "temperature": 0.0, "avg_logprob": -0.20920792178831238, "compression_ratio": 1.6762820512820513, "no_speech_prob": 0.00019903903012163937}, {"id": 26, "seek": 8624, "start": 104.44, "end": 106.64, "text": " But why we are building another database?", "tokens": [583, 983, 321, 366, 2390, 1071, 8149, 30], "temperature": 0.0, "avg_logprob": -0.20920792178831238, "compression_ratio": 1.6762820512820513, "no_speech_prob": 0.00019903903012163937}, {"id": 27, "seek": 8624, "start": 106.64, "end": 108.32, "text": " There are a lot of databases.", "tokens": [821, 366, 257, 688, 295, 22380, 13], "temperature": 0.0, "avg_logprob": -0.20920792178831238, "compression_ratio": 1.6762820512820513, "no_speech_prob": 0.00019903903012163937}, {"id": 28, "seek": 8624, "start": 108.32, "end": 112.11999999999999, "text": " If you walk around first, then you're going to read research about every type of database", "tokens": [759, 291, 1792, 926, 700, 11, 550, 291, 434, 516, 281, 1401, 2132, 466, 633, 2010, 295, 8149], "temperature": 0.0, "avg_logprob": -0.20920792178831238, "compression_ratio": 1.6762820512820513, "no_speech_prob": 0.00019903903012163937}, {"id": 29, "seek": 8624, "start": 112.11999999999999, "end": 113.11999999999999, "text": " out there.", "tokens": [484, 456, 13], "temperature": 0.0, "avg_logprob": -0.20920792178831238, "compression_ratio": 1.6762820512820513, "no_speech_prob": 0.00019903903012163937}, {"id": 30, "seek": 11312, "start": 113.12, "end": 117.84, "text": " And just today here, I saw MongoDB, I saw Clickhouse, there's someone about Postgres,", "tokens": [400, 445, 965, 510, 11, 286, 1866, 48380, 27735, 11, 286, 1866, 8230, 6410, 11, 456, 311, 1580, 466, 10223, 45189, 11], "temperature": 0.0, "avg_logprob": -0.23095034751571528, "compression_ratio": 1.6594202898550725, "no_speech_prob": 0.00038533619954250753}, {"id": 31, "seek": 11312, "start": 117.84, "end": 120.36, "text": " there's someone about SQL, about MariaDB.", "tokens": [456, 311, 1580, 466, 19200, 11, 466, 12734, 27735, 13], "temperature": 0.0, "avg_logprob": -0.23095034751571528, "compression_ratio": 1.6594202898550725, "no_speech_prob": 0.00038533619954250753}, {"id": 32, "seek": 11312, "start": 120.36, "end": 122.64, "text": " Why you need another database, another open source database?", "tokens": [1545, 291, 643, 1071, 8149, 11, 1071, 1269, 4009, 8149, 30], "temperature": 0.0, "avg_logprob": -0.23095034751571528, "compression_ratio": 1.6594202898550725, "no_speech_prob": 0.00038533619954250753}, {"id": 33, "seek": 11312, "start": 122.64, "end": 127.44, "text": " Well, because different data looks different and can have different problems.", "tokens": [1042, 11, 570, 819, 1412, 1542, 819, 293, 393, 362, 819, 2740, 13], "temperature": 0.0, "avg_logprob": -0.23095034751571528, "compression_ratio": 1.6594202898550725, "no_speech_prob": 0.00038533619954250753}, {"id": 34, "seek": 11312, "start": 127.44, "end": 130.96, "text": " And in our case, we are specialized on time series.", "tokens": [400, 294, 527, 1389, 11, 321, 366, 19813, 322, 565, 2638, 13], "temperature": 0.0, "avg_logprob": -0.23095034751571528, "compression_ratio": 1.6594202898550725, "no_speech_prob": 0.00038533619954250753}, {"id": 35, "seek": 11312, "start": 130.96, "end": 131.96, "text": " We don't do anything else.", "tokens": [492, 500, 380, 360, 1340, 1646, 13], "temperature": 0.0, "avg_logprob": -0.23095034751571528, "compression_ratio": 1.6594202898550725, "no_speech_prob": 0.00038533619954250753}, {"id": 36, "seek": 11312, "start": 131.96, "end": 138.56, "text": " I mean, if you try to use QuestDB for full text search analytics, we are truly the worst", "tokens": [286, 914, 11, 498, 291, 853, 281, 764, 8800, 27735, 337, 1577, 2487, 3164, 15370, 11, 321, 366, 4908, 264, 5855], "temperature": 0.0, "avg_logprob": -0.23095034751571528, "compression_ratio": 1.6594202898550725, "no_speech_prob": 0.00038533619954250753}, {"id": 37, "seek": 11312, "start": 138.56, "end": 141.12, "text": " database ever for that.", "tokens": [8149, 1562, 337, 300, 13], "temperature": 0.0, "avg_logprob": -0.23095034751571528, "compression_ratio": 1.6594202898550725, "no_speech_prob": 0.00038533619954250753}, {"id": 38, "seek": 14112, "start": 141.12, "end": 147.20000000000002, "text": " If you try to use QuestDB for geospatial queries, we support some geospatial themes", "tokens": [759, 291, 853, 281, 764, 8800, 27735, 337, 1519, 2763, 267, 831, 24109, 11, 321, 1406, 512, 1519, 2763, 267, 831, 13544], "temperature": 0.0, "avg_logprob": -0.15526906455435405, "compression_ratio": 1.721774193548387, "no_speech_prob": 0.00037021207390353084}, {"id": 39, "seek": 14112, "start": 147.20000000000002, "end": 149.24, "text": " kind of a bit.", "tokens": [733, 295, 257, 857, 13], "temperature": 0.0, "avg_logprob": -0.15526906455435405, "compression_ratio": 1.721774193548387, "no_speech_prob": 0.00037021207390353084}, {"id": 40, "seek": 14112, "start": 149.24, "end": 154.76, "text": " We have a specific data type about geohasses, so we have a type about that.", "tokens": [492, 362, 257, 2685, 1412, 2010, 466, 1519, 1445, 26615, 11, 370, 321, 362, 257, 2010, 466, 300, 13], "temperature": 0.0, "avg_logprob": -0.15526906455435405, "compression_ratio": 1.721774193548387, "no_speech_prob": 0.00037021207390353084}, {"id": 41, "seek": 14112, "start": 154.76, "end": 159.72, "text": " But we are not good for geospatial unless it is part of time series plus geo.", "tokens": [583, 321, 366, 406, 665, 337, 1519, 2763, 267, 831, 5969, 309, 307, 644, 295, 565, 2638, 1804, 1519, 78, 13], "temperature": 0.0, "avg_logprob": -0.15526906455435405, "compression_ratio": 1.721774193548387, "no_speech_prob": 0.00037021207390353084}, {"id": 42, "seek": 14112, "start": 159.72, "end": 160.72, "text": " That's kind of the idea.", "tokens": [663, 311, 733, 295, 264, 1558, 13], "temperature": 0.0, "avg_logprob": -0.15526906455435405, "compression_ratio": 1.721774193548387, "no_speech_prob": 0.00037021207390353084}, {"id": 43, "seek": 14112, "start": 160.72, "end": 166.72, "text": " So we specialize only on time series analytics, on data which is changing over time and you", "tokens": [407, 321, 37938, 787, 322, 565, 2638, 15370, 11, 322, 1412, 597, 307, 4473, 670, 565, 293, 291], "temperature": 0.0, "avg_logprob": -0.15526906455435405, "compression_ratio": 1.721774193548387, "no_speech_prob": 0.00037021207390353084}, {"id": 44, "seek": 14112, "start": 166.72, "end": 169.12, "text": " want to monitor and track those changes.", "tokens": [528, 281, 6002, 293, 2837, 729, 2962, 13], "temperature": 0.0, "avg_logprob": -0.15526906455435405, "compression_ratio": 1.721774193548387, "no_speech_prob": 0.00037021207390353084}, {"id": 45, "seek": 14112, "start": 169.12, "end": 170.12, "text": " That's the idea.", "tokens": [663, 311, 264, 1558, 13], "temperature": 0.0, "avg_logprob": -0.15526906455435405, "compression_ratio": 1.721774193548387, "no_speech_prob": 0.00037021207390353084}, {"id": 46, "seek": 17012, "start": 170.12, "end": 171.92000000000002, "text": " We are not good for anything else.", "tokens": [492, 366, 406, 665, 337, 1340, 1646, 13], "temperature": 0.0, "avg_logprob": -0.15254950043339058, "compression_ratio": 1.816326530612245, "no_speech_prob": 0.00030439120018854737}, {"id": 47, "seek": 17012, "start": 171.92000000000002, "end": 175.84, "text": " If you try to use QuestDB for everything, boy, what a disappointment we are going to", "tokens": [759, 291, 853, 281, 764, 8800, 27735, 337, 1203, 11, 3237, 11, 437, 257, 28175, 321, 366, 516, 281], "temperature": 0.0, "avg_logprob": -0.15254950043339058, "compression_ratio": 1.816326530612245, "no_speech_prob": 0.00030439120018854737}, {"id": 48, "seek": 17012, "start": 175.84, "end": 176.84, "text": " be.", "tokens": [312, 13], "temperature": 0.0, "avg_logprob": -0.15254950043339058, "compression_ratio": 1.816326530612245, "no_speech_prob": 0.00030439120018854737}, {"id": 49, "seek": 17012, "start": 176.84, "end": 179.64000000000001, "text": " But if you try for time series database, this will be one of the good ones.", "tokens": [583, 498, 291, 853, 337, 565, 2638, 8149, 11, 341, 486, 312, 472, 295, 264, 665, 2306, 13], "temperature": 0.0, "avg_logprob": -0.15254950043339058, "compression_ratio": 1.816326530612245, "no_speech_prob": 0.00030439120018854737}, {"id": 50, "seek": 17012, "start": 179.64000000000001, "end": 180.64000000000001, "text": " That's kind of the idea.", "tokens": [663, 311, 733, 295, 264, 1558, 13], "temperature": 0.0, "avg_logprob": -0.15254950043339058, "compression_ratio": 1.816326530612245, "no_speech_prob": 0.00030439120018854737}, {"id": 51, "seek": 17012, "start": 180.64000000000001, "end": 185.04, "text": " And that's why we are building QuestDB, because there are a lot of time series data out there.", "tokens": [400, 300, 311, 983, 321, 366, 2390, 8800, 27735, 11, 570, 456, 366, 257, 688, 295, 565, 2638, 1412, 484, 456, 13], "temperature": 0.0, "avg_logprob": -0.15254950043339058, "compression_ratio": 1.816326530612245, "no_speech_prob": 0.00030439120018854737}, {"id": 52, "seek": 17012, "start": 185.04, "end": 188.28, "text": " And how do you know if you have a time series tool and I have to hear a lot of things.", "tokens": [400, 577, 360, 291, 458, 498, 291, 362, 257, 565, 2638, 2290, 293, 286, 362, 281, 1568, 257, 688, 295, 721, 13], "temperature": 0.0, "avg_logprob": -0.15254950043339058, "compression_ratio": 1.816326530612245, "no_speech_prob": 0.00030439120018854737}, {"id": 53, "seek": 17012, "start": 188.28, "end": 190.6, "text": " I want to just read a couple of them.", "tokens": [286, 528, 281, 445, 1401, 257, 1916, 295, 552, 13], "temperature": 0.0, "avg_logprob": -0.15254950043339058, "compression_ratio": 1.816326530612245, "no_speech_prob": 0.00030439120018854737}, {"id": 54, "seek": 17012, "start": 190.6, "end": 197.28, "text": " But basically, if most of the time you are reading data on a slice of time, tell me which", "tokens": [583, 1936, 11, 498, 881, 295, 264, 565, 291, 366, 3760, 1412, 322, 257, 13153, 295, 565, 11, 980, 385, 597], "temperature": 0.0, "avg_logprob": -0.15254950043339058, "compression_ratio": 1.816326530612245, "no_speech_prob": 0.00030439120018854737}, {"id": 55, "seek": 19728, "start": 197.28, "end": 200.92, "text": " energy consumption I have over the last minute.", "tokens": [2281, 12126, 286, 362, 670, 264, 1036, 3456, 13], "temperature": 0.0, "avg_logprob": -0.16778641517716225, "compression_ratio": 1.7066666666666668, "no_speech_prob": 0.0004574870690703392}, {"id": 56, "seek": 19728, "start": 200.92, "end": 205.76, "text": " Tell me how is the nuclear reactor doing in the past 10 microseconds.", "tokens": [5115, 385, 577, 307, 264, 8179, 20628, 884, 294, 264, 1791, 1266, 3123, 37841, 28750, 13], "temperature": 0.0, "avg_logprob": -0.16778641517716225, "compression_ratio": 1.7066666666666668, "no_speech_prob": 0.0004574870690703392}, {"id": 57, "seek": 19728, "start": 205.76, "end": 211.64, "text": " Tell me what is the conversion for this user in the past week.", "tokens": [5115, 385, 437, 307, 264, 14298, 337, 341, 4195, 294, 264, 1791, 1243, 13], "temperature": 0.0, "avg_logprob": -0.16778641517716225, "compression_ratio": 1.7066666666666668, "no_speech_prob": 0.0004574870690703392}, {"id": 58, "seek": 19728, "start": 211.64, "end": 217.52, "text": " Let me know for all the data, I have a moving vehicle, which was the last position I saw", "tokens": [961, 385, 458, 337, 439, 264, 1412, 11, 286, 362, 257, 2684, 5864, 11, 597, 390, 264, 1036, 2535, 286, 1866], "temperature": 0.0, "avg_logprob": -0.16778641517716225, "compression_ratio": 1.7066666666666668, "no_speech_prob": 0.0004574870690703392}, {"id": 59, "seek": 19728, "start": 217.52, "end": 221.96, "text": " it and which was the sensor in this particular point in time.", "tokens": [309, 293, 597, 390, 264, 10200, 294, 341, 1729, 935, 294, 565, 13], "temperature": 0.0, "avg_logprob": -0.16778641517716225, "compression_ratio": 1.7066666666666668, "no_speech_prob": 0.0004574870690703392}, {"id": 60, "seek": 19728, "start": 221.96, "end": 224.88, "text": " So if you have that, time series can be interesting.", "tokens": [407, 498, 291, 362, 300, 11, 565, 2638, 393, 312, 1880, 13], "temperature": 0.0, "avg_logprob": -0.16778641517716225, "compression_ratio": 1.7066666666666668, "no_speech_prob": 0.0004574870690703392}, {"id": 61, "seek": 22488, "start": 224.88, "end": 227.88, "text": " So with time series, you have all that type of problems.", "tokens": [407, 365, 565, 2638, 11, 291, 362, 439, 300, 2010, 295, 2740, 13], "temperature": 0.0, "avg_logprob": -0.1699925094354348, "compression_ratio": 1.7672727272727273, "no_speech_prob": 0.0004617736267391592}, {"id": 62, "seek": 22488, "start": 227.88, "end": 232.48, "text": " Data tends to be inserting faster than it reads.", "tokens": [11888, 12258, 281, 312, 46567, 4663, 813, 309, 15700, 13], "temperature": 0.0, "avg_logprob": -0.1699925094354348, "compression_ratio": 1.7672727272727273, "no_speech_prob": 0.0004617736267391592}, {"id": 63, "seek": 22488, "start": 232.48, "end": 235.35999999999999, "text": " Databases, historically, have been optimized for reads.", "tokens": [40461, 1957, 11, 16180, 11, 362, 668, 26941, 337, 15700, 13], "temperature": 0.0, "avg_logprob": -0.1699925094354348, "compression_ratio": 1.7672727272727273, "no_speech_prob": 0.0004617736267391592}, {"id": 64, "seek": 22488, "start": 235.35999999999999, "end": 239.0, "text": " They try every trick in the book for making read super fast.", "tokens": [814, 853, 633, 4282, 294, 264, 1446, 337, 1455, 1401, 1687, 2370, 13], "temperature": 0.0, "avg_logprob": -0.1699925094354348, "compression_ratio": 1.7672727272727273, "no_speech_prob": 0.0004617736267391592}, {"id": 65, "seek": 22488, "start": 239.0, "end": 243.72, "text": " When you insert data, you need to define indexes and they are going to index by many different", "tokens": [1133, 291, 8969, 1412, 11, 291, 643, 281, 6964, 8186, 279, 293, 436, 366, 516, 281, 8186, 538, 867, 819], "temperature": 0.0, "avg_logprob": -0.1699925094354348, "compression_ratio": 1.7672727272727273, "no_speech_prob": 0.0004617736267391592}, {"id": 66, "seek": 22488, "start": 243.72, "end": 248.04, "text": " things and they keep caching memory for a lot of things and blah, blah, blah, blah.", "tokens": [721, 293, 436, 1066, 269, 2834, 4675, 337, 257, 688, 295, 721, 293, 12288, 11, 12288, 11, 12288, 11, 12288, 13], "temperature": 0.0, "avg_logprob": -0.1699925094354348, "compression_ratio": 1.7672727272727273, "no_speech_prob": 0.0004617736267391592}, {"id": 67, "seek": 22488, "start": 248.04, "end": 252.84, "text": " So reading is the key thing, because usually you read data much more than you write.", "tokens": [407, 3760, 307, 264, 2141, 551, 11, 570, 2673, 291, 1401, 1412, 709, 544, 813, 291, 2464, 13], "temperature": 0.0, "avg_logprob": -0.1699925094354348, "compression_ratio": 1.7672727272727273, "no_speech_prob": 0.0004617736267391592}, {"id": 68, "seek": 25284, "start": 252.84, "end": 257.56, "text": " But also in time series databases, we can support heavy reads on top of that, but we", "tokens": [583, 611, 294, 565, 2638, 22380, 11, 321, 393, 1406, 4676, 15700, 322, 1192, 295, 300, 11, 457, 321], "temperature": 0.0, "avg_logprob": -0.20503136771065847, "compression_ratio": 1.7970479704797049, "no_speech_prob": 0.0004083857056684792}, {"id": 69, "seek": 25284, "start": 257.56, "end": 261.04, "text": " need to support heavy inserts and keep performance of that.", "tokens": [643, 281, 1406, 4676, 49163, 293, 1066, 3389, 295, 300, 13], "temperature": 0.0, "avg_logprob": -0.20503136771065847, "compression_ratio": 1.7970479704797049, "no_speech_prob": 0.0004083857056684792}, {"id": 70, "seek": 25284, "start": 261.04, "end": 262.76, "text": " We don't use indexes.", "tokens": [492, 500, 380, 764, 8186, 279, 13], "temperature": 0.0, "avg_logprob": -0.20503136771065847, "compression_ratio": 1.7970479704797049, "no_speech_prob": 0.0004083857056684792}, {"id": 71, "seek": 25284, "start": 262.76, "end": 265.08, "text": " The performance you're going to see today is with no indexes.", "tokens": [440, 3389, 291, 434, 516, 281, 536, 965, 307, 365, 572, 8186, 279, 13], "temperature": 0.0, "avg_logprob": -0.20503136771065847, "compression_ratio": 1.7970479704797049, "no_speech_prob": 0.0004083857056684792}, {"id": 72, "seek": 25284, "start": 265.08, "end": 266.08, "text": " We don't need them.", "tokens": [492, 500, 380, 643, 552, 13], "temperature": 0.0, "avg_logprob": -0.20503136771065847, "compression_ratio": 1.7970479704797049, "no_speech_prob": 0.0004083857056684792}, {"id": 73, "seek": 25284, "start": 266.08, "end": 270.48, "text": " We don't want them, because having an index slowed down in gestion.", "tokens": [492, 500, 380, 528, 552, 11, 570, 1419, 364, 8186, 32057, 760, 294, 7219, 313, 13], "temperature": 0.0, "avg_logprob": -0.20503136771065847, "compression_ratio": 1.7970479704797049, "no_speech_prob": 0.0004083857056684792}, {"id": 74, "seek": 25284, "start": 270.48, "end": 272.2, "text": " It's a luxury we cannot have.", "tokens": [467, 311, 257, 15558, 321, 2644, 362, 13], "temperature": 0.0, "avg_logprob": -0.20503136771065847, "compression_ratio": 1.7970479704797049, "no_speech_prob": 0.0004083857056684792}, {"id": 75, "seek": 25284, "start": 272.2, "end": 276.12, "text": " So we have some kind of indexing, but we don't have indexes, not as you know them.", "tokens": [407, 321, 362, 512, 733, 295, 8186, 278, 11, 457, 321, 500, 380, 362, 8186, 279, 11, 406, 382, 291, 458, 552, 13], "temperature": 0.0, "avg_logprob": -0.20503136771065847, "compression_ratio": 1.7970479704797049, "no_speech_prob": 0.0004083857056684792}, {"id": 76, "seek": 25284, "start": 276.12, "end": 277.68, "text": " That's kind of the idea here.", "tokens": [663, 311, 733, 295, 264, 1558, 510, 13], "temperature": 0.0, "avg_logprob": -0.20503136771065847, "compression_ratio": 1.7970479704797049, "no_speech_prob": 0.0004083857056684792}, {"id": 77, "seek": 25284, "start": 277.68, "end": 279.16, "text": " So it's slightly different.", "tokens": [407, 309, 311, 4748, 819, 13], "temperature": 0.0, "avg_logprob": -0.20503136771065847, "compression_ratio": 1.7970479704797049, "no_speech_prob": 0.0004083857056684792}, {"id": 78, "seek": 27916, "start": 279.16, "end": 285.84000000000003, "text": " You have data that you are writing very often, that data is going to grow, and it can grow", "tokens": [509, 362, 1412, 300, 291, 366, 3579, 588, 2049, 11, 300, 1412, 307, 516, 281, 1852, 11, 293, 309, 393, 1852], "temperature": 0.0, "avg_logprob": -0.2005841748467807, "compression_ratio": 1.859375, "no_speech_prob": 0.00022844252816867083}, {"id": 79, "seek": 27916, "start": 285.84000000000003, "end": 286.84000000000003, "text": " fast.", "tokens": [2370, 13], "temperature": 0.0, "avg_logprob": -0.2005841748467807, "compression_ratio": 1.859375, "no_speech_prob": 0.00022844252816867083}, {"id": 80, "seek": 27916, "start": 286.84000000000003, "end": 290.92, "text": " And you need to have some way of loading or deleting that data.", "tokens": [400, 291, 643, 281, 362, 512, 636, 295, 15114, 420, 48946, 300, 1412, 13], "temperature": 0.0, "avg_logprob": -0.2005841748467807, "compression_ratio": 1.859375, "no_speech_prob": 0.00022844252816867083}, {"id": 81, "seek": 27916, "start": 290.92, "end": 295.96000000000004, "text": " On a traditional database, you just don't say, oh, I have, I don't know, I'm Amazon", "tokens": [1282, 257, 5164, 8149, 11, 291, 445, 500, 380, 584, 11, 1954, 11, 286, 362, 11, 286, 500, 380, 458, 11, 286, 478, 6795], "temperature": 0.0, "avg_logprob": -0.2005841748467807, "compression_ratio": 1.859375, "no_speech_prob": 0.00022844252816867083}, {"id": 82, "seek": 27916, "start": 295.96000000000004, "end": 297.44000000000005, "text": " and I'm getting users.", "tokens": [293, 286, 478, 1242, 5022, 13], "temperature": 0.0, "avg_logprob": -0.2005841748467807, "compression_ratio": 1.859375, "no_speech_prob": 0.00022844252816867083}, {"id": 83, "seek": 27916, "start": 297.44000000000005, "end": 301.48, "text": " It's like, oh, I already have a million users, a million one, I'm going to delete the old", "tokens": [467, 311, 411, 11, 1954, 11, 286, 1217, 362, 257, 2459, 5022, 11, 257, 2459, 472, 11, 286, 478, 516, 281, 12097, 264, 1331], "temperature": 0.0, "avg_logprob": -0.2005841748467807, "compression_ratio": 1.859375, "no_speech_prob": 0.00022844252816867083}, {"id": 84, "seek": 27916, "start": 301.48, "end": 302.48, "text": " users.", "tokens": [5022, 13], "temperature": 0.0, "avg_logprob": -0.2005841748467807, "compression_ratio": 1.859375, "no_speech_prob": 0.00022844252816867083}, {"id": 85, "seek": 27916, "start": 302.48, "end": 303.48, "text": " You don't do that.", "tokens": [509, 500, 380, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.2005841748467807, "compression_ratio": 1.859375, "no_speech_prob": 0.00022844252816867083}, {"id": 86, "seek": 27916, "start": 303.48, "end": 304.48, "text": " I mean, sometimes you do, but you don't do that.", "tokens": [286, 914, 11, 2171, 291, 360, 11, 457, 291, 500, 380, 360, 300, 13], "temperature": 0.0, "avg_logprob": -0.2005841748467807, "compression_ratio": 1.859375, "no_speech_prob": 0.00022844252816867083}, {"id": 87, "seek": 27916, "start": 304.48, "end": 306.88, "text": " You don't really do that on your databases.", "tokens": [509, 500, 380, 534, 360, 300, 322, 428, 22380, 13], "temperature": 0.0, "avg_logprob": -0.2005841748467807, "compression_ratio": 1.859375, "no_speech_prob": 0.00022844252816867083}, {"id": 88, "seek": 30688, "start": 306.88, "end": 312.0, "text": " On time series database, almost all of them have some mechanism to deal with historical", "tokens": [1282, 565, 2638, 8149, 11, 1920, 439, 295, 552, 362, 512, 7513, 281, 2028, 365, 8584], "temperature": 0.0, "avg_logprob": -0.21558257937431335, "compression_ratio": 1.8401486988847584, "no_speech_prob": 0.000714522204361856}, {"id": 89, "seek": 30688, "start": 312.0, "end": 314.24, "text": " data and do something with that.", "tokens": [1412, 293, 360, 746, 365, 300, 13], "temperature": 0.0, "avg_logprob": -0.21558257937431335, "compression_ratio": 1.8401486988847584, "no_speech_prob": 0.000714522204361856}, {"id": 90, "seek": 30688, "start": 314.24, "end": 317.92, "text": " In our case, you can amount partitions, you can amount to cheaper storage, those kind", "tokens": [682, 527, 1389, 11, 291, 393, 2372, 644, 2451, 11, 291, 393, 2372, 281, 12284, 6725, 11, 729, 733], "temperature": 0.0, "avg_logprob": -0.21558257937431335, "compression_ratio": 1.8401486988847584, "no_speech_prob": 0.000714522204361856}, {"id": 91, "seek": 30688, "start": 317.92, "end": 318.92, "text": " of things.", "tokens": [295, 721, 13], "temperature": 0.0, "avg_logprob": -0.21558257937431335, "compression_ratio": 1.8401486988847584, "no_speech_prob": 0.000714522204361856}, {"id": 92, "seek": 30688, "start": 318.92, "end": 322.8, "text": " But we have the commands and it is designed for that kind of thing.", "tokens": [583, 321, 362, 264, 16901, 293, 309, 307, 4761, 337, 300, 733, 295, 551, 13], "temperature": 0.0, "avg_logprob": -0.21558257937431335, "compression_ratio": 1.8401486988847584, "no_speech_prob": 0.000714522204361856}, {"id": 93, "seek": 30688, "start": 322.8, "end": 323.8, "text": " That kind of the idea.", "tokens": [663, 733, 295, 264, 1558, 13], "temperature": 0.0, "avg_logprob": -0.21558257937431335, "compression_ratio": 1.8401486988847584, "no_speech_prob": 0.000714522204361856}, {"id": 94, "seek": 30688, "start": 323.8, "end": 328.64, "text": " Many other things about how you have a time series storyline, but that kind of the idea.", "tokens": [5126, 661, 721, 466, 577, 291, 362, 257, 565, 2638, 30828, 11, 457, 300, 733, 295, 264, 1558, 13], "temperature": 0.0, "avg_logprob": -0.21558257937431335, "compression_ratio": 1.8401486988847584, "no_speech_prob": 0.000714522204361856}, {"id": 95, "seek": 30688, "start": 328.64, "end": 333.52, "text": " But better than me just telling you, I'm going to show you some queries on top of demo", "tokens": [583, 1101, 813, 385, 445, 3585, 291, 11, 286, 478, 516, 281, 855, 291, 512, 24109, 322, 1192, 295, 10723], "temperature": 0.0, "avg_logprob": -0.21558257937431335, "compression_ratio": 1.8401486988847584, "no_speech_prob": 0.000714522204361856}, {"id": 96, "seek": 30688, "start": 333.52, "end": 334.52, "text": " data sets.", "tokens": [1412, 6352, 13], "temperature": 0.0, "avg_logprob": -0.21558257937431335, "compression_ratio": 1.8401486988847584, "no_speech_prob": 0.000714522204361856}, {"id": 97, "seek": 33452, "start": 334.52, "end": 338.56, "text": " I'm going to get the feeling why a time series database might be interesting and then we're", "tokens": [286, 478, 516, 281, 483, 264, 2633, 983, 257, 565, 2638, 8149, 1062, 312, 1880, 293, 550, 321, 434], "temperature": 0.0, "avg_logprob": -0.32294498790394177, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.0008543793810531497}, {"id": 98, "seek": 33452, "start": 338.56, "end": 342.12, "text": " going to details about the ingesting data and about all those things.", "tokens": [516, 281, 4365, 466, 264, 3957, 8714, 1412, 293, 466, 439, 729, 721, 13], "temperature": 0.0, "avg_logprob": -0.32294498790394177, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.0008543793810531497}, {"id": 99, "seek": 33452, "start": 342.12, "end": 343.79999999999995, "text": " That's in sound good so far, yeah?", "tokens": [663, 311, 294, 1626, 665, 370, 1400, 11, 1338, 30], "temperature": 0.0, "avg_logprob": -0.32294498790394177, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.0008543793810531497}, {"id": 100, "seek": 33452, "start": 343.79999999999995, "end": 344.79999999999995, "text": " Do you have any questions?", "tokens": [1144, 291, 362, 604, 1651, 30], "temperature": 0.0, "avg_logprob": -0.32294498790394177, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.0008543793810531497}, {"id": 101, "seek": 33452, "start": 344.79999999999995, "end": 349.24, "text": " I'm happy to take them during the talk, by the way, not only at the end.", "tokens": [286, 478, 2055, 281, 747, 552, 1830, 264, 751, 11, 538, 264, 636, 11, 406, 787, 412, 264, 917, 13], "temperature": 0.0, "avg_logprob": -0.32294498790394177, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.0008543793810531497}, {"id": 102, "seek": 33452, "start": 349.24, "end": 359.79999999999995, "text": " So we have a live demo, demo.questdbe.io, which is running on a large machine on AWS.", "tokens": [407, 321, 362, 257, 1621, 10723, 11, 10723, 13, 20343, 67, 650, 13, 1004, 11, 597, 307, 2614, 322, 257, 2416, 3479, 322, 17650, 13], "temperature": 0.0, "avg_logprob": -0.32294498790394177, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.0008543793810531497}, {"id": 103, "seek": 33452, "start": 359.79999999999995, "end": 363.24, "text": " We don't need all the power, but since it's like, you know, open to the public.", "tokens": [492, 500, 380, 643, 439, 264, 1347, 11, 457, 1670, 309, 311, 411, 11, 291, 458, 11, 1269, 281, 264, 1908, 13], "temperature": 0.0, "avg_logprob": -0.32294498790394177, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.0008543793810531497}, {"id": 104, "seek": 36324, "start": 363.24, "end": 366.84000000000003, "text": " Again, we have a few different data sets.", "tokens": [3764, 11, 321, 362, 257, 1326, 819, 1412, 6352, 13], "temperature": 0.0, "avg_logprob": -0.23431427138192312, "compression_ratio": 1.7641921397379912, "no_speech_prob": 0.0002518424589652568}, {"id": 105, "seek": 36324, "start": 366.84000000000003, "end": 367.84000000000003, "text": " There is one.", "tokens": [821, 307, 472, 13], "temperature": 0.0, "avg_logprob": -0.23431427138192312, "compression_ratio": 1.7641921397379912, "no_speech_prob": 0.0002518424589652568}, {"id": 106, "seek": 36324, "start": 367.84000000000003, "end": 373.32, "text": " You are in a big data room, so you are truly familiar with the taxi rise, New York City", "tokens": [509, 366, 294, 257, 955, 1412, 1808, 11, 370, 291, 366, 4908, 4963, 365, 264, 18984, 6272, 11, 1873, 3609, 4392], "temperature": 0.0, "avg_logprob": -0.23431427138192312, "compression_ratio": 1.7641921397379912, "no_speech_prob": 0.0002518424589652568}, {"id": 107, "seek": 36324, "start": 373.32, "end": 374.88, "text": " taxi rise data set.", "tokens": [18984, 6272, 1412, 992, 13], "temperature": 0.0, "avg_logprob": -0.23431427138192312, "compression_ratio": 1.7641921397379912, "no_speech_prob": 0.0002518424589652568}, {"id": 108, "seek": 36324, "start": 374.88, "end": 379.12, "text": " It's the, and the city of New York has a data set, which is very cool for machine learning", "tokens": [467, 311, 264, 11, 293, 264, 2307, 295, 1873, 3609, 575, 257, 1412, 992, 11, 597, 307, 588, 1627, 337, 3479, 2539], "temperature": 0.0, "avg_logprob": -0.23431427138192312, "compression_ratio": 1.7641921397379912, "no_speech_prob": 0.0002518424589652568}, {"id": 109, "seek": 36324, "start": 379.12, "end": 384.64, "text": " and for big data, which is taxi rides in the city of New York.", "tokens": [293, 337, 955, 1412, 11, 597, 307, 18984, 20773, 294, 264, 2307, 295, 1873, 3609, 13], "temperature": 0.0, "avg_logprob": -0.23431427138192312, "compression_ratio": 1.7641921397379912, "no_speech_prob": 0.0002518424589652568}, {"id": 110, "seek": 36324, "start": 384.64, "end": 390.44, "text": " When the ride started, when it finished, also the coordinate and a few things like the", "tokens": [1133, 264, 5077, 1409, 11, 562, 309, 4335, 11, 611, 264, 15670, 293, 257, 1326, 721, 411, 264], "temperature": 0.0, "avg_logprob": -0.23431427138192312, "compression_ratio": 1.7641921397379912, "no_speech_prob": 0.0002518424589652568}, {"id": 111, "seek": 39044, "start": 390.44, "end": 393.92, "text": " tip and the amount of the fare, how many people, blah, blah, blah.", "tokens": [4125, 293, 264, 2372, 295, 264, 11994, 11, 577, 867, 561, 11, 12288, 11, 12288, 11, 12288, 13], "temperature": 0.0, "avg_logprob": -0.18708749854046366, "compression_ratio": 1.65, "no_speech_prob": 0.00013058418699074537}, {"id": 112, "seek": 39044, "start": 393.92, "end": 399.84, "text": " So we took that open data set and we just put it here on questdbe, a few years of the", "tokens": [407, 321, 1890, 300, 1269, 1412, 992, 293, 321, 445, 829, 309, 510, 322, 866, 67, 650, 11, 257, 1326, 924, 295, 264], "temperature": 0.0, "avg_logprob": -0.18708749854046366, "compression_ratio": 1.65, "no_speech_prob": 0.00013058418699074537}, {"id": 113, "seek": 39044, "start": 399.84, "end": 400.84, "text": " data set.", "tokens": [1412, 992, 13], "temperature": 0.0, "avg_logprob": -0.18708749854046366, "compression_ratio": 1.65, "no_speech_prob": 0.00013058418699074537}, {"id": 114, "seek": 39044, "start": 400.84, "end": 403.28, "text": " Yes, you know, a lot of columns here.", "tokens": [1079, 11, 291, 458, 11, 257, 688, 295, 13766, 510, 13], "temperature": 0.0, "avg_logprob": -0.18708749854046366, "compression_ratio": 1.65, "no_speech_prob": 0.00013058418699074537}, {"id": 115, "seek": 39044, "start": 403.28, "end": 407.2, "text": " So let me just show you how big this is.", "tokens": [407, 718, 385, 445, 855, 291, 577, 955, 341, 307, 13], "temperature": 0.0, "avg_logprob": -0.18708749854046366, "compression_ratio": 1.65, "no_speech_prob": 0.00013058418699074537}, {"id": 116, "seek": 39044, "start": 407.2, "end": 413.04, "text": " This is, right now, is the size okay or maybe not?", "tokens": [639, 307, 11, 558, 586, 11, 307, 264, 2744, 1392, 420, 1310, 406, 30], "temperature": 0.0, "avg_logprob": -0.18708749854046366, "compression_ratio": 1.65, "no_speech_prob": 0.00013058418699074537}, {"id": 117, "seek": 39044, "start": 413.04, "end": 418.2, "text": " Maybe I have to make it a bit, first this a bit bigger and then, okay.", "tokens": [2704, 286, 362, 281, 652, 309, 257, 857, 11, 700, 341, 257, 857, 3801, 293, 550, 11, 1392, 13], "temperature": 0.0, "avg_logprob": -0.18708749854046366, "compression_ratio": 1.65, "no_speech_prob": 0.00013058418699074537}, {"id": 118, "seek": 41820, "start": 418.2, "end": 420.88, "text": " So it's 1.6 billion rows, which is not huge.", "tokens": [407, 309, 311, 502, 13, 21, 5218, 13241, 11, 597, 307, 406, 2603, 13], "temperature": 0.0, "avg_logprob": -0.2172625969196188, "compression_ratio": 1.7289719626168225, "no_speech_prob": 0.0004038431798107922}, {"id": 119, "seek": 41820, "start": 420.88, "end": 428.32, "text": " I mean, if you have a relational database, 1.6 billion rows, they don't, relational", "tokens": [286, 914, 11, 498, 291, 362, 257, 38444, 8149, 11, 502, 13, 21, 5218, 13241, 11, 436, 500, 380, 11, 38444], "temperature": 0.0, "avg_logprob": -0.2172625969196188, "compression_ratio": 1.7289719626168225, "no_speech_prob": 0.0004038431798107922}, {"id": 120, "seek": 41820, "start": 428.32, "end": 430.71999999999997, "text": " databases today, they are great.", "tokens": [22380, 965, 11, 436, 366, 869, 13], "temperature": 0.0, "avg_logprob": -0.2172625969196188, "compression_ratio": 1.7289719626168225, "no_speech_prob": 0.0004038431798107922}, {"id": 121, "seek": 41820, "start": 430.71999999999997, "end": 437.08, "text": " But 1.6 billion rows is like, yeah, I couldn't work with that, I'm not super comfortable.", "tokens": [583, 502, 13, 21, 5218, 13241, 307, 411, 11, 1338, 11, 286, 2809, 380, 589, 365, 300, 11, 286, 478, 406, 1687, 4619, 13], "temperature": 0.0, "avg_logprob": -0.2172625969196188, "compression_ratio": 1.7289719626168225, "no_speech_prob": 0.0004038431798107922}, {"id": 122, "seek": 41820, "start": 437.08, "end": 438.08, "text": " For us, it's cute.", "tokens": [1171, 505, 11, 309, 311, 4052, 13], "temperature": 0.0, "avg_logprob": -0.2172625969196188, "compression_ratio": 1.7289719626168225, "no_speech_prob": 0.0004038431798107922}, {"id": 123, "seek": 41820, "start": 438.08, "end": 444.76, "text": " It's like, I mean, it's a data set which is respectable but not really huge, but 1.60", "tokens": [467, 311, 411, 11, 286, 914, 11, 309, 311, 257, 1412, 992, 597, 307, 44279, 457, 406, 534, 2603, 11, 457, 502, 13, 4550], "temperature": 0.0, "avg_logprob": -0.2172625969196188, "compression_ratio": 1.7289719626168225, "no_speech_prob": 0.0004038431798107922}, {"id": 124, "seek": 41820, "start": 444.76, "end": 446.15999999999997, "text": " billion rows.", "tokens": [5218, 13241, 13], "temperature": 0.0, "avg_logprob": -0.2172625969196188, "compression_ratio": 1.7289719626168225, "no_speech_prob": 0.0004038431798107922}, {"id": 125, "seek": 44616, "start": 446.16, "end": 450.48, "text": " And now, what if I want to do something like, for example, I don't know, I want to calculate", "tokens": [400, 586, 11, 437, 498, 286, 528, 281, 360, 746, 411, 11, 337, 1365, 11, 286, 500, 380, 458, 11, 286, 528, 281, 8873], "temperature": 0.0, "avg_logprob": -0.20049753691020764, "compression_ratio": 1.6926829268292682, "no_speech_prob": 0.00018360966350883245}, {"id": 126, "seek": 44616, "start": 450.48, "end": 459.68, "text": " the average of whichever, this for example, this number, I want to average the fair amount", "tokens": [264, 4274, 295, 24123, 11, 341, 337, 1365, 11, 341, 1230, 11, 286, 528, 281, 4274, 264, 3143, 2372], "temperature": 0.0, "avg_logprob": -0.20049753691020764, "compression_ratio": 1.6926829268292682, "no_speech_prob": 0.00018360966350883245}, {"id": 127, "seek": 44616, "start": 459.68, "end": 462.8, "text": " over 1.6 billion trips.", "tokens": [670, 502, 13, 21, 5218, 16051, 13], "temperature": 0.0, "avg_logprob": -0.20049753691020764, "compression_ratio": 1.6926829268292682, "no_speech_prob": 0.00018360966350883245}, {"id": 128, "seek": 44616, "start": 462.8, "end": 469.16, "text": " How long you will expect your database to take to go do a full scan over 1.6 billion", "tokens": [1012, 938, 291, 486, 2066, 428, 8149, 281, 747, 281, 352, 360, 257, 1577, 11049, 670, 502, 13, 21, 5218], "temperature": 0.0, "avg_logprob": -0.20049753691020764, "compression_ratio": 1.6926829268292682, "no_speech_prob": 0.00018360966350883245}, {"id": 129, "seek": 44616, "start": 469.16, "end": 473.68, "text": " rows and compute the average, no indexes, no anything.", "tokens": [13241, 293, 14722, 264, 4274, 11, 572, 8186, 279, 11, 572, 1340, 13], "temperature": 0.0, "avg_logprob": -0.20049753691020764, "compression_ratio": 1.6926829268292682, "no_speech_prob": 0.00018360966350883245}, {"id": 130, "seek": 47368, "start": 473.68, "end": 479.8, "text": " How long would you say, more or less, ballpark, 1.6 billion rows, no one?", "tokens": [1012, 938, 576, 291, 584, 11, 544, 420, 1570, 11, 2594, 31239, 11, 502, 13, 21, 5218, 13241, 11, 572, 472, 30], "temperature": 0.0, "avg_logprob": -0.3040389682935632, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.00020654479158110917}, {"id": 131, "seek": 47368, "start": 479.8, "end": 484.08, "text": " How is the size in gigabytes, megabytes?", "tokens": [1012, 307, 264, 2744, 294, 42741, 11, 10816, 24538, 30], "temperature": 0.0, "avg_logprob": -0.3040389682935632, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.00020654479158110917}, {"id": 132, "seek": 47368, "start": 484.08, "end": 489.40000000000003, "text": " I don't know for the whole data set, but this is a double, I mean, I really just know, it's", "tokens": [286, 500, 380, 458, 337, 264, 1379, 1412, 992, 11, 457, 341, 307, 257, 3834, 11, 286, 914, 11, 286, 534, 445, 458, 11, 309, 311], "temperature": 0.0, "avg_logprob": -0.3040389682935632, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.00020654479158110917}, {"id": 133, "seek": 47368, "start": 489.40000000000003, "end": 490.4, "text": " big, it's big.", "tokens": [955, 11, 309, 311, 955, 13], "temperature": 0.0, "avg_logprob": -0.3040389682935632, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.00020654479158110917}, {"id": 134, "seek": 47368, "start": 490.4, "end": 497.0, "text": " When you download the CSV, it's CSV, it's about 600 megabytes and you have several of those.", "tokens": [1133, 291, 5484, 264, 48814, 11, 309, 311, 48814, 11, 309, 311, 466, 11849, 10816, 24538, 293, 291, 362, 2940, 295, 729, 13], "temperature": 0.0, "avg_logprob": -0.3040389682935632, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.00020654479158110917}, {"id": 135, "seek": 47368, "start": 497.0, "end": 500.72, "text": " It's in the, you know, it's largesse.", "tokens": [467, 311, 294, 264, 11, 291, 458, 11, 309, 311, 1613, 2880, 405, 13], "temperature": 0.0, "avg_logprob": -0.3040389682935632, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.00020654479158110917}, {"id": 136, "seek": 50072, "start": 500.72, "end": 506.72, "text": " But anyway, well, actually it was slower than I thought.", "tokens": [583, 4033, 11, 731, 11, 767, 309, 390, 14009, 813, 286, 1194, 13], "temperature": 0.0, "avg_logprob": -0.2485150863875204, "compression_ratio": 1.7251908396946565, "no_speech_prob": 0.000477110588690266}, {"id": 137, "seek": 50072, "start": 506.72, "end": 512.08, "text": " It took, usually it takes half a second, this time it took 0.6 seconds.", "tokens": [467, 1890, 11, 2673, 309, 2516, 1922, 257, 1150, 11, 341, 565, 309, 1890, 1958, 13, 21, 3949, 13], "temperature": 0.0, "avg_logprob": -0.2485150863875204, "compression_ratio": 1.7251908396946565, "no_speech_prob": 0.000477110588690266}, {"id": 138, "seek": 50072, "start": 512.08, "end": 516.5600000000001, "text": " I know it's slow, I know, but it's with a reason, sort of that.", "tokens": [286, 458, 309, 311, 2964, 11, 286, 458, 11, 457, 309, 311, 365, 257, 1778, 11, 1333, 295, 300, 13], "temperature": 0.0, "avg_logprob": -0.2485150863875204, "compression_ratio": 1.7251908396946565, "no_speech_prob": 0.000477110588690266}, {"id": 139, "seek": 50072, "start": 516.5600000000001, "end": 520.1600000000001, "text": " But I told you, I told you, we are trying to see this database, we are super slow for", "tokens": [583, 286, 1907, 291, 11, 286, 1907, 291, 11, 321, 366, 1382, 281, 536, 341, 8149, 11, 321, 366, 1687, 2964, 337], "temperature": 0.0, "avg_logprob": -0.2485150863875204, "compression_ratio": 1.7251908396946565, "no_speech_prob": 0.000477110588690266}, {"id": 140, "seek": 50072, "start": 520.1600000000001, "end": 521.1600000000001, "text": " other things.", "tokens": [661, 721, 13], "temperature": 0.0, "avg_logprob": -0.2485150863875204, "compression_ratio": 1.7251908396946565, "no_speech_prob": 0.000477110588690266}, {"id": 141, "seek": 50072, "start": 521.1600000000001, "end": 525.52, "text": " This is not a time series query, did you see any timestamp here, I didn't see anything.", "tokens": [639, 307, 406, 257, 565, 2638, 14581, 11, 630, 291, 536, 604, 49108, 1215, 510, 11, 286, 994, 380, 536, 1340, 13], "temperature": 0.0, "avg_logprob": -0.2485150863875204, "compression_ratio": 1.7251908396946565, "no_speech_prob": 0.000477110588690266}, {"id": 142, "seek": 50072, "start": 525.52, "end": 530.52, "text": " This is just a full scan, we parallelize, we read data and we are slow.", "tokens": [639, 307, 445, 257, 1577, 11049, 11, 321, 8952, 1125, 11, 321, 1401, 1412, 293, 321, 366, 2964, 13], "temperature": 0.0, "avg_logprob": -0.2485150863875204, "compression_ratio": 1.7251908396946565, "no_speech_prob": 0.000477110588690266}, {"id": 143, "seek": 53052, "start": 530.52, "end": 536.3199999999999, "text": " We take almost over half a second to go over only 1.6 billion rows, unforgivable, sort", "tokens": [492, 747, 1920, 670, 1922, 257, 1150, 281, 352, 670, 787, 502, 13, 21, 5218, 13241, 11, 31411, 70, 34376, 11, 1333], "temperature": 0.0, "avg_logprob": -0.23871521810883456, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.0002916109806392342}, {"id": 144, "seek": 53052, "start": 536.3199999999999, "end": 537.3199999999999, "text": " of that.", "tokens": [295, 300, 13], "temperature": 0.0, "avg_logprob": -0.23871521810883456, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.0002916109806392342}, {"id": 145, "seek": 53052, "start": 537.3199999999999, "end": 543.16, "text": " But there with me here, no, that's the thing, I mean, I'm kind of half kidding but not really.", "tokens": [583, 456, 365, 385, 510, 11, 572, 11, 300, 311, 264, 551, 11, 286, 914, 11, 286, 478, 733, 295, 1922, 9287, 457, 406, 534, 13], "temperature": 0.0, "avg_logprob": -0.23871521810883456, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.0002916109806392342}, {"id": 146, "seek": 53052, "start": 543.16, "end": 553.68, "text": " But wait until I put a time dimension, now yes, I want only, for example, I want only", "tokens": [583, 1699, 1826, 286, 829, 257, 565, 10139, 11, 586, 2086, 11, 286, 528, 787, 11, 337, 1365, 11, 286, 528, 787], "temperature": 0.0, "avg_logprob": -0.23871521810883456, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.0002916109806392342}, {"id": 147, "seek": 53052, "start": 553.68, "end": 559.24, "text": " one year of data and I'm going to just also add another computation because I know that", "tokens": [472, 1064, 295, 1412, 293, 286, 478, 516, 281, 445, 611, 909, 1071, 24903, 570, 286, 458, 300], "temperature": 0.0, "avg_logprob": -0.23871521810883456, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.0002916109806392342}, {"id": 148, "seek": 55924, "start": 559.24, "end": 563.08, "text": " it's just counting data which is super fast.", "tokens": [309, 311, 445, 13251, 1412, 597, 307, 1687, 2370, 13], "temperature": 0.0, "avg_logprob": -0.2366866061561986, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0004137994546908885}, {"id": 149, "seek": 55924, "start": 563.08, "end": 567.0, "text": " So I'm going to add another computation, so I'm going to count the data and only for", "tokens": [407, 286, 478, 516, 281, 909, 1071, 24903, 11, 370, 286, 478, 516, 281, 1207, 264, 1412, 293, 787, 337], "temperature": 0.0, "avg_logprob": -0.2366866061561986, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0004137994546908885}, {"id": 150, "seek": 55924, "start": 567.0, "end": 574.84, "text": " 2016 and this is better, this is already 100 milliseconds because we are going only", "tokens": [6549, 293, 341, 307, 1101, 11, 341, 307, 1217, 2319, 34184, 570, 321, 366, 516, 787], "temperature": 0.0, "avg_logprob": -0.2366866061561986, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0004137994546908885}, {"id": 151, "seek": 55924, "start": 574.84, "end": 584.2, "text": " over a few rows, we are going only about, yeah, it's only 146 million rows, this is", "tokens": [670, 257, 1326, 13241, 11, 321, 366, 516, 787, 466, 11, 1338, 11, 309, 311, 787, 3499, 21, 2459, 13241, 11, 341, 307], "temperature": 0.0, "avg_logprob": -0.2366866061561986, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0004137994546908885}, {"id": 152, "seek": 55924, "start": 584.2, "end": 588.32, "text": " much more manageable, so only 140 million rows, that's better.", "tokens": [709, 544, 38798, 11, 370, 787, 21548, 2459, 13241, 11, 300, 311, 1101, 13], "temperature": 0.0, "avg_logprob": -0.2366866061561986, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0004137994546908885}, {"id": 153, "seek": 58832, "start": 588.32, "end": 593.96, "text": " So we can go actually very fast on this and then if you keep going down, oh no, I want", "tokens": [407, 321, 393, 352, 767, 588, 2370, 322, 341, 293, 550, 498, 291, 1066, 516, 760, 11, 1954, 572, 11, 286, 528], "temperature": 0.0, "avg_logprob": -0.15386208735014262, "compression_ratio": 1.5142857142857142, "no_speech_prob": 0.00025675646611489356}, {"id": 154, "seek": 58832, "start": 593.96, "end": 604.1600000000001, "text": " only one month of data which is, I don't know, still, yeah, 12 million rows, so a month", "tokens": [787, 472, 1618, 295, 1412, 597, 307, 11, 286, 500, 380, 458, 11, 920, 11, 1338, 11, 2272, 2459, 13241, 11, 370, 257, 1618], "temperature": 0.0, "avg_logprob": -0.15386208735014262, "compression_ratio": 1.5142857142857142, "no_speech_prob": 0.00025675646611489356}, {"id": 155, "seek": 58832, "start": 604.1600000000001, "end": 610.6800000000001, "text": " of data is 60 milliseconds, for one day of data, of course, is way faster, this is already", "tokens": [295, 1412, 307, 4060, 34184, 11, 337, 472, 786, 295, 1412, 11, 295, 1164, 11, 307, 636, 4663, 11, 341, 307, 1217], "temperature": 0.0, "avg_logprob": -0.15386208735014262, "compression_ratio": 1.5142857142857142, "no_speech_prob": 0.00025675646611489356}, {"id": 156, "seek": 61068, "start": 610.68, "end": 618.3599999999999, "text": " 50 milliseconds, if I go to one specific hour, a minute, it should be, you know, kind of,", "tokens": [2625, 34184, 11, 498, 286, 352, 281, 472, 2685, 1773, 11, 257, 3456, 11, 309, 820, 312, 11, 291, 458, 11, 733, 295, 11], "temperature": 0.0, "avg_logprob": -0.2402131800748864, "compression_ratio": 1.7033492822966507, "no_speech_prob": 0.00024413084611296654}, {"id": 157, "seek": 61068, "start": 618.3599999999999, "end": 627.56, "text": " not much faster because, oh yeah, it's under one millisecond actually, thank you for that,", "tokens": [406, 709, 4663, 570, 11, 1954, 1338, 11, 309, 311, 833, 472, 27940, 18882, 767, 11, 1309, 291, 337, 300, 11], "temperature": 0.0, "avg_logprob": -0.2402131800748864, "compression_ratio": 1.7033492822966507, "no_speech_prob": 0.00024413084611296654}, {"id": 158, "seek": 61068, "start": 627.56, "end": 634.28, "text": " but still, like, you know, we have partitions, so basically one thing we do, we only go to", "tokens": [457, 920, 11, 411, 11, 291, 458, 11, 321, 362, 644, 2451, 11, 370, 1936, 472, 551, 321, 360, 11, 321, 787, 352, 281], "temperature": 0.0, "avg_logprob": -0.2402131800748864, "compression_ratio": 1.7033492822966507, "no_speech_prob": 0.00024413084611296654}, {"id": 159, "seek": 61068, "start": 634.28, "end": 638.24, "text": " the partition where the data is stored, so we only attack that part of the data, but", "tokens": [264, 24808, 689, 264, 1412, 307, 12187, 11, 370, 321, 787, 2690, 300, 644, 295, 264, 1412, 11, 457], "temperature": 0.0, "avg_logprob": -0.2402131800748864, "compression_ratio": 1.7033492822966507, "no_speech_prob": 0.00024413084611296654}, {"id": 160, "seek": 63824, "start": 638.24, "end": 641.96, "text": " that's kind of the thing, for when you have like that time component, we are quite fast,", "tokens": [300, 311, 733, 295, 264, 551, 11, 337, 562, 291, 362, 411, 300, 565, 6542, 11, 321, 366, 1596, 2370, 11], "temperature": 0.0, "avg_logprob": -0.22081948943057303, "compression_ratio": 1.7804878048780488, "no_speech_prob": 0.0004441179917193949}, {"id": 161, "seek": 63824, "start": 641.96, "end": 646.88, "text": " oh, fairly fast, that's kind of the beauty for a time-serious database, and we can do", "tokens": [1954, 11, 6457, 2370, 11, 300, 311, 733, 295, 264, 6643, 337, 257, 565, 12, 12484, 851, 8149, 11, 293, 321, 393, 360], "temperature": 0.0, "avg_logprob": -0.22081948943057303, "compression_ratio": 1.7804878048780488, "no_speech_prob": 0.0004441179917193949}, {"id": 162, "seek": 63824, "start": 646.88, "end": 653.92, "text": " also interesting, other interesting things, if I go to the same table and I show you what", "tokens": [611, 1880, 11, 661, 1880, 721, 11, 498, 286, 352, 281, 264, 912, 3199, 293, 286, 855, 291, 437], "temperature": 0.0, "avg_logprob": -0.22081948943057303, "compression_ratio": 1.7804878048780488, "no_speech_prob": 0.0004441179917193949}, {"id": 163, "seek": 63824, "start": 653.92, "end": 659.76, "text": " this looks like, you can see that for the same second, I have many trips because this", "tokens": [341, 1542, 411, 11, 291, 393, 536, 300, 337, 264, 912, 1150, 11, 286, 362, 867, 16051, 570, 341], "temperature": 0.0, "avg_logprob": -0.22081948943057303, "compression_ratio": 1.7804878048780488, "no_speech_prob": 0.0004441179917193949}, {"id": 164, "seek": 63824, "start": 659.76, "end": 664.96, "text": " is New York, baby, and in New York, you know, the city that never sleeps, you can't get", "tokens": [307, 1873, 3609, 11, 3186, 11, 293, 294, 1873, 3609, 11, 291, 458, 11, 264, 2307, 300, 1128, 37991, 11, 291, 393, 380, 483], "temperature": 0.0, "avg_logprob": -0.22081948943057303, "compression_ratio": 1.7804878048780488, "no_speech_prob": 0.0004441179917193949}, {"id": 165, "seek": 66496, "start": 664.96, "end": 670.08, "text": " back in every corner, you get rich when you land in New York, I spent there one year,", "tokens": [646, 294, 633, 4538, 11, 291, 483, 4593, 562, 291, 2117, 294, 1873, 3609, 11, 286, 4418, 456, 472, 1064, 11], "temperature": 0.0, "avg_logprob": -0.2067971626917521, "compression_ratio": 1.7073170731707317, "no_speech_prob": 0.0001687553885858506}, {"id": 166, "seek": 66496, "start": 670.08, "end": 676.24, "text": " it's not like that, anyway, so in every particular second, even at midnight, you have always a", "tokens": [309, 311, 406, 411, 300, 11, 4033, 11, 370, 294, 633, 1729, 1150, 11, 754, 412, 19006, 11, 291, 362, 1009, 257], "temperature": 0.0, "avg_logprob": -0.2067971626917521, "compression_ratio": 1.7073170731707317, "no_speech_prob": 0.0001687553885858506}, {"id": 167, "seek": 66496, "start": 676.24, "end": 681.32, "text": " few trips at least, okay, so actually you could do that, we could do something like,", "tokens": [1326, 16051, 412, 1935, 11, 1392, 11, 370, 767, 291, 727, 360, 300, 11, 321, 727, 360, 746, 411, 11], "temperature": 0.0, "avg_logprob": -0.2067971626917521, "compression_ratio": 1.7073170731707317, "no_speech_prob": 0.0001687553885858506}, {"id": 168, "seek": 66496, "start": 681.32, "end": 689.6800000000001, "text": " I want to know the, I want to, if I want to do something like, give me the date time", "tokens": [286, 528, 281, 458, 264, 11, 286, 528, 281, 11, 498, 286, 528, 281, 360, 746, 411, 11, 976, 385, 264, 4002, 565], "temperature": 0.0, "avg_logprob": -0.2067971626917521, "compression_ratio": 1.7073170731707317, "no_speech_prob": 0.0001687553885858506}, {"id": 169, "seek": 68968, "start": 689.68, "end": 705.12, "text": " and how many trips are ending where this date time is in, for example, June 21st, city,", "tokens": [293, 577, 867, 16051, 366, 8121, 689, 341, 4002, 565, 307, 294, 11, 337, 1365, 11, 6928, 5080, 372, 11, 2307, 11], "temperature": 0.0, "avg_logprob": -0.19632975260416666, "compression_ratio": 1.4583333333333333, "no_speech_prob": 0.00016546480765100569}, {"id": 170, "seek": 68968, "start": 705.12, "end": 707.7199999999999, "text": " what are you doing there, man?", "tokens": [437, 366, 291, 884, 456, 11, 587, 30], "temperature": 0.0, "avg_logprob": -0.19632975260416666, "compression_ratio": 1.4583333333333333, "no_speech_prob": 0.00016546480765100569}, {"id": 171, "seek": 68968, "start": 707.7199999999999, "end": 715.92, "text": " I didn't even know I had city here, okay, so, I don't know, for example, in this particular", "tokens": [286, 994, 380, 754, 458, 286, 632, 2307, 510, 11, 1392, 11, 370, 11, 286, 500, 380, 458, 11, 337, 1365, 11, 294, 341, 1729], "temperature": 0.0, "avg_logprob": -0.19632975260416666, "compression_ratio": 1.4583333333333333, "no_speech_prob": 0.00016546480765100569}, {"id": 172, "seek": 71592, "start": 715.92, "end": 723.88, "text": " minute, in one particular day, I want to sample in one second interval and know how many trips", "tokens": [3456, 11, 294, 472, 1729, 786, 11, 286, 528, 281, 6889, 294, 472, 1150, 15035, 293, 458, 577, 867, 16051], "temperature": 0.0, "avg_logprob": -0.14631192762773115, "compression_ratio": 1.7389162561576355, "no_speech_prob": 0.0002948346664197743}, {"id": 173, "seek": 71592, "start": 723.88, "end": 727.24, "text": " I have for every particular second, so that's another thing you can do in a time series", "tokens": [286, 362, 337, 633, 1729, 1150, 11, 370, 300, 311, 1071, 551, 291, 393, 360, 294, 257, 565, 2638], "temperature": 0.0, "avg_logprob": -0.14631192762773115, "compression_ratio": 1.7389162561576355, "no_speech_prob": 0.0002948346664197743}, {"id": 174, "seek": 71592, "start": 727.24, "end": 732.4399999999999, "text": " database, rather than grouping by columns that you can also do, you can group by time,", "tokens": [8149, 11, 2831, 813, 40149, 538, 13766, 300, 291, 393, 611, 360, 11, 291, 393, 1594, 538, 565, 11], "temperature": 0.0, "avg_logprob": -0.14631192762773115, "compression_ratio": 1.7389162561576355, "no_speech_prob": 0.0002948346664197743}, {"id": 175, "seek": 71592, "start": 732.4399999999999, "end": 741.68, "text": " you call this sample by, so we can sample by any, we go from microsecond to year, I", "tokens": [291, 818, 341, 6889, 538, 11, 370, 321, 393, 6889, 538, 604, 11, 321, 352, 490, 3123, 37841, 18882, 281, 1064, 11, 286], "temperature": 0.0, "avg_logprob": -0.14631192762773115, "compression_ratio": 1.7389162561576355, "no_speech_prob": 0.0002948346664197743}, {"id": 176, "seek": 74168, "start": 741.68, "end": 747.4, "text": " guess, microsecond to year, so you can group by microsecond, millisecond, second, year,", "tokens": [2041, 11, 3123, 37841, 18882, 281, 1064, 11, 370, 291, 393, 1594, 538, 3123, 37841, 18882, 11, 27940, 18882, 11, 1150, 11, 1064, 11], "temperature": 0.0, "avg_logprob": -0.1983189466522961, "compression_ratio": 1.918103448275862, "no_speech_prob": 0.0001064130337908864}, {"id": 177, "seek": 74168, "start": 747.4, "end": 751.16, "text": " day, whatever, so in this case, I'm saying, okay, in this particular second, I have six", "tokens": [786, 11, 2035, 11, 370, 294, 341, 1389, 11, 286, 478, 1566, 11, 1392, 11, 294, 341, 1729, 1150, 11, 286, 362, 2309], "temperature": 0.0, "avg_logprob": -0.1983189466522961, "compression_ratio": 1.918103448275862, "no_speech_prob": 0.0001064130337908864}, {"id": 178, "seek": 74168, "start": 751.16, "end": 755.28, "text": " trips and five trips and blah, blah, blah, you get the idea, yeah, so something I wanted", "tokens": [16051, 293, 1732, 16051, 293, 12288, 11, 12288, 11, 12288, 11, 291, 483, 264, 1558, 11, 1338, 11, 370, 746, 286, 1415], "temperature": 0.0, "avg_logprob": -0.1983189466522961, "compression_ratio": 1.918103448275862, "no_speech_prob": 0.0001064130337908864}, {"id": 179, "seek": 74168, "start": 755.28, "end": 761.28, "text": " to show you, which is another cool one, it's, I have this data set with several trips every", "tokens": [281, 855, 291, 11, 597, 307, 1071, 1627, 472, 11, 309, 311, 11, 286, 362, 341, 1412, 992, 365, 2940, 16051, 633], "temperature": 0.0, "avg_logprob": -0.1983189466522961, "compression_ratio": 1.918103448275862, "no_speech_prob": 0.0001064130337908864}, {"id": 180, "seek": 74168, "start": 761.28, "end": 768.4399999999999, "text": " second, I have another data set, also with data from Manhattan, is the weather data set,", "tokens": [1150, 11, 286, 362, 1071, 1412, 992, 11, 611, 365, 1412, 490, 23633, 11, 307, 264, 5503, 1412, 992, 11], "temperature": 0.0, "avg_logprob": -0.1983189466522961, "compression_ratio": 1.918103448275862, "no_speech_prob": 0.0001064130337908864}, {"id": 181, "seek": 76844, "start": 768.44, "end": 774.6, "text": " so maybe it will be interesting to know, to join those two data sets, it will be cool", "tokens": [370, 1310, 309, 486, 312, 1880, 281, 458, 11, 281, 3917, 729, 732, 1412, 6352, 11, 309, 486, 312, 1627], "temperature": 0.0, "avg_logprob": -0.13465125100654468, "compression_ratio": 1.7164750957854407, "no_speech_prob": 0.00013053904694970697}, {"id": 182, "seek": 76844, "start": 774.6, "end": 779.8800000000001, "text": " to know the weather that I had for a particular trip, because maybe that gives me some insight,", "tokens": [281, 458, 264, 5503, 300, 286, 632, 337, 257, 1729, 4931, 11, 570, 1310, 300, 2709, 385, 512, 11269, 11], "temperature": 0.0, "avg_logprob": -0.13465125100654468, "compression_ratio": 1.7164750957854407, "no_speech_prob": 0.00013053904694970697}, {"id": 183, "seek": 76844, "start": 779.8800000000001, "end": 785.5200000000001, "text": " I don't know, the challenge is this data set, of course, is real life, it's a different", "tokens": [286, 500, 380, 458, 11, 264, 3430, 307, 341, 1412, 992, 11, 295, 1164, 11, 307, 957, 993, 11, 309, 311, 257, 819], "temperature": 0.0, "avg_logprob": -0.13465125100654468, "compression_ratio": 1.7164750957854407, "no_speech_prob": 0.00013053904694970697}, {"id": 184, "seek": 76844, "start": 785.5200000000001, "end": 792.24, "text": " open data set, it's not at the same resolution, we don't have weather changes every second,", "tokens": [1269, 1412, 992, 11, 309, 311, 406, 412, 264, 912, 8669, 11, 321, 500, 380, 362, 5503, 2962, 633, 1150, 11], "temperature": 0.0, "avg_logprob": -0.13465125100654468, "compression_ratio": 1.7164750957854407, "no_speech_prob": 0.00013053904694970697}, {"id": 185, "seek": 76844, "start": 792.24, "end": 796.96, "text": " in my hometown sometimes that happens, and when I was living in London that was crazy,", "tokens": [294, 452, 22112, 2171, 300, 2314, 11, 293, 562, 286, 390, 2647, 294, 7042, 300, 390, 3219, 11], "temperature": 0.0, "avg_logprob": -0.13465125100654468, "compression_ratio": 1.7164750957854407, "no_speech_prob": 0.00013053904694970697}, {"id": 186, "seek": 79696, "start": 796.96, "end": 803.8000000000001, "text": " but in real life, we don't measure, we don't store weather changes every second, in this", "tokens": [457, 294, 957, 993, 11, 321, 500, 380, 3481, 11, 321, 500, 380, 3531, 5503, 2962, 633, 1150, 11, 294, 341], "temperature": 0.0, "avg_logprob": -0.14154821876587906, "compression_ratio": 1.8755364806866952, "no_speech_prob": 0.0001487728877691552}, {"id": 187, "seek": 79696, "start": 803.8000000000001, "end": 809.5600000000001, "text": " particular data set, we have about two or three records every hour, so now if I want", "tokens": [1729, 1412, 992, 11, 321, 362, 466, 732, 420, 1045, 7724, 633, 1773, 11, 370, 586, 498, 286, 528], "temperature": 0.0, "avg_logprob": -0.14154821876587906, "compression_ratio": 1.8755364806866952, "no_speech_prob": 0.0001487728877691552}, {"id": 188, "seek": 79696, "start": 809.5600000000001, "end": 815.6800000000001, "text": " to join a data set with sub-second resolution, a data set with sub-hour resolution, and I", "tokens": [281, 3917, 257, 1412, 992, 365, 1422, 12, 27375, 8669, 11, 257, 1412, 992, 365, 1422, 12, 18048, 8669, 11, 293, 286], "temperature": 0.0, "avg_logprob": -0.14154821876587906, "compression_ratio": 1.8755364806866952, "no_speech_prob": 0.0001487728877691552}, {"id": 189, "seek": 79696, "start": 815.6800000000001, "end": 820.84, "text": " want to do a join, if I want to do it in other databases, I could do it, it will take me", "tokens": [528, 281, 360, 257, 3917, 11, 498, 286, 528, 281, 360, 309, 294, 661, 22380, 11, 286, 727, 360, 309, 11, 309, 486, 747, 385], "temperature": 0.0, "avg_logprob": -0.14154821876587906, "compression_ratio": 1.8755364806866952, "no_speech_prob": 0.0001487728877691552}, {"id": 190, "seek": 79696, "start": 820.84, "end": 825.72, "text": " a while, then I will think I have it and I wouldn't, and then it will be like, yeah,", "tokens": [257, 1339, 11, 550, 286, 486, 519, 286, 362, 309, 293, 286, 2759, 380, 11, 293, 550, 309, 486, 312, 411, 11, 1338, 11], "temperature": 0.0, "avg_logprob": -0.14154821876587906, "compression_ratio": 1.8755364806866952, "no_speech_prob": 0.0001487728877691552}, {"id": 191, "seek": 82572, "start": 825.72, "end": 829.6, "text": " this makes sense, or not really, and a week later I will be crying, I don't know, I don't", "tokens": [341, 1669, 2020, 11, 420, 406, 534, 11, 293, 257, 1243, 1780, 286, 486, 312, 8554, 11, 286, 500, 380, 458, 11, 286, 500, 380], "temperature": 0.0, "avg_logprob": -0.2838432372562469, "compression_ratio": 1.853658536585366, "no_speech_prob": 0.0006590255652554333}, {"id": 192, "seek": 82572, "start": 829.6, "end": 835.24, "text": " know, so you know, I should know, so one thing, one cool thing we have here, we have a demo", "tokens": [458, 11, 370, 291, 458, 11, 286, 820, 458, 11, 370, 472, 551, 11, 472, 1627, 551, 321, 362, 510, 11, 321, 362, 257, 10723], "temperature": 0.0, "avg_logprob": -0.2838432372562469, "compression_ratio": 1.853658536585366, "no_speech_prob": 0.0006590255652554333}, {"id": 193, "seek": 82572, "start": 835.24, "end": 840.96, "text": " set, it's an example, I'm going to move on to another thing really quickly, because otherwise,", "tokens": [992, 11, 309, 311, 364, 1365, 11, 286, 478, 516, 281, 1286, 322, 281, 1071, 551, 534, 2661, 11, 570, 5911, 11], "temperature": 0.0, "avg_logprob": -0.2838432372562469, "compression_ratio": 1.853658536585366, "no_speech_prob": 0.0006590255652554333}, {"id": 194, "seek": 82572, "start": 840.96, "end": 847.76, "text": " but this one I really like, we have a special type of join, which we call an ask of join,", "tokens": [457, 341, 472, 286, 534, 411, 11, 321, 362, 257, 2121, 2010, 295, 3917, 11, 597, 321, 818, 364, 1029, 295, 3917, 11], "temperature": 0.0, "avg_logprob": -0.2838432372562469, "compression_ratio": 1.853658536585366, "no_speech_prob": 0.0006590255652554333}, {"id": 195, "seek": 82572, "start": 847.76, "end": 853.44, "text": " which basically does this, I'm going to select the data from the table I told you already", "tokens": [597, 1936, 775, 341, 11, 286, 478, 516, 281, 3048, 264, 1412, 490, 264, 3199, 286, 1907, 291, 1217], "temperature": 0.0, "avg_logprob": -0.2838432372562469, "compression_ratio": 1.853658536585366, "no_speech_prob": 0.0006590255652554333}, {"id": 196, "seek": 85344, "start": 853.44, "end": 858.6, "text": " for one particular day in time, and then I'm going to do what we call an ask of join, which", "tokens": [337, 472, 1729, 786, 294, 565, 11, 293, 550, 286, 478, 516, 281, 360, 437, 321, 818, 364, 1029, 295, 3917, 11, 597], "temperature": 0.0, "avg_logprob": -0.14761735711778914, "compression_ratio": 1.9260869565217391, "no_speech_prob": 0.0003325598081573844}, {"id": 197, "seek": 85344, "start": 858.6, "end": 865.4000000000001, "text": " basically says, this table has a time stamp, we call it the designated time stamp, you", "tokens": [1936, 1619, 11, 341, 3199, 575, 257, 565, 9921, 11, 321, 818, 309, 264, 21688, 565, 9921, 11, 291], "temperature": 0.0, "avg_logprob": -0.14761735711778914, "compression_ratio": 1.9260869565217391, "no_speech_prob": 0.0003325598081573844}, {"id": 198, "seek": 85344, "start": 865.4000000000001, "end": 870.1600000000001, "text": " design which is the column, you have several, so we have the designated time stamp in one,", "tokens": [1715, 597, 307, 264, 7738, 11, 291, 362, 2940, 11, 370, 321, 362, 264, 21688, 565, 9921, 294, 472, 11], "temperature": 0.0, "avg_logprob": -0.14761735711778914, "compression_ratio": 1.9260869565217391, "no_speech_prob": 0.0003325598081573844}, {"id": 199, "seek": 85344, "start": 870.1600000000001, "end": 874.84, "text": " designated time stamp in the other, joined by the ones that are closer to each other,", "tokens": [21688, 565, 9921, 294, 264, 661, 11, 6869, 538, 264, 2306, 300, 366, 4966, 281, 1184, 661, 11], "temperature": 0.0, "avg_logprob": -0.14761735711778914, "compression_ratio": 1.9260869565217391, "no_speech_prob": 0.0003325598081573844}, {"id": 200, "seek": 85344, "start": 874.84, "end": 878.8000000000001, "text": " in this case, ask of means the one which is exactly the same, or immediately before me,", "tokens": [294, 341, 1389, 11, 1029, 295, 1355, 264, 472, 597, 307, 2293, 264, 912, 11, 420, 4258, 949, 385, 11], "temperature": 0.0, "avg_logprob": -0.14761735711778914, "compression_ratio": 1.9260869565217391, "no_speech_prob": 0.0003325598081573844}, {"id": 201, "seek": 87880, "start": 878.8, "end": 884.7199999999999, "text": " the one which is closer to me, what happened before, we have also the one strictly before", "tokens": [264, 472, 597, 307, 4966, 281, 385, 11, 437, 2011, 949, 11, 321, 362, 611, 264, 472, 20792, 949], "temperature": 0.0, "avg_logprob": -0.1559116656963642, "compression_ratio": 1.7649402390438247, "no_speech_prob": 9.771428449312225e-05}, {"id": 202, "seek": 87880, "start": 884.7199999999999, "end": 888.3599999999999, "text": " me cannot be the same, but that's the idea, so in this case for joining two different", "tokens": [385, 2644, 312, 264, 912, 11, 457, 300, 311, 264, 1558, 11, 370, 294, 341, 1389, 337, 5549, 732, 819], "temperature": 0.0, "avg_logprob": -0.1559116656963642, "compression_ratio": 1.7649402390438247, "no_speech_prob": 9.771428449312225e-05}, {"id": 203, "seek": 87880, "start": 888.3599999999999, "end": 894.92, "text": " data sets, I can just do that, also I'm going to add here the time stamp for the other table,", "tokens": [1412, 6352, 11, 286, 393, 445, 360, 300, 11, 611, 286, 478, 516, 281, 909, 510, 264, 565, 9921, 337, 264, 661, 3199, 11], "temperature": 0.0, "avg_logprob": -0.1559116656963642, "compression_ratio": 1.7649402390438247, "no_speech_prob": 9.771428449312225e-05}, {"id": 204, "seek": 87880, "start": 894.92, "end": 902.4799999999999, "text": " so it's clear, so if I run this query, now here I can see for each record on the New", "tokens": [370, 309, 311, 1850, 11, 370, 498, 286, 1190, 341, 14581, 11, 586, 510, 286, 393, 536, 337, 1184, 2136, 322, 264, 1873], "temperature": 0.0, "avg_logprob": -0.1559116656963642, "compression_ratio": 1.7649402390438247, "no_speech_prob": 9.771428449312225e-05}, {"id": 205, "seek": 87880, "start": 902.4799999999999, "end": 908.56, "text": " York taxi rides, I'm always getting the same time stamp in the weather data set, because", "tokens": [3609, 18984, 20773, 11, 286, 478, 1009, 1242, 264, 912, 565, 9921, 294, 264, 5503, 1412, 992, 11, 570], "temperature": 0.0, "avg_logprob": -0.1559116656963642, "compression_ratio": 1.7649402390438247, "no_speech_prob": 9.771428449312225e-05}, {"id": 206, "seek": 90856, "start": 908.56, "end": 914.9599999999999, "text": " I have only one entry every 40 or 45 minutes, if I move to a different point in the day", "tokens": [286, 362, 787, 472, 8729, 633, 3356, 420, 6905, 2077, 11, 498, 286, 1286, 281, 257, 819, 935, 294, 264, 786], "temperature": 0.0, "avg_logprob": -0.17763040045730205, "compression_ratio": 1.7098039215686274, "no_speech_prob": 0.0003028291976079345}, {"id": 207, "seek": 90856, "start": 914.9599999999999, "end": 922.52, "text": " to this day, but instead of at 12, at 12.55 for example, I should see already the time", "tokens": [281, 341, 786, 11, 457, 2602, 295, 412, 2272, 11, 412, 2272, 13, 13622, 337, 1365, 11, 286, 820, 536, 1217, 264, 565], "temperature": 0.0, "avg_logprob": -0.17763040045730205, "compression_ratio": 1.7098039215686274, "no_speech_prob": 0.0003028291976079345}, {"id": 208, "seek": 90856, "start": 922.52, "end": 928.3199999999999, "text": " matching to a different entry on this table, but that's it, I have different resolutions,", "tokens": [14324, 281, 257, 819, 8729, 322, 341, 3199, 11, 457, 300, 311, 309, 11, 286, 362, 819, 32179, 11], "temperature": 0.0, "avg_logprob": -0.17763040045730205, "compression_ratio": 1.7098039215686274, "no_speech_prob": 0.0003028291976079345}, {"id": 209, "seek": 90856, "start": 928.3199999999999, "end": 931.68, "text": " I don't care which one, we join by time, because we're about time, that's kind of the", "tokens": [286, 500, 380, 1127, 597, 472, 11, 321, 3917, 538, 565, 11, 570, 321, 434, 466, 565, 11, 300, 311, 733, 295, 264], "temperature": 0.0, "avg_logprob": -0.17763040045730205, "compression_ratio": 1.7098039215686274, "no_speech_prob": 0.0003028291976079345}, {"id": 210, "seek": 90856, "start": 931.68, "end": 935.8, "text": " idea, that's what I'm trying to say, I have more interesting queries, but maybe for a", "tokens": [1558, 11, 300, 311, 437, 286, 478, 1382, 281, 584, 11, 286, 362, 544, 1880, 24109, 11, 457, 1310, 337, 257], "temperature": 0.0, "avg_logprob": -0.17763040045730205, "compression_ratio": 1.7098039215686274, "no_speech_prob": 0.0003028291976079345}, {"id": 211, "seek": 93580, "start": 935.8, "end": 938.8399999999999, "text": " different day, so that's the first thing.", "tokens": [819, 786, 11, 370, 300, 311, 264, 700, 551, 13], "temperature": 0.0, "avg_logprob": -0.17265892028808594, "compression_ratio": 1.8058608058608059, "no_speech_prob": 0.0002524765150155872}, {"id": 212, "seek": 93580, "start": 938.8399999999999, "end": 942.88, "text": " So I told you, okay, now you get the idea why tensile is kind of interesting, the kind", "tokens": [407, 286, 1907, 291, 11, 1392, 11, 586, 291, 483, 264, 1558, 983, 10688, 794, 307, 733, 295, 1880, 11, 264, 733], "temperature": 0.0, "avg_logprob": -0.17265892028808594, "compression_ratio": 1.8058608058608059, "no_speech_prob": 0.0002524765150155872}, {"id": 213, "seek": 93580, "start": 942.88, "end": 947.16, "text": " of things we can do, down sampling, all those things, machine learning is very important,", "tokens": [295, 721, 321, 393, 360, 11, 760, 21179, 11, 439, 729, 721, 11, 3479, 2539, 307, 588, 1021, 11], "temperature": 0.0, "avg_logprob": -0.17265892028808594, "compression_ratio": 1.8058608058608059, "no_speech_prob": 0.0002524765150155872}, {"id": 214, "seek": 93580, "start": 947.16, "end": 951.68, "text": " you have data maybe every second, and then you want to do a forecasting, and it doesn't", "tokens": [291, 362, 1412, 1310, 633, 1150, 11, 293, 550, 291, 528, 281, 360, 257, 44331, 11, 293, 309, 1177, 380], "temperature": 0.0, "avg_logprob": -0.17265892028808594, "compression_ratio": 1.8058608058608059, "no_speech_prob": 0.0002524765150155872}, {"id": 215, "seek": 93580, "start": 951.68, "end": 957.0, "text": " make sense to train a model with every second data in many cases, maybe you want to down", "tokens": [652, 2020, 281, 3847, 257, 2316, 365, 633, 1150, 1412, 294, 867, 3331, 11, 1310, 291, 528, 281, 760], "temperature": 0.0, "avg_logprob": -0.17265892028808594, "compression_ratio": 1.8058608058608059, "no_speech_prob": 0.0002524765150155872}, {"id": 216, "seek": 93580, "start": 957.0, "end": 961.04, "text": " sample to 15 minutes intervals, with this trick you can do it easily, so that's kind", "tokens": [6889, 281, 2119, 2077, 26651, 11, 365, 341, 4282, 291, 393, 360, 309, 3612, 11, 370, 300, 311, 733], "temperature": 0.0, "avg_logprob": -0.17265892028808594, "compression_ratio": 1.8058608058608059, "no_speech_prob": 0.0002524765150155872}, {"id": 217, "seek": 93580, "start": 961.04, "end": 962.04, "text": " of the idea.", "tokens": [295, 264, 1558, 13], "temperature": 0.0, "avg_logprob": -0.17265892028808594, "compression_ratio": 1.8058608058608059, "no_speech_prob": 0.0002524765150155872}, {"id": 218, "seek": 96204, "start": 962.04, "end": 967.0799999999999, "text": " So I was speaking about ingesting data, so ingesting over one million times per second", "tokens": [407, 286, 390, 4124, 466, 3957, 8714, 1412, 11, 370, 3957, 8714, 670, 472, 2459, 1413, 680, 1150], "temperature": 0.0, "avg_logprob": -0.213657774366774, "compression_ratio": 1.9733333333333334, "no_speech_prob": 0.00024104208569042385}, {"id": 219, "seek": 96204, "start": 967.0799999999999, "end": 973.56, "text": " on a single instance, it's interesting, but ingesting over one million records per second", "tokens": [322, 257, 2167, 5197, 11, 309, 311, 1880, 11, 457, 3957, 8714, 670, 472, 2459, 7724, 680, 1150], "temperature": 0.0, "avg_logprob": -0.213657774366774, "compression_ratio": 1.9733333333333334, "no_speech_prob": 0.00024104208569042385}, {"id": 220, "seek": 96204, "start": 973.56, "end": 979.64, "text": " on a single instance, it's easy actually, I could just write to a file, a pending line,", "tokens": [322, 257, 2167, 5197, 11, 309, 311, 1858, 767, 11, 286, 727, 445, 2464, 281, 257, 3991, 11, 257, 32110, 1622, 11], "temperature": 0.0, "avg_logprob": -0.213657774366774, "compression_ratio": 1.9733333333333334, "no_speech_prob": 0.00024104208569042385}, {"id": 221, "seek": 96204, "start": 979.64, "end": 984.5999999999999, "text": " and that will be it, the interesting bit is actually being able to ingest data while you", "tokens": [293, 300, 486, 312, 309, 11, 264, 1880, 857, 307, 767, 885, 1075, 281, 3957, 377, 1412, 1339, 291], "temperature": 0.0, "avg_logprob": -0.213657774366774, "compression_ratio": 1.9733333333333334, "no_speech_prob": 0.00024104208569042385}, {"id": 222, "seek": 96204, "start": 984.5999999999999, "end": 988.68, "text": " are able to query data in real time, the same data you ingested, that's the trick, because", "tokens": [366, 1075, 281, 14581, 1412, 294, 957, 565, 11, 264, 912, 1412, 291, 3957, 21885, 11, 300, 311, 264, 4282, 11, 570], "temperature": 0.0, "avg_logprob": -0.213657774366774, "compression_ratio": 1.9733333333333334, "no_speech_prob": 0.00024104208569042385}, {"id": 223, "seek": 98868, "start": 988.68, "end": 993.0799999999999, "text": " just ingesting, I mean, you put it there and you're like, why ingesting a million records,", "tokens": [445, 3957, 8714, 11, 286, 914, 11, 291, 829, 309, 456, 293, 291, 434, 411, 11, 983, 3957, 8714, 257, 2459, 7724, 11], "temperature": 0.0, "avg_logprob": -0.1946554183959961, "compression_ratio": 1.81, "no_speech_prob": 0.0006340838735923171}, {"id": 224, "seek": 98868, "start": 993.0799999999999, "end": 996.64, "text": " when you think about it, it's like, well, wait, but how long I have to wait to query", "tokens": [562, 291, 519, 466, 309, 11, 309, 311, 411, 11, 731, 11, 1699, 11, 457, 577, 938, 286, 362, 281, 1699, 281, 14581], "temperature": 0.0, "avg_logprob": -0.1946554183959961, "compression_ratio": 1.81, "no_speech_prob": 0.0006340838735923171}, {"id": 225, "seek": 98868, "start": 996.64, "end": 1001.3599999999999, "text": " the data, and when I can, so the idea is you can query the data at the same time, all benchmarks", "tokens": [264, 1412, 11, 293, 562, 286, 393, 11, 370, 264, 1558, 307, 291, 393, 14581, 264, 1412, 412, 264, 912, 565, 11, 439, 43751], "temperature": 0.0, "avg_logprob": -0.1946554183959961, "compression_ratio": 1.81, "no_speech_prob": 0.0006340838735923171}, {"id": 226, "seek": 98868, "start": 1001.3599999999999, "end": 1005.64, "text": " are lies, of course, on the same benchmark that I'm going to tell you, other people will", "tokens": [366, 9134, 11, 295, 1164, 11, 322, 264, 912, 18927, 300, 286, 478, 516, 281, 980, 291, 11, 661, 561, 486], "temperature": 0.0, "avg_logprob": -0.1946554183959961, "compression_ratio": 1.81, "no_speech_prob": 0.0006340838735923171}, {"id": 227, "seek": 98868, "start": 1005.64, "end": 1010.1999999999999, "text": " tell you the contrary, and I'm totally fine with that, but a couple of years ago we published", "tokens": [980, 291, 264, 19506, 11, 293, 286, 478, 3879, 2489, 365, 300, 11, 457, 257, 1916, 295, 924, 2057, 321, 6572], "temperature": 0.0, "avg_logprob": -0.1946554183959961, "compression_ratio": 1.81, "no_speech_prob": 0.0006340838735923171}, {"id": 228, "seek": 98868, "start": 1010.1999999999999, "end": 1016.28, "text": " an article saying, hey, we can ingest now at 1.4 million, the slides are linked already", "tokens": [364, 7222, 1566, 11, 4177, 11, 321, 393, 3957, 377, 586, 412, 502, 13, 19, 2459, 11, 264, 9788, 366, 9408, 1217], "temperature": 0.0, "avg_logprob": -0.1946554183959961, "compression_ratio": 1.81, "no_speech_prob": 0.0006340838735923171}, {"id": 229, "seek": 101628, "start": 1016.28, "end": 1023.8399999999999, "text": " on the first page, by the way, thank you, so we, our CTO posted about, you know, how", "tokens": [322, 264, 700, 3028, 11, 538, 264, 636, 11, 1309, 291, 11, 370, 321, 11, 527, 383, 15427, 9437, 466, 11, 291, 458, 11, 577], "temperature": 0.0, "avg_logprob": -0.18793082483036003, "compression_ratio": 1.781725888324873, "no_speech_prob": 0.00020395686442498118}, {"id": 230, "seek": 101628, "start": 1023.8399999999999, "end": 1029.04, "text": " we were ingesting 1.4 million records per second, these records were, they have like", "tokens": [321, 645, 3957, 8714, 502, 13, 19, 2459, 7724, 680, 1150, 11, 613, 7724, 645, 11, 436, 362, 411], "temperature": 0.0, "avg_logprob": -0.18793082483036003, "compression_ratio": 1.781725888324873, "no_speech_prob": 0.00020395686442498118}, {"id": 231, "seek": 101628, "start": 1029.04, "end": 1034.32, "text": " 20 columns, 10 dimensions, 10 strings, and 10 metrics, 10 numbers, so, you know, we could", "tokens": [945, 13766, 11, 1266, 12819, 11, 1266, 13985, 11, 293, 1266, 16367, 11, 1266, 3547, 11, 370, 11, 291, 458, 11, 321, 727], "temperature": 0.0, "avg_logprob": -0.18793082483036003, "compression_ratio": 1.781725888324873, "no_speech_prob": 0.00020395686442498118}, {"id": 232, "seek": 101628, "start": 1034.32, "end": 1041.3999999999999, "text": " ingest records of 20 columns with 10 strings and 10 numbers, 1.4 million records per second", "tokens": [3957, 377, 7724, 295, 945, 13766, 365, 1266, 13985, 293, 1266, 3547, 11, 502, 13, 19, 2459, 7724, 680, 1150], "temperature": 0.0, "avg_logprob": -0.18793082483036003, "compression_ratio": 1.781725888324873, "no_speech_prob": 0.00020395686442498118}, {"id": 233, "seek": 104140, "start": 1041.4, "end": 1046.76, "text": " while running queries, which is the other bit, so we were able to scan over 4 million,", "tokens": [1339, 2614, 24109, 11, 597, 307, 264, 661, 857, 11, 370, 321, 645, 1075, 281, 11049, 670, 1017, 2459, 11], "temperature": 0.0, "avg_logprob": -0.1679512893452364, "compression_ratio": 1.7682119205298013, "no_speech_prob": 0.0001286647457163781}, {"id": 234, "seek": 104140, "start": 1046.76, "end": 1051.6000000000001, "text": " 4 billion records per second, you know, at the same time in relatively small machines,", "tokens": [1017, 5218, 7724, 680, 1150, 11, 291, 458, 11, 412, 264, 912, 565, 294, 7226, 1359, 8379, 11], "temperature": 0.0, "avg_logprob": -0.1679512893452364, "compression_ratio": 1.7682119205298013, "no_speech_prob": 0.0001286647457163781}, {"id": 235, "seek": 104140, "start": 1051.6000000000001, "end": 1056.44, "text": " relatively small, so that's kind of the, the idea, okay, and these benchmarks, we didn't", "tokens": [7226, 1359, 11, 370, 300, 311, 733, 295, 264, 11, 264, 1558, 11, 1392, 11, 293, 613, 43751, 11, 321, 994, 380], "temperature": 0.0, "avg_logprob": -0.1679512893452364, "compression_ratio": 1.7682119205298013, "no_speech_prob": 0.0001286647457163781}, {"id": 236, "seek": 104140, "start": 1056.44, "end": 1062.76, "text": " write it, it was, there is a benchmark specifically for 10 series databases, as I told you earlier,", "tokens": [2464, 309, 11, 309, 390, 11, 456, 307, 257, 18927, 4682, 337, 1266, 2638, 22380, 11, 382, 286, 1907, 291, 3071, 11], "temperature": 0.0, "avg_logprob": -0.1679512893452364, "compression_ratio": 1.7682119205298013, "no_speech_prob": 0.0001286647457163781}, {"id": 237, "seek": 104140, "start": 1062.76, "end": 1066.64, "text": " if you load data in QuestDB, you can load relational data into QuestDB, and you can", "tokens": [498, 291, 3677, 1412, 294, 8800, 27735, 11, 291, 393, 3677, 38444, 1412, 666, 8800, 27735, 11, 293, 291, 393], "temperature": 0.0, "avg_logprob": -0.1679512893452364, "compression_ratio": 1.7682119205298013, "no_speech_prob": 0.0001286647457163781}, {"id": 238, "seek": 104140, "start": 1066.64, "end": 1071.3200000000002, "text": " run queries, you try to run a conventional benchmark on QuestDB, it's going to be super", "tokens": [1190, 24109, 11, 291, 853, 281, 1190, 257, 16011, 18927, 322, 8800, 27735, 11, 309, 311, 516, 281, 312, 1687], "temperature": 0.0, "avg_logprob": -0.1679512893452364, "compression_ratio": 1.7682119205298013, "no_speech_prob": 0.0001286647457163781}, {"id": 239, "seek": 107132, "start": 1071.32, "end": 1076.96, "text": " slow, so we are not designed for full text search, we are not designed for, you know,", "tokens": [2964, 11, 370, 321, 366, 406, 4761, 337, 1577, 2487, 3164, 11, 321, 366, 406, 4761, 337, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.1855547516434281, "compression_ratio": 1.9508928571428572, "no_speech_prob": 0.00013187341392040253}, {"id": 240, "seek": 107132, "start": 1076.96, "end": 1082.0, "text": " just operations, reading individual records, or doing updating data, we are not designed", "tokens": [445, 7705, 11, 3760, 2609, 7724, 11, 420, 884, 25113, 1412, 11, 321, 366, 406, 4761], "temperature": 0.0, "avg_logprob": -0.1855547516434281, "compression_ratio": 1.9508928571428572, "no_speech_prob": 0.00013187341392040253}, {"id": 241, "seek": 107132, "start": 1082.0, "end": 1087.0, "text": " for that, we can do it, but we are not designed for that, so there is, and also there are", "tokens": [337, 300, 11, 321, 393, 360, 309, 11, 457, 321, 366, 406, 4761, 337, 300, 11, 370, 456, 307, 11, 293, 611, 456, 366], "temperature": 0.0, "avg_logprob": -0.1855547516434281, "compression_ratio": 1.9508928571428572, "no_speech_prob": 0.00013187341392040253}, {"id": 242, "seek": 107132, "start": 1087.0, "end": 1092.52, "text": " 10 series databases, so in FluxDB, another open source database, created this benchmark,", "tokens": [1266, 2638, 22380, 11, 370, 294, 3235, 2449, 27735, 11, 1071, 1269, 4009, 8149, 11, 2942, 341, 18927, 11], "temperature": 0.0, "avg_logprob": -0.1855547516434281, "compression_ratio": 1.9508928571428572, "no_speech_prob": 0.00013187341392040253}, {"id": 243, "seek": 107132, "start": 1092.52, "end": 1097.56, "text": " the TSBS benchmark, which is specifically about 10 series databases, so the queries", "tokens": [264, 37645, 8176, 18927, 11, 597, 307, 4682, 466, 1266, 2638, 22380, 11, 370, 264, 24109], "temperature": 0.0, "avg_logprob": -0.1855547516434281, "compression_ratio": 1.9508928571428572, "no_speech_prob": 0.00013187341392040253}, {"id": 244, "seek": 109756, "start": 1097.56, "end": 1101.8, "text": " and the ingestion patterns matches what you would expect from a 10 series database, now", "tokens": [293, 264, 3957, 31342, 8294, 10676, 437, 291, 576, 2066, 490, 257, 1266, 2638, 8149, 11, 586], "temperature": 0.0, "avg_logprob": -0.16664830544837436, "compression_ratio": 1.8148148148148149, "no_speech_prob": 0.00022676415392197669}, {"id": 245, "seek": 109756, "start": 1101.8, "end": 1107.6399999999999, "text": " it's maintained by time scale, which is another open source database on top of Postgres, and", "tokens": [309, 311, 17578, 538, 565, 4373, 11, 597, 307, 1071, 1269, 4009, 8149, 322, 1192, 295, 10223, 45189, 11, 293], "temperature": 0.0, "avg_logprob": -0.16664830544837436, "compression_ratio": 1.8148148148148149, "no_speech_prob": 0.00022676415392197669}, {"id": 246, "seek": 109756, "start": 1107.6399999999999, "end": 1113.56, "text": " we have our own, you know, there is an adapter for running that on top of QuestDB, and with", "tokens": [321, 362, 527, 1065, 11, 291, 458, 11, 456, 307, 364, 22860, 337, 2614, 300, 322, 1192, 295, 8800, 27735, 11, 293, 365], "temperature": 0.0, "avg_logprob": -0.16664830544837436, "compression_ratio": 1.8148148148148149, "no_speech_prob": 0.00022676415392197669}, {"id": 247, "seek": 109756, "start": 1113.56, "end": 1117.48, "text": " that benchmark, it's with the one that we are getting those results, so with that particular", "tokens": [300, 18927, 11, 309, 311, 365, 264, 472, 300, 321, 366, 1242, 729, 3542, 11, 370, 365, 300, 1729], "temperature": 0.0, "avg_logprob": -0.16664830544837436, "compression_ratio": 1.8148148148148149, "no_speech_prob": 0.00022676415392197669}, {"id": 248, "seek": 109756, "start": 1117.48, "end": 1121.36, "text": " benchmark, it's the one giving the results, so you know, your mileage might vary, also", "tokens": [18927, 11, 309, 311, 264, 472, 2902, 264, 3542, 11, 370, 291, 458, 11, 428, 43121, 1062, 10559, 11, 611], "temperature": 0.0, "avg_logprob": -0.16664830544837436, "compression_ratio": 1.8148148148148149, "no_speech_prob": 0.00022676415392197669}, {"id": 249, "seek": 109756, "start": 1121.36, "end": 1125.04, "text": " depending on the hardware, if you try to run the benchmark in the cloud, it's going to", "tokens": [5413, 322, 264, 8837, 11, 498, 291, 853, 281, 1190, 264, 18927, 294, 264, 4588, 11, 309, 311, 516, 281], "temperature": 0.0, "avg_logprob": -0.16664830544837436, "compression_ratio": 1.8148148148148149, "no_speech_prob": 0.00022676415392197669}, {"id": 250, "seek": 112504, "start": 1125.04, "end": 1132.6, "text": " be slower, always, because in the cloud, by default, you use on AWS, you use CVS, on", "tokens": [312, 14009, 11, 1009, 11, 570, 294, 264, 4588, 11, 538, 7576, 11, 291, 764, 322, 17650, 11, 291, 764, 22995, 50, 11, 322], "temperature": 0.0, "avg_logprob": -0.22013845443725585, "compression_ratio": 1.947136563876652, "no_speech_prob": 0.00048766544205136597}, {"id": 251, "seek": 112504, "start": 1132.6, "end": 1136.96, "text": " WorldCloud, you use the attached storage, it's networking storage, it has latency, because", "tokens": [3937, 32787, 11, 291, 764, 264, 8570, 6725, 11, 309, 311, 17985, 6725, 11, 309, 575, 27043, 11, 570], "temperature": 0.0, "avg_logprob": -0.22013845443725585, "compression_ratio": 1.947136563876652, "no_speech_prob": 0.00048766544205136597}, {"id": 252, "seek": 112504, "start": 1136.96, "end": 1140.8799999999999, "text": " they are not local disk, they are super cool, but they are not local, it's going to be always", "tokens": [436, 366, 406, 2654, 12355, 11, 436, 366, 1687, 1627, 11, 457, 436, 366, 406, 2654, 11, 309, 311, 516, 281, 312, 1009], "temperature": 0.0, "avg_logprob": -0.22013845443725585, "compression_ratio": 1.947136563876652, "no_speech_prob": 0.00048766544205136597}, {"id": 253, "seek": 112504, "start": 1140.8799999999999, "end": 1146.68, "text": " slower, you want to get this on WorldCloud or on AWS, you can do it, you have to use", "tokens": [14009, 11, 291, 528, 281, 483, 341, 322, 3937, 32787, 420, 322, 17650, 11, 291, 393, 360, 309, 11, 291, 362, 281, 764], "temperature": 0.0, "avg_logprob": -0.22013845443725585, "compression_ratio": 1.947136563876652, "no_speech_prob": 0.00048766544205136597}, {"id": 254, "seek": 112504, "start": 1146.68, "end": 1152.56, "text": " NVME disk, which are local disk, which are attached to the instance, but they disappear", "tokens": [46512, 15454, 12355, 11, 597, 366, 2654, 12355, 11, 597, 366, 8570, 281, 264, 5197, 11, 457, 436, 11596], "temperature": 0.0, "avg_logprob": -0.22013845443725585, "compression_ratio": 1.947136563876652, "no_speech_prob": 0.00048766544205136597}, {"id": 255, "seek": 115256, "start": 1152.56, "end": 1158.28, "text": " when you close the instance, but with those disks, you will be getting the same benchmark,", "tokens": [562, 291, 1998, 264, 5197, 11, 457, 365, 729, 41617, 11, 291, 486, 312, 1242, 264, 912, 18927, 11], "temperature": 0.0, "avg_logprob": -0.158929682960195, "compression_ratio": 1.7729083665338645, "no_speech_prob": 0.000341921579092741}, {"id": 256, "seek": 115256, "start": 1158.28, "end": 1162.6, "text": " so hardware is also important with the benchmark, but that's the idea, you know, that's how", "tokens": [370, 8837, 307, 611, 1021, 365, 264, 18927, 11, 457, 300, 311, 264, 1558, 11, 291, 458, 11, 300, 311, 577], "temperature": 0.0, "avg_logprob": -0.158929682960195, "compression_ratio": 1.7729083665338645, "no_speech_prob": 0.000341921579092741}, {"id": 257, "seek": 115256, "start": 1162.6, "end": 1167.44, "text": " we did it, and before, I tell you a bit about the technical decisions, that I will not have", "tokens": [321, 630, 309, 11, 293, 949, 11, 286, 980, 291, 257, 857, 466, 264, 6191, 5327, 11, 300, 286, 486, 406, 362], "temperature": 0.0, "avg_logprob": -0.158929682960195, "compression_ratio": 1.7729083665338645, "no_speech_prob": 0.000341921579092741}, {"id": 258, "seek": 115256, "start": 1167.44, "end": 1174.8, "text": " super time, but I want to show you how we are doing this in gestion, so let me just,", "tokens": [1687, 565, 11, 457, 286, 528, 281, 855, 291, 577, 321, 366, 884, 341, 294, 7219, 313, 11, 370, 718, 385, 445, 11], "temperature": 0.0, "avg_logprob": -0.158929682960195, "compression_ratio": 1.7729083665338645, "no_speech_prob": 0.000341921579092741}, {"id": 259, "seek": 115256, "start": 1174.8, "end": 1179.56, "text": " if I can move this out of the way, so this is a scripting goal, I don't know any goal", "tokens": [498, 286, 393, 1286, 341, 484, 295, 264, 636, 11, 370, 341, 307, 257, 5755, 278, 3387, 11, 286, 500, 380, 458, 604, 3387], "temperature": 0.0, "avg_logprob": -0.158929682960195, "compression_ratio": 1.7729083665338645, "no_speech_prob": 0.000341921579092741}, {"id": 260, "seek": 117956, "start": 1179.56, "end": 1185.52, "text": " at all, but I know to run this, so another developer advocate, I mean, I couldn't tell", "tokens": [412, 439, 11, 457, 286, 458, 281, 1190, 341, 11, 370, 1071, 10754, 14608, 11, 286, 914, 11, 286, 2809, 380, 980], "temperature": 0.0, "avg_logprob": -0.2174970776427026, "compression_ratio": 1.669767441860465, "no_speech_prob": 0.00020250218221917748}, {"id": 261, "seek": 117956, "start": 1185.52, "end": 1190.76, "text": " you that I know a lot of goals, but I have no idea, so goal lang is a language, so yeah,", "tokens": [291, 300, 286, 458, 257, 688, 295, 5493, 11, 457, 286, 362, 572, 1558, 11, 370, 3387, 2265, 307, 257, 2856, 11, 370, 1338, 11], "temperature": 0.0, "avg_logprob": -0.2174970776427026, "compression_ratio": 1.669767441860465, "no_speech_prob": 0.00020250218221917748}, {"id": 262, "seek": 117956, "start": 1190.76, "end": 1197.32, "text": " we have, I've been told it's pretty cool, so we have this library or package or whatever", "tokens": [321, 362, 11, 286, 600, 668, 1907, 309, 311, 1238, 1627, 11, 370, 321, 362, 341, 6405, 420, 7372, 420, 2035], "temperature": 0.0, "avg_logprob": -0.2174970776427026, "compression_ratio": 1.669767441860465, "no_speech_prob": 0.00020250218221917748}, {"id": 263, "seek": 117956, "start": 1197.32, "end": 1203.56, "text": " they call it in Go, which is our official package, cargo or whatever, I don't know, so this is", "tokens": [436, 818, 309, 294, 1037, 11, 597, 307, 527, 4783, 7372, 11, 19449, 420, 2035, 11, 286, 500, 380, 458, 11, 370, 341, 307], "temperature": 0.0, "avg_logprob": -0.2174970776427026, "compression_ratio": 1.669767441860465, "no_speech_prob": 0.00020250218221917748}, {"id": 264, "seek": 120356, "start": 1203.56, "end": 1210.32, "text": " my missing languages here, thank you, so yeah, this is our theme, I'm connecting to local", "tokens": [452, 5361, 8650, 510, 11, 1309, 291, 11, 370, 1338, 11, 341, 307, 527, 6314, 11, 286, 478, 11015, 281, 2654], "temperature": 0.0, "avg_logprob": -0.23241732670710638, "compression_ratio": 1.733644859813084, "no_speech_prob": 0.0004503267991822213}, {"id": 265, "seek": 120356, "start": 1210.32, "end": 1216.6, "text": " host to the default port in QuestDB, I'm going to be simulating data, so I'm simulating IoT", "tokens": [3975, 281, 264, 7576, 2436, 294, 8800, 27735, 11, 286, 478, 516, 281, 312, 1034, 12162, 1412, 11, 370, 286, 478, 1034, 12162, 30112], "temperature": 0.0, "avg_logprob": -0.23241732670710638, "compression_ratio": 1.733644859813084, "no_speech_prob": 0.0004503267991822213}, {"id": 266, "seek": 120356, "start": 1216.6, "end": 1223.24, "text": " data, and I'm going to be outputting a device type, it can be red or blue or green or yellow,", "tokens": [1412, 11, 293, 286, 478, 516, 281, 312, 5598, 783, 257, 4302, 2010, 11, 309, 393, 312, 2182, 420, 3344, 420, 3092, 420, 5566, 11], "temperature": 0.0, "avg_logprob": -0.23241732670710638, "compression_ratio": 1.733644859813084, "no_speech_prob": 0.0004503267991822213}, {"id": 267, "seek": 120356, "start": 1223.24, "end": 1230.1599999999999, "text": " I'm going to be outputting duration, latitude, longitude, speed, and time stamp in nanoseconds,", "tokens": [286, 478, 516, 281, 312, 5598, 783, 16365, 11, 45436, 11, 938, 4377, 11, 3073, 11, 293, 565, 9921, 294, 14067, 541, 28750, 11], "temperature": 0.0, "avg_logprob": -0.23241732670710638, "compression_ratio": 1.733644859813084, "no_speech_prob": 0.0004503267991822213}, {"id": 268, "seek": 123016, "start": 1230.16, "end": 1236.2, "text": " and I'm going to do this in chunks of, in batches of 50,000 records, I'm going to do", "tokens": [293, 286, 478, 516, 281, 360, 341, 294, 24004, 295, 11, 294, 15245, 279, 295, 2625, 11, 1360, 7724, 11, 286, 478, 516, 281, 360], "temperature": 0.0, "avg_logprob": -0.20796905076208194, "compression_ratio": 1.8347457627118644, "no_speech_prob": 0.0006243174429982901}, {"id": 269, "seek": 123016, "start": 1236.2, "end": 1241.72, "text": " this 200 times, 50,000 records, 200 times, 10 million records, I'm going to be inserting", "tokens": [341, 2331, 1413, 11, 2625, 11, 1360, 7724, 11, 2331, 1413, 11, 1266, 2459, 7724, 11, 286, 478, 516, 281, 312, 46567], "temperature": 0.0, "avg_logprob": -0.20796905076208194, "compression_ratio": 1.8347457627118644, "no_speech_prob": 0.0006243174429982901}, {"id": 270, "seek": 123016, "start": 1241.72, "end": 1246.24, "text": " 10 million records on a device, on a table that doesn't exist, QuestDB will create it", "tokens": [1266, 2459, 7724, 322, 257, 4302, 11, 322, 257, 3199, 300, 1177, 380, 2514, 11, 8800, 27735, 486, 1884, 309], "temperature": 0.0, "avg_logprob": -0.20796905076208194, "compression_ratio": 1.8347457627118644, "no_speech_prob": 0.0006243174429982901}, {"id": 271, "seek": 123016, "start": 1246.24, "end": 1250.72, "text": " automatically when it starts receiving data, so if I run this scripting goal, which run", "tokens": [6772, 562, 309, 3719, 10040, 1412, 11, 370, 498, 286, 1190, 341, 5755, 278, 3387, 11, 597, 1190], "temperature": 0.0, "avg_logprob": -0.20796905076208194, "compression_ratio": 1.8347457627118644, "no_speech_prob": 0.0006243174429982901}, {"id": 272, "seek": 123016, "start": 1250.72, "end": 1257.88, "text": " doing go run, well don't go, so go run, it's ingesting data, it should take less than", "tokens": [884, 352, 1190, 11, 731, 500, 380, 352, 11, 370, 352, 1190, 11, 309, 311, 3957, 8714, 1412, 11, 309, 820, 747, 1570, 813], "temperature": 0.0, "avg_logprob": -0.20796905076208194, "compression_ratio": 1.8347457627118644, "no_speech_prob": 0.0006243174429982901}, {"id": 273, "seek": 125788, "start": 1257.88, "end": 1262.88, "text": " 10 seconds because we are ingesting 10 million, and that's finished, so let me just go to", "tokens": [1266, 3949, 570, 321, 366, 3957, 8714, 1266, 2459, 11, 293, 300, 311, 4335, 11, 370, 718, 385, 445, 352, 281], "temperature": 0.0, "avg_logprob": -0.19036177042368296, "compression_ratio": 1.644578313253012, "no_speech_prob": 0.000469341961434111}, {"id": 274, "seek": 125788, "start": 1262.88, "end": 1275.92, "text": " my local host here, let me just select, select how many records did we ingest it for, I have", "tokens": [452, 2654, 3975, 510, 11, 718, 385, 445, 3048, 11, 3048, 577, 867, 7724, 630, 321, 3957, 377, 309, 337, 11, 286, 362], "temperature": 0.0, "avg_logprob": -0.19036177042368296, "compression_ratio": 1.644578313253012, "no_speech_prob": 0.000469341961434111}, {"id": 275, "seek": 125788, "start": 1275.92, "end": 1283.3600000000001, "text": " to refresh the tables, okay, how many records I ingested, 10 million records, that's good,", "tokens": [281, 15134, 264, 8020, 11, 1392, 11, 577, 867, 7724, 286, 3957, 21885, 11, 1266, 2459, 7724, 11, 300, 311, 665, 11], "temperature": 0.0, "avg_logprob": -0.19036177042368296, "compression_ratio": 1.644578313253012, "no_speech_prob": 0.000469341961434111}, {"id": 276, "seek": 128336, "start": 1283.36, "end": 1293.12, "text": " can you tell me the interval, so I can see what happened here, sampled by one second,", "tokens": [393, 291, 980, 385, 264, 15035, 11, 370, 286, 393, 536, 437, 2011, 510, 11, 3247, 15551, 538, 472, 1150, 11], "temperature": 0.0, "avg_logprob": -0.2719970781778552, "compression_ratio": 1.7715736040609138, "no_speech_prob": 0.0006042015156708658}, {"id": 277, "seek": 128336, "start": 1293.12, "end": 1298.12, "text": " and it's telling me, yeah, you know, in the first second only half a million, because", "tokens": [293, 309, 311, 3585, 385, 11, 1338, 11, 291, 458, 11, 294, 264, 700, 1150, 787, 1922, 257, 2459, 11, 570], "temperature": 0.0, "avg_logprob": -0.2719970781778552, "compression_ratio": 1.7715736040609138, "no_speech_prob": 0.0006042015156708658}, {"id": 278, "seek": 128336, "start": 1298.12, "end": 1302.6799999999998, "text": " we, we then started at the top of the second, it was probably at second or something, but", "tokens": [321, 11, 321, 550, 1409, 412, 264, 1192, 295, 264, 1150, 11, 309, 390, 1391, 412, 1150, 420, 746, 11, 457], "temperature": 0.0, "avg_logprob": -0.2719970781778552, "compression_ratio": 1.7715736040609138, "no_speech_prob": 0.0006042015156708658}, {"id": 279, "seek": 128336, "start": 1302.6799999999998, "end": 1308.9599999999998, "text": " after that, one million, one million, one million, ten, one, you see, you see the idea,", "tokens": [934, 300, 11, 472, 2459, 11, 472, 2459, 11, 472, 2459, 11, 2064, 11, 472, 11, 291, 536, 11, 291, 536, 264, 1558, 11], "temperature": 0.0, "avg_logprob": -0.2719970781778552, "compression_ratio": 1.7715736040609138, "no_speech_prob": 0.0006042015156708658}, {"id": 280, "seek": 130896, "start": 1308.96, "end": 1317.44, "text": " okay, that's not too bad, I can do this slightly better, I can run this script actually twice", "tokens": [1392, 11, 300, 311, 406, 886, 1578, 11, 286, 393, 360, 341, 4748, 1101, 11, 286, 393, 1190, 341, 5755, 767, 6091], "temperature": 0.0, "avg_logprob": -0.12198801429904237, "compression_ratio": 1.6962616822429906, "no_speech_prob": 0.00017830025171861053}, {"id": 281, "seek": 130896, "start": 1317.44, "end": 1324.0, "text": " ingesting in the same instant to two different tables, so now, if I refresh, I should see", "tokens": [3957, 8714, 294, 264, 912, 9836, 281, 732, 819, 8020, 11, 370, 586, 11, 498, 286, 15134, 11, 286, 820, 536], "temperature": 0.0, "avg_logprob": -0.12198801429904237, "compression_ratio": 1.6962616822429906, "no_speech_prob": 0.00017830025171861053}, {"id": 282, "seek": 130896, "start": 1324.0, "end": 1330.6000000000001, "text": " I have two tables, not only one, so I have two tables here, same hardware and everything,", "tokens": [286, 362, 732, 8020, 11, 406, 787, 472, 11, 370, 286, 362, 732, 8020, 510, 11, 912, 8837, 293, 1203, 11], "temperature": 0.0, "avg_logprob": -0.12198801429904237, "compression_ratio": 1.6962616822429906, "no_speech_prob": 0.00017830025171861053}, {"id": 283, "seek": 130896, "start": 1330.6000000000001, "end": 1338.24, "text": " if I run again, I'm going to select only the last 10 rows, so we only see the latest run,", "tokens": [498, 286, 1190, 797, 11, 286, 478, 516, 281, 3048, 787, 264, 1036, 1266, 13241, 11, 370, 321, 787, 536, 264, 6792, 1190, 11], "temperature": 0.0, "avg_logprob": -0.12198801429904237, "compression_ratio": 1.6962616822429906, "no_speech_prob": 0.00017830025171861053}, {"id": 284, "seek": 133824, "start": 1338.24, "end": 1342.92, "text": " so you can see it's just lower now, I was actually ingesting to two tables, so I'm ingesting", "tokens": [370, 291, 393, 536, 309, 311, 445, 3126, 586, 11, 286, 390, 767, 3957, 8714, 281, 732, 8020, 11, 370, 286, 478, 3957, 8714], "temperature": 0.0, "avg_logprob": -0.13113238510576267, "compression_ratio": 1.7661691542288558, "no_speech_prob": 9.537111327517778e-05}, {"id": 285, "seek": 133824, "start": 1342.92, "end": 1349.32, "text": " only 700,000 per second, something like that, but if I go to the same time to the other", "tokens": [787, 15204, 11, 1360, 680, 1150, 11, 746, 411, 300, 11, 457, 498, 286, 352, 281, 264, 912, 565, 281, 264, 661], "temperature": 0.0, "avg_logprob": -0.13113238510576267, "compression_ratio": 1.7661691542288558, "no_speech_prob": 9.537111327517778e-05}, {"id": 286, "seek": 133824, "start": 1349.32, "end": 1357.04, "text": " table, I can just do a union, if I go to the other table here, you should see that at the", "tokens": [3199, 11, 286, 393, 445, 360, 257, 11671, 11, 498, 286, 352, 281, 264, 661, 3199, 510, 11, 291, 820, 536, 300, 412, 264], "temperature": 0.0, "avg_logprob": -0.13113238510576267, "compression_ratio": 1.7661691542288558, "no_speech_prob": 9.537111327517778e-05}, {"id": 287, "seek": 133824, "start": 1357.04, "end": 1365.36, "text": " same time in the, oh yeah, I cannot apply limit here, sorry, in a union, so I should", "tokens": [912, 565, 294, 264, 11, 1954, 1338, 11, 286, 2644, 3079, 4948, 510, 11, 2597, 11, 294, 257, 11671, 11, 370, 286, 820], "temperature": 0.0, "avg_logprob": -0.13113238510576267, "compression_ratio": 1.7661691542288558, "no_speech_prob": 9.537111327517778e-05}, {"id": 288, "seek": 136536, "start": 1365.36, "end": 1371.28, "text": " see that, you know, even if I was going slower, the other table was reading data, and in this", "tokens": [536, 300, 11, 291, 458, 11, 754, 498, 286, 390, 516, 14009, 11, 264, 661, 3199, 390, 3760, 1412, 11, 293, 294, 341], "temperature": 0.0, "avg_logprob": -0.15550462567076392, "compression_ratio": 1.7087378640776698, "no_speech_prob": 0.00011359739437466487}, {"id": 289, "seek": 136536, "start": 1371.28, "end": 1375.4399999999998, "text": " format you cannot see it very well, but we can do something I told you earlier, I can", "tokens": [7877, 291, 2644, 536, 309, 588, 731, 11, 457, 321, 393, 360, 746, 286, 1907, 291, 3071, 11, 286, 393], "temperature": 0.0, "avg_logprob": -0.15550462567076392, "compression_ratio": 1.7087378640776698, "no_speech_prob": 0.00011359739437466487}, {"id": 290, "seek": 136536, "start": 1375.4399999999998, "end": 1384.1599999999999, "text": " just rather than do a join, I can just do something like, as of join, the first query", "tokens": [445, 2831, 813, 360, 257, 3917, 11, 286, 393, 445, 360, 746, 411, 11, 382, 295, 3917, 11, 264, 700, 14581], "temperature": 0.0, "avg_logprob": -0.15550462567076392, "compression_ratio": 1.7087378640776698, "no_speech_prob": 0.00011359739437466487}, {"id": 291, "seek": 136536, "start": 1384.1599999999999, "end": 1392.84, "text": " with the second, so I should be able to do this, now I have, in the first run, we were", "tokens": [365, 264, 1150, 11, 370, 286, 820, 312, 1075, 281, 360, 341, 11, 586, 286, 362, 11, 294, 264, 700, 1190, 11, 321, 645], "temperature": 0.0, "avg_logprob": -0.15550462567076392, "compression_ratio": 1.7087378640776698, "no_speech_prob": 0.00011359739437466487}, {"id": 292, "seek": 139284, "start": 1392.84, "end": 1399.08, "text": " running only one instance of sending data, and this one is the one in which I was running", "tokens": [2614, 787, 472, 5197, 295, 7750, 1412, 11, 293, 341, 472, 307, 264, 472, 294, 597, 286, 390, 2614], "temperature": 0.0, "avg_logprob": -0.15399585758243595, "compression_ratio": 1.6477272727272727, "no_speech_prob": 0.0002102978905895725}, {"id": 293, "seek": 139284, "start": 1399.08, "end": 1405.0, "text": " two, so you can see, for this particular second, we were ingesting 700,000 records", "tokens": [732, 11, 370, 291, 393, 536, 11, 337, 341, 1729, 1150, 11, 321, 645, 3957, 8714, 15204, 11, 1360, 7724], "temperature": 0.0, "avg_logprob": -0.15399585758243595, "compression_ratio": 1.6477272727272727, "no_speech_prob": 0.0002102978905895725}, {"id": 294, "seek": 139284, "start": 1405.0, "end": 1411.0, "text": " in one, 700,000 records in the other same time, so about 1.4 something million in total", "tokens": [294, 472, 11, 15204, 11, 1360, 7724, 294, 264, 661, 912, 565, 11, 370, 466, 502, 13, 19, 746, 2459, 294, 3217], "temperature": 0.0, "avg_logprob": -0.15399585758243595, "compression_ratio": 1.6477272727272727, "no_speech_prob": 0.0002102978905895725}, {"id": 295, "seek": 139284, "start": 1411.0, "end": 1416.72, "text": " because we're in different tables, out of the box, if I configure the writers and how", "tokens": [570, 321, 434, 294, 819, 8020, 11, 484, 295, 264, 2424, 11, 498, 286, 22162, 264, 13491, 293, 577], "temperature": 0.0, "avg_logprob": -0.15399585758243595, "compression_ratio": 1.6477272727272727, "no_speech_prob": 0.0002102978905895725}, {"id": 296, "seek": 139284, "start": 1416.72, "end": 1421.8, "text": " many threads I have for processing things, I can get it slightly faster than this, okay,", "tokens": [867, 19314, 286, 362, 337, 9007, 721, 11, 286, 393, 483, 309, 4748, 4663, 813, 341, 11, 1392, 11], "temperature": 0.0, "avg_logprob": -0.15399585758243595, "compression_ratio": 1.6477272727272727, "no_speech_prob": 0.0002102978905895725}, {"id": 297, "seek": 142180, "start": 1421.8, "end": 1427.56, "text": " but that's good enough, on a local, M1 laptop SSD, it's fast, but that's the idea, okay,", "tokens": [457, 300, 311, 665, 1547, 11, 322, 257, 2654, 11, 376, 16, 10732, 30262, 11, 309, 311, 2370, 11, 457, 300, 311, 264, 1558, 11, 1392, 11], "temperature": 0.0, "avg_logprob": -0.19311560983732928, "compression_ratio": 1.7374517374517375, "no_speech_prob": 0.0002915229997597635}, {"id": 298, "seek": 142180, "start": 1427.56, "end": 1431.24, "text": " so that's the one million there, I was not lying, I was just, you know, telling you things,", "tokens": [370, 300, 311, 264, 472, 2459, 456, 11, 286, 390, 406, 8493, 11, 286, 390, 445, 11, 291, 458, 11, 3585, 291, 721, 11], "temperature": 0.0, "avg_logprob": -0.19311560983732928, "compression_ratio": 1.7374517374517375, "no_speech_prob": 0.0002915229997597635}, {"id": 299, "seek": 142180, "start": 1431.24, "end": 1436.76, "text": " I have only a few minutes, but that's cool, how we got here, first, we can do a lot of", "tokens": [286, 362, 787, 257, 1326, 2077, 11, 457, 300, 311, 1627, 11, 577, 321, 658, 510, 11, 700, 11, 321, 393, 360, 257, 688, 295], "temperature": 0.0, "avg_logprob": -0.19311560983732928, "compression_ratio": 1.7374517374517375, "no_speech_prob": 0.0002915229997597635}, {"id": 300, "seek": 142180, "start": 1436.76, "end": 1443.48, "text": " assumptions about the data, this is time-serious, so we know people usually want to get not", "tokens": [17695, 466, 264, 1412, 11, 341, 307, 565, 12, 12484, 851, 11, 370, 321, 458, 561, 2673, 528, 281, 483, 406], "temperature": 0.0, "avg_logprob": -0.19311560983732928, "compression_ratio": 1.7374517374517375, "no_speech_prob": 0.0002915229997597635}, {"id": 301, "seek": 142180, "start": 1443.48, "end": 1450.36, "text": " individual rows, but computations over rows, we know people mostly want to group by things", "tokens": [2609, 13241, 11, 457, 2807, 763, 670, 13241, 11, 321, 458, 561, 5240, 528, 281, 1594, 538, 721], "temperature": 0.0, "avg_logprob": -0.19311560983732928, "compression_ratio": 1.7374517374517375, "no_speech_prob": 0.0002915229997597635}, {"id": 302, "seek": 145036, "start": 1450.36, "end": 1455.84, "text": " that are in the data, like strings, like the country name or the device name or the brand", "tokens": [300, 366, 294, 264, 1412, 11, 411, 13985, 11, 411, 264, 1941, 1315, 420, 264, 4302, 1315, 420, 264, 3360], "temperature": 0.0, "avg_logprob": -0.14714596966120203, "compression_ratio": 1.8714285714285714, "no_speech_prob": 0.0003293732588645071}, {"id": 303, "seek": 145036, "start": 1455.84, "end": 1460.84, "text": " or whatever, so instead of storing strings, we have a special symbol, which is called", "tokens": [420, 2035, 11, 370, 2602, 295, 26085, 13985, 11, 321, 362, 257, 2121, 5986, 11, 597, 307, 1219], "temperature": 0.0, "avg_logprob": -0.14714596966120203, "compression_ratio": 1.8714285714285714, "no_speech_prob": 0.0003293732588645071}, {"id": 304, "seek": 145036, "start": 1460.84, "end": 1465.08, "text": " a special type, which is called a symbol, if you give me a string, we convert into a", "tokens": [257, 2121, 2010, 11, 597, 307, 1219, 257, 5986, 11, 498, 291, 976, 385, 257, 6798, 11, 321, 7620, 666, 257], "temperature": 0.0, "avg_logprob": -0.14714596966120203, "compression_ratio": 1.8714285714285714, "no_speech_prob": 0.0003293732588645071}, {"id": 305, "seek": 145036, "start": 1465.08, "end": 1469.36, "text": " number and we do look up automatically those things, so we can make a lot of assumptions", "tokens": [1230, 293, 321, 360, 574, 493, 6772, 729, 721, 11, 370, 321, 393, 652, 257, 688, 295, 17695], "temperature": 0.0, "avg_logprob": -0.14714596966120203, "compression_ratio": 1.8714285714285714, "no_speech_prob": 0.0003293732588645071}, {"id": 306, "seek": 145036, "start": 1469.36, "end": 1474.8, "text": " because we hyper-specialize on one particular use case, we optimize storage, we don't use", "tokens": [570, 321, 9848, 12, 7053, 1013, 1125, 322, 472, 1729, 764, 1389, 11, 321, 19719, 6725, 11, 321, 500, 380, 764], "temperature": 0.0, "avg_logprob": -0.14714596966120203, "compression_ratio": 1.8714285714285714, "no_speech_prob": 0.0003293732588645071}, {"id": 307, "seek": 145036, "start": 1474.8, "end": 1480.1999999999998, "text": " indexes because we store everything always in incremental order per partition, if we", "tokens": [8186, 279, 570, 321, 3531, 1203, 1009, 294, 35759, 1668, 680, 24808, 11, 498, 321], "temperature": 0.0, "avg_logprob": -0.14714596966120203, "compression_ratio": 1.8714285714285714, "no_speech_prob": 0.0003293732588645071}, {"id": 308, "seek": 148020, "start": 1480.2, "end": 1485.04, "text": " get data out of order, we have to regret the partitions, but we don't need indexes because", "tokens": [483, 1412, 484, 295, 1668, 11, 321, 362, 281, 10879, 264, 644, 2451, 11, 457, 321, 500, 380, 643, 8186, 279, 570], "temperature": 0.0, "avg_logprob": -0.18800494545384458, "compression_ratio": 1.6159420289855073, "no_speech_prob": 0.0003129355318378657}, {"id": 309, "seek": 148020, "start": 1485.04, "end": 1489.88, "text": " we always have the data physically in order, so we can scan super quickly back and forth,", "tokens": [321, 1009, 362, 264, 1412, 9762, 294, 1668, 11, 370, 321, 393, 11049, 1687, 2661, 646, 293, 5220, 11], "temperature": 0.0, "avg_logprob": -0.18800494545384458, "compression_ratio": 1.6159420289855073, "no_speech_prob": 0.0003129355318378657}, {"id": 310, "seek": 148020, "start": 1489.88, "end": 1495.0800000000002, "text": " that's kind of the idea, we also parallelize as much as we can using different things,", "tokens": [300, 311, 733, 295, 264, 1558, 11, 321, 611, 8952, 1125, 382, 709, 382, 321, 393, 1228, 819, 721, 11], "temperature": 0.0, "avg_logprob": -0.18800494545384458, "compression_ratio": 1.6159420289855073, "no_speech_prob": 0.0003129355318378657}, {"id": 311, "seek": 148020, "start": 1495.0800000000002, "end": 1500.2, "text": " this is written in Java and it's from scratch, you will see some databases which I love,", "tokens": [341, 307, 3720, 294, 10745, 293, 309, 311, 490, 8459, 11, 291, 486, 536, 512, 22380, 597, 286, 959, 11], "temperature": 0.0, "avg_logprob": -0.18800494545384458, "compression_ratio": 1.6159420289855073, "no_speech_prob": 0.0003129355318378657}, {"id": 312, "seek": 148020, "start": 1500.2, "end": 1505.3600000000001, "text": " like MongoDB, excellent database for content, they have a time-serious module, we use the", "tokens": [411, 48380, 27735, 11, 7103, 8149, 337, 2701, 11, 436, 362, 257, 565, 12, 12484, 851, 10088, 11, 321, 764, 264], "temperature": 0.0, "avg_logprob": -0.18800494545384458, "compression_ratio": 1.6159420289855073, "no_speech_prob": 0.0003129355318378657}, {"id": 313, "seek": 150536, "start": 1505.36, "end": 1511.28, "text": " same MongoDB collections for doing time-series, they cannot be as fast because they are using", "tokens": [912, 48380, 27735, 16641, 337, 884, 565, 12, 12484, 530, 11, 436, 2644, 312, 382, 2370, 570, 436, 366, 1228], "temperature": 0.0, "avg_logprob": -0.1808147430419922, "compression_ratio": 1.7297297297297298, "no_speech_prob": 0.00016639167733956128}, {"id": 314, "seek": 150536, "start": 1511.28, "end": 1516.8799999999999, "text": " exactly what they are using for content, it's very convenient, I can do everything, but", "tokens": [2293, 437, 436, 366, 1228, 337, 2701, 11, 309, 311, 588, 10851, 11, 286, 393, 360, 1203, 11, 457], "temperature": 0.0, "avg_logprob": -0.1808147430419922, "compression_ratio": 1.7297297297297298, "no_speech_prob": 0.00016639167733956128}, {"id": 315, "seek": 150536, "start": 1516.8799999999999, "end": 1520.84, "text": " same thing with other engines that are built on top of other things, we don't have any", "tokens": [912, 551, 365, 661, 12982, 300, 366, 3094, 322, 1192, 295, 661, 721, 11, 321, 500, 380, 362, 604], "temperature": 0.0, "avg_logprob": -0.1808147430419922, "compression_ratio": 1.7297297297297298, "no_speech_prob": 0.00016639167733956128}, {"id": 316, "seek": 150536, "start": 1520.84, "end": 1527.6399999999999, "text": " dependencies, everything is built for scratch, actually we are writing some of the libraries", "tokens": [36606, 11, 1203, 307, 3094, 337, 8459, 11, 767, 321, 366, 3579, 512, 295, 264, 15148], "temperature": 0.0, "avg_logprob": -0.1808147430419922, "compression_ratio": 1.7297297297297298, "no_speech_prob": 0.00016639167733956128}, {"id": 317, "seek": 150536, "start": 1527.6399999999999, "end": 1533.8, "text": " in Java like strings and loggers and so on to avoid conversions, there are things that", "tokens": [294, 10745, 411, 13985, 293, 450, 1615, 433, 293, 370, 322, 281, 5042, 42256, 11, 456, 366, 721, 300], "temperature": 0.0, "avg_logprob": -0.1808147430419922, "compression_ratio": 1.7297297297297298, "no_speech_prob": 0.00016639167733956128}, {"id": 318, "seek": 153380, "start": 1533.8, "end": 1539.28, "text": " we don't use, so we don't use them, we have libraries for strings, we have libraries for", "tokens": [321, 500, 380, 764, 11, 370, 321, 500, 380, 764, 552, 11, 321, 362, 15148, 337, 13985, 11, 321, 362, 15148, 337], "temperature": 0.0, "avg_logprob": -0.1875196749025637, "compression_ratio": 1.8902439024390243, "no_speech_prob": 0.0002522678696550429}, {"id": 319, "seek": 153380, "start": 1539.28, "end": 1545.28, "text": " memory management, we have libraries for absolutely everything, they are written in our own version,", "tokens": [4675, 4592, 11, 321, 362, 15148, 337, 3122, 1203, 11, 436, 366, 3720, 294, 527, 1065, 3037, 11], "temperature": 0.0, "avg_logprob": -0.1875196749025637, "compression_ratio": 1.8902439024390243, "no_speech_prob": 0.0002522678696550429}, {"id": 320, "seek": 153380, "start": 1545.28, "end": 1550.28, "text": " we had our own Justintine compiler because the original Justintine compiler in Java was", "tokens": [321, 632, 527, 1065, 1449, 686, 533, 31958, 570, 264, 3380, 1449, 686, 533, 31958, 294, 10745, 390], "temperature": 0.0, "avg_logprob": -0.1875196749025637, "compression_ratio": 1.8902439024390243, "no_speech_prob": 0.0002522678696550429}, {"id": 321, "seek": 153380, "start": 1550.28, "end": 1555.3999999999999, "text": " not performed enough for some of the parallelization inquiries wanted to do, so we wrote everything,", "tokens": [406, 10332, 1547, 337, 512, 295, 264, 8952, 2144, 13570, 38619, 1415, 281, 360, 11, 370, 321, 4114, 1203, 11], "temperature": 0.0, "avg_logprob": -0.1875196749025637, "compression_ratio": 1.8902439024390243, "no_speech_prob": 0.0002522678696550429}, {"id": 322, "seek": 153380, "start": 1555.3999999999999, "end": 1561.48, "text": " our Java is kind of weird, Jeremy can tell you more about that, it's super weird Java,", "tokens": [527, 10745, 307, 733, 295, 3657, 11, 17809, 393, 980, 291, 544, 466, 300, 11, 309, 311, 1687, 3657, 10745, 11], "temperature": 0.0, "avg_logprob": -0.1875196749025637, "compression_ratio": 1.8902439024390243, "no_speech_prob": 0.0002522678696550429}, {"id": 323, "seek": 156148, "start": 1561.48, "end": 1567.84, "text": " but it's still Java, that's kind of the idea, we even route our own input output functions,", "tokens": [457, 309, 311, 920, 10745, 11, 300, 311, 733, 295, 264, 1558, 11, 321, 754, 7955, 527, 1065, 4846, 5598, 6828, 11], "temperature": 0.0, "avg_logprob": -0.25544170497619, "compression_ratio": 1.7241379310344827, "no_speech_prob": 0.00038523515104316175}, {"id": 324, "seek": 156148, "start": 1567.84, "end": 1569.28, "text": " that's kind of a thing, why?", "tokens": [300, 311, 733, 295, 257, 551, 11, 983, 30], "temperature": 0.0, "avg_logprob": -0.25544170497619, "compression_ratio": 1.7241379310344827, "no_speech_prob": 0.00038523515104316175}, {"id": 325, "seek": 156148, "start": 1569.28, "end": 1576.4, "text": " Because we can get nanoseconds faster, this is log4j, log4j, we don't speak about log4j,", "tokens": [1436, 321, 393, 483, 14067, 541, 28750, 4663, 11, 341, 307, 3565, 19, 73, 11, 3565, 19, 73, 11, 321, 500, 380, 1710, 466, 3565, 19, 73, 11], "temperature": 0.0, "avg_logprob": -0.25544170497619, "compression_ratio": 1.7241379310344827, "no_speech_prob": 0.00038523515104316175}, {"id": 326, "seek": 156148, "start": 1576.4, "end": 1584.08, "text": " but this is awesome, but you know this is log4j, j for log4j, and this is the nanoseconds,", "tokens": [457, 341, 307, 3476, 11, 457, 291, 458, 341, 307, 3565, 19, 73, 11, 361, 337, 3565, 19, 73, 11, 293, 341, 307, 264, 14067, 541, 28750, 11], "temperature": 0.0, "avg_logprob": -0.25544170497619, "compression_ratio": 1.7241379310344827, "no_speech_prob": 0.00038523515104316175}, {"id": 327, "seek": 158408, "start": 1584.08, "end": 1592.6799999999998, "text": " the operations you can do in each nanosecond, so with log4j, login, integer, you can do", "tokens": [264, 7705, 291, 393, 360, 294, 1184, 14067, 541, 18882, 11, 370, 365, 3565, 19, 73, 11, 3565, 259, 11, 24922, 11, 291, 393, 360], "temperature": 0.0, "avg_logprob": -0.20703963077429569, "compression_ratio": 1.7414634146341463, "no_speech_prob": 8.830734441289678e-05}, {"id": 328, "seek": 158408, "start": 1592.6799999999998, "end": 1600.04, "text": " 82 operations per nanosecond, we can do 800 operations per nanosecond, which is, do you", "tokens": [29097, 7705, 680, 14067, 541, 18882, 11, 321, 393, 360, 13083, 7705, 680, 14067, 541, 18882, 11, 597, 307, 11, 360, 291], "temperature": 0.0, "avg_logprob": -0.20703963077429569, "compression_ratio": 1.7414634146341463, "no_speech_prob": 8.830734441289678e-05}, {"id": 329, "seek": 158408, "start": 1600.04, "end": 1605.48, "text": " have to go down to the nanosecond, if you are doing a CRUT application, probably not,", "tokens": [362, 281, 352, 760, 281, 264, 14067, 541, 18882, 11, 498, 291, 366, 884, 257, 14123, 8709, 3861, 11, 1391, 406, 11], "temperature": 0.0, "avg_logprob": -0.20703963077429569, "compression_ratio": 1.7414634146341463, "no_speech_prob": 8.830734441289678e-05}, {"id": 330, "seek": 158408, "start": 1605.48, "end": 1609.96, "text": " it really depends what you are building, that's kind of why we are writing things from scratch,", "tokens": [309, 534, 5946, 437, 291, 366, 2390, 11, 300, 311, 733, 295, 983, 321, 366, 3579, 721, 490, 8459, 11], "temperature": 0.0, "avg_logprob": -0.20703963077429569, "compression_ratio": 1.7414634146341463, "no_speech_prob": 8.830734441289678e-05}, {"id": 331, "seek": 160996, "start": 1609.96, "end": 1615.2, "text": " so basically the approach of QuestDB to performance, you know this, this is like, I don't know", "tokens": [370, 1936, 264, 3109, 295, 8800, 27735, 281, 3389, 11, 291, 458, 341, 11, 341, 307, 411, 11, 286, 500, 380, 458], "temperature": 0.0, "avg_logprob": -0.15263744465355733, "compression_ratio": 1.79, "no_speech_prob": 0.0008404030231758952}, {"id": 332, "seek": 160996, "start": 1615.2, "end": 1620.88, "text": " who you are, but I don't know you, but I will find you and I will kill you, that's kind", "tokens": [567, 291, 366, 11, 457, 286, 500, 380, 458, 291, 11, 457, 286, 486, 915, 291, 293, 286, 486, 1961, 291, 11, 300, 311, 733], "temperature": 0.0, "avg_logprob": -0.15263744465355733, "compression_ratio": 1.79, "no_speech_prob": 0.0008404030231758952}, {"id": 333, "seek": 160996, "start": 1620.88, "end": 1626.8, "text": " of the same approach I see on QuestDB team, they are like, I don't know, we can get faster", "tokens": [295, 264, 912, 3109, 286, 536, 322, 8800, 27735, 1469, 11, 436, 366, 411, 11, 286, 500, 380, 458, 11, 321, 393, 483, 4663], "temperature": 0.0, "avg_logprob": -0.15263744465355733, "compression_ratio": 1.79, "no_speech_prob": 0.0008404030231758952}, {"id": 334, "seek": 160996, "start": 1626.8, "end": 1632.24, "text": " at some obscure thing here, so that's kind of the idea, and we try to be a good team", "tokens": [412, 512, 34443, 551, 510, 11, 370, 300, 311, 733, 295, 264, 1558, 11, 293, 321, 853, 281, 312, 257, 665, 1469], "temperature": 0.0, "avg_logprob": -0.15263744465355733, "compression_ratio": 1.79, "no_speech_prob": 0.0008404030231758952}, {"id": 335, "seek": 163224, "start": 1632.24, "end": 1640.96, "text": " player, Jeremy here has contributed himself, only alone, the connectors for KafkaConnet,", "tokens": [4256, 11, 17809, 510, 575, 18434, 3647, 11, 787, 3312, 11, 264, 31865, 337, 47064, 9838, 7129, 11], "temperature": 0.0, "avg_logprob": -0.2051896734552069, "compression_ratio": 1.7177033492822966, "no_speech_prob": 0.0006456959526985884}, {"id": 336, "seek": 163224, "start": 1640.96, "end": 1646.28, "text": " connectors for Apache Flink, so we try to integrate with the rest of the ecosystem, we love it", "tokens": [31865, 337, 46597, 3235, 475, 11, 370, 321, 853, 281, 13365, 365, 264, 1472, 295, 264, 11311, 11, 321, 959, 309], "temperature": 0.0, "avg_logprob": -0.2051896734552069, "compression_ratio": 1.7177033492822966, "no_speech_prob": 0.0006456959526985884}, {"id": 337, "seek": 163224, "start": 1646.28, "end": 1652.48, "text": " if you try QuestDB, you are open source geeks, you like, we have stars, we like you have", "tokens": [498, 291, 853, 8800, 27735, 11, 291, 366, 1269, 4009, 1519, 24785, 11, 291, 411, 11, 321, 362, 6105, 11, 321, 411, 291, 362], "temperature": 0.0, "avg_logprob": -0.2051896734552069, "compression_ratio": 1.7177033492822966, "no_speech_prob": 0.0006456959526985884}, {"id": 338, "seek": 163224, "start": 1652.48, "end": 1658.16, "text": " stars, please contribute, please start on GitHub if you like it, we have a contributor", "tokens": [6105, 11, 1767, 10586, 11, 1767, 722, 322, 23331, 498, 291, 411, 309, 11, 321, 362, 257, 42859], "temperature": 0.0, "avg_logprob": -0.2051896734552069, "compression_ratio": 1.7177033492822966, "no_speech_prob": 0.0006456959526985884}, {"id": 339, "seek": 165816, "start": 1658.16, "end": 1664.4, "text": " to the Slack channel, we are quite friendly, we are fast, we work with interesting problems,", "tokens": [281, 264, 37211, 2269, 11, 321, 366, 1596, 9208, 11, 321, 366, 2370, 11, 321, 589, 365, 1880, 2740, 11], "temperature": 0.0, "avg_logprob": -0.22543877940024099, "compression_ratio": 1.5947712418300655, "no_speech_prob": 0.000786796270404011}, {"id": 340, "seek": 165816, "start": 1664.4, "end": 1669.6000000000001, "text": " if you like interesting problems, if you like weird Java, we would love to have you here,", "tokens": [498, 291, 411, 1880, 2740, 11, 498, 291, 411, 3657, 10745, 11, 321, 576, 959, 281, 362, 291, 510, 11], "temperature": 0.0, "avg_logprob": -0.22543877940024099, "compression_ratio": 1.5947712418300655, "no_speech_prob": 0.000786796270404011}, {"id": 341, "seek": 165816, "start": 1669.6000000000001, "end": 1672.24, "text": " so thank you very much, and I can take any questions outside.", "tokens": [370, 1309, 291, 588, 709, 11, 293, 286, 393, 747, 604, 1651, 2380, 13], "temperature": 0.0, "avg_logprob": -0.22543877940024099, "compression_ratio": 1.5947712418300655, "no_speech_prob": 0.000786796270404011}, {"id": 342, "seek": 167224, "start": 1672.24, "end": 1690.92, "text": " Oh, one question for the chat, thank you, yeah, yeah, yeah, yeah, it's a, someone was", "tokens": [876, 11, 472, 1168, 337, 264, 5081, 11, 1309, 291, 11, 1338, 11, 1338, 11, 1338, 11, 1338, 11, 309, 311, 257, 11, 1580, 390], "temperature": 0.0, "avg_logprob": -0.38695180641030363, "compression_ratio": 1.4824561403508771, "no_speech_prob": 0.002189821330830455}, {"id": 343, "seek": 167224, "start": 1690.92, "end": 1696.42, "text": " asking, is QuestDB can work with GPS data, yes, you can work with GPS data, we have", "tokens": [3365, 11, 307, 8800, 27735, 393, 589, 365, 19462, 1412, 11, 2086, 11, 291, 393, 589, 365, 19462, 1412, 11, 321, 362], "temperature": 0.0, "avg_logprob": -0.38695180641030363, "compression_ratio": 1.4824561403508771, "no_speech_prob": 0.002189821330830455}, {"id": 344, "seek": 169642, "start": 1696.42, "end": 1703.5600000000002, "text": " doubles that we can use for that, we don't have a lot of geospatial functions, we have", "tokens": [31634, 300, 321, 393, 764, 337, 300, 11, 321, 500, 380, 362, 257, 688, 295, 1519, 2763, 267, 831, 6828, 11, 321, 362], "temperature": 0.0, "avg_logprob": -0.22210970232563634, "compression_ratio": 1.6635514018691588, "no_speech_prob": 0.0010023160139098763}, {"id": 345, "seek": 169642, "start": 1703.5600000000002, "end": 1710.0800000000002, "text": " geohashes, which basically allow you to define in which, at different resolutions, in which", "tokens": [1519, 1445, 12808, 11, 597, 1936, 2089, 291, 281, 6964, 294, 597, 11, 412, 819, 32179, 11, 294, 597], "temperature": 0.0, "avg_logprob": -0.22210970232563634, "compression_ratio": 1.6635514018691588, "no_speech_prob": 0.0010023160139098763}, {"id": 346, "seek": 169642, "start": 1710.0800000000002, "end": 1715.72, "text": " square in the world something is, so if you are talking about finding where a point is", "tokens": [3732, 294, 264, 1002, 746, 307, 11, 370, 498, 291, 366, 1417, 466, 5006, 689, 257, 935, 307], "temperature": 0.0, "avg_logprob": -0.22210970232563634, "compression_ratio": 1.6635514018691588, "no_speech_prob": 0.0010023160139098763}, {"id": 347, "seek": 169642, "start": 1715.72, "end": 1720.6000000000001, "text": " in the world, at a particular point in time, QuestDB is very cool, if you need to do other", "tokens": [294, 264, 1002, 11, 412, 257, 1729, 935, 294, 565, 11, 8800, 27735, 307, 588, 1627, 11, 498, 291, 643, 281, 360, 661], "temperature": 0.0, "avg_logprob": -0.22210970232563634, "compression_ratio": 1.6635514018691588, "no_speech_prob": 0.0010023160139098763}, {"id": 348, "seek": 172060, "start": 1720.6, "end": 1727.3999999999999, "text": " things, we support some math libraries, calls and all those things to do your own calculations,", "tokens": [721, 11, 321, 1406, 512, 5221, 15148, 11, 5498, 293, 439, 729, 721, 281, 360, 428, 1065, 20448, 11], "temperature": 0.0, "avg_logprob": -0.22763046465421977, "compression_ratio": 1.40625, "no_speech_prob": 0.0012055567931383848}, {"id": 349, "seek": 172060, "start": 1727.3999999999999, "end": 1731.4399999999998, "text": " but yeah, it can be used for GPS, and some people are, a lot of people are actually doing", "tokens": [457, 1338, 11, 309, 393, 312, 1143, 337, 19462, 11, 293, 512, 561, 366, 11, 257, 688, 295, 561, 366, 767, 884], "temperature": 0.0, "avg_logprob": -0.22763046465421977, "compression_ratio": 1.40625, "no_speech_prob": 0.0012055567931383848}, {"id": 350, "seek": 173144, "start": 1731.44, "end": 1753.92, "text": " asset tracking with QuestDB, thank you.", "tokens": [11999, 11603, 365, 8800, 27735, 11, 1309, 291, 13], "temperature": 0.0, "avg_logprob": -0.3988036742577186, "compression_ratio": 0.8297872340425532, "no_speech_prob": 0.0008954799268394709}], "language": "en"}