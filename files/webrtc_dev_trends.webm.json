{"text": " This is actually my first time at FOSDEM. I've been meeting to come here for many, many years, and Saul Lorenzo been bothering me that I should come here and speak. So I'm glad, actually, I finally made it. If you, I run a blog, WebRC hacks for developers. I got a lot of guest authors and I hope readers in the audience here. You might also recognize me if you watch YouTube videos about WebRC stuff. I do an event series and videos at Cranky Geek. But today, I'm here to talk about some trends I did by analyzing GitHub and similar repositories. I'll talk about that in a second. But before we start, what are some things that would be nice to know what's going on in the tree? I'm an analyst like to watch this stuff and write about it. So one, is the community still growing? What are some of the interesting projects? What are some of the new trends? Are people using things like WebCodex yet or not? So how do you go about doing that? Well, I came up with a, I have a methodology. It's largely based on BigQuery and there's a bunch actually, a bunch of providers give data to BigQuery or make their datasets public available there. So you can grab that. GitHub is definitely the best one, basically any time, any public repo, any time you do any kind of commit pull request issue that all gets sent and stored in a BigQuery database. There's actually some other datasets that are cool in there too. I've used in the past and I actually use Stack Overflow in this one. And I often cross-reference that with other sources like the Chrome platform status is a good way to see what actual APIs are being used, at least in the Chrome world. So you get all that data. I actually like to use Colab, which is just a Google's hosted Jupyter notebook type ecosystem to do the analysis and follow things. And then when I get frustrated about coding and doing stuff like making charts with Python, then I fall back to Excel for quick analysis. So some of the hard things about this and important to keep in mind about the analysis, you can't see it there. But all this is really based on regular expressions and pulling out keywords to identify a repo as WebRTC or something as one term or another. So that obviously has some flaws because there'd be false hits in there and you have to be careful with your selection. So a lot of the time I spend is actually just going through looking at the data to make sure it's not junk. And I found in the past, there's a lot of bots. So you gotta remove those things and these data sets themselves aren't perfect. There's always missing data or junk data. So keep that in mind. But I've been doing this occasionally more frequently now. Since 2015, I've been tweaking the methodology along the way. It's held up so far, but always open to feedback. So let's just dive in. How are we doing here in WebRTC? So this just looks since 2019. I don't think it's a big surprise to anyone. But there was a peak during the pandemic. So you can see here, it's actually April of that year. And this particular graph shows distinct users, right? So anybody like anyone on GitHub, just based on unique GitHub IDs per period in there, so that was over 10,000 in April. But if you look here, actually, we're not doing so bad. This is bad data, I was missing that month. We're not actually doing so bad here, but we're only about 60% of past peak. So it's still pretty above where we were before the pandemic. But another thing I find actually very interesting is also because you can look at these events, who's actually contributing, right? And you can look at the blog, I'll have some links to more on the methodology. But essentially, people doing pull requests, pull requests reviews. That sort of thing that counts as a contributor, right? And actually contributors, if you believe me, are actually up more than ever. So first, one interesting point here you can see. So there was a peak number of users in April, but actually the peak contributions, it was in actually May. And maybe that makes sense, like people during the pandemic, got an issue in WebRTC, start looking at it, they maybe could star a repo, get involved, but then it takes them a few weeks actually before they actually contribute, start adding things into that repo. But as I said here, our most recent peak here was actually in August. And we're not actually too far off for the rest of the year looking at that. So I want to look into see what was going on and compare these two peaks. So one is this is actually from the August peak, I dug into the sea. Where's some of the repos that we're actually having, I had the most activity. And one of them, very popular WebRTC project is Coturn, the open source kind of stone and turn server. And actually one of my co-workers Gustavo took over that project. So I asked him what was going on here, what happened, why do we have such a big spike in this and wrote a whole blog post about it. But essentially, that project was kind of stale, not a lot of activity for a while, he and Pavel took that over and then started really get the community involved and there's a huge spike and things like that. So then I wondered, is basically is this, sorry, is the other peaks in August in here because of spikes? Or is there a lot of regular activity? You can see here, interestingly, you see things like AdGuard is always high in there. Like people actually plan to block WebRTC and its usage, right? But they have a lot of activity every month around that. But actually it wasn't actually, you see some commonality, but some difference here. And, sorry, but when you actually look at the distributions and the change between April of 2020 and August of 2022, the actual distributions across the top 10, top 20, top 100, they're actually not a whole lot different. So what does this all mean? It's like actually the WebRTC development actually is not really getting a lot more concentrated. You can look for a given period of time. Obviously some projects are doing more popular and doing well, have more activity than others. But overall, it's not like we're consolidating down to a few projects, right? It's the same kind of more equal distribution that's existed at least for several years now. So another data set, and this is actually a new one I hadn't looked at before, is Stack Overflow. So I zoomed in to take a look at that. And that's to see if this follows a similar pattern. Now bear in mind compared to the previous charts, this goes back all the way to 2012, so it's a much longer data period. And you can see here, this is comments on Stack Overflow questions and actually the questions themselves. And unfortunately, you can't see the font too much of answers within Stack Overflow, but it essentially looks very similar to the questions side of things. And you can see very similar here, peak in April of 2020. Also, unlike the GitHub analysis, this actually shows a peak and is here also in April of 2022. I didn't have a chance to dig into to see what was driving that particular peak this year. But overall, I think you can see it's a little bit harder compared to the other one, but we're still generally up compared to prior to the pandemic in terms of questions and answers. And actually, it's a pretty good sign that there's a lot of activity there. And I also just took a look to see as a percentage of all the questions on Stack Overflow, what percentage of them had at least something that mentioned WebRTC or one of these terms? And very surprising, actually, it's actually very high. So it's something like one in, during the pandemic, it was one out of every 1400 questions on Stack Overflow had something that mentioned WebRTC, which that seems like quite a bit because I still consider WebRTC kind of a very niche sort of thing. And even if you look today, just in the last data point in this one is November, at that point it was still one in, I'm sorry, it was one in 900 during the peak of April of 2020. It's still one in 1400 today, which was still actually very high. So you can see, you can interpret this two ways. One, WebRTC is very confusing and people have a lot of questions. So you need to comment on it, or you can also see there's a lot of people involved. I think both are good, right? But yeah. So also very interesting that can we look at this data set to understand development trends, what's going on in the market. And one of the very interesting things I always like to look at is what are some of the language trends, programming languages that people are using. And this is a jumble and hard to see, so let's actually zoom in. So one of the ones I've been trying to track for a while is JavaScript versus TypeScript. I've been delaying, converting to TypeScript and I'm kind of wondering, do I need to, is it time for me to really switch over or can I wait a little bit longer? You can see here, well, obviously TypeScript's been getting more popular. We just, you know, just in December reached the 50-50 point, right? Where, you know, all these repos where TypeScript's half. So I think I'm probably behind it and need to switch. So there's also, at this conference, a bunch of exciting new languages that are coming out. So I wanted to zoom in and kind of take a look to see what's going on with them. So, you know, Go, Kotlin and Rust in particular. So I will say one of the challenges, I didn't get any chance to filter this out, but this Go jump from November to December is some bots. So that's just bot activity. So you can, yeah, I thought originally maybe it's just Christmas and Go developers don't have anything better to do. So over the holidays, you know, they're just programming a lot and starting a lot of new repos. That wasn't, it was actually, it was some bugs. But you can see here, you know, steadily increasing. It's not a huge, huge spike for these other, these other two, but it is going up. But as a new language that's getting popular, I guess you'd expect to see more of that. So in addition to languages, also there's a bunch of the new APIs, some that were referenced earlier today. So Insertable Streams is one such API, and that's actually two sub-APIs, a media stream track processor and track generator. First took a look on Chrome status, actually credit to Fippo, you know, Phil Hankey for having a, he built a custom viewer of the Chrome status information that you can see or so compare them both at the same time. You can see that, you know, these are actually peaking, you know, quite a bit towards the end of the year going up quite a bit. So I was curious, like, who, you know, can we see our open source repos actually using these or is it somebody else? And looking at it, you know, there's a big spike here, but it doesn't look like much. So what's going on there? Zoom in a little bit more, and again, apologies, it's really small, but like that initial spike, a lot of that was just pure standards related activity of the W3C repos and WebKit and others that are just basically adopting, you know, adopting those APIs in the first place. So you see a big jump. After that, it's really kind of hit or miss, and I was, I mean, I love working with Insertable Streams, you know, let's see, do a lot of fun stuff. So hoping to see more, but it's kind of just spotty. So, you know, going back to the Chrome status, what does that mean? Well, at least people that are using it are probably someone like Google Meet, sort of thing that don't have public repos, right? Or there's something else outside of the public GitHub data set that's driving that usage. So another one is Web Codex. It's another one. This one doesn't have quite the same peak. It's a little bit, you know, Web Codex is not quite as far along, but they're still driving up. You want to see if there's something going on here too. And again, you see gradual increase, not a ton, except for this one spike. And this one spike, again, was largely related to, you know, the initial standards release of WebKit and W3C type repos and related once to deploy that. So we see some uptick, but nothing all that significant yet. And for the last section, I was also wondering, is WebRC winning? Like, we don't talk a whole lot about WebRC having competition so much anymore, at least I haven't. But in the early days, it was always, you know, WebRC versus SIP. And is it, you know, should SIP, you know, those SIP type developers, that ecosystems, should they shift over to WebRTC? And we haven't seen that a whole lot, but I think in reality, there still is competition. And that is certainly during the pandemic, you know, well, it's Zoom, right? And I actually presented this a couple of years ago at Dan's conference, an interesting fact where, you know, there was a month in time where Zoom was worth more than the seventh largest Analyze put together, at least our market capitalization, which is still insane when you think about it, right? But, you know, that was the reality. So I did want to check to see if that's still the case, and it's not, right? So, yeah, Zoom is, you know, using next to the same data point and just extending it out, you know, a little bit further, you know, Zoom's down near 80% where they were back in February of 2020. The airlines, though, aren't actually doing all that much better, right? So still relative, Zoom's not doing some bad relative to the airlines, at least those same seven. But anyway, Zoom, not quite what it was, but they still really are competition, right? And particularly because Zoom now has released a Zoom SDK, and they have a Web version of this SDK. So as a developer, you do have a choice. Hey, I want to go build a real-time communications application. You can choose to use the WebRC and, you know, all the vendors in the ecosystem, or you can go to choose Zoom for this. And I was curious, in Zoom's marketing, it's a lot. I'll probably have a post on WebRC hacks with football, hopefully in a few weeks that, you know, where Zoom's been promoting the benefits of this. And it's a, I'll go into why that's not completely true. During the post. But I wanted to see our developers actually choosing Zoom over, or at least mentioning the Zoom SDK over WebRC. It was going to take me a while to dig into all this on the GitHub analysis. It wasn't clear, so I didn't include that part yet. But on Stack Overflow, it's pretty actually clear. There's a distinct Zoom SDK tag or label that they have there. And you can see here, actually, at least for now, WebRC is still way more popular than the Zoom SDK. Two minutes, okay. And actually, I am done. So I guess what we've learned here, I mean, part of it is what are your expectations here? I didn't necessarily go into any expectations other than I was interested to see what are some of the trends and can we find or like learn things about new APIs or new repos. And I do go through the list, actually, is interesting to see new projects. Didn't have time to fit all that stuff in there. But again, you can reference some of the blog posts on this. But overall, my impression of WebRC is still doing pretty well. Obviously, it's not pandemic well. But given the circumstances, we're better than it was before the pandemic. We have more developers involved and it seems that developers that are involved, it is a lot of measures to say that they're more mature. They're better developers, right? They're contributing more than in the past. And I think that's a great thing.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 8.16, "text": " This is actually my first time at FOSDEM.", "tokens": [50364, 639, 307, 767, 452, 700, 565, 412, 479, 4367, 35, 6683, 13, 50772], "temperature": 0.0, "avg_logprob": -0.36450911541374365, "compression_ratio": 1.481818181818182, "no_speech_prob": 0.2053619921207428}, {"id": 1, "seek": 0, "start": 8.16, "end": 12.52, "text": " I've been meeting to come here for many, many years,", "tokens": [50772, 286, 600, 668, 3440, 281, 808, 510, 337, 867, 11, 867, 924, 11, 50990], "temperature": 0.0, "avg_logprob": -0.36450911541374365, "compression_ratio": 1.481818181818182, "no_speech_prob": 0.2053619921207428}, {"id": 2, "seek": 0, "start": 12.52, "end": 15.72, "text": " and Saul Lorenzo been bothering me that I should come here and speak.", "tokens": [50990, 293, 6299, 425, 37162, 4765, 668, 31432, 385, 300, 286, 820, 808, 510, 293, 1710, 13, 51150], "temperature": 0.0, "avg_logprob": -0.36450911541374365, "compression_ratio": 1.481818181818182, "no_speech_prob": 0.2053619921207428}, {"id": 3, "seek": 0, "start": 15.72, "end": 18.36, "text": " So I'm glad, actually, I finally made it.", "tokens": [51150, 407, 286, 478, 5404, 11, 767, 11, 286, 2721, 1027, 309, 13, 51282], "temperature": 0.0, "avg_logprob": -0.36450911541374365, "compression_ratio": 1.481818181818182, "no_speech_prob": 0.2053619921207428}, {"id": 4, "seek": 0, "start": 18.36, "end": 23.96, "text": " If you, I run a blog, WebRC hacks for developers.", "tokens": [51282, 759, 291, 11, 286, 1190, 257, 6968, 11, 9573, 49, 34, 33617, 337, 8849, 13, 51562], "temperature": 0.0, "avg_logprob": -0.36450911541374365, "compression_ratio": 1.481818181818182, "no_speech_prob": 0.2053619921207428}, {"id": 5, "seek": 0, "start": 23.96, "end": 28.88, "text": " I got a lot of guest authors and I hope readers in the audience here.", "tokens": [51562, 286, 658, 257, 688, 295, 8341, 16552, 293, 286, 1454, 17147, 294, 264, 4034, 510, 13, 51808], "temperature": 0.0, "avg_logprob": -0.36450911541374365, "compression_ratio": 1.481818181818182, "no_speech_prob": 0.2053619921207428}, {"id": 6, "seek": 2888, "start": 28.88, "end": 33.8, "text": " You might also recognize me if you watch YouTube videos about WebRC stuff.", "tokens": [50364, 509, 1062, 611, 5521, 385, 498, 291, 1159, 3088, 2145, 466, 9573, 49, 34, 1507, 13, 50610], "temperature": 0.0, "avg_logprob": -0.23647011466648268, "compression_ratio": 1.5907335907335907, "no_speech_prob": 0.005213770549744368}, {"id": 7, "seek": 2888, "start": 33.8, "end": 37.56, "text": " I do an event series and videos at Cranky Geek.", "tokens": [50610, 286, 360, 364, 2280, 2638, 293, 2145, 412, 4779, 657, 88, 2876, 916, 13, 50798], "temperature": 0.0, "avg_logprob": -0.23647011466648268, "compression_ratio": 1.5907335907335907, "no_speech_prob": 0.005213770549744368}, {"id": 8, "seek": 2888, "start": 37.56, "end": 43.879999999999995, "text": " But today, I'm here to talk about some trends I did by", "tokens": [50798, 583, 965, 11, 286, 478, 510, 281, 751, 466, 512, 13892, 286, 630, 538, 51114], "temperature": 0.0, "avg_logprob": -0.23647011466648268, "compression_ratio": 1.5907335907335907, "no_speech_prob": 0.005213770549744368}, {"id": 9, "seek": 2888, "start": 43.879999999999995, "end": 46.36, "text": " analyzing GitHub and similar repositories.", "tokens": [51114, 23663, 23331, 293, 2531, 22283, 2083, 13, 51238], "temperature": 0.0, "avg_logprob": -0.23647011466648268, "compression_ratio": 1.5907335907335907, "no_speech_prob": 0.005213770549744368}, {"id": 10, "seek": 2888, "start": 46.36, "end": 47.08, "text": " I'll talk about that in a second.", "tokens": [51238, 286, 603, 751, 466, 300, 294, 257, 1150, 13, 51274], "temperature": 0.0, "avg_logprob": -0.23647011466648268, "compression_ratio": 1.5907335907335907, "no_speech_prob": 0.005213770549744368}, {"id": 11, "seek": 2888, "start": 47.08, "end": 48.64, "text": " But before we start,", "tokens": [51274, 583, 949, 321, 722, 11, 51352], "temperature": 0.0, "avg_logprob": -0.23647011466648268, "compression_ratio": 1.5907335907335907, "no_speech_prob": 0.005213770549744368}, {"id": 12, "seek": 2888, "start": 48.64, "end": 52.599999999999994, "text": " what are some things that would be nice to know what's going on in the tree?", "tokens": [51352, 437, 366, 512, 721, 300, 576, 312, 1481, 281, 458, 437, 311, 516, 322, 294, 264, 4230, 30, 51550], "temperature": 0.0, "avg_logprob": -0.23647011466648268, "compression_ratio": 1.5907335907335907, "no_speech_prob": 0.005213770549744368}, {"id": 13, "seek": 2888, "start": 52.599999999999994, "end": 56.239999999999995, "text": " I'm an analyst like to watch this stuff and write about it.", "tokens": [51550, 286, 478, 364, 19085, 411, 281, 1159, 341, 1507, 293, 2464, 466, 309, 13, 51732], "temperature": 0.0, "avg_logprob": -0.23647011466648268, "compression_ratio": 1.5907335907335907, "no_speech_prob": 0.005213770549744368}, {"id": 14, "seek": 5624, "start": 56.24, "end": 58.800000000000004, "text": " So one, is the community still growing?", "tokens": [50364, 407, 472, 11, 307, 264, 1768, 920, 4194, 30, 50492], "temperature": 0.0, "avg_logprob": -0.2473037222157354, "compression_ratio": 1.5931558935361216, "no_speech_prob": 0.0005701376940123737}, {"id": 15, "seek": 5624, "start": 58.800000000000004, "end": 60.440000000000005, "text": " What are some of the interesting projects?", "tokens": [50492, 708, 366, 512, 295, 264, 1880, 4455, 30, 50574], "temperature": 0.0, "avg_logprob": -0.2473037222157354, "compression_ratio": 1.5931558935361216, "no_speech_prob": 0.0005701376940123737}, {"id": 16, "seek": 5624, "start": 60.440000000000005, "end": 62.160000000000004, "text": " What are some of the new trends?", "tokens": [50574, 708, 366, 512, 295, 264, 777, 13892, 30, 50660], "temperature": 0.0, "avg_logprob": -0.2473037222157354, "compression_ratio": 1.5931558935361216, "no_speech_prob": 0.0005701376940123737}, {"id": 17, "seek": 5624, "start": 62.160000000000004, "end": 66.08, "text": " Are people using things like WebCodex yet or not?", "tokens": [50660, 2014, 561, 1228, 721, 411, 9573, 34, 1429, 87, 1939, 420, 406, 30, 50856], "temperature": 0.0, "avg_logprob": -0.2473037222157354, "compression_ratio": 1.5931558935361216, "no_speech_prob": 0.0005701376940123737}, {"id": 18, "seek": 5624, "start": 66.08, "end": 68.72, "text": " So how do you go about doing that?", "tokens": [50856, 407, 577, 360, 291, 352, 466, 884, 300, 30, 50988], "temperature": 0.0, "avg_logprob": -0.2473037222157354, "compression_ratio": 1.5931558935361216, "no_speech_prob": 0.0005701376940123737}, {"id": 19, "seek": 5624, "start": 68.72, "end": 72.36, "text": " Well, I came up with a, I have a methodology.", "tokens": [50988, 1042, 11, 286, 1361, 493, 365, 257, 11, 286, 362, 257, 24850, 13, 51170], "temperature": 0.0, "avg_logprob": -0.2473037222157354, "compression_ratio": 1.5931558935361216, "no_speech_prob": 0.0005701376940123737}, {"id": 20, "seek": 5624, "start": 72.36, "end": 77.12, "text": " It's largely based on BigQuery and there's a bunch actually,", "tokens": [51170, 467, 311, 11611, 2361, 322, 43422, 293, 456, 311, 257, 3840, 767, 11, 51408], "temperature": 0.0, "avg_logprob": -0.2473037222157354, "compression_ratio": 1.5931558935361216, "no_speech_prob": 0.0005701376940123737}, {"id": 21, "seek": 5624, "start": 77.12, "end": 82.68, "text": " a bunch of providers give data to BigQuery or make their datasets public available there.", "tokens": [51408, 257, 3840, 295, 11330, 976, 1412, 281, 43422, 420, 652, 641, 42856, 1908, 2435, 456, 13, 51686], "temperature": 0.0, "avg_logprob": -0.2473037222157354, "compression_ratio": 1.5931558935361216, "no_speech_prob": 0.0005701376940123737}, {"id": 22, "seek": 5624, "start": 82.68, "end": 83.68, "text": " So you can grab that.", "tokens": [51686, 407, 291, 393, 4444, 300, 13, 51736], "temperature": 0.0, "avg_logprob": -0.2473037222157354, "compression_ratio": 1.5931558935361216, "no_speech_prob": 0.0005701376940123737}, {"id": 23, "seek": 8368, "start": 83.68, "end": 85.72000000000001, "text": " GitHub is definitely the best one,", "tokens": [50364, 23331, 307, 2138, 264, 1151, 472, 11, 50466], "temperature": 0.0, "avg_logprob": -0.22882561934621712, "compression_ratio": 1.6223021582733812, "no_speech_prob": 0.0006875225808471441}, {"id": 24, "seek": 8368, "start": 85.72000000000001, "end": 88.56, "text": " basically any time, any public repo,", "tokens": [50466, 1936, 604, 565, 11, 604, 1908, 49040, 11, 50608], "temperature": 0.0, "avg_logprob": -0.22882561934621712, "compression_ratio": 1.6223021582733812, "no_speech_prob": 0.0006875225808471441}, {"id": 25, "seek": 8368, "start": 88.56, "end": 92.36000000000001, "text": " any time you do any kind of commit pull request issue that all gets", "tokens": [50608, 604, 565, 291, 360, 604, 733, 295, 5599, 2235, 5308, 2734, 300, 439, 2170, 50798], "temperature": 0.0, "avg_logprob": -0.22882561934621712, "compression_ratio": 1.6223021582733812, "no_speech_prob": 0.0006875225808471441}, {"id": 26, "seek": 8368, "start": 92.36000000000001, "end": 96.4, "text": " sent and stored in a BigQuery database.", "tokens": [50798, 2279, 293, 12187, 294, 257, 43422, 8149, 13, 51000], "temperature": 0.0, "avg_logprob": -0.22882561934621712, "compression_ratio": 1.6223021582733812, "no_speech_prob": 0.0006875225808471441}, {"id": 27, "seek": 8368, "start": 96.4, "end": 100.0, "text": " There's actually some other datasets that are cool in there too.", "tokens": [51000, 821, 311, 767, 512, 661, 42856, 300, 366, 1627, 294, 456, 886, 13, 51180], "temperature": 0.0, "avg_logprob": -0.22882561934621712, "compression_ratio": 1.6223021582733812, "no_speech_prob": 0.0006875225808471441}, {"id": 28, "seek": 8368, "start": 100.0, "end": 103.48, "text": " I've used in the past and I actually use Stack Overflow in this one.", "tokens": [51180, 286, 600, 1143, 294, 264, 1791, 293, 286, 767, 764, 37649, 4886, 10565, 294, 341, 472, 13, 51354], "temperature": 0.0, "avg_logprob": -0.22882561934621712, "compression_ratio": 1.6223021582733812, "no_speech_prob": 0.0006875225808471441}, {"id": 29, "seek": 8368, "start": 103.48, "end": 108.0, "text": " And I often cross-reference that with other sources like the Chrome platform status is", "tokens": [51354, 400, 286, 2049, 3278, 12, 265, 5158, 300, 365, 661, 7139, 411, 264, 15327, 3663, 6558, 307, 51580], "temperature": 0.0, "avg_logprob": -0.22882561934621712, "compression_ratio": 1.6223021582733812, "no_speech_prob": 0.0006875225808471441}, {"id": 30, "seek": 8368, "start": 108.0, "end": 111.76, "text": " a good way to see what actual APIs are being used,", "tokens": [51580, 257, 665, 636, 281, 536, 437, 3539, 21445, 366, 885, 1143, 11, 51768], "temperature": 0.0, "avg_logprob": -0.22882561934621712, "compression_ratio": 1.6223021582733812, "no_speech_prob": 0.0006875225808471441}, {"id": 31, "seek": 11176, "start": 111.96000000000001, "end": 114.28, "text": " at least in the Chrome world.", "tokens": [50374, 412, 1935, 294, 264, 15327, 1002, 13, 50490], "temperature": 0.0, "avg_logprob": -0.22148298509050124, "compression_ratio": 1.5708661417322836, "no_speech_prob": 0.00048772033187560737}, {"id": 32, "seek": 11176, "start": 115.64, "end": 118.24000000000001, "text": " So you get all that data.", "tokens": [50558, 407, 291, 483, 439, 300, 1412, 13, 50688], "temperature": 0.0, "avg_logprob": -0.22148298509050124, "compression_ratio": 1.5708661417322836, "no_speech_prob": 0.00048772033187560737}, {"id": 33, "seek": 11176, "start": 118.24000000000001, "end": 123.56, "text": " I actually like to use Colab, which is just a Google's hosted", "tokens": [50688, 286, 767, 411, 281, 764, 4004, 455, 11, 597, 307, 445, 257, 3329, 311, 19204, 50954], "temperature": 0.0, "avg_logprob": -0.22148298509050124, "compression_ratio": 1.5708661417322836, "no_speech_prob": 0.00048772033187560737}, {"id": 34, "seek": 11176, "start": 123.56, "end": 127.44, "text": " Jupyter notebook type ecosystem to do the analysis and follow things.", "tokens": [50954, 22125, 88, 391, 21060, 2010, 11311, 281, 360, 264, 5215, 293, 1524, 721, 13, 51148], "temperature": 0.0, "avg_logprob": -0.22148298509050124, "compression_ratio": 1.5708661417322836, "no_speech_prob": 0.00048772033187560737}, {"id": 35, "seek": 11176, "start": 127.44, "end": 131.52, "text": " And then when I get frustrated about coding and doing stuff like", "tokens": [51148, 400, 550, 562, 286, 483, 15751, 466, 17720, 293, 884, 1507, 411, 51352], "temperature": 0.0, "avg_logprob": -0.22148298509050124, "compression_ratio": 1.5708661417322836, "no_speech_prob": 0.00048772033187560737}, {"id": 36, "seek": 11176, "start": 131.52, "end": 137.20000000000002, "text": " making charts with Python, then I fall back to Excel for quick analysis.", "tokens": [51352, 1455, 17767, 365, 15329, 11, 550, 286, 2100, 646, 281, 19060, 337, 1702, 5215, 13, 51636], "temperature": 0.0, "avg_logprob": -0.22148298509050124, "compression_ratio": 1.5708661417322836, "no_speech_prob": 0.00048772033187560737}, {"id": 37, "seek": 11176, "start": 137.20000000000002, "end": 139.96, "text": " So some of the hard things about this and important to keep in mind about", "tokens": [51636, 407, 512, 295, 264, 1152, 721, 466, 341, 293, 1021, 281, 1066, 294, 1575, 466, 51774], "temperature": 0.0, "avg_logprob": -0.22148298509050124, "compression_ratio": 1.5708661417322836, "no_speech_prob": 0.00048772033187560737}, {"id": 38, "seek": 13996, "start": 139.96, "end": 141.48000000000002, "text": " the analysis, you can't see it there.", "tokens": [50364, 264, 5215, 11, 291, 393, 380, 536, 309, 456, 13, 50440], "temperature": 0.0, "avg_logprob": -0.1732514222462972, "compression_ratio": 1.6113074204946995, "no_speech_prob": 0.0016225442523136735}, {"id": 39, "seek": 13996, "start": 141.48000000000002, "end": 146.08, "text": " But all this is really based on regular expressions and pulling out", "tokens": [50440, 583, 439, 341, 307, 534, 2361, 322, 3890, 15277, 293, 8407, 484, 50670], "temperature": 0.0, "avg_logprob": -0.1732514222462972, "compression_ratio": 1.6113074204946995, "no_speech_prob": 0.0016225442523136735}, {"id": 40, "seek": 13996, "start": 146.08, "end": 154.24, "text": " keywords to identify a repo as WebRTC or something as one term or another.", "tokens": [50670, 21009, 281, 5876, 257, 49040, 382, 9573, 49, 18238, 420, 746, 382, 472, 1433, 420, 1071, 13, 51078], "temperature": 0.0, "avg_logprob": -0.1732514222462972, "compression_ratio": 1.6113074204946995, "no_speech_prob": 0.0016225442523136735}, {"id": 41, "seek": 13996, "start": 154.24, "end": 157.92000000000002, "text": " So that obviously has some flaws because there'd be false hits in there and", "tokens": [51078, 407, 300, 2745, 575, 512, 27108, 570, 456, 1116, 312, 7908, 8664, 294, 456, 293, 51262], "temperature": 0.0, "avg_logprob": -0.1732514222462972, "compression_ratio": 1.6113074204946995, "no_speech_prob": 0.0016225442523136735}, {"id": 42, "seek": 13996, "start": 157.92000000000002, "end": 159.4, "text": " you have to be careful with your selection.", "tokens": [51262, 291, 362, 281, 312, 5026, 365, 428, 9450, 13, 51336], "temperature": 0.0, "avg_logprob": -0.1732514222462972, "compression_ratio": 1.6113074204946995, "no_speech_prob": 0.0016225442523136735}, {"id": 43, "seek": 13996, "start": 159.4, "end": 161.76000000000002, "text": " So a lot of the time I spend is actually just going through looking at", "tokens": [51336, 407, 257, 688, 295, 264, 565, 286, 3496, 307, 767, 445, 516, 807, 1237, 412, 51454], "temperature": 0.0, "avg_logprob": -0.1732514222462972, "compression_ratio": 1.6113074204946995, "no_speech_prob": 0.0016225442523136735}, {"id": 44, "seek": 13996, "start": 161.76000000000002, "end": 163.4, "text": " the data to make sure it's not junk.", "tokens": [51454, 264, 1412, 281, 652, 988, 309, 311, 406, 19109, 13, 51536], "temperature": 0.0, "avg_logprob": -0.1732514222462972, "compression_ratio": 1.6113074204946995, "no_speech_prob": 0.0016225442523136735}, {"id": 45, "seek": 13996, "start": 163.4, "end": 166.24, "text": " And I found in the past, there's a lot of bots.", "tokens": [51536, 400, 286, 1352, 294, 264, 1791, 11, 456, 311, 257, 688, 295, 35410, 13, 51678], "temperature": 0.0, "avg_logprob": -0.1732514222462972, "compression_ratio": 1.6113074204946995, "no_speech_prob": 0.0016225442523136735}, {"id": 46, "seek": 16624, "start": 166.24, "end": 170.0, "text": " So you gotta remove those things and these data sets themselves aren't perfect.", "tokens": [50364, 407, 291, 3428, 4159, 729, 721, 293, 613, 1412, 6352, 2969, 3212, 380, 2176, 13, 50552], "temperature": 0.0, "avg_logprob": -0.18337173121316092, "compression_ratio": 1.5363984674329503, "no_speech_prob": 0.00021991955873090774}, {"id": 47, "seek": 16624, "start": 170.0, "end": 172.04000000000002, "text": " There's always missing data or junk data.", "tokens": [50552, 821, 311, 1009, 5361, 1412, 420, 19109, 1412, 13, 50654], "temperature": 0.0, "avg_logprob": -0.18337173121316092, "compression_ratio": 1.5363984674329503, "no_speech_prob": 0.00021991955873090774}, {"id": 48, "seek": 16624, "start": 172.04000000000002, "end": 174.32000000000002, "text": " So keep that in mind.", "tokens": [50654, 407, 1066, 300, 294, 1575, 13, 50768], "temperature": 0.0, "avg_logprob": -0.18337173121316092, "compression_ratio": 1.5363984674329503, "no_speech_prob": 0.00021991955873090774}, {"id": 49, "seek": 16624, "start": 174.32000000000002, "end": 178.44, "text": " But I've been doing this occasionally more frequently now.", "tokens": [50768, 583, 286, 600, 668, 884, 341, 16895, 544, 10374, 586, 13, 50974], "temperature": 0.0, "avg_logprob": -0.18337173121316092, "compression_ratio": 1.5363984674329503, "no_speech_prob": 0.00021991955873090774}, {"id": 50, "seek": 16624, "start": 178.44, "end": 181.84, "text": " Since 2015, I've been tweaking the methodology along the way.", "tokens": [50974, 4162, 7546, 11, 286, 600, 668, 6986, 2456, 264, 24850, 2051, 264, 636, 13, 51144], "temperature": 0.0, "avg_logprob": -0.18337173121316092, "compression_ratio": 1.5363984674329503, "no_speech_prob": 0.00021991955873090774}, {"id": 51, "seek": 16624, "start": 181.84, "end": 186.64000000000001, "text": " It's held up so far, but always open to feedback.", "tokens": [51144, 467, 311, 5167, 493, 370, 1400, 11, 457, 1009, 1269, 281, 5824, 13, 51384], "temperature": 0.0, "avg_logprob": -0.18337173121316092, "compression_ratio": 1.5363984674329503, "no_speech_prob": 0.00021991955873090774}, {"id": 52, "seek": 16624, "start": 186.64000000000001, "end": 188.0, "text": " So let's just dive in.", "tokens": [51384, 407, 718, 311, 445, 9192, 294, 13, 51452], "temperature": 0.0, "avg_logprob": -0.18337173121316092, "compression_ratio": 1.5363984674329503, "no_speech_prob": 0.00021991955873090774}, {"id": 53, "seek": 16624, "start": 188.0, "end": 189.8, "text": " How are we doing here in WebRTC?", "tokens": [51452, 1012, 366, 321, 884, 510, 294, 9573, 49, 18238, 30, 51542], "temperature": 0.0, "avg_logprob": -0.18337173121316092, "compression_ratio": 1.5363984674329503, "no_speech_prob": 0.00021991955873090774}, {"id": 54, "seek": 16624, "start": 191.12, "end": 193.64000000000001, "text": " So this just looks since 2019.", "tokens": [51608, 407, 341, 445, 1542, 1670, 6071, 13, 51734], "temperature": 0.0, "avg_logprob": -0.18337173121316092, "compression_ratio": 1.5363984674329503, "no_speech_prob": 0.00021991955873090774}, {"id": 55, "seek": 19364, "start": 193.64, "end": 196.83999999999997, "text": " I don't think it's a big surprise to anyone.", "tokens": [50364, 286, 500, 380, 519, 309, 311, 257, 955, 6365, 281, 2878, 13, 50524], "temperature": 0.0, "avg_logprob": -0.21099501389723557, "compression_ratio": 1.5735849056603775, "no_speech_prob": 0.00337539822794497}, {"id": 56, "seek": 19364, "start": 196.83999999999997, "end": 199.51999999999998, "text": " But there was a peak during the pandemic.", "tokens": [50524, 583, 456, 390, 257, 10651, 1830, 264, 5388, 13, 50658], "temperature": 0.0, "avg_logprob": -0.21099501389723557, "compression_ratio": 1.5735849056603775, "no_speech_prob": 0.00337539822794497}, {"id": 57, "seek": 19364, "start": 199.51999999999998, "end": 203.92, "text": " So you can see here, it's actually April of that year.", "tokens": [50658, 407, 291, 393, 536, 510, 11, 309, 311, 767, 6929, 295, 300, 1064, 13, 50878], "temperature": 0.0, "avg_logprob": -0.21099501389723557, "compression_ratio": 1.5735849056603775, "no_speech_prob": 0.00337539822794497}, {"id": 58, "seek": 19364, "start": 203.92, "end": 207.48, "text": " And this particular graph shows distinct users, right?", "tokens": [50878, 400, 341, 1729, 4295, 3110, 10644, 5022, 11, 558, 30, 51056], "temperature": 0.0, "avg_logprob": -0.21099501389723557, "compression_ratio": 1.5735849056603775, "no_speech_prob": 0.00337539822794497}, {"id": 59, "seek": 19364, "start": 207.48, "end": 212.39999999999998, "text": " So anybody like anyone on GitHub, just based on unique GitHub IDs per", "tokens": [51056, 407, 4472, 411, 2878, 322, 23331, 11, 445, 2361, 322, 3845, 23331, 48212, 680, 51302], "temperature": 0.0, "avg_logprob": -0.21099501389723557, "compression_ratio": 1.5735849056603775, "no_speech_prob": 0.00337539822794497}, {"id": 60, "seek": 19364, "start": 212.39999999999998, "end": 215.95999999999998, "text": " period in there, so that was over 10,000 in April.", "tokens": [51302, 2896, 294, 456, 11, 370, 300, 390, 670, 1266, 11, 1360, 294, 6929, 13, 51480], "temperature": 0.0, "avg_logprob": -0.21099501389723557, "compression_ratio": 1.5735849056603775, "no_speech_prob": 0.00337539822794497}, {"id": 61, "seek": 19364, "start": 215.95999999999998, "end": 218.76, "text": " But if you look here, actually, we're not doing so bad.", "tokens": [51480, 583, 498, 291, 574, 510, 11, 767, 11, 321, 434, 406, 884, 370, 1578, 13, 51620], "temperature": 0.0, "avg_logprob": -0.21099501389723557, "compression_ratio": 1.5735849056603775, "no_speech_prob": 0.00337539822794497}, {"id": 62, "seek": 19364, "start": 218.76, "end": 220.76, "text": " This is bad data, I was missing that month.", "tokens": [51620, 639, 307, 1578, 1412, 11, 286, 390, 5361, 300, 1618, 13, 51720], "temperature": 0.0, "avg_logprob": -0.21099501389723557, "compression_ratio": 1.5735849056603775, "no_speech_prob": 0.00337539822794497}, {"id": 63, "seek": 22076, "start": 221.32, "end": 227.64, "text": " We're not actually doing so bad here, but we're only about 60% of past peak.", "tokens": [50392, 492, 434, 406, 767, 884, 370, 1578, 510, 11, 457, 321, 434, 787, 466, 4060, 4, 295, 1791, 10651, 13, 50708], "temperature": 0.0, "avg_logprob": -0.2900911905233142, "compression_ratio": 1.6328125, "no_speech_prob": 0.0003149809781461954}, {"id": 64, "seek": 22076, "start": 227.64, "end": 232.04, "text": " So it's still pretty above where we were before the pandemic.", "tokens": [50708, 407, 309, 311, 920, 1238, 3673, 689, 321, 645, 949, 264, 5388, 13, 50928], "temperature": 0.0, "avg_logprob": -0.2900911905233142, "compression_ratio": 1.6328125, "no_speech_prob": 0.0003149809781461954}, {"id": 65, "seek": 22076, "start": 233.79999999999998, "end": 238.12, "text": " But another thing I find actually very interesting is also because you can look", "tokens": [51016, 583, 1071, 551, 286, 915, 767, 588, 1880, 307, 611, 570, 291, 393, 574, 51232], "temperature": 0.0, "avg_logprob": -0.2900911905233142, "compression_ratio": 1.6328125, "no_speech_prob": 0.0003149809781461954}, {"id": 66, "seek": 22076, "start": 238.12, "end": 240.07999999999998, "text": " at these events, who's actually contributing, right?", "tokens": [51232, 412, 613, 3931, 11, 567, 311, 767, 19270, 11, 558, 30, 51330], "temperature": 0.0, "avg_logprob": -0.2900911905233142, "compression_ratio": 1.6328125, "no_speech_prob": 0.0003149809781461954}, {"id": 67, "seek": 22076, "start": 240.07999999999998, "end": 245.28, "text": " And you can look at the blog, I'll have some links to more on the methodology.", "tokens": [51330, 400, 291, 393, 574, 412, 264, 6968, 11, 286, 603, 362, 512, 6123, 281, 544, 322, 264, 24850, 13, 51590], "temperature": 0.0, "avg_logprob": -0.2900911905233142, "compression_ratio": 1.6328125, "no_speech_prob": 0.0003149809781461954}, {"id": 68, "seek": 22076, "start": 245.28, "end": 248.56, "text": " But essentially, people doing pull requests, pull requests reviews.", "tokens": [51590, 583, 4476, 11, 561, 884, 2235, 12475, 11, 2235, 12475, 10229, 13, 51754], "temperature": 0.0, "avg_logprob": -0.2900911905233142, "compression_ratio": 1.6328125, "no_speech_prob": 0.0003149809781461954}, {"id": 69, "seek": 24856, "start": 249.56, "end": 252.68, "text": " That sort of thing that counts as a contributor, right?", "tokens": [50414, 663, 1333, 295, 551, 300, 14893, 382, 257, 42859, 11, 558, 30, 50570], "temperature": 0.0, "avg_logprob": -0.3634378259832209, "compression_ratio": 1.683794466403162, "no_speech_prob": 0.0002868019219022244}, {"id": 70, "seek": 24856, "start": 252.68, "end": 257.92, "text": " And actually contributors, if you believe me, are actually up more than ever.", "tokens": [50570, 400, 767, 45627, 11, 498, 291, 1697, 385, 11, 366, 767, 493, 544, 813, 1562, 13, 50832], "temperature": 0.0, "avg_logprob": -0.3634378259832209, "compression_ratio": 1.683794466403162, "no_speech_prob": 0.0002868019219022244}, {"id": 71, "seek": 24856, "start": 259.0, "end": 262.84000000000003, "text": " So first, one interesting point here you can see.", "tokens": [50886, 407, 700, 11, 472, 1880, 935, 510, 291, 393, 536, 13, 51078], "temperature": 0.0, "avg_logprob": -0.3634378259832209, "compression_ratio": 1.683794466403162, "no_speech_prob": 0.0002868019219022244}, {"id": 72, "seek": 24856, "start": 262.84000000000003, "end": 264.8, "text": " So there was a peak number of users in April, but", "tokens": [51078, 407, 456, 390, 257, 10651, 1230, 295, 5022, 294, 6929, 11, 457, 51176], "temperature": 0.0, "avg_logprob": -0.3634378259832209, "compression_ratio": 1.683794466403162, "no_speech_prob": 0.0002868019219022244}, {"id": 73, "seek": 24856, "start": 264.8, "end": 267.88, "text": " actually the peak contributions, it was in actually May.", "tokens": [51176, 767, 264, 10651, 15725, 11, 309, 390, 294, 767, 1891, 13, 51330], "temperature": 0.0, "avg_logprob": -0.3634378259832209, "compression_ratio": 1.683794466403162, "no_speech_prob": 0.0002868019219022244}, {"id": 74, "seek": 24856, "start": 267.88, "end": 270.04, "text": " And maybe that makes sense, like people during the pandemic,", "tokens": [51330, 400, 1310, 300, 1669, 2020, 11, 411, 561, 1830, 264, 5388, 11, 51438], "temperature": 0.0, "avg_logprob": -0.3634378259832209, "compression_ratio": 1.683794466403162, "no_speech_prob": 0.0002868019219022244}, {"id": 75, "seek": 24856, "start": 271.52, "end": 277.08, "text": " got an issue in WebRTC, start looking at it, they maybe could star a repo,", "tokens": [51512, 658, 364, 2734, 294, 9573, 49, 18238, 11, 722, 1237, 412, 309, 11, 436, 1310, 727, 3543, 257, 49040, 11, 51790], "temperature": 0.0, "avg_logprob": -0.3634378259832209, "compression_ratio": 1.683794466403162, "no_speech_prob": 0.0002868019219022244}, {"id": 76, "seek": 27708, "start": 277.59999999999997, "end": 280.88, "text": " get involved, but then it takes them a few weeks actually before they actually", "tokens": [50390, 483, 3288, 11, 457, 550, 309, 2516, 552, 257, 1326, 3259, 767, 949, 436, 767, 50554], "temperature": 0.0, "avg_logprob": -0.21440730904633143, "compression_ratio": 1.71900826446281, "no_speech_prob": 0.0008828684804029763}, {"id": 77, "seek": 27708, "start": 280.88, "end": 284.32, "text": " contribute, start adding things into that repo.", "tokens": [50554, 10586, 11, 722, 5127, 721, 666, 300, 49040, 13, 50726], "temperature": 0.0, "avg_logprob": -0.21440730904633143, "compression_ratio": 1.71900826446281, "no_speech_prob": 0.0008828684804029763}, {"id": 78, "seek": 27708, "start": 284.32, "end": 289.2, "text": " But as I said here, our most recent peak here was actually in August.", "tokens": [50726, 583, 382, 286, 848, 510, 11, 527, 881, 5162, 10651, 510, 390, 767, 294, 6897, 13, 50970], "temperature": 0.0, "avg_logprob": -0.21440730904633143, "compression_ratio": 1.71900826446281, "no_speech_prob": 0.0008828684804029763}, {"id": 79, "seek": 27708, "start": 289.2, "end": 292.24, "text": " And we're not actually too far off for the rest of the year looking at that.", "tokens": [50970, 400, 321, 434, 406, 767, 886, 1400, 766, 337, 264, 1472, 295, 264, 1064, 1237, 412, 300, 13, 51122], "temperature": 0.0, "avg_logprob": -0.21440730904633143, "compression_ratio": 1.71900826446281, "no_speech_prob": 0.0008828684804029763}, {"id": 80, "seek": 27708, "start": 292.24, "end": 297.44, "text": " So I want to look into see what was going on and compare these two peaks.", "tokens": [51122, 407, 286, 528, 281, 574, 666, 536, 437, 390, 516, 322, 293, 6794, 613, 732, 26897, 13, 51382], "temperature": 0.0, "avg_logprob": -0.21440730904633143, "compression_ratio": 1.71900826446281, "no_speech_prob": 0.0008828684804029763}, {"id": 81, "seek": 27708, "start": 297.44, "end": 303.12, "text": " So one is this is actually from the August peak, I dug into the sea.", "tokens": [51382, 407, 472, 307, 341, 307, 767, 490, 264, 6897, 10651, 11, 286, 22954, 666, 264, 4158, 13, 51666], "temperature": 0.0, "avg_logprob": -0.21440730904633143, "compression_ratio": 1.71900826446281, "no_speech_prob": 0.0008828684804029763}, {"id": 82, "seek": 30312, "start": 303.12, "end": 307.12, "text": " Where's some of the repos that we're actually having, I had the most activity.", "tokens": [50364, 2305, 311, 512, 295, 264, 1085, 329, 300, 321, 434, 767, 1419, 11, 286, 632, 264, 881, 5191, 13, 50564], "temperature": 0.0, "avg_logprob": -0.23724253845214843, "compression_ratio": 1.644927536231884, "no_speech_prob": 0.0014100385596975684}, {"id": 83, "seek": 30312, "start": 307.12, "end": 310.84000000000003, "text": " And one of them, very popular WebRTC project is Coturn,", "tokens": [50564, 400, 472, 295, 552, 11, 588, 3743, 9573, 49, 18238, 1716, 307, 383, 310, 925, 11, 50750], "temperature": 0.0, "avg_logprob": -0.23724253845214843, "compression_ratio": 1.644927536231884, "no_speech_prob": 0.0014100385596975684}, {"id": 84, "seek": 30312, "start": 310.84000000000003, "end": 315.08, "text": " the open source kind of stone and turn server.", "tokens": [50750, 264, 1269, 4009, 733, 295, 7581, 293, 1261, 7154, 13, 50962], "temperature": 0.0, "avg_logprob": -0.23724253845214843, "compression_ratio": 1.644927536231884, "no_speech_prob": 0.0014100385596975684}, {"id": 85, "seek": 30312, "start": 315.08, "end": 318.8, "text": " And actually one of my co-workers Gustavo took over that project.", "tokens": [50962, 400, 767, 472, 295, 452, 598, 12, 37101, 32337, 25713, 1890, 670, 300, 1716, 13, 51148], "temperature": 0.0, "avg_logprob": -0.23724253845214843, "compression_ratio": 1.644927536231884, "no_speech_prob": 0.0014100385596975684}, {"id": 86, "seek": 30312, "start": 318.8, "end": 321.12, "text": " So I asked him what was going on here, what happened,", "tokens": [51148, 407, 286, 2351, 796, 437, 390, 516, 322, 510, 11, 437, 2011, 11, 51264], "temperature": 0.0, "avg_logprob": -0.23724253845214843, "compression_ratio": 1.644927536231884, "no_speech_prob": 0.0014100385596975684}, {"id": 87, "seek": 30312, "start": 321.12, "end": 326.04, "text": " why do we have such a big spike in this and wrote a whole blog post about it.", "tokens": [51264, 983, 360, 321, 362, 1270, 257, 955, 21053, 294, 341, 293, 4114, 257, 1379, 6968, 2183, 466, 309, 13, 51510], "temperature": 0.0, "avg_logprob": -0.23724253845214843, "compression_ratio": 1.644927536231884, "no_speech_prob": 0.0014100385596975684}, {"id": 88, "seek": 30312, "start": 326.04, "end": 331.36, "text": " But essentially, that project was kind of stale, not a lot of activity for", "tokens": [51510, 583, 4476, 11, 300, 1716, 390, 733, 295, 342, 1220, 11, 406, 257, 688, 295, 5191, 337, 51776], "temperature": 0.0, "avg_logprob": -0.23724253845214843, "compression_ratio": 1.644927536231884, "no_speech_prob": 0.0014100385596975684}, {"id": 89, "seek": 33136, "start": 331.36, "end": 338.12, "text": " a while, he and Pavel took that over and then started really get the community", "tokens": [50364, 257, 1339, 11, 415, 293, 3426, 779, 1890, 300, 670, 293, 550, 1409, 534, 483, 264, 1768, 50702], "temperature": 0.0, "avg_logprob": -0.3830621639887492, "compression_ratio": 1.5964912280701755, "no_speech_prob": 0.002590309362858534}, {"id": 90, "seek": 33136, "start": 338.12, "end": 340.96000000000004, "text": " involved and there's a huge spike and things like that.", "tokens": [50702, 3288, 293, 456, 311, 257, 2603, 21053, 293, 721, 411, 300, 13, 50844], "temperature": 0.0, "avg_logprob": -0.3830621639887492, "compression_ratio": 1.5964912280701755, "no_speech_prob": 0.002590309362858534}, {"id": 91, "seek": 33136, "start": 340.96000000000004, "end": 347.16, "text": " So then I wondered, is basically is this, sorry,", "tokens": [50844, 407, 550, 286, 17055, 11, 307, 1936, 307, 341, 11, 2597, 11, 51154], "temperature": 0.0, "avg_logprob": -0.3830621639887492, "compression_ratio": 1.5964912280701755, "no_speech_prob": 0.002590309362858534}, {"id": 92, "seek": 33136, "start": 347.16, "end": 351.72, "text": " is the other peaks in August in here because of spikes?", "tokens": [51154, 307, 264, 661, 26897, 294, 6897, 294, 510, 570, 295, 28997, 30, 51382], "temperature": 0.0, "avg_logprob": -0.3830621639887492, "compression_ratio": 1.5964912280701755, "no_speech_prob": 0.002590309362858534}, {"id": 93, "seek": 33136, "start": 351.72, "end": 353.68, "text": " Or is there a lot of regular activity?", "tokens": [51382, 1610, 307, 456, 257, 688, 295, 3890, 5191, 30, 51480], "temperature": 0.0, "avg_logprob": -0.3830621639887492, "compression_ratio": 1.5964912280701755, "no_speech_prob": 0.002590309362858534}, {"id": 94, "seek": 33136, "start": 353.68, "end": 360.28000000000003, "text": " You can see here, interestingly, you see things like AdGuard is always high in there.", "tokens": [51480, 509, 393, 536, 510, 11, 25873, 11, 291, 536, 721, 411, 1999, 38, 16981, 307, 1009, 1090, 294, 456, 13, 51810], "temperature": 0.0, "avg_logprob": -0.3830621639887492, "compression_ratio": 1.5964912280701755, "no_speech_prob": 0.002590309362858534}, {"id": 95, "seek": 36028, "start": 360.28, "end": 363.55999999999995, "text": " Like people actually plan to block WebRTC and its usage, right?", "tokens": [50364, 1743, 561, 767, 1393, 281, 3461, 9573, 49, 18238, 293, 1080, 14924, 11, 558, 30, 50528], "temperature": 0.0, "avg_logprob": -0.2626066914311162, "compression_ratio": 1.66796875, "no_speech_prob": 0.0012840388808399439}, {"id": 96, "seek": 36028, "start": 363.55999999999995, "end": 367.96, "text": " But they have a lot of activity every month around that.", "tokens": [50528, 583, 436, 362, 257, 688, 295, 5191, 633, 1618, 926, 300, 13, 50748], "temperature": 0.0, "avg_logprob": -0.2626066914311162, "compression_ratio": 1.66796875, "no_speech_prob": 0.0012840388808399439}, {"id": 97, "seek": 36028, "start": 367.96, "end": 372.79999999999995, "text": " But actually it wasn't actually, you see some commonality, but some difference here.", "tokens": [50748, 583, 767, 309, 2067, 380, 767, 11, 291, 536, 512, 2689, 1860, 11, 457, 512, 2649, 510, 13, 50990], "temperature": 0.0, "avg_logprob": -0.2626066914311162, "compression_ratio": 1.66796875, "no_speech_prob": 0.0012840388808399439}, {"id": 98, "seek": 36028, "start": 372.79999999999995, "end": 378.28, "text": " And, sorry, but when you actually look at the distributions and", "tokens": [50990, 400, 11, 2597, 11, 457, 562, 291, 767, 574, 412, 264, 37870, 293, 51264], "temperature": 0.0, "avg_logprob": -0.2626066914311162, "compression_ratio": 1.66796875, "no_speech_prob": 0.0012840388808399439}, {"id": 99, "seek": 36028, "start": 378.28, "end": 383.15999999999997, "text": " the change between April of 2020 and August of 2022,", "tokens": [51264, 264, 1319, 1296, 6929, 295, 4808, 293, 6897, 295, 20229, 11, 51508], "temperature": 0.0, "avg_logprob": -0.2626066914311162, "compression_ratio": 1.66796875, "no_speech_prob": 0.0012840388808399439}, {"id": 100, "seek": 36028, "start": 383.15999999999997, "end": 386.76, "text": " the actual distributions across the top 10, top 20, top 100,", "tokens": [51508, 264, 3539, 37870, 2108, 264, 1192, 1266, 11, 1192, 945, 11, 1192, 2319, 11, 51688], "temperature": 0.0, "avg_logprob": -0.2626066914311162, "compression_ratio": 1.66796875, "no_speech_prob": 0.0012840388808399439}, {"id": 101, "seek": 36028, "start": 386.76, "end": 389.32, "text": " they're actually not a whole lot different.", "tokens": [51688, 436, 434, 767, 406, 257, 1379, 688, 819, 13, 51816], "temperature": 0.0, "avg_logprob": -0.2626066914311162, "compression_ratio": 1.66796875, "no_speech_prob": 0.0012840388808399439}, {"id": 102, "seek": 38932, "start": 389.32, "end": 391.64, "text": " So what does this all mean?", "tokens": [50364, 407, 437, 775, 341, 439, 914, 30, 50480], "temperature": 0.0, "avg_logprob": -0.23825928971574112, "compression_ratio": 1.588235294117647, "no_speech_prob": 4.2644805944291875e-05}, {"id": 103, "seek": 38932, "start": 391.64, "end": 395.04, "text": " It's like actually the WebRTC development actually is not really getting a lot more", "tokens": [50480, 467, 311, 411, 767, 264, 9573, 49, 18238, 3250, 767, 307, 406, 534, 1242, 257, 688, 544, 50650], "temperature": 0.0, "avg_logprob": -0.23825928971574112, "compression_ratio": 1.588235294117647, "no_speech_prob": 4.2644805944291875e-05}, {"id": 104, "seek": 38932, "start": 395.04, "end": 396.08, "text": " concentrated.", "tokens": [50650, 21321, 13, 50702], "temperature": 0.0, "avg_logprob": -0.23825928971574112, "compression_ratio": 1.588235294117647, "no_speech_prob": 4.2644805944291875e-05}, {"id": 105, "seek": 38932, "start": 396.08, "end": 397.44, "text": " You can look for a given period of time.", "tokens": [50702, 509, 393, 574, 337, 257, 2212, 2896, 295, 565, 13, 50770], "temperature": 0.0, "avg_logprob": -0.23825928971574112, "compression_ratio": 1.588235294117647, "no_speech_prob": 4.2644805944291875e-05}, {"id": 106, "seek": 38932, "start": 397.44, "end": 399.64, "text": " Obviously some projects are doing more popular and", "tokens": [50770, 7580, 512, 4455, 366, 884, 544, 3743, 293, 50880], "temperature": 0.0, "avg_logprob": -0.23825928971574112, "compression_ratio": 1.588235294117647, "no_speech_prob": 4.2644805944291875e-05}, {"id": 107, "seek": 38932, "start": 399.64, "end": 402.4, "text": " doing well, have more activity than others.", "tokens": [50880, 884, 731, 11, 362, 544, 5191, 813, 2357, 13, 51018], "temperature": 0.0, "avg_logprob": -0.23825928971574112, "compression_ratio": 1.588235294117647, "no_speech_prob": 4.2644805944291875e-05}, {"id": 108, "seek": 38932, "start": 402.4, "end": 406.4, "text": " But overall, it's not like we're consolidating down to a few projects, right?", "tokens": [51018, 583, 4787, 11, 309, 311, 406, 411, 321, 434, 19045, 990, 760, 281, 257, 1326, 4455, 11, 558, 30, 51218], "temperature": 0.0, "avg_logprob": -0.23825928971574112, "compression_ratio": 1.588235294117647, "no_speech_prob": 4.2644805944291875e-05}, {"id": 109, "seek": 38932, "start": 406.4, "end": 412.12, "text": " It's the same kind of more equal distribution that's existed at least for", "tokens": [51218, 467, 311, 264, 912, 733, 295, 544, 2681, 7316, 300, 311, 13135, 412, 1935, 337, 51504], "temperature": 0.0, "avg_logprob": -0.23825928971574112, "compression_ratio": 1.588235294117647, "no_speech_prob": 4.2644805944291875e-05}, {"id": 110, "seek": 38932, "start": 412.12, "end": 412.68, "text": " several years now.", "tokens": [51504, 2940, 924, 586, 13, 51532], "temperature": 0.0, "avg_logprob": -0.23825928971574112, "compression_ratio": 1.588235294117647, "no_speech_prob": 4.2644805944291875e-05}, {"id": 111, "seek": 41268, "start": 413.52, "end": 419.36, "text": " So another data set, and this is actually a new one I hadn't looked at before,", "tokens": [50406, 407, 1071, 1412, 992, 11, 293, 341, 307, 767, 257, 777, 472, 286, 8782, 380, 2956, 412, 949, 11, 50698], "temperature": 0.0, "avg_logprob": -0.34368386669693707, "compression_ratio": 1.5679012345679013, "no_speech_prob": 0.0005032980698160827}, {"id": 112, "seek": 41268, "start": 419.36, "end": 421.64, "text": " is Stack Overflow.", "tokens": [50698, 307, 37649, 4886, 10565, 13, 50812], "temperature": 0.0, "avg_logprob": -0.34368386669693707, "compression_ratio": 1.5679012345679013, "no_speech_prob": 0.0005032980698160827}, {"id": 113, "seek": 41268, "start": 421.64, "end": 425.84000000000003, "text": " So I zoomed in to take a look at that.", "tokens": [50812, 407, 286, 8863, 292, 294, 281, 747, 257, 574, 412, 300, 13, 51022], "temperature": 0.0, "avg_logprob": -0.34368386669693707, "compression_ratio": 1.5679012345679013, "no_speech_prob": 0.0005032980698160827}, {"id": 114, "seek": 41268, "start": 425.84000000000003, "end": 428.92, "text": " And that's to see if this follows a similar pattern.", "tokens": [51022, 400, 300, 311, 281, 536, 498, 341, 10002, 257, 2531, 5102, 13, 51176], "temperature": 0.0, "avg_logprob": -0.34368386669693707, "compression_ratio": 1.5679012345679013, "no_speech_prob": 0.0005032980698160827}, {"id": 115, "seek": 41268, "start": 428.92, "end": 432.64, "text": " Now bear in mind compared to the previous charts, this goes back all the way to", "tokens": [51176, 823, 6155, 294, 1575, 5347, 281, 264, 3894, 17767, 11, 341, 1709, 646, 439, 264, 636, 281, 51362], "temperature": 0.0, "avg_logprob": -0.34368386669693707, "compression_ratio": 1.5679012345679013, "no_speech_prob": 0.0005032980698160827}, {"id": 116, "seek": 41268, "start": 432.64, "end": 435.16, "text": " 2012, so it's a much longer data period.", "tokens": [51362, 9125, 11, 370, 309, 311, 257, 709, 2854, 1412, 2896, 13, 51488], "temperature": 0.0, "avg_logprob": -0.34368386669693707, "compression_ratio": 1.5679012345679013, "no_speech_prob": 0.0005032980698160827}, {"id": 117, "seek": 41268, "start": 435.16, "end": 440.36, "text": " And you can see here, this is comments on Stack Overflow questions and", "tokens": [51488, 400, 291, 393, 536, 510, 11, 341, 307, 3053, 322, 37649, 4886, 10565, 1651, 293, 51748], "temperature": 0.0, "avg_logprob": -0.34368386669693707, "compression_ratio": 1.5679012345679013, "no_speech_prob": 0.0005032980698160827}, {"id": 118, "seek": 44036, "start": 440.56, "end": 443.24, "text": " actually the questions themselves.", "tokens": [50374, 767, 264, 1651, 2969, 13, 50508], "temperature": 0.0, "avg_logprob": -0.2912024943033854, "compression_ratio": 1.5495049504950495, "no_speech_prob": 0.0006262619863264263}, {"id": 119, "seek": 44036, "start": 443.24, "end": 448.48, "text": " And unfortunately, you can't see the font too much of answers within Stack", "tokens": [50508, 400, 7015, 11, 291, 393, 380, 536, 264, 10703, 886, 709, 295, 6338, 1951, 37649, 50770], "temperature": 0.0, "avg_logprob": -0.2912024943033854, "compression_ratio": 1.5495049504950495, "no_speech_prob": 0.0006262619863264263}, {"id": 120, "seek": 44036, "start": 448.48, "end": 452.96000000000004, "text": " Overflow, but it essentially looks very similar to the questions side of things.", "tokens": [50770, 4886, 10565, 11, 457, 309, 4476, 1542, 588, 2531, 281, 264, 1651, 1252, 295, 721, 13, 50994], "temperature": 0.0, "avg_logprob": -0.2912024943033854, "compression_ratio": 1.5495049504950495, "no_speech_prob": 0.0006262619863264263}, {"id": 121, "seek": 44036, "start": 452.96000000000004, "end": 457.36, "text": " And you can see very similar here, peak in April of 2020.", "tokens": [50994, 400, 291, 393, 536, 588, 2531, 510, 11, 10651, 294, 6929, 295, 4808, 13, 51214], "temperature": 0.0, "avg_logprob": -0.2912024943033854, "compression_ratio": 1.5495049504950495, "no_speech_prob": 0.0006262619863264263}, {"id": 122, "seek": 44036, "start": 459.48, "end": 465.68, "text": " Also, unlike the GitHub analysis, this actually shows a peak and", "tokens": [51320, 2743, 11, 8343, 264, 23331, 5215, 11, 341, 767, 3110, 257, 10651, 293, 51630], "temperature": 0.0, "avg_logprob": -0.2912024943033854, "compression_ratio": 1.5495049504950495, "no_speech_prob": 0.0006262619863264263}, {"id": 123, "seek": 46568, "start": 465.68, "end": 470.8, "text": " is here also in April of 2022.", "tokens": [50364, 307, 510, 611, 294, 6929, 295, 20229, 13, 50620], "temperature": 0.0, "avg_logprob": -0.2369666894276937, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0008294559665955603}, {"id": 124, "seek": 46568, "start": 470.8, "end": 474.6, "text": " I didn't have a chance to dig into to see what was driving that particular peak", "tokens": [50620, 286, 994, 380, 362, 257, 2931, 281, 2528, 666, 281, 536, 437, 390, 4840, 300, 1729, 10651, 50810], "temperature": 0.0, "avg_logprob": -0.2369666894276937, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0008294559665955603}, {"id": 125, "seek": 46568, "start": 474.6, "end": 475.72, "text": " this year.", "tokens": [50810, 341, 1064, 13, 50866], "temperature": 0.0, "avg_logprob": -0.2369666894276937, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0008294559665955603}, {"id": 126, "seek": 46568, "start": 475.72, "end": 479.48, "text": " But overall, I think you can see it's a little bit harder compared to the other", "tokens": [50866, 583, 4787, 11, 286, 519, 291, 393, 536, 309, 311, 257, 707, 857, 6081, 5347, 281, 264, 661, 51054], "temperature": 0.0, "avg_logprob": -0.2369666894276937, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0008294559665955603}, {"id": 127, "seek": 46568, "start": 479.48, "end": 484.0, "text": " one, but we're still generally up compared to prior to the pandemic in terms of", "tokens": [51054, 472, 11, 457, 321, 434, 920, 5101, 493, 5347, 281, 4059, 281, 264, 5388, 294, 2115, 295, 51280], "temperature": 0.0, "avg_logprob": -0.2369666894276937, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0008294559665955603}, {"id": 128, "seek": 46568, "start": 484.0, "end": 484.88, "text": " questions and answers.", "tokens": [51280, 1651, 293, 6338, 13, 51324], "temperature": 0.0, "avg_logprob": -0.2369666894276937, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0008294559665955603}, {"id": 129, "seek": 46568, "start": 484.88, "end": 487.72, "text": " And actually, it's a pretty good sign that there's a lot of activity there.", "tokens": [51324, 400, 767, 11, 309, 311, 257, 1238, 665, 1465, 300, 456, 311, 257, 688, 295, 5191, 456, 13, 51466], "temperature": 0.0, "avg_logprob": -0.2369666894276937, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0008294559665955603}, {"id": 130, "seek": 46568, "start": 489.64, "end": 495.16, "text": " And I also just took a look to see as a percentage of all the questions on", "tokens": [51562, 400, 286, 611, 445, 1890, 257, 574, 281, 536, 382, 257, 9668, 295, 439, 264, 1651, 322, 51838], "temperature": 0.0, "avg_logprob": -0.2369666894276937, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0008294559665955603}, {"id": 131, "seek": 49516, "start": 495.16, "end": 499.56, "text": " Stack Overflow, what percentage of them had at least something that mentioned", "tokens": [50364, 37649, 4886, 10565, 11, 437, 9668, 295, 552, 632, 412, 1935, 746, 300, 2835, 50584], "temperature": 0.0, "avg_logprob": -0.2626833105986973, "compression_ratio": 1.7125, "no_speech_prob": 0.002978660399094224}, {"id": 132, "seek": 49516, "start": 499.56, "end": 501.64000000000004, "text": " WebRTC or one of these terms?", "tokens": [50584, 9573, 49, 18238, 420, 472, 295, 613, 2115, 30, 50688], "temperature": 0.0, "avg_logprob": -0.2626833105986973, "compression_ratio": 1.7125, "no_speech_prob": 0.002978660399094224}, {"id": 133, "seek": 49516, "start": 502.64000000000004, "end": 505.44, "text": " And very surprising, actually, it's actually very high.", "tokens": [50738, 400, 588, 8830, 11, 767, 11, 309, 311, 767, 588, 1090, 13, 50878], "temperature": 0.0, "avg_logprob": -0.2626833105986973, "compression_ratio": 1.7125, "no_speech_prob": 0.002978660399094224}, {"id": 134, "seek": 49516, "start": 507.12, "end": 513.12, "text": " So it's something like one in, during the pandemic,", "tokens": [50962, 407, 309, 311, 746, 411, 472, 294, 11, 1830, 264, 5388, 11, 51262], "temperature": 0.0, "avg_logprob": -0.2626833105986973, "compression_ratio": 1.7125, "no_speech_prob": 0.002978660399094224}, {"id": 135, "seek": 49516, "start": 513.12, "end": 517.4, "text": " it was one out of every 1400 questions on Stack Overflow had something that", "tokens": [51262, 309, 390, 472, 484, 295, 633, 46795, 1651, 322, 37649, 4886, 10565, 632, 746, 300, 51476], "temperature": 0.0, "avg_logprob": -0.2626833105986973, "compression_ratio": 1.7125, "no_speech_prob": 0.002978660399094224}, {"id": 136, "seek": 49516, "start": 517.4, "end": 520.64, "text": " mentioned WebRTC, which that seems like quite a bit because I still consider", "tokens": [51476, 2835, 9573, 49, 18238, 11, 597, 300, 2544, 411, 1596, 257, 857, 570, 286, 920, 1949, 51638], "temperature": 0.0, "avg_logprob": -0.2626833105986973, "compression_ratio": 1.7125, "no_speech_prob": 0.002978660399094224}, {"id": 137, "seek": 49516, "start": 520.64, "end": 523.5600000000001, "text": " WebRTC kind of a very niche sort of thing.", "tokens": [51638, 9573, 49, 18238, 733, 295, 257, 588, 19956, 1333, 295, 551, 13, 51784], "temperature": 0.0, "avg_logprob": -0.2626833105986973, "compression_ratio": 1.7125, "no_speech_prob": 0.002978660399094224}, {"id": 138, "seek": 52356, "start": 523.56, "end": 529.68, "text": " And even if you look today, just in the last data point in this one is November,", "tokens": [50364, 400, 754, 498, 291, 574, 965, 11, 445, 294, 264, 1036, 1412, 935, 294, 341, 472, 307, 7674, 11, 50670], "temperature": 0.0, "avg_logprob": -0.26036355590820315, "compression_ratio": 1.6591760299625469, "no_speech_prob": 0.00034594093449413776}, {"id": 139, "seek": 52356, "start": 529.68, "end": 535.7199999999999, "text": " at that point it was still one in, I'm sorry, it was one in 900 during the peak", "tokens": [50670, 412, 300, 935, 309, 390, 920, 472, 294, 11, 286, 478, 2597, 11, 309, 390, 472, 294, 22016, 1830, 264, 10651, 50972], "temperature": 0.0, "avg_logprob": -0.26036355590820315, "compression_ratio": 1.6591760299625469, "no_speech_prob": 0.00034594093449413776}, {"id": 140, "seek": 52356, "start": 535.7199999999999, "end": 538.56, "text": " of April of 2020.", "tokens": [50972, 295, 6929, 295, 4808, 13, 51114], "temperature": 0.0, "avg_logprob": -0.26036355590820315, "compression_ratio": 1.6591760299625469, "no_speech_prob": 0.00034594093449413776}, {"id": 141, "seek": 52356, "start": 538.56, "end": 541.88, "text": " It's still one in 1400 today, which was still actually very high.", "tokens": [51114, 467, 311, 920, 472, 294, 46795, 965, 11, 597, 390, 920, 767, 588, 1090, 13, 51280], "temperature": 0.0, "avg_logprob": -0.26036355590820315, "compression_ratio": 1.6591760299625469, "no_speech_prob": 0.00034594093449413776}, {"id": 142, "seek": 52356, "start": 541.88, "end": 544.4, "text": " So you can see, you can interpret this two ways.", "tokens": [51280, 407, 291, 393, 536, 11, 291, 393, 7302, 341, 732, 2098, 13, 51406], "temperature": 0.0, "avg_logprob": -0.26036355590820315, "compression_ratio": 1.6591760299625469, "no_speech_prob": 0.00034594093449413776}, {"id": 143, "seek": 52356, "start": 544.4, "end": 547.76, "text": " One, WebRTC is very confusing and people have a lot of questions.", "tokens": [51406, 1485, 11, 9573, 49, 18238, 307, 588, 13181, 293, 561, 362, 257, 688, 295, 1651, 13, 51574], "temperature": 0.0, "avg_logprob": -0.26036355590820315, "compression_ratio": 1.6591760299625469, "no_speech_prob": 0.00034594093449413776}, {"id": 144, "seek": 52356, "start": 547.76, "end": 550.2399999999999, "text": " So you need to comment on it, or you can also see there's a lot of people involved.", "tokens": [51574, 407, 291, 643, 281, 2871, 322, 309, 11, 420, 291, 393, 611, 536, 456, 311, 257, 688, 295, 561, 3288, 13, 51698], "temperature": 0.0, "avg_logprob": -0.26036355590820315, "compression_ratio": 1.6591760299625469, "no_speech_prob": 0.00034594093449413776}, {"id": 145, "seek": 55024, "start": 550.24, "end": 552.96, "text": " I think both are good, right?", "tokens": [50364, 286, 519, 1293, 366, 665, 11, 558, 30, 50500], "temperature": 0.0, "avg_logprob": -0.296098343049637, "compression_ratio": 1.6506550218340612, "no_speech_prob": 0.0009106628713198006}, {"id": 146, "seek": 55024, "start": 555.46, "end": 555.96, "text": " But yeah.", "tokens": [50625, 583, 1338, 13, 50650], "temperature": 0.0, "avg_logprob": -0.296098343049637, "compression_ratio": 1.6506550218340612, "no_speech_prob": 0.0009106628713198006}, {"id": 147, "seek": 55024, "start": 557.76, "end": 562.92, "text": " So also very interesting that can we look at this data set to understand", "tokens": [50740, 407, 611, 588, 1880, 300, 393, 321, 574, 412, 341, 1412, 992, 281, 1223, 50998], "temperature": 0.0, "avg_logprob": -0.296098343049637, "compression_ratio": 1.6506550218340612, "no_speech_prob": 0.0009106628713198006}, {"id": 148, "seek": 55024, "start": 562.92, "end": 566.6, "text": " development trends, what's going on in the market.", "tokens": [50998, 3250, 13892, 11, 437, 311, 516, 322, 294, 264, 2142, 13, 51182], "temperature": 0.0, "avg_logprob": -0.296098343049637, "compression_ratio": 1.6506550218340612, "no_speech_prob": 0.0009106628713198006}, {"id": 149, "seek": 55024, "start": 566.6, "end": 569.72, "text": " And one of the very interesting things I always like to look at is what are some of", "tokens": [51182, 400, 472, 295, 264, 588, 1880, 721, 286, 1009, 411, 281, 574, 412, 307, 437, 366, 512, 295, 51338], "temperature": 0.0, "avg_logprob": -0.296098343049637, "compression_ratio": 1.6506550218340612, "no_speech_prob": 0.0009106628713198006}, {"id": 150, "seek": 55024, "start": 569.72, "end": 573.84, "text": " the language trends, programming languages that people are using.", "tokens": [51338, 264, 2856, 13892, 11, 9410, 8650, 300, 561, 366, 1228, 13, 51544], "temperature": 0.0, "avg_logprob": -0.296098343049637, "compression_ratio": 1.6506550218340612, "no_speech_prob": 0.0009106628713198006}, {"id": 151, "seek": 55024, "start": 573.84, "end": 578.36, "text": " And this is a jumble and hard to see, so let's actually zoom in.", "tokens": [51544, 400, 341, 307, 257, 361, 16473, 293, 1152, 281, 536, 11, 370, 718, 311, 767, 8863, 294, 13, 51770], "temperature": 0.0, "avg_logprob": -0.296098343049637, "compression_ratio": 1.6506550218340612, "no_speech_prob": 0.0009106628713198006}, {"id": 152, "seek": 57836, "start": 578.36, "end": 583.32, "text": " So one of the ones I've been trying to track for a while is JavaScript versus TypeScript.", "tokens": [50364, 407, 472, 295, 264, 2306, 286, 600, 668, 1382, 281, 2837, 337, 257, 1339, 307, 15778, 5717, 15576, 14237, 13, 50612], "temperature": 0.0, "avg_logprob": -0.23602608161243965, "compression_ratio": 1.6423357664233578, "no_speech_prob": 0.000910745351575315}, {"id": 153, "seek": 57836, "start": 583.32, "end": 590.76, "text": " I've been delaying, converting to TypeScript and I'm kind of wondering, do I need to, is", "tokens": [50612, 286, 600, 668, 8577, 278, 11, 29942, 281, 15576, 14237, 293, 286, 478, 733, 295, 6359, 11, 360, 286, 643, 281, 11, 307, 50984], "temperature": 0.0, "avg_logprob": -0.23602608161243965, "compression_ratio": 1.6423357664233578, "no_speech_prob": 0.000910745351575315}, {"id": 154, "seek": 57836, "start": 590.76, "end": 594.24, "text": " it time for me to really switch over or can I wait a little bit longer?", "tokens": [50984, 309, 565, 337, 385, 281, 534, 3679, 670, 420, 393, 286, 1699, 257, 707, 857, 2854, 30, 51158], "temperature": 0.0, "avg_logprob": -0.23602608161243965, "compression_ratio": 1.6423357664233578, "no_speech_prob": 0.000910745351575315}, {"id": 155, "seek": 57836, "start": 594.24, "end": 597.84, "text": " You can see here, well, obviously TypeScript's been getting more popular.", "tokens": [51158, 509, 393, 536, 510, 11, 731, 11, 2745, 15576, 14237, 311, 668, 1242, 544, 3743, 13, 51338], "temperature": 0.0, "avg_logprob": -0.23602608161243965, "compression_ratio": 1.6423357664233578, "no_speech_prob": 0.000910745351575315}, {"id": 156, "seek": 57836, "start": 597.84, "end": 603.16, "text": " We just, you know, just in December reached the 50-50 point, right?", "tokens": [51338, 492, 445, 11, 291, 458, 11, 445, 294, 7687, 6488, 264, 2625, 12, 2803, 935, 11, 558, 30, 51604], "temperature": 0.0, "avg_logprob": -0.23602608161243965, "compression_ratio": 1.6423357664233578, "no_speech_prob": 0.000910745351575315}, {"id": 157, "seek": 57836, "start": 603.16, "end": 606.72, "text": " Where, you know, all these repos where TypeScript's half.", "tokens": [51604, 2305, 11, 291, 458, 11, 439, 613, 1085, 329, 689, 15576, 14237, 311, 1922, 13, 51782], "temperature": 0.0, "avg_logprob": -0.23602608161243965, "compression_ratio": 1.6423357664233578, "no_speech_prob": 0.000910745351575315}, {"id": 158, "seek": 60672, "start": 606.72, "end": 609.48, "text": " So I think I'm probably behind it and need to switch.", "tokens": [50364, 407, 286, 519, 286, 478, 1391, 2261, 309, 293, 643, 281, 3679, 13, 50502], "temperature": 0.0, "avg_logprob": -0.23270172647910542, "compression_ratio": 1.5584415584415585, "no_speech_prob": 0.00016343448078259826}, {"id": 159, "seek": 60672, "start": 613.6, "end": 619.5600000000001, "text": " So there's also, at this conference, a bunch of exciting new languages that are coming out.", "tokens": [50708, 407, 456, 311, 611, 11, 412, 341, 7586, 11, 257, 3840, 295, 4670, 777, 8650, 300, 366, 1348, 484, 13, 51006], "temperature": 0.0, "avg_logprob": -0.23270172647910542, "compression_ratio": 1.5584415584415585, "no_speech_prob": 0.00016343448078259826}, {"id": 160, "seek": 60672, "start": 619.5600000000001, "end": 624.08, "text": " So I wanted to zoom in and kind of take a look to see what's going on with them.", "tokens": [51006, 407, 286, 1415, 281, 8863, 294, 293, 733, 295, 747, 257, 574, 281, 536, 437, 311, 516, 322, 365, 552, 13, 51232], "temperature": 0.0, "avg_logprob": -0.23270172647910542, "compression_ratio": 1.5584415584415585, "no_speech_prob": 0.00016343448078259826}, {"id": 161, "seek": 60672, "start": 624.08, "end": 627.9200000000001, "text": " So, you know, Go, Kotlin and Rust in particular.", "tokens": [51232, 407, 11, 291, 458, 11, 1037, 11, 30123, 5045, 293, 34952, 294, 1729, 13, 51424], "temperature": 0.0, "avg_logprob": -0.23270172647910542, "compression_ratio": 1.5584415584415585, "no_speech_prob": 0.00016343448078259826}, {"id": 162, "seek": 60672, "start": 627.9200000000001, "end": 632.9200000000001, "text": " So I will say one of the challenges, I didn't get any chance to filter this out, but", "tokens": [51424, 407, 286, 486, 584, 472, 295, 264, 4759, 11, 286, 994, 380, 483, 604, 2931, 281, 6608, 341, 484, 11, 457, 51674], "temperature": 0.0, "avg_logprob": -0.23270172647910542, "compression_ratio": 1.5584415584415585, "no_speech_prob": 0.00016343448078259826}, {"id": 163, "seek": 63292, "start": 632.92, "end": 637.4, "text": " this Go jump from November to December is some bots.", "tokens": [50364, 341, 1037, 3012, 490, 7674, 281, 7687, 307, 512, 35410, 13, 50588], "temperature": 0.0, "avg_logprob": -0.24194358883047462, "compression_ratio": 1.6736842105263159, "no_speech_prob": 0.003272031666710973}, {"id": 164, "seek": 63292, "start": 637.4, "end": 639.7199999999999, "text": " So that's just bot activity.", "tokens": [50588, 407, 300, 311, 445, 10592, 5191, 13, 50704], "temperature": 0.0, "avg_logprob": -0.24194358883047462, "compression_ratio": 1.6736842105263159, "no_speech_prob": 0.003272031666710973}, {"id": 165, "seek": 63292, "start": 639.7199999999999, "end": 644.68, "text": " So you can, yeah, I thought originally maybe it's just Christmas and Go developers don't", "tokens": [50704, 407, 291, 393, 11, 1338, 11, 286, 1194, 7993, 1310, 309, 311, 445, 5272, 293, 1037, 8849, 500, 380, 50952], "temperature": 0.0, "avg_logprob": -0.24194358883047462, "compression_ratio": 1.6736842105263159, "no_speech_prob": 0.003272031666710973}, {"id": 166, "seek": 63292, "start": 644.68, "end": 645.68, "text": " have anything better to do.", "tokens": [50952, 362, 1340, 1101, 281, 360, 13, 51002], "temperature": 0.0, "avg_logprob": -0.24194358883047462, "compression_ratio": 1.6736842105263159, "no_speech_prob": 0.003272031666710973}, {"id": 167, "seek": 63292, "start": 645.68, "end": 649.1999999999999, "text": " So over the holidays, you know, they're just programming a lot and starting a lot of new", "tokens": [51002, 407, 670, 264, 15734, 11, 291, 458, 11, 436, 434, 445, 9410, 257, 688, 293, 2891, 257, 688, 295, 777, 51178], "temperature": 0.0, "avg_logprob": -0.24194358883047462, "compression_ratio": 1.6736842105263159, "no_speech_prob": 0.003272031666710973}, {"id": 168, "seek": 63292, "start": 649.1999999999999, "end": 650.1999999999999, "text": " repos.", "tokens": [51178, 1085, 329, 13, 51228], "temperature": 0.0, "avg_logprob": -0.24194358883047462, "compression_ratio": 1.6736842105263159, "no_speech_prob": 0.003272031666710973}, {"id": 169, "seek": 63292, "start": 650.1999999999999, "end": 653.12, "text": " That wasn't, it was actually, it was some bugs.", "tokens": [51228, 663, 2067, 380, 11, 309, 390, 767, 11, 309, 390, 512, 15120, 13, 51374], "temperature": 0.0, "avg_logprob": -0.24194358883047462, "compression_ratio": 1.6736842105263159, "no_speech_prob": 0.003272031666710973}, {"id": 170, "seek": 63292, "start": 653.12, "end": 655.24, "text": " But you can see here, you know, steadily increasing.", "tokens": [51374, 583, 291, 393, 536, 510, 11, 291, 458, 11, 36129, 5662, 13, 51480], "temperature": 0.0, "avg_logprob": -0.24194358883047462, "compression_ratio": 1.6736842105263159, "no_speech_prob": 0.003272031666710973}, {"id": 171, "seek": 63292, "start": 655.24, "end": 661.5999999999999, "text": " It's not a huge, huge spike for these other, these other two, but it is going up.", "tokens": [51480, 467, 311, 406, 257, 2603, 11, 2603, 21053, 337, 613, 661, 11, 613, 661, 732, 11, 457, 309, 307, 516, 493, 13, 51798], "temperature": 0.0, "avg_logprob": -0.24194358883047462, "compression_ratio": 1.6736842105263159, "no_speech_prob": 0.003272031666710973}, {"id": 172, "seek": 66160, "start": 661.6, "end": 667.36, "text": " But as a new language that's getting popular, I guess you'd expect to see more of that.", "tokens": [50364, 583, 382, 257, 777, 2856, 300, 311, 1242, 3743, 11, 286, 2041, 291, 1116, 2066, 281, 536, 544, 295, 300, 13, 50652], "temperature": 0.0, "avg_logprob": -0.29697813681506235, "compression_ratio": 1.5875486381322956, "no_speech_prob": 0.0028882974293082952}, {"id": 173, "seek": 66160, "start": 667.36, "end": 672.44, "text": " So in addition to languages, also there's a bunch of the new APIs, some that were referenced", "tokens": [50652, 407, 294, 4500, 281, 8650, 11, 611, 456, 311, 257, 3840, 295, 264, 777, 21445, 11, 512, 300, 645, 32734, 50906], "temperature": 0.0, "avg_logprob": -0.29697813681506235, "compression_ratio": 1.5875486381322956, "no_speech_prob": 0.0028882974293082952}, {"id": 174, "seek": 66160, "start": 672.44, "end": 673.6800000000001, "text": " earlier today.", "tokens": [50906, 3071, 965, 13, 50968], "temperature": 0.0, "avg_logprob": -0.29697813681506235, "compression_ratio": 1.5875486381322956, "no_speech_prob": 0.0028882974293082952}, {"id": 175, "seek": 66160, "start": 673.6800000000001, "end": 680.36, "text": " So Insertable Streams is one such API, and that's actually two sub-APIs, a media stream", "tokens": [50968, 407, 36487, 712, 24904, 82, 307, 472, 1270, 9362, 11, 293, 300, 311, 767, 732, 1422, 12, 4715, 6802, 11, 257, 3021, 4309, 51302], "temperature": 0.0, "avg_logprob": -0.29697813681506235, "compression_ratio": 1.5875486381322956, "no_speech_prob": 0.0028882974293082952}, {"id": 176, "seek": 66160, "start": 680.36, "end": 683.84, "text": " track processor and track generator.", "tokens": [51302, 2837, 15321, 293, 2837, 19265, 13, 51476], "temperature": 0.0, "avg_logprob": -0.29697813681506235, "compression_ratio": 1.5875486381322956, "no_speech_prob": 0.0028882974293082952}, {"id": 177, "seek": 66160, "start": 683.84, "end": 689.76, "text": " First took a look on Chrome status, actually credit to Fippo, you know, Phil Hankey for", "tokens": [51476, 2386, 1890, 257, 574, 322, 15327, 6558, 11, 767, 5397, 281, 479, 2488, 78, 11, 291, 458, 11, 7777, 7820, 4119, 337, 51772], "temperature": 0.0, "avg_logprob": -0.29697813681506235, "compression_ratio": 1.5875486381322956, "no_speech_prob": 0.0028882974293082952}, {"id": 178, "seek": 68976, "start": 689.76, "end": 695.48, "text": " having a, he built a custom viewer of the Chrome status information that you can see", "tokens": [50364, 1419, 257, 11, 415, 3094, 257, 2375, 16767, 295, 264, 15327, 6558, 1589, 300, 291, 393, 536, 50650], "temperature": 0.0, "avg_logprob": -0.21021021113676183, "compression_ratio": 1.7563636363636363, "no_speech_prob": 0.01911834441125393}, {"id": 179, "seek": 68976, "start": 695.48, "end": 697.88, "text": " or so compare them both at the same time.", "tokens": [50650, 420, 370, 6794, 552, 1293, 412, 264, 912, 565, 13, 50770], "temperature": 0.0, "avg_logprob": -0.21021021113676183, "compression_ratio": 1.7563636363636363, "no_speech_prob": 0.01911834441125393}, {"id": 180, "seek": 68976, "start": 697.88, "end": 701.2, "text": " You can see that, you know, these are actually peaking, you know, quite a bit towards the", "tokens": [50770, 509, 393, 536, 300, 11, 291, 458, 11, 613, 366, 767, 520, 2456, 11, 291, 458, 11, 1596, 257, 857, 3030, 264, 50936], "temperature": 0.0, "avg_logprob": -0.21021021113676183, "compression_ratio": 1.7563636363636363, "no_speech_prob": 0.01911834441125393}, {"id": 181, "seek": 68976, "start": 701.2, "end": 702.2, "text": " end of the year going up quite a bit.", "tokens": [50936, 917, 295, 264, 1064, 516, 493, 1596, 257, 857, 13, 50986], "temperature": 0.0, "avg_logprob": -0.21021021113676183, "compression_ratio": 1.7563636363636363, "no_speech_prob": 0.01911834441125393}, {"id": 182, "seek": 68976, "start": 702.2, "end": 706.4399999999999, "text": " So I was curious, like, who, you know, can we see our open source repos actually using", "tokens": [50986, 407, 286, 390, 6369, 11, 411, 11, 567, 11, 291, 458, 11, 393, 321, 536, 527, 1269, 4009, 1085, 329, 767, 1228, 51198], "temperature": 0.0, "avg_logprob": -0.21021021113676183, "compression_ratio": 1.7563636363636363, "no_speech_prob": 0.01911834441125393}, {"id": 183, "seek": 68976, "start": 706.4399999999999, "end": 709.04, "text": " these or is it somebody else?", "tokens": [51198, 613, 420, 307, 309, 2618, 1646, 30, 51328], "temperature": 0.0, "avg_logprob": -0.21021021113676183, "compression_ratio": 1.7563636363636363, "no_speech_prob": 0.01911834441125393}, {"id": 184, "seek": 68976, "start": 709.04, "end": 715.72, "text": " And looking at it, you know, there's a big spike here, but it doesn't look like much.", "tokens": [51328, 400, 1237, 412, 309, 11, 291, 458, 11, 456, 311, 257, 955, 21053, 510, 11, 457, 309, 1177, 380, 574, 411, 709, 13, 51662], "temperature": 0.0, "avg_logprob": -0.21021021113676183, "compression_ratio": 1.7563636363636363, "no_speech_prob": 0.01911834441125393}, {"id": 185, "seek": 68976, "start": 715.72, "end": 717.24, "text": " So what's going on there?", "tokens": [51662, 407, 437, 311, 516, 322, 456, 30, 51738], "temperature": 0.0, "avg_logprob": -0.21021021113676183, "compression_ratio": 1.7563636363636363, "no_speech_prob": 0.01911834441125393}, {"id": 186, "seek": 71724, "start": 717.28, "end": 721.92, "text": " Zoom in a little bit more, and again, apologies, it's really small, but like that initial spike,", "tokens": [50366, 13453, 294, 257, 707, 857, 544, 11, 293, 797, 11, 34929, 11, 309, 311, 534, 1359, 11, 457, 411, 300, 5883, 21053, 11, 50598], "temperature": 0.0, "avg_logprob": -0.2184874267578125, "compression_ratio": 1.63003663003663, "no_speech_prob": 0.017161544412374496}, {"id": 187, "seek": 71724, "start": 721.92, "end": 730.2, "text": " a lot of that was just pure standards related activity of the W3C repos and WebKit and others", "tokens": [50598, 257, 688, 295, 300, 390, 445, 6075, 7787, 4077, 5191, 295, 264, 343, 18, 34, 1085, 329, 293, 9573, 45626, 293, 2357, 51012], "temperature": 0.0, "avg_logprob": -0.2184874267578125, "compression_ratio": 1.63003663003663, "no_speech_prob": 0.017161544412374496}, {"id": 188, "seek": 71724, "start": 730.2, "end": 733.4, "text": " that are just basically adopting, you know, adopting those APIs in the first place.", "tokens": [51012, 300, 366, 445, 1936, 32328, 11, 291, 458, 11, 32328, 729, 21445, 294, 264, 700, 1081, 13, 51172], "temperature": 0.0, "avg_logprob": -0.2184874267578125, "compression_ratio": 1.63003663003663, "no_speech_prob": 0.017161544412374496}, {"id": 189, "seek": 71724, "start": 733.4, "end": 735.44, "text": " So you see a big jump.", "tokens": [51172, 407, 291, 536, 257, 955, 3012, 13, 51274], "temperature": 0.0, "avg_logprob": -0.2184874267578125, "compression_ratio": 1.63003663003663, "no_speech_prob": 0.017161544412374496}, {"id": 190, "seek": 71724, "start": 735.44, "end": 740.28, "text": " After that, it's really kind of hit or miss, and I was, I mean, I love working with Insertable", "tokens": [51274, 2381, 300, 11, 309, 311, 534, 733, 295, 2045, 420, 1713, 11, 293, 286, 390, 11, 286, 914, 11, 286, 959, 1364, 365, 36487, 712, 51516], "temperature": 0.0, "avg_logprob": -0.2184874267578125, "compression_ratio": 1.63003663003663, "no_speech_prob": 0.017161544412374496}, {"id": 191, "seek": 71724, "start": 740.28, "end": 742.52, "text": " Streams, you know, let's see, do a lot of fun stuff.", "tokens": [51516, 24904, 82, 11, 291, 458, 11, 718, 311, 536, 11, 360, 257, 688, 295, 1019, 1507, 13, 51628], "temperature": 0.0, "avg_logprob": -0.2184874267578125, "compression_ratio": 1.63003663003663, "no_speech_prob": 0.017161544412374496}, {"id": 192, "seek": 74252, "start": 742.84, "end": 746.12, "text": " So hoping to see more, but it's kind of just spotty.", "tokens": [50380, 407, 7159, 281, 536, 544, 11, 457, 309, 311, 733, 295, 445, 4008, 874, 13, 50544], "temperature": 0.0, "avg_logprob": -0.1834436575571696, "compression_ratio": 1.6142322097378277, "no_speech_prob": 0.0033761311788111925}, {"id": 193, "seek": 74252, "start": 746.12, "end": 748.4399999999999, "text": " So, you know, going back to the Chrome status, what does that mean?", "tokens": [50544, 407, 11, 291, 458, 11, 516, 646, 281, 264, 15327, 6558, 11, 437, 775, 300, 914, 30, 50660], "temperature": 0.0, "avg_logprob": -0.1834436575571696, "compression_ratio": 1.6142322097378277, "no_speech_prob": 0.0033761311788111925}, {"id": 194, "seek": 74252, "start": 748.4399999999999, "end": 754.52, "text": " Well, at least people that are using it are probably someone like Google Meet, sort of", "tokens": [50660, 1042, 11, 412, 1935, 561, 300, 366, 1228, 309, 366, 1391, 1580, 411, 3329, 22963, 11, 1333, 295, 50964], "temperature": 0.0, "avg_logprob": -0.1834436575571696, "compression_ratio": 1.6142322097378277, "no_speech_prob": 0.0033761311788111925}, {"id": 195, "seek": 74252, "start": 754.52, "end": 756.4, "text": " thing that don't have public repos, right?", "tokens": [50964, 551, 300, 500, 380, 362, 1908, 1085, 329, 11, 558, 30, 51058], "temperature": 0.0, "avg_logprob": -0.1834436575571696, "compression_ratio": 1.6142322097378277, "no_speech_prob": 0.0033761311788111925}, {"id": 196, "seek": 74252, "start": 756.4, "end": 761.52, "text": " Or there's something else outside of the public GitHub data set that's driving that usage.", "tokens": [51058, 1610, 456, 311, 746, 1646, 2380, 295, 264, 1908, 23331, 1412, 992, 300, 311, 4840, 300, 14924, 13, 51314], "temperature": 0.0, "avg_logprob": -0.1834436575571696, "compression_ratio": 1.6142322097378277, "no_speech_prob": 0.0033761311788111925}, {"id": 197, "seek": 74252, "start": 763.8, "end": 766.64, "text": " So another one is Web Codex.", "tokens": [51428, 407, 1071, 472, 307, 9573, 15549, 87, 13, 51570], "temperature": 0.0, "avg_logprob": -0.1834436575571696, "compression_ratio": 1.6142322097378277, "no_speech_prob": 0.0033761311788111925}, {"id": 198, "seek": 74252, "start": 766.64, "end": 767.3199999999999, "text": " It's another one.", "tokens": [51570, 467, 311, 1071, 472, 13, 51604], "temperature": 0.0, "avg_logprob": -0.1834436575571696, "compression_ratio": 1.6142322097378277, "no_speech_prob": 0.0033761311788111925}, {"id": 199, "seek": 74252, "start": 767.3199999999999, "end": 768.68, "text": " This one doesn't have quite the same peak.", "tokens": [51604, 639, 472, 1177, 380, 362, 1596, 264, 912, 10651, 13, 51672], "temperature": 0.0, "avg_logprob": -0.1834436575571696, "compression_ratio": 1.6142322097378277, "no_speech_prob": 0.0033761311788111925}, {"id": 200, "seek": 76868, "start": 768.7199999999999, "end": 774.64, "text": " It's a little bit, you know, Web Codex is not quite as far along, but they're still driving up.", "tokens": [50366, 467, 311, 257, 707, 857, 11, 291, 458, 11, 9573, 15549, 87, 307, 406, 1596, 382, 1400, 2051, 11, 457, 436, 434, 920, 4840, 493, 13, 50662], "temperature": 0.0, "avg_logprob": -0.15565796528965975, "compression_ratio": 1.6236162361623616, "no_speech_prob": 0.0004441617347765714}, {"id": 201, "seek": 76868, "start": 774.64, "end": 777.3199999999999, "text": " You want to see if there's something going on here too.", "tokens": [50662, 509, 528, 281, 536, 498, 456, 311, 746, 516, 322, 510, 886, 13, 50796], "temperature": 0.0, "avg_logprob": -0.15565796528965975, "compression_ratio": 1.6236162361623616, "no_speech_prob": 0.0004441617347765714}, {"id": 202, "seek": 76868, "start": 777.3199999999999, "end": 782.0, "text": " And again, you see gradual increase, not a ton, except for this one spike.", "tokens": [50796, 400, 797, 11, 291, 536, 32890, 3488, 11, 406, 257, 2952, 11, 3993, 337, 341, 472, 21053, 13, 51030], "temperature": 0.0, "avg_logprob": -0.15565796528965975, "compression_ratio": 1.6236162361623616, "no_speech_prob": 0.0004441617347765714}, {"id": 203, "seek": 76868, "start": 782.0, "end": 788.56, "text": " And this one spike, again, was largely related to, you know, the initial standards release", "tokens": [51030, 400, 341, 472, 21053, 11, 797, 11, 390, 11611, 4077, 281, 11, 291, 458, 11, 264, 5883, 7787, 4374, 51358], "temperature": 0.0, "avg_logprob": -0.15565796528965975, "compression_ratio": 1.6236162361623616, "no_speech_prob": 0.0004441617347765714}, {"id": 204, "seek": 76868, "start": 788.56, "end": 793.04, "text": " of WebKit and W3C type repos and related once to deploy that.", "tokens": [51358, 295, 9573, 45626, 293, 343, 18, 34, 2010, 1085, 329, 293, 4077, 1564, 281, 7274, 300, 13, 51582], "temperature": 0.0, "avg_logprob": -0.15565796528965975, "compression_ratio": 1.6236162361623616, "no_speech_prob": 0.0004441617347765714}, {"id": 205, "seek": 76868, "start": 793.04, "end": 797.68, "text": " So we see some uptick, but nothing all that significant yet.", "tokens": [51582, 407, 321, 536, 512, 493, 83, 618, 11, 457, 1825, 439, 300, 4776, 1939, 13, 51814], "temperature": 0.0, "avg_logprob": -0.15565796528965975, "compression_ratio": 1.6236162361623616, "no_speech_prob": 0.0004441617347765714}, {"id": 206, "seek": 79868, "start": 799.68, "end": 807.3199999999999, "text": " And for the last section, I was also wondering, is WebRC winning?", "tokens": [50414, 400, 337, 264, 1036, 3541, 11, 286, 390, 611, 6359, 11, 307, 9573, 49, 34, 8224, 30, 50796], "temperature": 0.0, "avg_logprob": -0.2241301981608073, "compression_ratio": 1.7128712871287128, "no_speech_prob": 0.00031992231379263103}, {"id": 207, "seek": 79868, "start": 807.3199999999999, "end": 811.76, "text": " Like, we don't talk a whole lot about WebRC having competition so much anymore, at least I haven't.", "tokens": [50796, 1743, 11, 321, 500, 380, 751, 257, 1379, 688, 466, 9573, 49, 34, 1419, 6211, 370, 709, 3602, 11, 412, 1935, 286, 2378, 380, 13, 51018], "temperature": 0.0, "avg_logprob": -0.2241301981608073, "compression_ratio": 1.7128712871287128, "no_speech_prob": 0.00031992231379263103}, {"id": 208, "seek": 79868, "start": 811.76, "end": 814.8, "text": " But in the early days, it was always, you know, WebRC versus SIP.", "tokens": [51018, 583, 294, 264, 2440, 1708, 11, 309, 390, 1009, 11, 291, 458, 11, 9573, 49, 34, 5717, 318, 9139, 13, 51170], "temperature": 0.0, "avg_logprob": -0.2241301981608073, "compression_ratio": 1.7128712871287128, "no_speech_prob": 0.00031992231379263103}, {"id": 209, "seek": 79868, "start": 814.8, "end": 817.0, "text": " And is it, you know, should SIP, you know, those SIP type developers,", "tokens": [51170, 400, 307, 309, 11, 291, 458, 11, 820, 318, 9139, 11, 291, 458, 11, 729, 318, 9139, 2010, 8849, 11, 51280], "temperature": 0.0, "avg_logprob": -0.2241301981608073, "compression_ratio": 1.7128712871287128, "no_speech_prob": 0.00031992231379263103}, {"id": 210, "seek": 79868, "start": 817.0, "end": 819.5999999999999, "text": " that ecosystems, should they shift over to WebRTC?", "tokens": [51280, 300, 32647, 11, 820, 436, 5513, 670, 281, 9573, 49, 18238, 30, 51410], "temperature": 0.0, "avg_logprob": -0.2241301981608073, "compression_ratio": 1.7128712871287128, "no_speech_prob": 0.00031992231379263103}, {"id": 211, "seek": 79868, "start": 819.5999999999999, "end": 823.8399999999999, "text": " And we haven't seen that a whole lot, but I think in reality, there still is competition.", "tokens": [51410, 400, 321, 2378, 380, 1612, 300, 257, 1379, 688, 11, 457, 286, 519, 294, 4103, 11, 456, 920, 307, 6211, 13, 51622], "temperature": 0.0, "avg_logprob": -0.2241301981608073, "compression_ratio": 1.7128712871287128, "no_speech_prob": 0.00031992231379263103}, {"id": 212, "seek": 79868, "start": 823.8399999999999, "end": 828.56, "text": " And that is certainly during the pandemic, you know, well, it's Zoom, right?", "tokens": [51622, 400, 300, 307, 3297, 1830, 264, 5388, 11, 291, 458, 11, 731, 11, 309, 311, 13453, 11, 558, 30, 51858], "temperature": 0.0, "avg_logprob": -0.2241301981608073, "compression_ratio": 1.7128712871287128, "no_speech_prob": 0.00031992231379263103}, {"id": 213, "seek": 82856, "start": 828.56, "end": 832.16, "text": " And I actually presented this a couple of years ago at Dan's conference,", "tokens": [50364, 400, 286, 767, 8212, 341, 257, 1916, 295, 924, 2057, 412, 3394, 311, 7586, 11, 50544], "temperature": 0.0, "avg_logprob": -0.21030404674473094, "compression_ratio": 1.6902356902356903, "no_speech_prob": 0.0005191964446566999}, {"id": 214, "seek": 82856, "start": 832.16, "end": 837.16, "text": " an interesting fact where, you know, there was a month in time where Zoom was worth more", "tokens": [50544, 364, 1880, 1186, 689, 11, 291, 458, 11, 456, 390, 257, 1618, 294, 565, 689, 13453, 390, 3163, 544, 50794], "temperature": 0.0, "avg_logprob": -0.21030404674473094, "compression_ratio": 1.6902356902356903, "no_speech_prob": 0.0005191964446566999}, {"id": 215, "seek": 82856, "start": 837.16, "end": 840.64, "text": " than the seventh largest Analyze put together, at least our market capitalization,", "tokens": [50794, 813, 264, 17875, 6443, 1107, 5222, 1381, 829, 1214, 11, 412, 1935, 527, 2142, 4238, 2144, 11, 50968], "temperature": 0.0, "avg_logprob": -0.21030404674473094, "compression_ratio": 1.6902356902356903, "no_speech_prob": 0.0005191964446566999}, {"id": 216, "seek": 82856, "start": 840.64, "end": 842.4399999999999, "text": " which is still insane when you think about it, right?", "tokens": [50968, 597, 307, 920, 10838, 562, 291, 519, 466, 309, 11, 558, 30, 51058], "temperature": 0.0, "avg_logprob": -0.21030404674473094, "compression_ratio": 1.6902356902356903, "no_speech_prob": 0.0005191964446566999}, {"id": 217, "seek": 82856, "start": 842.4399999999999, "end": 843.8, "text": " But, you know, that was the reality.", "tokens": [51058, 583, 11, 291, 458, 11, 300, 390, 264, 4103, 13, 51126], "temperature": 0.0, "avg_logprob": -0.21030404674473094, "compression_ratio": 1.6902356902356903, "no_speech_prob": 0.0005191964446566999}, {"id": 218, "seek": 82856, "start": 843.8, "end": 849.3599999999999, "text": " So I did want to check to see if that's still the case, and it's not, right?", "tokens": [51126, 407, 286, 630, 528, 281, 1520, 281, 536, 498, 300, 311, 920, 264, 1389, 11, 293, 309, 311, 406, 11, 558, 30, 51404], "temperature": 0.0, "avg_logprob": -0.21030404674473094, "compression_ratio": 1.6902356902356903, "no_speech_prob": 0.0005191964446566999}, {"id": 219, "seek": 82856, "start": 849.3599999999999, "end": 854.7199999999999, "text": " So, yeah, Zoom is, you know, using next to the same data point and just extending it out,", "tokens": [51404, 407, 11, 1338, 11, 13453, 307, 11, 291, 458, 11, 1228, 958, 281, 264, 912, 1412, 935, 293, 445, 24360, 309, 484, 11, 51672], "temperature": 0.0, "avg_logprob": -0.21030404674473094, "compression_ratio": 1.6902356902356903, "no_speech_prob": 0.0005191964446566999}, {"id": 220, "seek": 85472, "start": 854.72, "end": 858.9200000000001, "text": " you know, a little bit further, you know, Zoom's down near 80% where they were back", "tokens": [50364, 291, 458, 11, 257, 707, 857, 3052, 11, 291, 458, 11, 13453, 311, 760, 2651, 4688, 4, 689, 436, 645, 646, 50574], "temperature": 0.0, "avg_logprob": -0.22779566342713403, "compression_ratio": 1.6041666666666667, "no_speech_prob": 0.005728286691009998}, {"id": 221, "seek": 85472, "start": 858.9200000000001, "end": 860.9200000000001, "text": " in February of 2020.", "tokens": [50574, 294, 8711, 295, 4808, 13, 50674], "temperature": 0.0, "avg_logprob": -0.22779566342713403, "compression_ratio": 1.6041666666666667, "no_speech_prob": 0.005728286691009998}, {"id": 222, "seek": 85472, "start": 860.9200000000001, "end": 863.28, "text": " The airlines, though, aren't actually doing all that much better, right?", "tokens": [50674, 440, 37147, 11, 1673, 11, 3212, 380, 767, 884, 439, 300, 709, 1101, 11, 558, 30, 50792], "temperature": 0.0, "avg_logprob": -0.22779566342713403, "compression_ratio": 1.6041666666666667, "no_speech_prob": 0.005728286691009998}, {"id": 223, "seek": 85472, "start": 863.28, "end": 867.6, "text": " So still relative, Zoom's not doing some bad relative to the airlines,", "tokens": [50792, 407, 920, 4972, 11, 13453, 311, 406, 884, 512, 1578, 4972, 281, 264, 37147, 11, 51008], "temperature": 0.0, "avg_logprob": -0.22779566342713403, "compression_ratio": 1.6041666666666667, "no_speech_prob": 0.005728286691009998}, {"id": 224, "seek": 85472, "start": 867.6, "end": 869.4, "text": " at least those same seven.", "tokens": [51008, 412, 1935, 729, 912, 3407, 13, 51098], "temperature": 0.0, "avg_logprob": -0.22779566342713403, "compression_ratio": 1.6041666666666667, "no_speech_prob": 0.005728286691009998}, {"id": 225, "seek": 85472, "start": 869.4, "end": 877.12, "text": " But anyway, Zoom, not quite what it was, but they still really are competition, right?", "tokens": [51098, 583, 4033, 11, 13453, 11, 406, 1596, 437, 309, 390, 11, 457, 436, 920, 534, 366, 6211, 11, 558, 30, 51484], "temperature": 0.0, "avg_logprob": -0.22779566342713403, "compression_ratio": 1.6041666666666667, "no_speech_prob": 0.005728286691009998}, {"id": 226, "seek": 85472, "start": 877.12, "end": 880.48, "text": " And particularly because Zoom now has released a Zoom SDK,", "tokens": [51484, 400, 4098, 570, 13453, 586, 575, 4736, 257, 13453, 37135, 11, 51652], "temperature": 0.0, "avg_logprob": -0.22779566342713403, "compression_ratio": 1.6041666666666667, "no_speech_prob": 0.005728286691009998}, {"id": 227, "seek": 85472, "start": 880.48, "end": 882.12, "text": " and they have a Web version of this SDK.", "tokens": [51652, 293, 436, 362, 257, 9573, 3037, 295, 341, 37135, 13, 51734], "temperature": 0.0, "avg_logprob": -0.22779566342713403, "compression_ratio": 1.6041666666666667, "no_speech_prob": 0.005728286691009998}, {"id": 228, "seek": 88212, "start": 882.12, "end": 886.32, "text": " So as a developer, you do have a choice.", "tokens": [50364, 407, 382, 257, 10754, 11, 291, 360, 362, 257, 3922, 13, 50574], "temperature": 0.0, "avg_logprob": -0.2157573974389824, "compression_ratio": 1.643835616438356, "no_speech_prob": 0.0008824096294119954}, {"id": 229, "seek": 88212, "start": 886.32, "end": 889.52, "text": " Hey, I want to go build a real-time communications application.", "tokens": [50574, 1911, 11, 286, 528, 281, 352, 1322, 257, 957, 12, 3766, 15163, 3861, 13, 50734], "temperature": 0.0, "avg_logprob": -0.2157573974389824, "compression_ratio": 1.643835616438356, "no_speech_prob": 0.0008824096294119954}, {"id": 230, "seek": 88212, "start": 889.52, "end": 892.6, "text": " You can choose to use the WebRC and, you know, all the vendors in the ecosystem,", "tokens": [50734, 509, 393, 2826, 281, 764, 264, 9573, 49, 34, 293, 11, 291, 458, 11, 439, 264, 22056, 294, 264, 11311, 11, 50888], "temperature": 0.0, "avg_logprob": -0.2157573974389824, "compression_ratio": 1.643835616438356, "no_speech_prob": 0.0008824096294119954}, {"id": 231, "seek": 88212, "start": 892.6, "end": 895.04, "text": " or you can go to choose Zoom for this.", "tokens": [50888, 420, 291, 393, 352, 281, 2826, 13453, 337, 341, 13, 51010], "temperature": 0.0, "avg_logprob": -0.2157573974389824, "compression_ratio": 1.643835616438356, "no_speech_prob": 0.0008824096294119954}, {"id": 232, "seek": 88212, "start": 895.04, "end": 897.92, "text": " And I was curious, in Zoom's marketing, it's a lot.", "tokens": [51010, 400, 286, 390, 6369, 11, 294, 13453, 311, 6370, 11, 309, 311, 257, 688, 13, 51154], "temperature": 0.0, "avg_logprob": -0.2157573974389824, "compression_ratio": 1.643835616438356, "no_speech_prob": 0.0008824096294119954}, {"id": 233, "seek": 88212, "start": 897.92, "end": 902.8, "text": " I'll probably have a post on WebRC hacks with football, hopefully in a few weeks", "tokens": [51154, 286, 603, 1391, 362, 257, 2183, 322, 9573, 49, 34, 33617, 365, 7346, 11, 4696, 294, 257, 1326, 3259, 51398], "temperature": 0.0, "avg_logprob": -0.2157573974389824, "compression_ratio": 1.643835616438356, "no_speech_prob": 0.0008824096294119954}, {"id": 234, "seek": 88212, "start": 902.8, "end": 905.72, "text": " that, you know, where Zoom's been promoting the benefits of this.", "tokens": [51398, 300, 11, 291, 458, 11, 689, 13453, 311, 668, 16383, 264, 5311, 295, 341, 13, 51544], "temperature": 0.0, "avg_logprob": -0.2157573974389824, "compression_ratio": 1.643835616438356, "no_speech_prob": 0.0008824096294119954}, {"id": 235, "seek": 88212, "start": 905.72, "end": 911.5600000000001, "text": " And it's a, I'll go into why that's not completely true.", "tokens": [51544, 400, 309, 311, 257, 11, 286, 603, 352, 666, 983, 300, 311, 406, 2584, 2074, 13, 51836], "temperature": 0.0, "avg_logprob": -0.2157573974389824, "compression_ratio": 1.643835616438356, "no_speech_prob": 0.0008824096294119954}, {"id": 236, "seek": 91156, "start": 912.0, "end": 912.64, "text": " During the post.", "tokens": [50386, 6842, 264, 2183, 13, 50418], "temperature": 0.0, "avg_logprob": -0.1901501712636051, "compression_ratio": 1.6007604562737643, "no_speech_prob": 0.025162316858768463}, {"id": 237, "seek": 91156, "start": 912.64, "end": 917.4, "text": " But I wanted to see our developers actually choosing Zoom over,", "tokens": [50418, 583, 286, 1415, 281, 536, 527, 8849, 767, 10875, 13453, 670, 11, 50656], "temperature": 0.0, "avg_logprob": -0.1901501712636051, "compression_ratio": 1.6007604562737643, "no_speech_prob": 0.025162316858768463}, {"id": 238, "seek": 91156, "start": 917.4, "end": 922.92, "text": " or at least mentioning the Zoom SDK over WebRC.", "tokens": [50656, 420, 412, 1935, 18315, 264, 13453, 37135, 670, 9573, 49, 34, 13, 50932], "temperature": 0.0, "avg_logprob": -0.1901501712636051, "compression_ratio": 1.6007604562737643, "no_speech_prob": 0.025162316858768463}, {"id": 239, "seek": 91156, "start": 922.92, "end": 927.4399999999999, "text": " It was going to take me a while to dig into all this on the GitHub analysis.", "tokens": [50932, 467, 390, 516, 281, 747, 385, 257, 1339, 281, 2528, 666, 439, 341, 322, 264, 23331, 5215, 13, 51158], "temperature": 0.0, "avg_logprob": -0.1901501712636051, "compression_ratio": 1.6007604562737643, "no_speech_prob": 0.025162316858768463}, {"id": 240, "seek": 91156, "start": 927.4399999999999, "end": 930.16, "text": " It wasn't clear, so I didn't include that part yet.", "tokens": [51158, 467, 2067, 380, 1850, 11, 370, 286, 994, 380, 4090, 300, 644, 1939, 13, 51294], "temperature": 0.0, "avg_logprob": -0.1901501712636051, "compression_ratio": 1.6007604562737643, "no_speech_prob": 0.025162316858768463}, {"id": 241, "seek": 91156, "start": 930.16, "end": 932.0, "text": " But on Stack Overflow, it's pretty actually clear.", "tokens": [51294, 583, 322, 37649, 4886, 10565, 11, 309, 311, 1238, 767, 1850, 13, 51386], "temperature": 0.0, "avg_logprob": -0.1901501712636051, "compression_ratio": 1.6007604562737643, "no_speech_prob": 0.025162316858768463}, {"id": 242, "seek": 91156, "start": 932.0, "end": 937.0, "text": " There's a distinct Zoom SDK tag or label that they have there.", "tokens": [51386, 821, 311, 257, 10644, 13453, 37135, 6162, 420, 7645, 300, 436, 362, 456, 13, 51636], "temperature": 0.0, "avg_logprob": -0.1901501712636051, "compression_ratio": 1.6007604562737643, "no_speech_prob": 0.025162316858768463}, {"id": 243, "seek": 91156, "start": 937.0, "end": 938.9599999999999, "text": " And you can see here, actually, at least for now,", "tokens": [51636, 400, 291, 393, 536, 510, 11, 767, 11, 412, 1935, 337, 586, 11, 51734], "temperature": 0.0, "avg_logprob": -0.1901501712636051, "compression_ratio": 1.6007604562737643, "no_speech_prob": 0.025162316858768463}, {"id": 244, "seek": 93896, "start": 938.96, "end": 942.36, "text": " WebRC is still way more popular than the Zoom SDK.", "tokens": [50364, 9573, 49, 34, 307, 920, 636, 544, 3743, 813, 264, 13453, 37135, 13, 50534], "temperature": 0.0, "avg_logprob": -0.23107312137919261, "compression_ratio": 1.6275167785234899, "no_speech_prob": 0.0005526539171114564}, {"id": 245, "seek": 93896, "start": 944.2, "end": 945.84, "text": " Two minutes, okay.", "tokens": [50626, 4453, 2077, 11, 1392, 13, 50708], "temperature": 0.0, "avg_logprob": -0.23107312137919261, "compression_ratio": 1.6275167785234899, "no_speech_prob": 0.0005526539171114564}, {"id": 246, "seek": 93896, "start": 945.84, "end": 948.12, "text": " And actually, I am done.", "tokens": [50708, 400, 767, 11, 286, 669, 1096, 13, 50822], "temperature": 0.0, "avg_logprob": -0.23107312137919261, "compression_ratio": 1.6275167785234899, "no_speech_prob": 0.0005526539171114564}, {"id": 247, "seek": 93896, "start": 948.12, "end": 953.0, "text": " So I guess what we've learned here, I mean, part of it is what are your expectations here?", "tokens": [50822, 407, 286, 2041, 437, 321, 600, 3264, 510, 11, 286, 914, 11, 644, 295, 309, 307, 437, 366, 428, 9843, 510, 30, 51066], "temperature": 0.0, "avg_logprob": -0.23107312137919261, "compression_ratio": 1.6275167785234899, "no_speech_prob": 0.0005526539171114564}, {"id": 248, "seek": 93896, "start": 953.0, "end": 955.88, "text": " I didn't necessarily go into any expectations other than I was interested", "tokens": [51066, 286, 994, 380, 4725, 352, 666, 604, 9843, 661, 813, 286, 390, 3102, 51210], "temperature": 0.0, "avg_logprob": -0.23107312137919261, "compression_ratio": 1.6275167785234899, "no_speech_prob": 0.0005526539171114564}, {"id": 249, "seek": 93896, "start": 955.88, "end": 960.6800000000001, "text": " to see what are some of the trends and can we find or like learn things about new APIs", "tokens": [51210, 281, 536, 437, 366, 512, 295, 264, 13892, 293, 393, 321, 915, 420, 411, 1466, 721, 466, 777, 21445, 51450], "temperature": 0.0, "avg_logprob": -0.23107312137919261, "compression_ratio": 1.6275167785234899, "no_speech_prob": 0.0005526539171114564}, {"id": 250, "seek": 93896, "start": 960.6800000000001, "end": 961.76, "text": " or new repos.", "tokens": [51450, 420, 777, 1085, 329, 13, 51504], "temperature": 0.0, "avg_logprob": -0.23107312137919261, "compression_ratio": 1.6275167785234899, "no_speech_prob": 0.0005526539171114564}, {"id": 251, "seek": 93896, "start": 961.76, "end": 965.24, "text": " And I do go through the list, actually, is interesting to see new projects.", "tokens": [51504, 400, 286, 360, 352, 807, 264, 1329, 11, 767, 11, 307, 1880, 281, 536, 777, 4455, 13, 51678], "temperature": 0.0, "avg_logprob": -0.23107312137919261, "compression_ratio": 1.6275167785234899, "no_speech_prob": 0.0005526539171114564}, {"id": 252, "seek": 93896, "start": 965.24, "end": 966.64, "text": " Didn't have time to fit all that stuff in there.", "tokens": [51678, 11151, 380, 362, 565, 281, 3318, 439, 300, 1507, 294, 456, 13, 51748], "temperature": 0.0, "avg_logprob": -0.23107312137919261, "compression_ratio": 1.6275167785234899, "no_speech_prob": 0.0005526539171114564}, {"id": 253, "seek": 96664, "start": 966.64, "end": 969.36, "text": " But again, you can reference some of the blog posts on this.", "tokens": [50364, 583, 797, 11, 291, 393, 6408, 512, 295, 264, 6968, 12300, 322, 341, 13, 50500], "temperature": 0.0, "avg_logprob": -0.19675567073206748, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.002320194151252508}, {"id": 254, "seek": 96664, "start": 969.36, "end": 971.84, "text": " But overall, my impression of WebRC is still doing pretty well.", "tokens": [50500, 583, 4787, 11, 452, 9995, 295, 9573, 49, 34, 307, 920, 884, 1238, 731, 13, 50624], "temperature": 0.0, "avg_logprob": -0.19675567073206748, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.002320194151252508}, {"id": 255, "seek": 96664, "start": 971.84, "end": 973.52, "text": " Obviously, it's not pandemic well.", "tokens": [50624, 7580, 11, 309, 311, 406, 5388, 731, 13, 50708], "temperature": 0.0, "avg_logprob": -0.19675567073206748, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.002320194151252508}, {"id": 256, "seek": 96664, "start": 973.52, "end": 978.4, "text": " But given the circumstances, we're better than it was before the pandemic.", "tokens": [50708, 583, 2212, 264, 9121, 11, 321, 434, 1101, 813, 309, 390, 949, 264, 5388, 13, 50952], "temperature": 0.0, "avg_logprob": -0.19675567073206748, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.002320194151252508}, {"id": 257, "seek": 96664, "start": 978.4, "end": 981.76, "text": " We have more developers involved and it seems that developers that are involved,", "tokens": [50952, 492, 362, 544, 8849, 3288, 293, 309, 2544, 300, 8849, 300, 366, 3288, 11, 51120], "temperature": 0.0, "avg_logprob": -0.19675567073206748, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.002320194151252508}, {"id": 258, "seek": 96664, "start": 981.76, "end": 984.08, "text": " it is a lot of measures to say that they're more mature.", "tokens": [51120, 309, 307, 257, 688, 295, 8000, 281, 584, 300, 436, 434, 544, 14442, 13, 51236], "temperature": 0.0, "avg_logprob": -0.19675567073206748, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.002320194151252508}, {"id": 259, "seek": 96664, "start": 984.08, "end": 985.0, "text": " They're better developers, right?", "tokens": [51236, 814, 434, 1101, 8849, 11, 558, 30, 51282], "temperature": 0.0, "avg_logprob": -0.19675567073206748, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.002320194151252508}, {"id": 260, "seek": 96664, "start": 985.0, "end": 987.48, "text": " They're contributing more than in the past.", "tokens": [51282, 814, 434, 19270, 544, 813, 294, 264, 1791, 13, 51406], "temperature": 0.0, "avg_logprob": -0.19675567073206748, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.002320194151252508}, {"id": 261, "seek": 96664, "start": 987.48, "end": 988.72, "text": " And I think that's a great thing.", "tokens": [51406, 400, 286, 519, 300, 311, 257, 869, 551, 13, 51468], "temperature": 0.0, "avg_logprob": -0.19675567073206748, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.002320194151252508}], "language": "en"}