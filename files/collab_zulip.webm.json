{"text": " Great. Again, I hope everyone's had a great first day at FOSSTEM in person again, and thank you for staying to the last presentation. My name is Lauren, and I'm a software engineer at Condor Labs, and I work on the open source project ZULIP, and I'm going to be talking about how you can collaborate via chat, hopefully transparently, efficiently, and asynchronously. So as a collaboration tool, and we're thinking especially here as open source communities, open source software projects, open research projects, what are some of the benefits of chat that we have? And really, I mean, we have so many collaboration tools and communication tools. We have email, we have our issue trackers, but chat can really be a place of generating some community and connection, and also it's kind of a low friction, lightweight place to connect, right, and create some of those things. So it's a really, can be a really beneficial place for our projects, but it comes with some challenges. So who here works with some folks that are maybe in a different time zone than them? Yeah, me, I definitely do. And so that can be really challenging if you have a chat application going because we think of chat as being live, right, when we're all sitting down at our computers together, but if you're working with someone in a totally different time zone, then your chat is not going to be synchronous. It's going to need to be functional in sort of a different sense. So that's a challenge of chat in our communities. Also in our communities, we have so many things going on, right? We have new features that we want to implement. We have bugs that we're fixing, issues that we're dealing with. We have releases to manage, conferences to attend. So we've got a lot going on and that can really make chat become very overwhelming very quickly. And we have a lot of different folks in our communities, right, and they all have different needs and play different roles. And so I'm going to go through an analysis, and I encourage you to kind of think about your open source community, your open research community maybe, and these roles and what their needs might be, in addition to the ones that I've kind of specified here. So project leaders, the folks who are leading the charge of your project, the people who are making it happen, what are some of their needs and challenges with chat? Well, they want to be there and have those connections with the community in chat, but they also really want to make sure that they're not missing anything in chat, right, if they're not there. So there's this kind of balance between connecting and also being able to step away from it that we have as project leaders. We have core contributors. I'm a core contributor to Zulip and when your core folks come on, you know, they're working more often, they're checking on a chat more often, but what they really want when they check in with chat for it to be some relevant to the work they're doing and helpful that they're participating in chat. And then they also kind of want to be able to go away and focus on their work and then come back to chat. So it's again this kind of coming and going that becomes a challenge. Our casual contributors, folks who are maybe invested in our projects but are not there day to day, folks who are checking in maybe on the weekends or once in a while. So what about these folks? Well, honestly, if the chat is just a big volume of messages that are coming in in this huge stream, they may not even use chat as a collaboration tool, right? Because when they come in and see that there are hundreds and hundreds of unread messages that they have to sort through and see through, they're going to say, hey, I'm going to go somewhere else to collaborate. I'm going to look at the issue tracker. I'm going to be on the email list or whatnot. And they're not going to really know what's going on in the way that chat is. So that can be really a challenge. If we want our communities to grow, we need new folks coming in, right? New contributors, new people getting invested in our projects. And when they come in, we don't want those people lurking, hiding. I don't know what to do, what's going on, you know? We want those people to be able to feel like they have a space to step forward and start participating, right? Have a voice and not be kind of this shadowy person in the background until they figure things out, right? And we want them to get a sense of who our community is, what they're doing, what we're doing together, what we're building. And we have end users, right? The people who are using our projects. So when they come into a chat, again, it's overwhelming, lots of conversations going on. And they have a question or a doubt or maybe some feedback to give. They may not choose to do that in your chat if there's not a space for them that they feel like their voice is going to be heard, right? So if it's this kind of chaotic, loud, cacophonous, like chat, hey, what's going on, da-da-da-da, lots of things going on, they may be like, all right, no, this is not, I'm not going to be able to engage here. So we really want to create a chat space that they can have these needs met. And, of course, we have lots of interact, we're talking about interacting with these people, but it was 20 minutes and kind of going on. These are kind of three characteristics of collaboration and communication with chat that I've identified as being kind of core to serving open source, open research projects. And that's as well as live having an asynchronous ability to chat, having an efficient chat experience, and having a transparent chat experience. So something that we're working on together. So going back to Zulip, again, I'm a contributor to the Zulip open source project. It's 100% open source, modern chat application. We have many, many contributors from all over the world, lots of people making their first time contribution to open source through either an internship program like Outreachy, or Google Summer Code, or just for their own interests. And folks can choose to self-host, obviously, open source, their own server with their own chat application, or we also host Zulip Cloud for folks who want to be organizations on the cloud. So let's start talking about tackling those characteristics that I talked about. So Zulip has this unique topic-based threading model. So you're probably familiar from chat applications who has, everyone has a chat application they're using, right, with some shape or other on their phone or whatnot. So we have maybe, we call them in Zulip, we call them streams. You might be familiar with them as channels or rooms. And this is kind of the big bucket that we set out for conversations that we're having. And the thing about Zulip is we create another layer of context in our streams. So, for example, I have an image here of a stream for our annual summit that we're having. We're going to have a great time at our annual summit. And we've actually, within our annual summit conversation, our stream, we have topics that are coming in and binding those groups of conversations together, kind of like an email subject line would have. So it's the end of my day. I've just got my CI passing on my issue. I'm super excited, but I'm going to sign off. But I signed into chat just before I go, and I look and I have 78 unread messages in my annual summit stream. And I was supposed to check in about this today. And I'm looking through it and I look up, I open up the topics and I say, you know what? They are having a very lively discussion about a bouncy castle at our annual summit. But you know what? I don't like bouncy castles. I could care less about the bouncy castle. I have no interest in bouncy castle. I'm not going to be jumping in the bouncy castle at the summit. So that is 48 messages that I know right there from the topic. I don't need to read right now. I can save those for later. I can mark them unread now, whatever I'd like to do. But I can look at these topics and say, you know what? I'm really interested in the catering because I know some people attending our summit have some not allergies that are very severe. And I want to make sure that's part of this discussion focused on our catering. So I'm going to look at that topic and that focus conversation context there. And if no one's brought that up in those four different messages, then I'm going to put in a pertinent question there. Hey, do we know that people are coming with not allergies? Are we making sure our catering is accommodating that need? So by reading through my topics, topic by topic, I can focus on what my interests are, where I can add value to the chat, and it makes the whole experience much more manageable. So topics really make asynchronous chat work. We now have folks all over the globe who can participate with more contextual feedback when they're online. So again, if they really care about that bouncy castle conversation that happened, they can still jump in and add their feedback there. Again, we make some space for people whose voices might get lost, new folks and users. And so chat becomes more useful for them. But of course, topics are being used by humans. Humans do not always work. We don't have conversations in straight lines. We don't always make sense all the time. And we need to make sure that they work with the humans that are working with them. So at Zulip, we've made a number of tools to work with this kind of patterns of conversations that we have. So for example, maybe we have this really, we have this new feature we're implementing during this really intense design conversation in our design stream. And somebody has this really great new idea right here. What we're going to do is take that new idea message. We're going to move it over here to its own topic with the new idea. We're going to create a link between these two topics in the same stream for the design. And now we have two parallel topic conversations going on in the same stream about design that have context. We can go back. We can connect them. Maybe we're having this really intense conversation about the new release. And we have a really excited new contributor jump in to say, hey, my name is, and I'm really excited. And what do we do? How do I get things done? And we can take that message, move it over to the new person stream, say introductions. Hi, welcome. We're so glad you're here. Please read our documentation. Let us know if you have questions. And this really important release conversation that's going on in our release stream continues uninterrupted, and we keep our flow organized and efficient. Maybe you have some come in with a help question, right? They're asking for help. They're working on upgrading to the new release. They have some questions. They've had some issues. Some of our SysOps people get on, work with them with a question, and they come to a resolution. That user can then mark that topic as resolved. A big check mark will show up in front of that topic visually. And now we know that that question has been answered and resolved. And so we have this kind of, they have the ability to step out and say, hey, you know what? My question was answered. Thank you so much. This is done. So again, creating organization within our topics makes things more efficient. People can prioritize their time. We can move conversations forward. And people have agency to say, thank you. I'm done. Or, hey, this unresolved this topic. We thought we fixed it, but we didn't. It's still an issue. Let's unresolve it. And we're building up all of this. These conversations are happening. They're branching off here. They're branching off there. They're branching out there. And we built this big tree, this repository of knowledge. Now our chat is not something ephemeral, happening in the moment. We're really starting to create sort of a repository of knowledge that's there for everyone to share. So we've got this asynchronous conversations. We've got this repository of knowledge. What about the transparency, right? So in our most recent Zulu release in November, 6.0, our public access feature was landed. And what public access basically is, is an organization with a Zulip can decide, you know what, that help stream we have, that's really important information we want to share with everyone. So we're going to make that web public, which basically means that anyone on the Internet can access those conversations without signing in and without logging into your Zulip. So that now is information that's on the Internet available to anyone. Whatever their questions are, however they get there, they can start accessing that information. Those help questions right away. Maybe we have our design conversations and we don't put those in a public. So people know, what is our design ethic? Where are we moving? What are we working on? And we can make that web public and people can engage. Maybe we've had this really great conversation about a new feature that we're implementing in our chat. And we have over here in GitLab our issue tracker for that feature. We can actually now, if that conversation happened on a web public stream, we can take that, make a link to the chat. And again, anyone who gets to GitLab and looks at our issue and says, oh, there's more information here, click relevant chat conversation. And now all of that information without logging in is available to that person. So again, we're really taking our chat with the public access and moving it beyond our community and making it relevant to anyone who's curious about our open source, our open research projects, like what we're doing. This is a value of open source that we have. So again, if we're making decisions in chat, this is available for people to see. New community members can start learning before they even sign up. And we have this repository, this tree of knowledge that we built that's now out there in the wild, in the forest of the internet that we have, that we're sharing with everyone. So really creating that transparent and chat's becoming much more relevant beyond just an ephemeral conversation. So as I mentioned, Zulip is 100% open source, free. You can start your own server. And we also have our Zulip Cloud, which has a free level of support, similarly to Slack before they made their change this summer, which is like limited. You have a certain history of messages. With non-profits, open source projects, academic research, we actually offer sponsorship on our Zulip Cloud standard, which is normally a paid platform. So you get even more history available to the public. It's not limited. That public access is there. So we really are committed to being part of the open source community and making sure that all of our projects have great connection, collaboration, and are engaging all of the people who want to be involved in the organizations. Again, thank you so much. That's about it for me. I have some great links that are in the slides here. The community's directory is a directory of organizations on Zulip that have opted into the public access already. So if you're curious, that's a great place to start looking. You can find me at Zulip Development Community. That's where we are talking about Zulip and the features that we're implementing and what we're doing. We have some case studies, etc. So I want to open it to questions or I can jump into one of these open Zulip instances if anyone's interested. Yeah, so thank you. Yes. So for topics to work efficiently, you need to be really strict with moving messages around. That means that moderators, I guess, would have to scan every message and move things around. Yeah, yeah. So the question is, for topics to work and we're moving things around and when people come in, you take on a lot of moderators who have to kind of be very active and efficient in that. Yes, definitely in my experience in Zulip Cloud, it depends on your organization. You can actually set that up. So for example, just moving topics within the same stream, like maybe somebody didn't name it very well, you can actually set that permission level to a generic user right now and we're actually working on our user groups so that they can be even more designed to be unique to the organization. So like those levels of permissions can kind of be shared out throughout your user base. So we actually have this in our new users a lot of times are coming in and to Zulip who want to contribute and they're sending messages and very quickly, they'll start actually, if they see a message kind of go jump into a stream and interrupt a conversation, they'll even just move that out right as like a person maybe who is there for two weeks. But it does require that kind of communal engagement, but you can disperse that so it's not just on your core contributors or your moderators, it can kind of be dispersed and hopefully with user groups which is a feature that we're working on and planning, that'll be even more can be fine tuned to your organization and how you, the community you want to create with your Zulip chat. Other questions, yes. Right, so each Zulip organization is deciding, so the question is how do you control privacy with public streams and what's going on for the folks listening at home. So definitely your organization is deciding what streams are web public, right? So that is definitely kind of when you sign on and you're posting in those streams, it's kind of like this information is available in general on the internet. There are private streams in Zulip, there are streams that are public within your Zulip organization that people have to sign in. So for example, on our Zulip development community, the stream for like asking help with, for new contributors like getting help with development, that's not a web public stream because that's kind of folks being vulnerable and maybe asking questions and saying like, I don't know how to do this, can someone help? Like obviously that's not something, I mean that's super brave of them and we're proud, you know, we want that as public within our organization but we're not sending that out to the internet. So we've made that choice culturally as an organization. So each organization that decides. So I believe like the Rust language that's using the public access feature, they've decided that all of their streams are web public. So basically when you sign up to be part of that chat discussion on the Rust language community, whatever your discussion you're having there is available on the internet. And so that's just part of kind of like the culture of each organization that you're setting up. You can definitely set it up so there are more privacy, you know, focused organizations. But again, thinking about open source communities and the fact that we want to be having, you know, there are definitely certain parts of our conversations and chats at me. We might want to be having as publicly as possible, right? So, yeah. Any other questions? Yes? Do you have any integration at the end? Yes, yes. We have lots of integrations. Right, yeah. So you can move from Slack to Zulip, for instance. Yes, yes. Well, GitHub for tracking issues and Zulip is a chat application work together, yeah. So like, so we track our, we're on GitHub for our open source that's where our code is. And so our issues link and we use integrations for like bots to communicate and stuff. So, but definitely there are lots of integrations and such that one can use lots of different authentication methods, et cetera. It's a fully fledged modern chat app. Yeah. Other questions? Curiosity. Again, if your curiosity has been for your open source projects, please I'll be around tomorrow or come on the Zulip development community, check us out. We have lots of public streams and I'm just been really excited to see everyone here at Pustum and thank you for having me.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 14.24, "text": " Great. Again, I hope everyone's had a great first day at FOSSTEM in person again, and", "tokens": [3769, 13, 3764, 11, 286, 1454, 1518, 311, 632, 257, 869, 700, 786, 412, 479, 4367, 6840, 6683, 294, 954, 797, 11, 293], "temperature": 0.0, "avg_logprob": -0.24122484842936198, "compression_ratio": 1.4010416666666667, "no_speech_prob": 0.16031970083713531}, {"id": 1, "seek": 0, "start": 14.24, "end": 19.92, "text": " thank you for staying to the last presentation. My name is Lauren, and I'm a software engineer", "tokens": [1309, 291, 337, 7939, 281, 264, 1036, 5860, 13, 1222, 1315, 307, 18915, 11, 293, 286, 478, 257, 4722, 11403], "temperature": 0.0, "avg_logprob": -0.24122484842936198, "compression_ratio": 1.4010416666666667, "no_speech_prob": 0.16031970083713531}, {"id": 2, "seek": 0, "start": 19.92, "end": 25.8, "text": " at Condor Labs, and I work on the open source project ZULIP, and I'm going to be talking", "tokens": [412, 21793, 284, 40047, 11, 293, 286, 589, 322, 264, 1269, 4009, 1716, 1176, 10253, 9139, 11, 293, 286, 478, 516, 281, 312, 1417], "temperature": 0.0, "avg_logprob": -0.24122484842936198, "compression_ratio": 1.4010416666666667, "no_speech_prob": 0.16031970083713531}, {"id": 3, "seek": 2580, "start": 25.8, "end": 39.4, "text": " about how you can collaborate via chat, hopefully transparently, efficiently, and asynchronously.", "tokens": [466, 577, 291, 393, 18338, 5766, 5081, 11, 4696, 7132, 6420, 11, 19621, 11, 293, 42642, 5098, 13], "temperature": 0.0, "avg_logprob": -0.16437693773689915, "compression_ratio": 1.5771428571428572, "no_speech_prob": 1.7758608009899035e-05}, {"id": 4, "seek": 2580, "start": 39.4, "end": 46.400000000000006, "text": " So as a collaboration tool, and we're thinking especially here as open source communities,", "tokens": [407, 382, 257, 9363, 2290, 11, 293, 321, 434, 1953, 2318, 510, 382, 1269, 4009, 4456, 11], "temperature": 0.0, "avg_logprob": -0.16437693773689915, "compression_ratio": 1.5771428571428572, "no_speech_prob": 1.7758608009899035e-05}, {"id": 5, "seek": 2580, "start": 46.400000000000006, "end": 50.760000000000005, "text": " open source software projects, open research projects, what are some of the benefits of", "tokens": [1269, 4009, 4722, 4455, 11, 1269, 2132, 4455, 11, 437, 366, 512, 295, 264, 5311, 295], "temperature": 0.0, "avg_logprob": -0.16437693773689915, "compression_ratio": 1.5771428571428572, "no_speech_prob": 1.7758608009899035e-05}, {"id": 6, "seek": 5076, "start": 50.76, "end": 56.64, "text": " chat that we have? And really, I mean, we have so many collaboration tools and communication", "tokens": [5081, 300, 321, 362, 30, 400, 534, 11, 286, 914, 11, 321, 362, 370, 867, 9363, 3873, 293, 6101], "temperature": 0.0, "avg_logprob": -0.149672974480523, "compression_ratio": 1.7391304347826086, "no_speech_prob": 4.0639723010826856e-05}, {"id": 7, "seek": 5076, "start": 56.64, "end": 65.2, "text": " tools. We have email, we have our issue trackers, but chat can really be a place of generating", "tokens": [3873, 13, 492, 362, 3796, 11, 321, 362, 527, 2734, 2837, 433, 11, 457, 5081, 393, 534, 312, 257, 1081, 295, 17746], "temperature": 0.0, "avg_logprob": -0.149672974480523, "compression_ratio": 1.7391304347826086, "no_speech_prob": 4.0639723010826856e-05}, {"id": 8, "seek": 5076, "start": 65.2, "end": 71.28, "text": " some community and connection, and also it's kind of a low friction, lightweight place", "tokens": [512, 1768, 293, 4984, 11, 293, 611, 309, 311, 733, 295, 257, 2295, 17710, 11, 22052, 1081], "temperature": 0.0, "avg_logprob": -0.149672974480523, "compression_ratio": 1.7391304347826086, "no_speech_prob": 4.0639723010826856e-05}, {"id": 9, "seek": 5076, "start": 71.28, "end": 75.32, "text": " to connect, right, and create some of those things. So it's a really, can be a really", "tokens": [281, 1745, 11, 558, 11, 293, 1884, 512, 295, 729, 721, 13, 407, 309, 311, 257, 534, 11, 393, 312, 257, 534], "temperature": 0.0, "avg_logprob": -0.149672974480523, "compression_ratio": 1.7391304347826086, "no_speech_prob": 4.0639723010826856e-05}, {"id": 10, "seek": 7532, "start": 75.32, "end": 88.08, "text": " beneficial place for our projects, but it comes with some challenges. So who here works with", "tokens": [14072, 1081, 337, 527, 4455, 11, 457, 309, 1487, 365, 512, 4759, 13, 407, 567, 510, 1985, 365], "temperature": 0.0, "avg_logprob": -0.11594967561609605, "compression_ratio": 1.5299145299145298, "no_speech_prob": 3.7245135899866e-06}, {"id": 11, "seek": 7532, "start": 88.08, "end": 93.83999999999999, "text": " some folks that are maybe in a different time zone than them? Yeah, me, I definitely do.", "tokens": [512, 4024, 300, 366, 1310, 294, 257, 819, 565, 6668, 813, 552, 30, 865, 11, 385, 11, 286, 2138, 360, 13], "temperature": 0.0, "avg_logprob": -0.11594967561609605, "compression_ratio": 1.5299145299145298, "no_speech_prob": 3.7245135899866e-06}, {"id": 12, "seek": 7532, "start": 93.83999999999999, "end": 98.24, "text": " And so that can be really challenging if you have a chat application going because we think", "tokens": [400, 370, 300, 393, 312, 534, 7595, 498, 291, 362, 257, 5081, 3861, 516, 570, 321, 519], "temperature": 0.0, "avg_logprob": -0.11594967561609605, "compression_ratio": 1.5299145299145298, "no_speech_prob": 3.7245135899866e-06}, {"id": 13, "seek": 7532, "start": 98.24, "end": 101.83999999999999, "text": " of chat as being live, right, when we're all sitting down at our computers together,", "tokens": [295, 5081, 382, 885, 1621, 11, 558, 11, 562, 321, 434, 439, 3798, 760, 412, 527, 10807, 1214, 11], "temperature": 0.0, "avg_logprob": -0.11594967561609605, "compression_ratio": 1.5299145299145298, "no_speech_prob": 3.7245135899866e-06}, {"id": 14, "seek": 10184, "start": 101.84, "end": 107.16, "text": " but if you're working with someone in a totally different time zone, then your chat is not", "tokens": [457, 498, 291, 434, 1364, 365, 1580, 294, 257, 3879, 819, 565, 6668, 11, 550, 428, 5081, 307, 406], "temperature": 0.0, "avg_logprob": -0.1054888205094771, "compression_ratio": 1.796812749003984, "no_speech_prob": 1.5437495676451363e-05}, {"id": 15, "seek": 10184, "start": 107.16, "end": 113.08, "text": " going to be synchronous. It's going to need to be functional in sort of a different sense.", "tokens": [516, 281, 312, 44743, 13, 467, 311, 516, 281, 643, 281, 312, 11745, 294, 1333, 295, 257, 819, 2020, 13], "temperature": 0.0, "avg_logprob": -0.1054888205094771, "compression_ratio": 1.796812749003984, "no_speech_prob": 1.5437495676451363e-05}, {"id": 16, "seek": 10184, "start": 113.08, "end": 118.52000000000001, "text": " So that's a challenge of chat in our communities. Also in our communities, we have so many", "tokens": [407, 300, 311, 257, 3430, 295, 5081, 294, 527, 4456, 13, 2743, 294, 527, 4456, 11, 321, 362, 370, 867], "temperature": 0.0, "avg_logprob": -0.1054888205094771, "compression_ratio": 1.796812749003984, "no_speech_prob": 1.5437495676451363e-05}, {"id": 17, "seek": 10184, "start": 118.52000000000001, "end": 122.68, "text": " things going on, right? We have new features that we want to implement. We have bugs that", "tokens": [721, 516, 322, 11, 558, 30, 492, 362, 777, 4122, 300, 321, 528, 281, 4445, 13, 492, 362, 15120, 300], "temperature": 0.0, "avg_logprob": -0.1054888205094771, "compression_ratio": 1.796812749003984, "no_speech_prob": 1.5437495676451363e-05}, {"id": 18, "seek": 10184, "start": 122.68, "end": 128.6, "text": " we're fixing, issues that we're dealing with. We have releases to manage, conferences to", "tokens": [321, 434, 19442, 11, 2663, 300, 321, 434, 6260, 365, 13, 492, 362, 16952, 281, 3067, 11, 22032, 281], "temperature": 0.0, "avg_logprob": -0.1054888205094771, "compression_ratio": 1.796812749003984, "no_speech_prob": 1.5437495676451363e-05}, {"id": 19, "seek": 12860, "start": 128.6, "end": 134.32, "text": " attend. So we've got a lot going on and that can really make chat become very overwhelming", "tokens": [6888, 13, 407, 321, 600, 658, 257, 688, 516, 322, 293, 300, 393, 534, 652, 5081, 1813, 588, 13373], "temperature": 0.0, "avg_logprob": -0.12990030561174665, "compression_ratio": 1.7374517374517375, "no_speech_prob": 1.4056981854082551e-05}, {"id": 20, "seek": 12860, "start": 134.32, "end": 139.12, "text": " very quickly. And we have a lot of different folks in our communities, right, and they", "tokens": [588, 2661, 13, 400, 321, 362, 257, 688, 295, 819, 4024, 294, 527, 4456, 11, 558, 11, 293, 436], "temperature": 0.0, "avg_logprob": -0.12990030561174665, "compression_ratio": 1.7374517374517375, "no_speech_prob": 1.4056981854082551e-05}, {"id": 21, "seek": 12860, "start": 139.12, "end": 145.28, "text": " all have different needs and play different roles. And so I'm going to go through an analysis,", "tokens": [439, 362, 819, 2203, 293, 862, 819, 9604, 13, 400, 370, 286, 478, 516, 281, 352, 807, 364, 5215, 11], "temperature": 0.0, "avg_logprob": -0.12990030561174665, "compression_ratio": 1.7374517374517375, "no_speech_prob": 1.4056981854082551e-05}, {"id": 22, "seek": 12860, "start": 145.28, "end": 149.0, "text": " and I encourage you to kind of think about your open source community, your open research", "tokens": [293, 286, 5373, 291, 281, 733, 295, 519, 466, 428, 1269, 4009, 1768, 11, 428, 1269, 2132], "temperature": 0.0, "avg_logprob": -0.12990030561174665, "compression_ratio": 1.7374517374517375, "no_speech_prob": 1.4056981854082551e-05}, {"id": 23, "seek": 12860, "start": 149.0, "end": 154.0, "text": " community maybe, and these roles and what their needs might be, in addition to the ones", "tokens": [1768, 1310, 11, 293, 613, 9604, 293, 437, 641, 2203, 1062, 312, 11, 294, 4500, 281, 264, 2306], "temperature": 0.0, "avg_logprob": -0.12990030561174665, "compression_ratio": 1.7374517374517375, "no_speech_prob": 1.4056981854082551e-05}, {"id": 24, "seek": 15400, "start": 154.0, "end": 160.24, "text": " that I've kind of specified here. So project leaders, the folks who are leading the charge", "tokens": [300, 286, 600, 733, 295, 22206, 510, 13, 407, 1716, 3523, 11, 264, 4024, 567, 366, 5775, 264, 4602], "temperature": 0.0, "avg_logprob": -0.07231103249315946, "compression_ratio": 1.7777777777777777, "no_speech_prob": 1.5187092685664538e-05}, {"id": 25, "seek": 15400, "start": 160.24, "end": 166.24, "text": " of your project, the people who are making it happen, what are some of their needs and", "tokens": [295, 428, 1716, 11, 264, 561, 567, 366, 1455, 309, 1051, 11, 437, 366, 512, 295, 641, 2203, 293], "temperature": 0.0, "avg_logprob": -0.07231103249315946, "compression_ratio": 1.7777777777777777, "no_speech_prob": 1.5187092685664538e-05}, {"id": 26, "seek": 15400, "start": 166.24, "end": 171.24, "text": " challenges with chat? Well, they want to be there and have those connections with the", "tokens": [4759, 365, 5081, 30, 1042, 11, 436, 528, 281, 312, 456, 293, 362, 729, 9271, 365, 264], "temperature": 0.0, "avg_logprob": -0.07231103249315946, "compression_ratio": 1.7777777777777777, "no_speech_prob": 1.5187092685664538e-05}, {"id": 27, "seek": 15400, "start": 171.24, "end": 176.32, "text": " community in chat, but they also really want to make sure that they're not missing anything", "tokens": [1768, 294, 5081, 11, 457, 436, 611, 534, 528, 281, 652, 988, 300, 436, 434, 406, 5361, 1340], "temperature": 0.0, "avg_logprob": -0.07231103249315946, "compression_ratio": 1.7777777777777777, "no_speech_prob": 1.5187092685664538e-05}, {"id": 28, "seek": 15400, "start": 176.32, "end": 181.4, "text": " in chat, right, if they're not there. So there's this kind of balance between connecting and", "tokens": [294, 5081, 11, 558, 11, 498, 436, 434, 406, 456, 13, 407, 456, 311, 341, 733, 295, 4772, 1296, 11015, 293], "temperature": 0.0, "avg_logprob": -0.07231103249315946, "compression_ratio": 1.7777777777777777, "no_speech_prob": 1.5187092685664538e-05}, {"id": 29, "seek": 18140, "start": 181.4, "end": 188.4, "text": " also being able to step away from it that we have as project leaders. We have core contributors.", "tokens": [611, 885, 1075, 281, 1823, 1314, 490, 309, 300, 321, 362, 382, 1716, 3523, 13, 492, 362, 4965, 45627, 13], "temperature": 0.0, "avg_logprob": -0.14672476844450014, "compression_ratio": 1.812, "no_speech_prob": 1.4500217730528675e-05}, {"id": 30, "seek": 18140, "start": 188.4, "end": 194.04000000000002, "text": " I'm a core contributor to Zulip and when your core folks come on, you know, they're working", "tokens": [286, 478, 257, 4965, 42859, 281, 1176, 425, 647, 293, 562, 428, 4965, 4024, 808, 322, 11, 291, 458, 11, 436, 434, 1364], "temperature": 0.0, "avg_logprob": -0.14672476844450014, "compression_ratio": 1.812, "no_speech_prob": 1.4500217730528675e-05}, {"id": 31, "seek": 18140, "start": 194.04000000000002, "end": 198.88, "text": " more often, they're checking on a chat more often, but what they really want when they", "tokens": [544, 2049, 11, 436, 434, 8568, 322, 257, 5081, 544, 2049, 11, 457, 437, 436, 534, 528, 562, 436], "temperature": 0.0, "avg_logprob": -0.14672476844450014, "compression_ratio": 1.812, "no_speech_prob": 1.4500217730528675e-05}, {"id": 32, "seek": 18140, "start": 198.88, "end": 205.8, "text": " check in with chat for it to be some relevant to the work they're doing and helpful that", "tokens": [1520, 294, 365, 5081, 337, 309, 281, 312, 512, 7340, 281, 264, 589, 436, 434, 884, 293, 4961, 300], "temperature": 0.0, "avg_logprob": -0.14672476844450014, "compression_ratio": 1.812, "no_speech_prob": 1.4500217730528675e-05}, {"id": 33, "seek": 18140, "start": 205.8, "end": 210.88, "text": " they're participating in chat. And then they also kind of want to be able to go away and", "tokens": [436, 434, 13950, 294, 5081, 13, 400, 550, 436, 611, 733, 295, 528, 281, 312, 1075, 281, 352, 1314, 293], "temperature": 0.0, "avg_logprob": -0.14672476844450014, "compression_ratio": 1.812, "no_speech_prob": 1.4500217730528675e-05}, {"id": 34, "seek": 21088, "start": 210.88, "end": 214.79999999999998, "text": " focus on their work and then come back to chat. So it's again this kind of coming and", "tokens": [1879, 322, 641, 589, 293, 550, 808, 646, 281, 5081, 13, 407, 309, 311, 797, 341, 733, 295, 1348, 293], "temperature": 0.0, "avg_logprob": -0.14084033532576126, "compression_ratio": 1.6018099547511313, "no_speech_prob": 1.3621170182886999e-05}, {"id": 35, "seek": 21088, "start": 214.79999999999998, "end": 222.28, "text": " going that becomes a challenge. Our casual contributors, folks who are maybe invested", "tokens": [516, 300, 3643, 257, 3430, 13, 2621, 13052, 45627, 11, 4024, 567, 366, 1310, 13104], "temperature": 0.0, "avg_logprob": -0.14084033532576126, "compression_ratio": 1.6018099547511313, "no_speech_prob": 1.3621170182886999e-05}, {"id": 36, "seek": 21088, "start": 222.28, "end": 228.48, "text": " in our projects but are not there day to day, folks who are checking in maybe on the weekends", "tokens": [294, 527, 4455, 457, 366, 406, 456, 786, 281, 786, 11, 4024, 567, 366, 8568, 294, 1310, 322, 264, 23595], "temperature": 0.0, "avg_logprob": -0.14084033532576126, "compression_ratio": 1.6018099547511313, "no_speech_prob": 1.3621170182886999e-05}, {"id": 37, "seek": 21088, "start": 228.48, "end": 238.16, "text": " or once in a while. So what about these folks? Well, honestly, if the chat is just a big", "tokens": [420, 1564, 294, 257, 1339, 13, 407, 437, 466, 613, 4024, 30, 1042, 11, 6095, 11, 498, 264, 5081, 307, 445, 257, 955], "temperature": 0.0, "avg_logprob": -0.14084033532576126, "compression_ratio": 1.6018099547511313, "no_speech_prob": 1.3621170182886999e-05}, {"id": 38, "seek": 23816, "start": 238.16, "end": 244.0, "text": " volume of messages that are coming in in this huge stream, they may not even use chat as", "tokens": [5523, 295, 7897, 300, 366, 1348, 294, 294, 341, 2603, 4309, 11, 436, 815, 406, 754, 764, 5081, 382], "temperature": 0.0, "avg_logprob": -0.11244089669043865, "compression_ratio": 1.8516949152542372, "no_speech_prob": 1.3841706277162302e-05}, {"id": 39, "seek": 23816, "start": 244.0, "end": 247.96, "text": " a collaboration tool, right? Because when they come in and see that there are hundreds", "tokens": [257, 9363, 2290, 11, 558, 30, 1436, 562, 436, 808, 294, 293, 536, 300, 456, 366, 6779], "temperature": 0.0, "avg_logprob": -0.11244089669043865, "compression_ratio": 1.8516949152542372, "no_speech_prob": 1.3841706277162302e-05}, {"id": 40, "seek": 23816, "start": 247.96, "end": 251.48, "text": " and hundreds of unread messages that they have to sort through and see through, they're", "tokens": [293, 6779, 295, 517, 2538, 7897, 300, 436, 362, 281, 1333, 807, 293, 536, 807, 11, 436, 434], "temperature": 0.0, "avg_logprob": -0.11244089669043865, "compression_ratio": 1.8516949152542372, "no_speech_prob": 1.3841706277162302e-05}, {"id": 41, "seek": 23816, "start": 251.48, "end": 255.4, "text": " going to say, hey, I'm going to go somewhere else to collaborate. I'm going to look at", "tokens": [516, 281, 584, 11, 4177, 11, 286, 478, 516, 281, 352, 4079, 1646, 281, 18338, 13, 286, 478, 516, 281, 574, 412], "temperature": 0.0, "avg_logprob": -0.11244089669043865, "compression_ratio": 1.8516949152542372, "no_speech_prob": 1.3841706277162302e-05}, {"id": 42, "seek": 23816, "start": 255.4, "end": 262.28, "text": " the issue tracker. I'm going to be on the email list or whatnot. And they're not going", "tokens": [264, 2734, 37516, 13, 286, 478, 516, 281, 312, 322, 264, 3796, 1329, 420, 25882, 13, 400, 436, 434, 406, 516], "temperature": 0.0, "avg_logprob": -0.11244089669043865, "compression_ratio": 1.8516949152542372, "no_speech_prob": 1.3841706277162302e-05}, {"id": 43, "seek": 26228, "start": 262.28, "end": 268.67999999999995, "text": " to really know what's going on in the way that chat is. So that can be really a challenge.", "tokens": [281, 534, 458, 437, 311, 516, 322, 294, 264, 636, 300, 5081, 307, 13, 407, 300, 393, 312, 534, 257, 3430, 13], "temperature": 0.0, "avg_logprob": -0.1331348830255969, "compression_ratio": 1.7230769230769232, "no_speech_prob": 7.29444809621782e-06}, {"id": 44, "seek": 26228, "start": 268.67999999999995, "end": 272.91999999999996, "text": " If we want our communities to grow, we need new folks coming in, right? New contributors,", "tokens": [759, 321, 528, 527, 4456, 281, 1852, 11, 321, 643, 777, 4024, 1348, 294, 11, 558, 30, 1873, 45627, 11], "temperature": 0.0, "avg_logprob": -0.1331348830255969, "compression_ratio": 1.7230769230769232, "no_speech_prob": 7.29444809621782e-06}, {"id": 45, "seek": 26228, "start": 272.91999999999996, "end": 280.2, "text": " new people getting invested in our projects. And when they come in, we don't want those", "tokens": [777, 561, 1242, 13104, 294, 527, 4455, 13, 400, 562, 436, 808, 294, 11, 321, 500, 380, 528, 729], "temperature": 0.0, "avg_logprob": -0.1331348830255969, "compression_ratio": 1.7230769230769232, "no_speech_prob": 7.29444809621782e-06}, {"id": 46, "seek": 26228, "start": 280.2, "end": 286.2, "text": " people lurking, hiding. I don't know what to do, what's going on, you know? We want", "tokens": [561, 35583, 5092, 11, 10596, 13, 286, 500, 380, 458, 437, 281, 360, 11, 437, 311, 516, 322, 11, 291, 458, 30, 492, 528], "temperature": 0.0, "avg_logprob": -0.1331348830255969, "compression_ratio": 1.7230769230769232, "no_speech_prob": 7.29444809621782e-06}, {"id": 47, "seek": 26228, "start": 286.2, "end": 290.4, "text": " those people to be able to feel like they have a space to step forward and start participating,", "tokens": [729, 561, 281, 312, 1075, 281, 841, 411, 436, 362, 257, 1901, 281, 1823, 2128, 293, 722, 13950, 11], "temperature": 0.0, "avg_logprob": -0.1331348830255969, "compression_ratio": 1.7230769230769232, "no_speech_prob": 7.29444809621782e-06}, {"id": 48, "seek": 29040, "start": 290.4, "end": 295.59999999999997, "text": " right? Have a voice and not be kind of this shadowy person in the background until they", "tokens": [558, 30, 3560, 257, 3177, 293, 406, 312, 733, 295, 341, 8576, 88, 954, 294, 264, 3678, 1826, 436], "temperature": 0.0, "avg_logprob": -0.11548633985621955, "compression_ratio": 1.6055045871559632, "no_speech_prob": 7.069483672239585e-06}, {"id": 49, "seek": 29040, "start": 295.59999999999997, "end": 301.84, "text": " figure things out, right? And we want them to get a sense of who our community is, what", "tokens": [2573, 721, 484, 11, 558, 30, 400, 321, 528, 552, 281, 483, 257, 2020, 295, 567, 527, 1768, 307, 11, 437], "temperature": 0.0, "avg_logprob": -0.11548633985621955, "compression_ratio": 1.6055045871559632, "no_speech_prob": 7.069483672239585e-06}, {"id": 50, "seek": 29040, "start": 301.84, "end": 309.35999999999996, "text": " they're doing, what we're doing together, what we're building. And we have end users,", "tokens": [436, 434, 884, 11, 437, 321, 434, 884, 1214, 11, 437, 321, 434, 2390, 13, 400, 321, 362, 917, 5022, 11], "temperature": 0.0, "avg_logprob": -0.11548633985621955, "compression_ratio": 1.6055045871559632, "no_speech_prob": 7.069483672239585e-06}, {"id": 51, "seek": 29040, "start": 309.35999999999996, "end": 315.32, "text": " right? The people who are using our projects. So when they come into a chat, again, it's", "tokens": [558, 30, 440, 561, 567, 366, 1228, 527, 4455, 13, 407, 562, 436, 808, 666, 257, 5081, 11, 797, 11, 309, 311], "temperature": 0.0, "avg_logprob": -0.11548633985621955, "compression_ratio": 1.6055045871559632, "no_speech_prob": 7.069483672239585e-06}, {"id": 52, "seek": 31532, "start": 315.32, "end": 321.68, "text": " overwhelming, lots of conversations going on. And they have a question or a doubt or", "tokens": [13373, 11, 3195, 295, 7315, 516, 322, 13, 400, 436, 362, 257, 1168, 420, 257, 6385, 420], "temperature": 0.0, "avg_logprob": -0.146392822265625, "compression_ratio": 1.7891156462585034, "no_speech_prob": 9.970078281185124e-06}, {"id": 53, "seek": 31532, "start": 321.68, "end": 325.71999999999997, "text": " maybe some feedback to give. They may not choose to do that in your chat if there's", "tokens": [1310, 512, 5824, 281, 976, 13, 814, 815, 406, 2826, 281, 360, 300, 294, 428, 5081, 498, 456, 311], "temperature": 0.0, "avg_logprob": -0.146392822265625, "compression_ratio": 1.7891156462585034, "no_speech_prob": 9.970078281185124e-06}, {"id": 54, "seek": 31532, "start": 325.71999999999997, "end": 329.64, "text": " not a space for them that they feel like their voice is going to be heard, right? So if it's", "tokens": [406, 257, 1901, 337, 552, 300, 436, 841, 411, 641, 3177, 307, 516, 281, 312, 2198, 11, 558, 30, 407, 498, 309, 311], "temperature": 0.0, "avg_logprob": -0.146392822265625, "compression_ratio": 1.7891156462585034, "no_speech_prob": 9.970078281185124e-06}, {"id": 55, "seek": 31532, "start": 329.64, "end": 334.08, "text": " this kind of chaotic, loud, cacophonous, like chat, hey, what's going on, da-da-da-da, lots", "tokens": [341, 733, 295, 27013, 11, 6588, 11, 269, 326, 5317, 266, 563, 11, 411, 5081, 11, 4177, 11, 437, 311, 516, 322, 11, 1120, 12, 2675, 12, 2675, 12, 2675, 11, 3195], "temperature": 0.0, "avg_logprob": -0.146392822265625, "compression_ratio": 1.7891156462585034, "no_speech_prob": 9.970078281185124e-06}, {"id": 56, "seek": 31532, "start": 334.08, "end": 338.24, "text": " of things going on, they may be like, all right, no, this is not, I'm not going to be", "tokens": [295, 721, 516, 322, 11, 436, 815, 312, 411, 11, 439, 558, 11, 572, 11, 341, 307, 406, 11, 286, 478, 406, 516, 281, 312], "temperature": 0.0, "avg_logprob": -0.146392822265625, "compression_ratio": 1.7891156462585034, "no_speech_prob": 9.970078281185124e-06}, {"id": 57, "seek": 31532, "start": 338.24, "end": 344.48, "text": " able to engage here. So we really want to create a chat space that they can have these", "tokens": [1075, 281, 4683, 510, 13, 407, 321, 534, 528, 281, 1884, 257, 5081, 1901, 300, 436, 393, 362, 613], "temperature": 0.0, "avg_logprob": -0.146392822265625, "compression_ratio": 1.7891156462585034, "no_speech_prob": 9.970078281185124e-06}, {"id": 58, "seek": 34448, "start": 344.48, "end": 351.6, "text": " needs met. And, of course, we have lots of interact, we're talking about interacting", "tokens": [2203, 1131, 13, 400, 11, 295, 1164, 11, 321, 362, 3195, 295, 4648, 11, 321, 434, 1417, 466, 18017], "temperature": 0.0, "avg_logprob": -0.14942338990002144, "compression_ratio": 1.6081081081081081, "no_speech_prob": 2.6676618290366605e-05}, {"id": 59, "seek": 34448, "start": 351.6, "end": 357.24, "text": " with these people, but it was 20 minutes and kind of going on. These are kind of three", "tokens": [365, 613, 561, 11, 457, 309, 390, 945, 2077, 293, 733, 295, 516, 322, 13, 1981, 366, 733, 295, 1045], "temperature": 0.0, "avg_logprob": -0.14942338990002144, "compression_ratio": 1.6081081081081081, "no_speech_prob": 2.6676618290366605e-05}, {"id": 60, "seek": 34448, "start": 357.24, "end": 363.40000000000003, "text": " characteristics of collaboration and communication with chat that I've identified as being kind", "tokens": [10891, 295, 9363, 293, 6101, 365, 5081, 300, 286, 600, 9234, 382, 885, 733], "temperature": 0.0, "avg_logprob": -0.14942338990002144, "compression_ratio": 1.6081081081081081, "no_speech_prob": 2.6676618290366605e-05}, {"id": 61, "seek": 34448, "start": 363.40000000000003, "end": 369.68, "text": " of core to serving open source, open research projects. And that's as well as live having", "tokens": [295, 4965, 281, 8148, 1269, 4009, 11, 1269, 2132, 4455, 13, 400, 300, 311, 382, 731, 382, 1621, 1419], "temperature": 0.0, "avg_logprob": -0.14942338990002144, "compression_ratio": 1.6081081081081081, "no_speech_prob": 2.6676618290366605e-05}, {"id": 62, "seek": 36968, "start": 369.68, "end": 375.92, "text": " an asynchronous ability to chat, having an efficient chat experience, and having a transparent", "tokens": [364, 49174, 3485, 281, 5081, 11, 1419, 364, 7148, 5081, 1752, 11, 293, 1419, 257, 12737], "temperature": 0.0, "avg_logprob": -0.17347326511290015, "compression_ratio": 1.6047619047619048, "no_speech_prob": 6.047441274859011e-06}, {"id": 63, "seek": 36968, "start": 375.92, "end": 383.52, "text": " chat experience. So something that we're working on together.", "tokens": [5081, 1752, 13, 407, 746, 300, 321, 434, 1364, 322, 1214, 13], "temperature": 0.0, "avg_logprob": -0.17347326511290015, "compression_ratio": 1.6047619047619048, "no_speech_prob": 6.047441274859011e-06}, {"id": 64, "seek": 36968, "start": 383.52, "end": 388.36, "text": " So going back to Zulip, again, I'm a contributor to the Zulip open source project. It's 100%", "tokens": [407, 516, 646, 281, 1176, 425, 647, 11, 797, 11, 286, 478, 257, 42859, 281, 264, 1176, 425, 647, 1269, 4009, 1716, 13, 467, 311, 2319, 4], "temperature": 0.0, "avg_logprob": -0.17347326511290015, "compression_ratio": 1.6047619047619048, "no_speech_prob": 6.047441274859011e-06}, {"id": 65, "seek": 36968, "start": 388.36, "end": 394.04, "text": " open source, modern chat application. We have many, many contributors from all over the", "tokens": [1269, 4009, 11, 4363, 5081, 3861, 13, 492, 362, 867, 11, 867, 45627, 490, 439, 670, 264], "temperature": 0.0, "avg_logprob": -0.17347326511290015, "compression_ratio": 1.6047619047619048, "no_speech_prob": 6.047441274859011e-06}, {"id": 66, "seek": 39404, "start": 394.04, "end": 399.68, "text": " world, lots of people making their first time contribution to open source through either", "tokens": [1002, 11, 3195, 295, 561, 1455, 641, 700, 565, 13150, 281, 1269, 4009, 807, 2139], "temperature": 0.0, "avg_logprob": -0.16145585832141696, "compression_ratio": 1.5627705627705628, "no_speech_prob": 8.528899343218654e-06}, {"id": 67, "seek": 39404, "start": 399.68, "end": 407.88, "text": " an internship program like Outreachy, or Google Summer Code, or just for their own interests.", "tokens": [364, 16861, 1461, 411, 5925, 16226, 88, 11, 420, 3329, 16161, 15549, 11, 420, 445, 337, 641, 1065, 8847, 13], "temperature": 0.0, "avg_logprob": -0.16145585832141696, "compression_ratio": 1.5627705627705628, "no_speech_prob": 8.528899343218654e-06}, {"id": 68, "seek": 39404, "start": 407.88, "end": 412.84000000000003, "text": " And folks can choose to self-host, obviously, open source, their own server with their own", "tokens": [400, 4024, 393, 2826, 281, 2698, 12, 6037, 11, 2745, 11, 1269, 4009, 11, 641, 1065, 7154, 365, 641, 1065], "temperature": 0.0, "avg_logprob": -0.16145585832141696, "compression_ratio": 1.5627705627705628, "no_speech_prob": 8.528899343218654e-06}, {"id": 69, "seek": 39404, "start": 412.84000000000003, "end": 418.88, "text": " chat application, or we also host Zulip Cloud for folks who want to be organizations on", "tokens": [5081, 3861, 11, 420, 321, 611, 3975, 1176, 425, 647, 8061, 337, 4024, 567, 528, 281, 312, 6150, 322], "temperature": 0.0, "avg_logprob": -0.16145585832141696, "compression_ratio": 1.5627705627705628, "no_speech_prob": 8.528899343218654e-06}, {"id": 70, "seek": 41888, "start": 418.88, "end": 428.44, "text": " the cloud. So let's start talking about tackling those characteristics that I talked about.", "tokens": [264, 4588, 13, 407, 718, 311, 722, 1417, 466, 34415, 729, 10891, 300, 286, 2825, 466, 13], "temperature": 0.0, "avg_logprob": -0.15239970250563187, "compression_ratio": 1.6210045662100456, "no_speech_prob": 5.254590632830514e-06}, {"id": 71, "seek": 41888, "start": 428.44, "end": 434.76, "text": " So Zulip has this unique topic-based threading model. So you're probably familiar from chat", "tokens": [407, 1176, 425, 647, 575, 341, 3845, 4829, 12, 6032, 7207, 278, 2316, 13, 407, 291, 434, 1391, 4963, 490, 5081], "temperature": 0.0, "avg_logprob": -0.15239970250563187, "compression_ratio": 1.6210045662100456, "no_speech_prob": 5.254590632830514e-06}, {"id": 72, "seek": 41888, "start": 434.76, "end": 439.68, "text": " applications who has, everyone has a chat application they're using, right, with some", "tokens": [5821, 567, 575, 11, 1518, 575, 257, 5081, 3861, 436, 434, 1228, 11, 558, 11, 365, 512], "temperature": 0.0, "avg_logprob": -0.15239970250563187, "compression_ratio": 1.6210045662100456, "no_speech_prob": 5.254590632830514e-06}, {"id": 73, "seek": 41888, "start": 439.68, "end": 444.15999999999997, "text": " shape or other on their phone or whatnot. So we have maybe, we call them in Zulip, we", "tokens": [3909, 420, 661, 322, 641, 2593, 420, 25882, 13, 407, 321, 362, 1310, 11, 321, 818, 552, 294, 1176, 425, 647, 11, 321], "temperature": 0.0, "avg_logprob": -0.15239970250563187, "compression_ratio": 1.6210045662100456, "no_speech_prob": 5.254590632830514e-06}, {"id": 74, "seek": 44416, "start": 444.16, "end": 450.36, "text": " call them streams. You might be familiar with them as channels or rooms. And this is kind", "tokens": [818, 552, 15842, 13, 509, 1062, 312, 4963, 365, 552, 382, 9235, 420, 9396, 13, 400, 341, 307, 733], "temperature": 0.0, "avg_logprob": -0.14441712348015753, "compression_ratio": 1.6543778801843319, "no_speech_prob": 6.141443009255454e-06}, {"id": 75, "seek": 44416, "start": 450.36, "end": 456.40000000000003, "text": " of the big bucket that we set out for conversations that we're having. And the thing about Zulip", "tokens": [295, 264, 955, 13058, 300, 321, 992, 484, 337, 7315, 300, 321, 434, 1419, 13, 400, 264, 551, 466, 1176, 425, 647], "temperature": 0.0, "avg_logprob": -0.14441712348015753, "compression_ratio": 1.6543778801843319, "no_speech_prob": 6.141443009255454e-06}, {"id": 76, "seek": 44416, "start": 456.40000000000003, "end": 464.04, "text": " is we create another layer of context in our streams. So, for example, I have an image", "tokens": [307, 321, 1884, 1071, 4583, 295, 4319, 294, 527, 15842, 13, 407, 11, 337, 1365, 11, 286, 362, 364, 3256], "temperature": 0.0, "avg_logprob": -0.14441712348015753, "compression_ratio": 1.6543778801843319, "no_speech_prob": 6.141443009255454e-06}, {"id": 77, "seek": 44416, "start": 464.04, "end": 469.12, "text": " here of a stream for our annual summit that we're having. We're going to have a great", "tokens": [510, 295, 257, 4309, 337, 527, 9784, 21564, 300, 321, 434, 1419, 13, 492, 434, 516, 281, 362, 257, 869], "temperature": 0.0, "avg_logprob": -0.14441712348015753, "compression_ratio": 1.6543778801843319, "no_speech_prob": 6.141443009255454e-06}, {"id": 78, "seek": 46912, "start": 469.12, "end": 475.12, "text": " time at our annual summit. And we've actually, within our annual summit conversation, our", "tokens": [565, 412, 527, 9784, 21564, 13, 400, 321, 600, 767, 11, 1951, 527, 9784, 21564, 3761, 11, 527], "temperature": 0.0, "avg_logprob": -0.15699795073112555, "compression_ratio": 1.6628787878787878, "no_speech_prob": 5.9545964177232236e-06}, {"id": 79, "seek": 46912, "start": 475.12, "end": 479.4, "text": " stream, we have topics that are coming in and binding those groups of conversations", "tokens": [4309, 11, 321, 362, 8378, 300, 366, 1348, 294, 293, 17359, 729, 3935, 295, 7315], "temperature": 0.0, "avg_logprob": -0.15699795073112555, "compression_ratio": 1.6628787878787878, "no_speech_prob": 5.9545964177232236e-06}, {"id": 80, "seek": 46912, "start": 479.4, "end": 486.08, "text": " together, kind of like an email subject line would have. So it's the end of my day. I've", "tokens": [1214, 11, 733, 295, 411, 364, 3796, 3983, 1622, 576, 362, 13, 407, 309, 311, 264, 917, 295, 452, 786, 13, 286, 600], "temperature": 0.0, "avg_logprob": -0.15699795073112555, "compression_ratio": 1.6628787878787878, "no_speech_prob": 5.9545964177232236e-06}, {"id": 81, "seek": 46912, "start": 486.08, "end": 493.48, "text": " just got my CI passing on my issue. I'm super excited, but I'm going to sign off. But I", "tokens": [445, 658, 452, 37777, 8437, 322, 452, 2734, 13, 286, 478, 1687, 2919, 11, 457, 286, 478, 516, 281, 1465, 766, 13, 583, 286], "temperature": 0.0, "avg_logprob": -0.15699795073112555, "compression_ratio": 1.6628787878787878, "no_speech_prob": 5.9545964177232236e-06}, {"id": 82, "seek": 46912, "start": 493.48, "end": 498.24, "text": " signed into chat just before I go, and I look and I have 78 unread messages in my annual", "tokens": [8175, 666, 5081, 445, 949, 286, 352, 11, 293, 286, 574, 293, 286, 362, 26369, 517, 2538, 7897, 294, 452, 9784], "temperature": 0.0, "avg_logprob": -0.15699795073112555, "compression_ratio": 1.6628787878787878, "no_speech_prob": 5.9545964177232236e-06}, {"id": 83, "seek": 49824, "start": 498.24, "end": 502.0, "text": " summit stream. And I was supposed to check in about this today. And I'm looking through", "tokens": [21564, 4309, 13, 400, 286, 390, 3442, 281, 1520, 294, 466, 341, 965, 13, 400, 286, 478, 1237, 807], "temperature": 0.0, "avg_logprob": -0.15680374477220618, "compression_ratio": 1.7862903225806452, "no_speech_prob": 2.586442860774696e-05}, {"id": 84, "seek": 49824, "start": 502.0, "end": 506.88, "text": " it and I look up, I open up the topics and I say, you know what? They are having a very", "tokens": [309, 293, 286, 574, 493, 11, 286, 1269, 493, 264, 8378, 293, 286, 584, 11, 291, 458, 437, 30, 814, 366, 1419, 257, 588], "temperature": 0.0, "avg_logprob": -0.15680374477220618, "compression_ratio": 1.7862903225806452, "no_speech_prob": 2.586442860774696e-05}, {"id": 85, "seek": 49824, "start": 506.88, "end": 512.5600000000001, "text": " lively discussion about a bouncy castle at our annual summit. But you know what? I don't", "tokens": [30866, 5017, 466, 257, 49704, 14114, 412, 527, 9784, 21564, 13, 583, 291, 458, 437, 30, 286, 500, 380], "temperature": 0.0, "avg_logprob": -0.15680374477220618, "compression_ratio": 1.7862903225806452, "no_speech_prob": 2.586442860774696e-05}, {"id": 86, "seek": 49824, "start": 512.5600000000001, "end": 518.0, "text": " like bouncy castles. I could care less about the bouncy castle. I have no interest in bouncy", "tokens": [411, 49704, 4193, 904, 13, 286, 727, 1127, 1570, 466, 264, 49704, 14114, 13, 286, 362, 572, 1179, 294, 49704], "temperature": 0.0, "avg_logprob": -0.15680374477220618, "compression_ratio": 1.7862903225806452, "no_speech_prob": 2.586442860774696e-05}, {"id": 87, "seek": 49824, "start": 518.0, "end": 524.36, "text": " castle. I'm not going to be jumping in the bouncy castle at the summit. So that is 48", "tokens": [14114, 13, 286, 478, 406, 516, 281, 312, 11233, 294, 264, 49704, 14114, 412, 264, 21564, 13, 407, 300, 307, 11174], "temperature": 0.0, "avg_logprob": -0.15680374477220618, "compression_ratio": 1.7862903225806452, "no_speech_prob": 2.586442860774696e-05}, {"id": 88, "seek": 52436, "start": 524.36, "end": 529.44, "text": " messages that I know right there from the topic. I don't need to read right now. I can", "tokens": [7897, 300, 286, 458, 558, 456, 490, 264, 4829, 13, 286, 500, 380, 643, 281, 1401, 558, 586, 13, 286, 393], "temperature": 0.0, "avg_logprob": -0.09995151802345559, "compression_ratio": 1.7540983606557377, "no_speech_prob": 1.568685911479406e-05}, {"id": 89, "seek": 52436, "start": 529.44, "end": 534.76, "text": " save those for later. I can mark them unread now, whatever I'd like to do. But I can look", "tokens": [3155, 729, 337, 1780, 13, 286, 393, 1491, 552, 517, 2538, 586, 11, 2035, 286, 1116, 411, 281, 360, 13, 583, 286, 393, 574], "temperature": 0.0, "avg_logprob": -0.09995151802345559, "compression_ratio": 1.7540983606557377, "no_speech_prob": 1.568685911479406e-05}, {"id": 90, "seek": 52436, "start": 534.76, "end": 538.0, "text": " at these topics and say, you know what? I'm really interested in the catering because", "tokens": [412, 613, 8378, 293, 584, 11, 291, 458, 437, 30, 286, 478, 534, 3102, 294, 264, 21557, 278, 570], "temperature": 0.0, "avg_logprob": -0.09995151802345559, "compression_ratio": 1.7540983606557377, "no_speech_prob": 1.568685911479406e-05}, {"id": 91, "seek": 52436, "start": 538.0, "end": 542.36, "text": " I know some people attending our summit have some not allergies that are very severe. And", "tokens": [286, 458, 512, 561, 15862, 527, 21564, 362, 512, 406, 37007, 300, 366, 588, 8922, 13, 400], "temperature": 0.0, "avg_logprob": -0.09995151802345559, "compression_ratio": 1.7540983606557377, "no_speech_prob": 1.568685911479406e-05}, {"id": 92, "seek": 52436, "start": 542.36, "end": 548.44, "text": " I want to make sure that's part of this discussion focused on our catering. So I'm going to look", "tokens": [286, 528, 281, 652, 988, 300, 311, 644, 295, 341, 5017, 5178, 322, 527, 21557, 278, 13, 407, 286, 478, 516, 281, 574], "temperature": 0.0, "avg_logprob": -0.09995151802345559, "compression_ratio": 1.7540983606557377, "no_speech_prob": 1.568685911479406e-05}, {"id": 93, "seek": 52436, "start": 548.44, "end": 552.76, "text": " at that topic and that focus conversation context there. And if no one's brought that", "tokens": [412, 300, 4829, 293, 300, 1879, 3761, 4319, 456, 13, 400, 498, 572, 472, 311, 3038, 300], "temperature": 0.0, "avg_logprob": -0.09995151802345559, "compression_ratio": 1.7540983606557377, "no_speech_prob": 1.568685911479406e-05}, {"id": 94, "seek": 55276, "start": 552.76, "end": 558.4399999999999, "text": " up in those four different messages, then I'm going to put in a pertinent question there.", "tokens": [493, 294, 729, 1451, 819, 7897, 11, 550, 286, 478, 516, 281, 829, 294, 257, 13269, 11058, 1168, 456, 13], "temperature": 0.0, "avg_logprob": -0.1247088352096415, "compression_ratio": 1.602189781021898, "no_speech_prob": 8.529136721335817e-06}, {"id": 95, "seek": 55276, "start": 558.4399999999999, "end": 562.36, "text": " Hey, do we know that people are coming with not allergies? Are we making sure our catering", "tokens": [1911, 11, 360, 321, 458, 300, 561, 366, 1348, 365, 406, 37007, 30, 2014, 321, 1455, 988, 527, 21557, 278], "temperature": 0.0, "avg_logprob": -0.1247088352096415, "compression_ratio": 1.602189781021898, "no_speech_prob": 8.529136721335817e-06}, {"id": 96, "seek": 55276, "start": 562.36, "end": 569.92, "text": " is accommodating that need? So by reading through my topics, topic by topic, I can focus", "tokens": [307, 11713, 990, 300, 643, 30, 407, 538, 3760, 807, 452, 8378, 11, 4829, 538, 4829, 11, 286, 393, 1879], "temperature": 0.0, "avg_logprob": -0.1247088352096415, "compression_ratio": 1.602189781021898, "no_speech_prob": 8.529136721335817e-06}, {"id": 97, "seek": 55276, "start": 569.92, "end": 575.18, "text": " on what my interests are, where I can add value to the chat, and it makes the whole", "tokens": [322, 437, 452, 8847, 366, 11, 689, 286, 393, 909, 2158, 281, 264, 5081, 11, 293, 309, 1669, 264, 1379], "temperature": 0.0, "avg_logprob": -0.1247088352096415, "compression_ratio": 1.602189781021898, "no_speech_prob": 8.529136721335817e-06}, {"id": 98, "seek": 55276, "start": 575.18, "end": 580.92, "text": " experience much more manageable. So topics really make asynchronous chat work. We now", "tokens": [1752, 709, 544, 38798, 13, 407, 8378, 534, 652, 49174, 5081, 589, 13, 492, 586], "temperature": 0.0, "avg_logprob": -0.1247088352096415, "compression_ratio": 1.602189781021898, "no_speech_prob": 8.529136721335817e-06}, {"id": 99, "seek": 58092, "start": 580.92, "end": 590.36, "text": " have folks all over the globe who can participate with more contextual feedback when they're", "tokens": [362, 4024, 439, 670, 264, 15371, 567, 393, 8197, 365, 544, 35526, 5824, 562, 436, 434], "temperature": 0.0, "avg_logprob": -0.15814293622970582, "compression_ratio": 1.5884955752212389, "no_speech_prob": 1.2602280548890121e-05}, {"id": 100, "seek": 58092, "start": 590.36, "end": 594.9599999999999, "text": " online. So again, if they really care about that bouncy castle conversation that happened,", "tokens": [2950, 13, 407, 797, 11, 498, 436, 534, 1127, 466, 300, 49704, 14114, 3761, 300, 2011, 11], "temperature": 0.0, "avg_logprob": -0.15814293622970582, "compression_ratio": 1.5884955752212389, "no_speech_prob": 1.2602280548890121e-05}, {"id": 101, "seek": 58092, "start": 594.9599999999999, "end": 600.4, "text": " they can still jump in and add their feedback there. Again, we make some space for people", "tokens": [436, 393, 920, 3012, 294, 293, 909, 641, 5824, 456, 13, 3764, 11, 321, 652, 512, 1901, 337, 561], "temperature": 0.0, "avg_logprob": -0.15814293622970582, "compression_ratio": 1.5884955752212389, "no_speech_prob": 1.2602280548890121e-05}, {"id": 102, "seek": 58092, "start": 600.4, "end": 609.0, "text": " whose voices might get lost, new folks and users. And so chat becomes more useful for", "tokens": [6104, 9802, 1062, 483, 2731, 11, 777, 4024, 293, 5022, 13, 400, 370, 5081, 3643, 544, 4420, 337], "temperature": 0.0, "avg_logprob": -0.15814293622970582, "compression_ratio": 1.5884955752212389, "no_speech_prob": 1.2602280548890121e-05}, {"id": 103, "seek": 60900, "start": 609.0, "end": 618.4, "text": " them. But of course, topics are being used by humans. Humans do not always work. We don't", "tokens": [552, 13, 583, 295, 1164, 11, 8378, 366, 885, 1143, 538, 6255, 13, 35809, 360, 406, 1009, 589, 13, 492, 500, 380], "temperature": 0.0, "avg_logprob": -0.14814232076917375, "compression_ratio": 1.7529411764705882, "no_speech_prob": 1.3841208783560432e-05}, {"id": 104, "seek": 60900, "start": 618.4, "end": 623.64, "text": " have conversations in straight lines. We don't always make sense all the time. And we need", "tokens": [362, 7315, 294, 2997, 3876, 13, 492, 500, 380, 1009, 652, 2020, 439, 264, 565, 13, 400, 321, 643], "temperature": 0.0, "avg_logprob": -0.14814232076917375, "compression_ratio": 1.7529411764705882, "no_speech_prob": 1.3841208783560432e-05}, {"id": 105, "seek": 60900, "start": 623.64, "end": 626.68, "text": " to make sure that they work with the humans that are working with them. So at Zulip, we've", "tokens": [281, 652, 988, 300, 436, 589, 365, 264, 6255, 300, 366, 1364, 365, 552, 13, 407, 412, 1176, 425, 647, 11, 321, 600], "temperature": 0.0, "avg_logprob": -0.14814232076917375, "compression_ratio": 1.7529411764705882, "no_speech_prob": 1.3841208783560432e-05}, {"id": 106, "seek": 60900, "start": 626.68, "end": 632.68, "text": " made a number of tools to work with this kind of patterns of conversations that we have.", "tokens": [1027, 257, 1230, 295, 3873, 281, 589, 365, 341, 733, 295, 8294, 295, 7315, 300, 321, 362, 13], "temperature": 0.0, "avg_logprob": -0.14814232076917375, "compression_ratio": 1.7529411764705882, "no_speech_prob": 1.3841208783560432e-05}, {"id": 107, "seek": 60900, "start": 632.68, "end": 638.04, "text": " So for example, maybe we have this really, we have this new feature we're implementing", "tokens": [407, 337, 1365, 11, 1310, 321, 362, 341, 534, 11, 321, 362, 341, 777, 4111, 321, 434, 18114], "temperature": 0.0, "avg_logprob": -0.14814232076917375, "compression_ratio": 1.7529411764705882, "no_speech_prob": 1.3841208783560432e-05}, {"id": 108, "seek": 63804, "start": 638.04, "end": 642.8399999999999, "text": " during this really intense design conversation in our design stream. And somebody has this", "tokens": [1830, 341, 534, 9447, 1715, 3761, 294, 527, 1715, 4309, 13, 400, 2618, 575, 341], "temperature": 0.0, "avg_logprob": -0.14138632839165846, "compression_ratio": 1.960352422907489, "no_speech_prob": 1.5933197573758662e-05}, {"id": 109, "seek": 63804, "start": 642.8399999999999, "end": 647.0799999999999, "text": " really great new idea right here. What we're going to do is take that new idea message.", "tokens": [534, 869, 777, 1558, 558, 510, 13, 708, 321, 434, 516, 281, 360, 307, 747, 300, 777, 1558, 3636, 13], "temperature": 0.0, "avg_logprob": -0.14138632839165846, "compression_ratio": 1.960352422907489, "no_speech_prob": 1.5933197573758662e-05}, {"id": 110, "seek": 63804, "start": 647.0799999999999, "end": 650.88, "text": " We're going to move it over here to its own topic with the new idea. We're going to create", "tokens": [492, 434, 516, 281, 1286, 309, 670, 510, 281, 1080, 1065, 4829, 365, 264, 777, 1558, 13, 492, 434, 516, 281, 1884], "temperature": 0.0, "avg_logprob": -0.14138632839165846, "compression_ratio": 1.960352422907489, "no_speech_prob": 1.5933197573758662e-05}, {"id": 111, "seek": 63804, "start": 650.88, "end": 655.48, "text": " a link between these two topics in the same stream for the design. And now we have two", "tokens": [257, 2113, 1296, 613, 732, 8378, 294, 264, 912, 4309, 337, 264, 1715, 13, 400, 586, 321, 362, 732], "temperature": 0.0, "avg_logprob": -0.14138632839165846, "compression_ratio": 1.960352422907489, "no_speech_prob": 1.5933197573758662e-05}, {"id": 112, "seek": 63804, "start": 655.48, "end": 660.76, "text": " parallel topic conversations going on in the same stream about design that have context.", "tokens": [8952, 4829, 7315, 516, 322, 294, 264, 912, 4309, 466, 1715, 300, 362, 4319, 13], "temperature": 0.0, "avg_logprob": -0.14138632839165846, "compression_ratio": 1.960352422907489, "no_speech_prob": 1.5933197573758662e-05}, {"id": 113, "seek": 66076, "start": 660.76, "end": 668.08, "text": " We can go back. We can connect them. Maybe we're having this really intense conversation", "tokens": [492, 393, 352, 646, 13, 492, 393, 1745, 552, 13, 2704, 321, 434, 1419, 341, 534, 9447, 3761], "temperature": 0.0, "avg_logprob": -0.1648176790193747, "compression_ratio": 1.74, "no_speech_prob": 3.3921664908120874e-06}, {"id": 114, "seek": 66076, "start": 668.08, "end": 672.08, "text": " about the new release. And we have a really excited new contributor jump in to say, hey,", "tokens": [466, 264, 777, 4374, 13, 400, 321, 362, 257, 534, 2919, 777, 42859, 3012, 294, 281, 584, 11, 4177, 11], "temperature": 0.0, "avg_logprob": -0.1648176790193747, "compression_ratio": 1.74, "no_speech_prob": 3.3921664908120874e-06}, {"id": 115, "seek": 66076, "start": 672.08, "end": 675.6, "text": " my name is, and I'm really excited. And what do we do? How do I get things done? And we", "tokens": [452, 1315, 307, 11, 293, 286, 478, 534, 2919, 13, 400, 437, 360, 321, 360, 30, 1012, 360, 286, 483, 721, 1096, 30, 400, 321], "temperature": 0.0, "avg_logprob": -0.1648176790193747, "compression_ratio": 1.74, "no_speech_prob": 3.3921664908120874e-06}, {"id": 116, "seek": 66076, "start": 675.6, "end": 680.6, "text": " can take that message, move it over to the new person stream, say introductions. Hi,", "tokens": [393, 747, 300, 3636, 11, 1286, 309, 670, 281, 264, 777, 954, 4309, 11, 584, 48032, 13, 2421, 11], "temperature": 0.0, "avg_logprob": -0.1648176790193747, "compression_ratio": 1.74, "no_speech_prob": 3.3921664908120874e-06}, {"id": 117, "seek": 66076, "start": 680.6, "end": 683.76, "text": " welcome. We're so glad you're here. Please read our documentation. Let us know if you", "tokens": [2928, 13, 492, 434, 370, 5404, 291, 434, 510, 13, 2555, 1401, 527, 14333, 13, 961, 505, 458, 498, 291], "temperature": 0.0, "avg_logprob": -0.1648176790193747, "compression_ratio": 1.74, "no_speech_prob": 3.3921664908120874e-06}, {"id": 118, "seek": 66076, "start": 683.76, "end": 686.84, "text": " have questions. And this really important release conversation that's going on in our", "tokens": [362, 1651, 13, 400, 341, 534, 1021, 4374, 3761, 300, 311, 516, 322, 294, 527], "temperature": 0.0, "avg_logprob": -0.1648176790193747, "compression_ratio": 1.74, "no_speech_prob": 3.3921664908120874e-06}, {"id": 119, "seek": 68684, "start": 686.84, "end": 693.6800000000001, "text": " release stream continues uninterrupted, and we keep our flow organized and efficient.", "tokens": [4374, 4309, 6515, 49234, 5428, 292, 11, 293, 321, 1066, 527, 3095, 9983, 293, 7148, 13], "temperature": 0.0, "avg_logprob": -0.18715684678819444, "compression_ratio": 1.6470588235294117, "no_speech_prob": 2.2120459107100032e-05}, {"id": 120, "seek": 68684, "start": 693.6800000000001, "end": 700.8000000000001, "text": " Maybe you have some come in with a help question, right? They're asking for help. They're working", "tokens": [2704, 291, 362, 512, 808, 294, 365, 257, 854, 1168, 11, 558, 30, 814, 434, 3365, 337, 854, 13, 814, 434, 1364], "temperature": 0.0, "avg_logprob": -0.18715684678819444, "compression_ratio": 1.6470588235294117, "no_speech_prob": 2.2120459107100032e-05}, {"id": 121, "seek": 68684, "start": 700.8000000000001, "end": 705.2800000000001, "text": " on upgrading to the new release. They have some questions. They've had some issues. Some", "tokens": [322, 36249, 281, 264, 777, 4374, 13, 814, 362, 512, 1651, 13, 814, 600, 632, 512, 2663, 13, 2188], "temperature": 0.0, "avg_logprob": -0.18715684678819444, "compression_ratio": 1.6470588235294117, "no_speech_prob": 2.2120459107100032e-05}, {"id": 122, "seek": 68684, "start": 705.2800000000001, "end": 713.6, "text": " of our SysOps people get on, work with them with a question, and they come to a resolution.", "tokens": [295, 527, 318, 749, 36179, 561, 483, 322, 11, 589, 365, 552, 365, 257, 1168, 11, 293, 436, 808, 281, 257, 8669, 13], "temperature": 0.0, "avg_logprob": -0.18715684678819444, "compression_ratio": 1.6470588235294117, "no_speech_prob": 2.2120459107100032e-05}, {"id": 123, "seek": 71360, "start": 713.6, "end": 718.16, "text": " That user can then mark that topic as resolved. A big check mark will show up in front of", "tokens": [663, 4195, 393, 550, 1491, 300, 4829, 382, 20772, 13, 316, 955, 1520, 1491, 486, 855, 493, 294, 1868, 295], "temperature": 0.0, "avg_logprob": -0.13094843103644555, "compression_ratio": 1.613953488372093, "no_speech_prob": 1.2802739547623787e-05}, {"id": 124, "seek": 71360, "start": 718.16, "end": 723.6800000000001, "text": " that topic visually. And now we know that that question has been answered and resolved.", "tokens": [300, 4829, 19622, 13, 400, 586, 321, 458, 300, 300, 1168, 575, 668, 10103, 293, 20772, 13], "temperature": 0.0, "avg_logprob": -0.13094843103644555, "compression_ratio": 1.613953488372093, "no_speech_prob": 1.2802739547623787e-05}, {"id": 125, "seek": 71360, "start": 723.6800000000001, "end": 734.5600000000001, "text": " And so we have this kind of, they have the ability to step out and say, hey, you know", "tokens": [400, 370, 321, 362, 341, 733, 295, 11, 436, 362, 264, 3485, 281, 1823, 484, 293, 584, 11, 4177, 11, 291, 458], "temperature": 0.0, "avg_logprob": -0.13094843103644555, "compression_ratio": 1.613953488372093, "no_speech_prob": 1.2802739547623787e-05}, {"id": 126, "seek": 71360, "start": 734.5600000000001, "end": 741.8000000000001, "text": " what? My question was answered. Thank you so much. This is done. So again, creating", "tokens": [437, 30, 1222, 1168, 390, 10103, 13, 1044, 291, 370, 709, 13, 639, 307, 1096, 13, 407, 797, 11, 4084], "temperature": 0.0, "avg_logprob": -0.13094843103644555, "compression_ratio": 1.613953488372093, "no_speech_prob": 1.2802739547623787e-05}, {"id": 127, "seek": 74180, "start": 741.8, "end": 747.3199999999999, "text": " organization within our topics makes things more efficient. People can prioritize their", "tokens": [4475, 1951, 527, 8378, 1669, 721, 544, 7148, 13, 3432, 393, 25164, 641], "temperature": 0.0, "avg_logprob": -0.1536708719590131, "compression_ratio": 1.7939189189189189, "no_speech_prob": 3.119628308922984e-05}, {"id": 128, "seek": 74180, "start": 747.3199999999999, "end": 753.16, "text": " time. We can move conversations forward. And people have agency to say, thank you. I'm", "tokens": [565, 13, 492, 393, 1286, 7315, 2128, 13, 400, 561, 362, 7934, 281, 584, 11, 1309, 291, 13, 286, 478], "temperature": 0.0, "avg_logprob": -0.1536708719590131, "compression_ratio": 1.7939189189189189, "no_speech_prob": 3.119628308922984e-05}, {"id": 129, "seek": 74180, "start": 753.16, "end": 758.76, "text": " done. Or, hey, this unresolved this topic. We thought we fixed it, but we didn't. It's", "tokens": [1096, 13, 1610, 11, 4177, 11, 341, 517, 495, 29110, 341, 4829, 13, 492, 1194, 321, 6806, 309, 11, 457, 321, 994, 380, 13, 467, 311], "temperature": 0.0, "avg_logprob": -0.1536708719590131, "compression_ratio": 1.7939189189189189, "no_speech_prob": 3.119628308922984e-05}, {"id": 130, "seek": 74180, "start": 758.76, "end": 763.16, "text": " still an issue. Let's unresolve it. And we're building up all of this. These conversations", "tokens": [920, 364, 2734, 13, 961, 311, 517, 495, 37361, 309, 13, 400, 321, 434, 2390, 493, 439, 295, 341, 13, 1981, 7315], "temperature": 0.0, "avg_logprob": -0.1536708719590131, "compression_ratio": 1.7939189189189189, "no_speech_prob": 3.119628308922984e-05}, {"id": 131, "seek": 74180, "start": 763.16, "end": 765.8, "text": " are happening. They're branching off here. They're branching off there. They're branching", "tokens": [366, 2737, 13, 814, 434, 9819, 278, 766, 510, 13, 814, 434, 9819, 278, 766, 456, 13, 814, 434, 9819, 278], "temperature": 0.0, "avg_logprob": -0.1536708719590131, "compression_ratio": 1.7939189189189189, "no_speech_prob": 3.119628308922984e-05}, {"id": 132, "seek": 74180, "start": 765.8, "end": 769.8, "text": " out there. And we built this big tree, this repository of knowledge. Now our chat is not", "tokens": [484, 456, 13, 400, 321, 3094, 341, 955, 4230, 11, 341, 25841, 295, 3601, 13, 823, 527, 5081, 307, 406], "temperature": 0.0, "avg_logprob": -0.1536708719590131, "compression_ratio": 1.7939189189189189, "no_speech_prob": 3.119628308922984e-05}, {"id": 133, "seek": 76980, "start": 769.8, "end": 773.92, "text": " something ephemeral, happening in the moment. We're really starting to create sort of a", "tokens": [746, 308, 41245, 2790, 11, 2737, 294, 264, 1623, 13, 492, 434, 534, 2891, 281, 1884, 1333, 295, 257], "temperature": 0.0, "avg_logprob": -0.17174409978529986, "compression_ratio": 1.5720524017467248, "no_speech_prob": 1.3630196917802095e-05}, {"id": 134, "seek": 76980, "start": 773.92, "end": 779.64, "text": " repository of knowledge that's there for everyone to share. So we've got this asynchronous", "tokens": [25841, 295, 3601, 300, 311, 456, 337, 1518, 281, 2073, 13, 407, 321, 600, 658, 341, 49174], "temperature": 0.0, "avg_logprob": -0.17174409978529986, "compression_ratio": 1.5720524017467248, "no_speech_prob": 1.3630196917802095e-05}, {"id": 135, "seek": 76980, "start": 779.64, "end": 785.4799999999999, "text": " conversations. We've got this repository of knowledge. What about the transparency, right?", "tokens": [7315, 13, 492, 600, 658, 341, 25841, 295, 3601, 13, 708, 466, 264, 17131, 11, 558, 30], "temperature": 0.0, "avg_logprob": -0.17174409978529986, "compression_ratio": 1.5720524017467248, "no_speech_prob": 1.3630196917802095e-05}, {"id": 136, "seek": 76980, "start": 785.4799999999999, "end": 794.4799999999999, "text": " So in our most recent Zulu release in November, 6.0, our public access feature was landed.", "tokens": [407, 294, 527, 881, 5162, 1176, 12845, 4374, 294, 7674, 11, 1386, 13, 15, 11, 527, 1908, 2105, 4111, 390, 15336, 13], "temperature": 0.0, "avg_logprob": -0.17174409978529986, "compression_ratio": 1.5720524017467248, "no_speech_prob": 1.3630196917802095e-05}, {"id": 137, "seek": 79448, "start": 794.48, "end": 801.44, "text": " And what public access basically is, is an organization with a Zulip can decide, you", "tokens": [400, 437, 1908, 2105, 1936, 307, 11, 307, 364, 4475, 365, 257, 1176, 425, 647, 393, 4536, 11, 291], "temperature": 0.0, "avg_logprob": -0.1325230551238107, "compression_ratio": 1.7628458498023716, "no_speech_prob": 1.0951290278171655e-05}, {"id": 138, "seek": 79448, "start": 801.44, "end": 805.76, "text": " know what, that help stream we have, that's really important information we want to share", "tokens": [458, 437, 11, 300, 854, 4309, 321, 362, 11, 300, 311, 534, 1021, 1589, 321, 528, 281, 2073], "temperature": 0.0, "avg_logprob": -0.1325230551238107, "compression_ratio": 1.7628458498023716, "no_speech_prob": 1.0951290278171655e-05}, {"id": 139, "seek": 79448, "start": 805.76, "end": 810.08, "text": " with everyone. So we're going to make that web public, which basically means that anyone", "tokens": [365, 1518, 13, 407, 321, 434, 516, 281, 652, 300, 3670, 1908, 11, 597, 1936, 1355, 300, 2878], "temperature": 0.0, "avg_logprob": -0.1325230551238107, "compression_ratio": 1.7628458498023716, "no_speech_prob": 1.0951290278171655e-05}, {"id": 140, "seek": 79448, "start": 810.08, "end": 815.04, "text": " on the Internet can access those conversations without signing in and without logging into", "tokens": [322, 264, 7703, 393, 2105, 729, 7315, 1553, 13393, 294, 293, 1553, 27991, 666], "temperature": 0.0, "avg_logprob": -0.1325230551238107, "compression_ratio": 1.7628458498023716, "no_speech_prob": 1.0951290278171655e-05}, {"id": 141, "seek": 79448, "start": 815.04, "end": 821.36, "text": " your Zulip. So that now is information that's on the Internet available to anyone. Whatever", "tokens": [428, 1176, 425, 647, 13, 407, 300, 586, 307, 1589, 300, 311, 322, 264, 7703, 2435, 281, 2878, 13, 8541], "temperature": 0.0, "avg_logprob": -0.1325230551238107, "compression_ratio": 1.7628458498023716, "no_speech_prob": 1.0951290278171655e-05}, {"id": 142, "seek": 82136, "start": 821.36, "end": 825.92, "text": " their questions are, however they get there, they can start accessing that information.", "tokens": [641, 1651, 366, 11, 4461, 436, 483, 456, 11, 436, 393, 722, 26440, 300, 1589, 13], "temperature": 0.0, "avg_logprob": -0.137804977292937, "compression_ratio": 1.7796610169491525, "no_speech_prob": 1.8922019080491737e-05}, {"id": 143, "seek": 82136, "start": 825.92, "end": 830.0, "text": " Those help questions right away. Maybe we have our design conversations and we don't put", "tokens": [3950, 854, 1651, 558, 1314, 13, 2704, 321, 362, 527, 1715, 7315, 293, 321, 500, 380, 829], "temperature": 0.0, "avg_logprob": -0.137804977292937, "compression_ratio": 1.7796610169491525, "no_speech_prob": 1.8922019080491737e-05}, {"id": 144, "seek": 82136, "start": 830.0, "end": 834.44, "text": " those in a public. So people know, what is our design ethic? Where are we moving? What", "tokens": [729, 294, 257, 1908, 13, 407, 561, 458, 11, 437, 307, 527, 1715, 37820, 30, 2305, 366, 321, 2684, 30, 708], "temperature": 0.0, "avg_logprob": -0.137804977292937, "compression_ratio": 1.7796610169491525, "no_speech_prob": 1.8922019080491737e-05}, {"id": 145, "seek": 82136, "start": 834.44, "end": 840.5600000000001, "text": " are we working on? And we can make that web public and people can engage. Maybe we've", "tokens": [366, 321, 1364, 322, 30, 400, 321, 393, 652, 300, 3670, 1908, 293, 561, 393, 4683, 13, 2704, 321, 600], "temperature": 0.0, "avg_logprob": -0.137804977292937, "compression_ratio": 1.7796610169491525, "no_speech_prob": 1.8922019080491737e-05}, {"id": 146, "seek": 82136, "start": 840.5600000000001, "end": 844.64, "text": " had this really great conversation about a new feature that we're implementing in our", "tokens": [632, 341, 534, 869, 3761, 466, 257, 777, 4111, 300, 321, 434, 18114, 294, 527], "temperature": 0.0, "avg_logprob": -0.137804977292937, "compression_ratio": 1.7796610169491525, "no_speech_prob": 1.8922019080491737e-05}, {"id": 147, "seek": 82136, "start": 844.64, "end": 851.08, "text": " chat. And we have over here in GitLab our issue tracker for that feature. We can actually", "tokens": [5081, 13, 400, 321, 362, 670, 510, 294, 16939, 37880, 527, 2734, 37516, 337, 300, 4111, 13, 492, 393, 767], "temperature": 0.0, "avg_logprob": -0.137804977292937, "compression_ratio": 1.7796610169491525, "no_speech_prob": 1.8922019080491737e-05}, {"id": 148, "seek": 85108, "start": 851.08, "end": 857.0, "text": " now, if that conversation happened on a web public stream, we can take that, make a link", "tokens": [586, 11, 498, 300, 3761, 2011, 322, 257, 3670, 1908, 4309, 11, 321, 393, 747, 300, 11, 652, 257, 2113], "temperature": 0.0, "avg_logprob": -0.11607481738713783, "compression_ratio": 1.7755775577557755, "no_speech_prob": 2.467562080710195e-05}, {"id": 149, "seek": 85108, "start": 857.0, "end": 861.84, "text": " to the chat. And again, anyone who gets to GitLab and looks at our issue and says, oh,", "tokens": [281, 264, 5081, 13, 400, 797, 11, 2878, 567, 2170, 281, 16939, 37880, 293, 1542, 412, 527, 2734, 293, 1619, 11, 1954, 11], "temperature": 0.0, "avg_logprob": -0.11607481738713783, "compression_ratio": 1.7755775577557755, "no_speech_prob": 2.467562080710195e-05}, {"id": 150, "seek": 85108, "start": 861.84, "end": 866.4000000000001, "text": " there's more information here, click relevant chat conversation. And now all of that information", "tokens": [456, 311, 544, 1589, 510, 11, 2052, 7340, 5081, 3761, 13, 400, 586, 439, 295, 300, 1589], "temperature": 0.0, "avg_logprob": -0.11607481738713783, "compression_ratio": 1.7755775577557755, "no_speech_prob": 2.467562080710195e-05}, {"id": 151, "seek": 85108, "start": 866.4000000000001, "end": 871.0400000000001, "text": " without logging in is available to that person. So again, we're really taking our chat with", "tokens": [1553, 27991, 294, 307, 2435, 281, 300, 954, 13, 407, 797, 11, 321, 434, 534, 1940, 527, 5081, 365], "temperature": 0.0, "avg_logprob": -0.11607481738713783, "compression_ratio": 1.7755775577557755, "no_speech_prob": 2.467562080710195e-05}, {"id": 152, "seek": 85108, "start": 871.0400000000001, "end": 876.48, "text": " the public access and moving it beyond our community and making it relevant to anyone", "tokens": [264, 1908, 2105, 293, 2684, 309, 4399, 527, 1768, 293, 1455, 309, 7340, 281, 2878], "temperature": 0.0, "avg_logprob": -0.11607481738713783, "compression_ratio": 1.7755775577557755, "no_speech_prob": 2.467562080710195e-05}, {"id": 153, "seek": 85108, "start": 876.48, "end": 880.2800000000001, "text": " who's curious about our open source, our open research projects, like what we're doing.", "tokens": [567, 311, 6369, 466, 527, 1269, 4009, 11, 527, 1269, 2132, 4455, 11, 411, 437, 321, 434, 884, 13], "temperature": 0.0, "avg_logprob": -0.11607481738713783, "compression_ratio": 1.7755775577557755, "no_speech_prob": 2.467562080710195e-05}, {"id": 154, "seek": 88028, "start": 880.28, "end": 887.0, "text": " This is a value of open source that we have. So again, if we're making decisions in chat,", "tokens": [639, 307, 257, 2158, 295, 1269, 4009, 300, 321, 362, 13, 407, 797, 11, 498, 321, 434, 1455, 5327, 294, 5081, 11], "temperature": 0.0, "avg_logprob": -0.09565032612193715, "compression_ratio": 1.6255707762557077, "no_speech_prob": 2.013107223319821e-05}, {"id": 155, "seek": 88028, "start": 887.0, "end": 892.36, "text": " this is available for people to see. New community members can start learning before they even", "tokens": [341, 307, 2435, 337, 561, 281, 536, 13, 1873, 1768, 2679, 393, 722, 2539, 949, 436, 754], "temperature": 0.0, "avg_logprob": -0.09565032612193715, "compression_ratio": 1.6255707762557077, "no_speech_prob": 2.013107223319821e-05}, {"id": 156, "seek": 88028, "start": 892.36, "end": 897.8399999999999, "text": " sign up. And we have this repository, this tree of knowledge that we built that's now", "tokens": [1465, 493, 13, 400, 321, 362, 341, 25841, 11, 341, 4230, 295, 3601, 300, 321, 3094, 300, 311, 586], "temperature": 0.0, "avg_logprob": -0.09565032612193715, "compression_ratio": 1.6255707762557077, "no_speech_prob": 2.013107223319821e-05}, {"id": 157, "seek": 88028, "start": 897.8399999999999, "end": 904.3199999999999, "text": " out there in the wild, in the forest of the internet that we have, that we're sharing", "tokens": [484, 456, 294, 264, 4868, 11, 294, 264, 6719, 295, 264, 4705, 300, 321, 362, 11, 300, 321, 434, 5414], "temperature": 0.0, "avg_logprob": -0.09565032612193715, "compression_ratio": 1.6255707762557077, "no_speech_prob": 2.013107223319821e-05}, {"id": 158, "seek": 90432, "start": 904.32, "end": 911.12, "text": " with everyone. So really creating that transparent and chat's becoming much more relevant beyond", "tokens": [365, 1518, 13, 407, 534, 4084, 300, 12737, 293, 5081, 311, 5617, 709, 544, 7340, 4399], "temperature": 0.0, "avg_logprob": -0.1864901860555013, "compression_ratio": 1.4959016393442623, "no_speech_prob": 6.8516719693434425e-06}, {"id": 159, "seek": 90432, "start": 911.12, "end": 919.6800000000001, "text": " just an ephemeral conversation. So as I mentioned, Zulip is 100% open source, free. You can", "tokens": [445, 364, 308, 41245, 2790, 3761, 13, 407, 382, 286, 2835, 11, 1176, 425, 647, 307, 2319, 4, 1269, 4009, 11, 1737, 13, 509, 393], "temperature": 0.0, "avg_logprob": -0.1864901860555013, "compression_ratio": 1.4959016393442623, "no_speech_prob": 6.8516719693434425e-06}, {"id": 160, "seek": 90432, "start": 919.6800000000001, "end": 926.5600000000001, "text": " start your own server. And we also have our Zulip Cloud, which has a free level of support,", "tokens": [722, 428, 1065, 7154, 13, 400, 321, 611, 362, 527, 1176, 425, 647, 8061, 11, 597, 575, 257, 1737, 1496, 295, 1406, 11], "temperature": 0.0, "avg_logprob": -0.1864901860555013, "compression_ratio": 1.4959016393442623, "no_speech_prob": 6.8516719693434425e-06}, {"id": 161, "seek": 90432, "start": 926.5600000000001, "end": 931.8800000000001, "text": " similarly to Slack before they made their change this summer, which is like limited.", "tokens": [14138, 281, 37211, 949, 436, 1027, 641, 1319, 341, 4266, 11, 597, 307, 411, 5567, 13], "temperature": 0.0, "avg_logprob": -0.1864901860555013, "compression_ratio": 1.4959016393442623, "no_speech_prob": 6.8516719693434425e-06}, {"id": 162, "seek": 93188, "start": 931.88, "end": 939.08, "text": " You have a certain history of messages. With non-profits, open source projects, academic", "tokens": [509, 362, 257, 1629, 2503, 295, 7897, 13, 2022, 2107, 12, 32480, 11, 1269, 4009, 4455, 11, 7778], "temperature": 0.0, "avg_logprob": -0.13060308939003082, "compression_ratio": 1.5347826086956522, "no_speech_prob": 1.2401438652887009e-05}, {"id": 163, "seek": 93188, "start": 939.08, "end": 943.4399999999999, "text": " research, we actually offer sponsorship on our Zulip Cloud standard, which is normally", "tokens": [2132, 11, 321, 767, 2626, 42922, 322, 527, 1176, 425, 647, 8061, 3832, 11, 597, 307, 5646], "temperature": 0.0, "avg_logprob": -0.13060308939003082, "compression_ratio": 1.5347826086956522, "no_speech_prob": 1.2401438652887009e-05}, {"id": 164, "seek": 93188, "start": 943.4399999999999, "end": 949.6, "text": " a paid platform. So you get even more history available to the public. It's not limited.", "tokens": [257, 4835, 3663, 13, 407, 291, 483, 754, 544, 2503, 2435, 281, 264, 1908, 13, 467, 311, 406, 5567, 13], "temperature": 0.0, "avg_logprob": -0.13060308939003082, "compression_ratio": 1.5347826086956522, "no_speech_prob": 1.2401438652887009e-05}, {"id": 165, "seek": 93188, "start": 949.6, "end": 955.56, "text": " That public access is there. So we really are committed to being part of the open source", "tokens": [663, 1908, 2105, 307, 456, 13, 407, 321, 534, 366, 7784, 281, 885, 644, 295, 264, 1269, 4009], "temperature": 0.0, "avg_logprob": -0.13060308939003082, "compression_ratio": 1.5347826086956522, "no_speech_prob": 1.2401438652887009e-05}, {"id": 166, "seek": 95556, "start": 955.56, "end": 964.0799999999999, "text": " community and making sure that all of our projects have great connection, collaboration,", "tokens": [1768, 293, 1455, 988, 300, 439, 295, 527, 4455, 362, 869, 4984, 11, 9363, 11], "temperature": 0.0, "avg_logprob": -0.1076538697728571, "compression_ratio": 1.6905660377358491, "no_speech_prob": 1.6948401025729254e-05}, {"id": 167, "seek": 95556, "start": 964.0799999999999, "end": 968.92, "text": " and are engaging all of the people who want to be involved in the organizations. Again,", "tokens": [293, 366, 11268, 439, 295, 264, 561, 567, 528, 281, 312, 3288, 294, 264, 6150, 13, 3764, 11], "temperature": 0.0, "avg_logprob": -0.1076538697728571, "compression_ratio": 1.6905660377358491, "no_speech_prob": 1.6948401025729254e-05}, {"id": 168, "seek": 95556, "start": 968.92, "end": 972.9599999999999, "text": " thank you so much. That's about it for me. I have some great links that are in the slides", "tokens": [1309, 291, 370, 709, 13, 663, 311, 466, 309, 337, 385, 13, 286, 362, 512, 869, 6123, 300, 366, 294, 264, 9788], "temperature": 0.0, "avg_logprob": -0.1076538697728571, "compression_ratio": 1.6905660377358491, "no_speech_prob": 1.6948401025729254e-05}, {"id": 169, "seek": 95556, "start": 972.9599999999999, "end": 977.8, "text": " here. The community's directory is a directory of organizations on Zulip that have opted", "tokens": [510, 13, 440, 1768, 311, 21120, 307, 257, 21120, 295, 6150, 322, 1176, 425, 647, 300, 362, 40768], "temperature": 0.0, "avg_logprob": -0.1076538697728571, "compression_ratio": 1.6905660377358491, "no_speech_prob": 1.6948401025729254e-05}, {"id": 170, "seek": 95556, "start": 977.8, "end": 982.8, "text": " into the public access already. So if you're curious, that's a great place to start looking.", "tokens": [666, 264, 1908, 2105, 1217, 13, 407, 498, 291, 434, 6369, 11, 300, 311, 257, 869, 1081, 281, 722, 1237, 13], "temperature": 0.0, "avg_logprob": -0.1076538697728571, "compression_ratio": 1.6905660377358491, "no_speech_prob": 1.6948401025729254e-05}, {"id": 171, "seek": 98280, "start": 982.8, "end": 986.88, "text": " You can find me at Zulip Development Community. That's where we are talking about Zulip and", "tokens": [509, 393, 915, 385, 412, 1176, 425, 647, 15041, 10421, 13, 663, 311, 689, 321, 366, 1417, 466, 1176, 425, 647, 293], "temperature": 0.0, "avg_logprob": -0.20137475785754977, "compression_ratio": 1.4834123222748816, "no_speech_prob": 1.0441444828757085e-05}, {"id": 172, "seek": 98280, "start": 986.88, "end": 992.4, "text": " the features that we're implementing and what we're doing. We have some case studies, etc.", "tokens": [264, 4122, 300, 321, 434, 18114, 293, 437, 321, 434, 884, 13, 492, 362, 512, 1389, 5313, 11, 5183, 13], "temperature": 0.0, "avg_logprob": -0.20137475785754977, "compression_ratio": 1.4834123222748816, "no_speech_prob": 1.0441444828757085e-05}, {"id": 173, "seek": 98280, "start": 992.4, "end": 998.8, "text": " So I want to open it to questions or I can jump into one of these open Zulip instances", "tokens": [407, 286, 528, 281, 1269, 309, 281, 1651, 420, 286, 393, 3012, 666, 472, 295, 613, 1269, 1176, 425, 647, 14519], "temperature": 0.0, "avg_logprob": -0.20137475785754977, "compression_ratio": 1.4834123222748816, "no_speech_prob": 1.0441444828757085e-05}, {"id": 174, "seek": 98280, "start": 998.8, "end": 1003.0, "text": " if anyone's interested. Yeah, so thank you.", "tokens": [498, 2878, 311, 3102, 13, 865, 11, 370, 1309, 291, 13], "temperature": 0.0, "avg_logprob": -0.20137475785754977, "compression_ratio": 1.4834123222748816, "no_speech_prob": 1.0441444828757085e-05}, {"id": 175, "seek": 100300, "start": 1003.0, "end": 1015.68, "text": " Yes. So for topics to work efficiently, you need to be really strict with moving messages", "tokens": [1079, 13, 407, 337, 8378, 281, 589, 19621, 11, 291, 643, 281, 312, 534, 10910, 365, 2684, 7897], "temperature": 0.0, "avg_logprob": -0.2579759828972094, "compression_ratio": 1.5375722543352601, "no_speech_prob": 0.00013085559476166964}, {"id": 176, "seek": 100300, "start": 1015.68, "end": 1024.56, "text": " around. That means that moderators, I guess, would have to scan every message and move", "tokens": [926, 13, 663, 1355, 300, 10494, 3391, 11, 286, 2041, 11, 576, 362, 281, 11049, 633, 3636, 293, 1286], "temperature": 0.0, "avg_logprob": -0.2579759828972094, "compression_ratio": 1.5375722543352601, "no_speech_prob": 0.00013085559476166964}, {"id": 177, "seek": 100300, "start": 1024.56, "end": 1031.2, "text": " things around. Yeah, yeah. So the question is, for topics to work and we're moving things", "tokens": [721, 926, 13, 865, 11, 1338, 13, 407, 264, 1168, 307, 11, 337, 8378, 281, 589, 293, 321, 434, 2684, 721], "temperature": 0.0, "avg_logprob": -0.2579759828972094, "compression_ratio": 1.5375722543352601, "no_speech_prob": 0.00013085559476166964}, {"id": 178, "seek": 103120, "start": 1031.2, "end": 1037.52, "text": " around and when people come in, you take on a lot of moderators who have to kind of be", "tokens": [926, 293, 562, 561, 808, 294, 11, 291, 747, 322, 257, 688, 295, 10494, 3391, 567, 362, 281, 733, 295, 312], "temperature": 0.0, "avg_logprob": -0.13639980387464862, "compression_ratio": 1.6167883211678833, "no_speech_prob": 1.7771493730833754e-05}, {"id": 179, "seek": 103120, "start": 1037.52, "end": 1045.16, "text": " very active and efficient in that. Yes, definitely in my experience in Zulip Cloud, it depends", "tokens": [588, 4967, 293, 7148, 294, 300, 13, 1079, 11, 2138, 294, 452, 1752, 294, 1176, 425, 647, 8061, 11, 309, 5946], "temperature": 0.0, "avg_logprob": -0.13639980387464862, "compression_ratio": 1.6167883211678833, "no_speech_prob": 1.7771493730833754e-05}, {"id": 180, "seek": 103120, "start": 1045.16, "end": 1049.96, "text": " on your organization. You can actually set that up. So for example, just moving topics", "tokens": [322, 428, 4475, 13, 509, 393, 767, 992, 300, 493, 13, 407, 337, 1365, 11, 445, 2684, 8378], "temperature": 0.0, "avg_logprob": -0.13639980387464862, "compression_ratio": 1.6167883211678833, "no_speech_prob": 1.7771493730833754e-05}, {"id": 181, "seek": 103120, "start": 1049.96, "end": 1055.56, "text": " within the same stream, like maybe somebody didn't name it very well, you can actually", "tokens": [1951, 264, 912, 4309, 11, 411, 1310, 2618, 994, 380, 1315, 309, 588, 731, 11, 291, 393, 767], "temperature": 0.0, "avg_logprob": -0.13639980387464862, "compression_ratio": 1.6167883211678833, "no_speech_prob": 1.7771493730833754e-05}, {"id": 182, "seek": 103120, "start": 1055.56, "end": 1060.56, "text": " set that permission level to a generic user right now and we're actually working on our", "tokens": [992, 300, 11226, 1496, 281, 257, 19577, 4195, 558, 586, 293, 321, 434, 767, 1364, 322, 527], "temperature": 0.0, "avg_logprob": -0.13639980387464862, "compression_ratio": 1.6167883211678833, "no_speech_prob": 1.7771493730833754e-05}, {"id": 183, "seek": 106056, "start": 1060.56, "end": 1066.6, "text": " user groups so that they can be even more designed to be unique to the organization.", "tokens": [4195, 3935, 370, 300, 436, 393, 312, 754, 544, 4761, 281, 312, 3845, 281, 264, 4475, 13], "temperature": 0.0, "avg_logprob": -0.13615543108720046, "compression_ratio": 1.6961538461538461, "no_speech_prob": 2.2119085770100355e-05}, {"id": 184, "seek": 106056, "start": 1066.6, "end": 1071.6, "text": " So like those levels of permissions can kind of be shared out throughout your user base.", "tokens": [407, 411, 729, 4358, 295, 32723, 393, 733, 295, 312, 5507, 484, 3710, 428, 4195, 3096, 13], "temperature": 0.0, "avg_logprob": -0.13615543108720046, "compression_ratio": 1.6961538461538461, "no_speech_prob": 2.2119085770100355e-05}, {"id": 185, "seek": 106056, "start": 1071.6, "end": 1077.72, "text": " So we actually have this in our new users a lot of times are coming in and to Zulip who", "tokens": [407, 321, 767, 362, 341, 294, 527, 777, 5022, 257, 688, 295, 1413, 366, 1348, 294, 293, 281, 1176, 425, 647, 567], "temperature": 0.0, "avg_logprob": -0.13615543108720046, "compression_ratio": 1.6961538461538461, "no_speech_prob": 2.2119085770100355e-05}, {"id": 186, "seek": 106056, "start": 1077.72, "end": 1083.32, "text": " want to contribute and they're sending messages and very quickly, they'll start actually,", "tokens": [528, 281, 10586, 293, 436, 434, 7750, 7897, 293, 588, 2661, 11, 436, 603, 722, 767, 11], "temperature": 0.0, "avg_logprob": -0.13615543108720046, "compression_ratio": 1.6961538461538461, "no_speech_prob": 2.2119085770100355e-05}, {"id": 187, "seek": 106056, "start": 1083.32, "end": 1088.04, "text": " if they see a message kind of go jump into a stream and interrupt a conversation, they'll", "tokens": [498, 436, 536, 257, 3636, 733, 295, 352, 3012, 666, 257, 4309, 293, 12729, 257, 3761, 11, 436, 603], "temperature": 0.0, "avg_logprob": -0.13615543108720046, "compression_ratio": 1.6961538461538461, "no_speech_prob": 2.2119085770100355e-05}, {"id": 188, "seek": 108804, "start": 1088.04, "end": 1092.48, "text": " even just move that out right as like a person maybe who is there for two weeks. But it does", "tokens": [754, 445, 1286, 300, 484, 558, 382, 411, 257, 954, 1310, 567, 307, 456, 337, 732, 3259, 13, 583, 309, 775], "temperature": 0.0, "avg_logprob": -0.17446935401772554, "compression_ratio": 1.6973180076628354, "no_speech_prob": 2.7932581360801123e-05}, {"id": 189, "seek": 108804, "start": 1092.48, "end": 1098.72, "text": " require that kind of communal engagement, but you can disperse that so it's not just", "tokens": [3651, 300, 733, 295, 43893, 8742, 11, 457, 291, 393, 717, 610, 405, 300, 370, 309, 311, 406, 445], "temperature": 0.0, "avg_logprob": -0.17446935401772554, "compression_ratio": 1.6973180076628354, "no_speech_prob": 2.7932581360801123e-05}, {"id": 190, "seek": 108804, "start": 1098.72, "end": 1102.56, "text": " on your core contributors or your moderators, it can kind of be dispersed and hopefully", "tokens": [322, 428, 4965, 45627, 420, 428, 10494, 3391, 11, 309, 393, 733, 295, 312, 48059, 293, 4696], "temperature": 0.0, "avg_logprob": -0.17446935401772554, "compression_ratio": 1.6973180076628354, "no_speech_prob": 2.7932581360801123e-05}, {"id": 191, "seek": 108804, "start": 1102.56, "end": 1107.0, "text": " with user groups which is a feature that we're working on and planning, that'll be even more", "tokens": [365, 4195, 3935, 597, 307, 257, 4111, 300, 321, 434, 1364, 322, 293, 5038, 11, 300, 603, 312, 754, 544], "temperature": 0.0, "avg_logprob": -0.17446935401772554, "compression_ratio": 1.6973180076628354, "no_speech_prob": 2.7932581360801123e-05}, {"id": 192, "seek": 108804, "start": 1107.0, "end": 1110.96, "text": " can be fine tuned to your organization and how you, the community you want to create", "tokens": [393, 312, 2489, 10870, 281, 428, 4475, 293, 577, 291, 11, 264, 1768, 291, 528, 281, 1884], "temperature": 0.0, "avg_logprob": -0.17446935401772554, "compression_ratio": 1.6973180076628354, "no_speech_prob": 2.7932581360801123e-05}, {"id": 193, "seek": 111096, "start": 1110.96, "end": 1117.96, "text": " with your Zulip chat. Other questions, yes.", "tokens": [365, 428, 1176, 425, 647, 5081, 13, 5358, 1651, 11, 2086, 13], "temperature": 0.0, "avg_logprob": -0.33307273764359324, "compression_ratio": 1.2592592592592593, "no_speech_prob": 6.491227395599708e-05}, {"id": 194, "seek": 111096, "start": 1117.96, "end": 1139.92, "text": " Right, so each Zulip organization is deciding, so the question is how do you control privacy", "tokens": [1779, 11, 370, 1184, 1176, 425, 647, 4475, 307, 17990, 11, 370, 264, 1168, 307, 577, 360, 291, 1969, 11427], "temperature": 0.0, "avg_logprob": -0.33307273764359324, "compression_ratio": 1.2592592592592593, "no_speech_prob": 6.491227395599708e-05}, {"id": 195, "seek": 113992, "start": 1139.92, "end": 1146.8400000000001, "text": " with public streams and what's going on for the folks listening at home. So definitely", "tokens": [365, 1908, 15842, 293, 437, 311, 516, 322, 337, 264, 4024, 4764, 412, 1280, 13, 407, 2138], "temperature": 0.0, "avg_logprob": -0.13781789563736827, "compression_ratio": 1.7890625, "no_speech_prob": 3.534295319695957e-05}, {"id": 196, "seek": 113992, "start": 1146.8400000000001, "end": 1151.8400000000001, "text": " your organization is deciding what streams are web public, right? So that is definitely", "tokens": [428, 4475, 307, 17990, 437, 15842, 366, 3670, 1908, 11, 558, 30, 407, 300, 307, 2138], "temperature": 0.0, "avg_logprob": -0.13781789563736827, "compression_ratio": 1.7890625, "no_speech_prob": 3.534295319695957e-05}, {"id": 197, "seek": 113992, "start": 1151.8400000000001, "end": 1157.88, "text": " kind of when you sign on and you're posting in those streams, it's kind of like this information", "tokens": [733, 295, 562, 291, 1465, 322, 293, 291, 434, 15978, 294, 729, 15842, 11, 309, 311, 733, 295, 411, 341, 1589], "temperature": 0.0, "avg_logprob": -0.13781789563736827, "compression_ratio": 1.7890625, "no_speech_prob": 3.534295319695957e-05}, {"id": 198, "seek": 113992, "start": 1157.88, "end": 1164.1200000000001, "text": " is available in general on the internet. There are private streams in Zulip, there are streams", "tokens": [307, 2435, 294, 2674, 322, 264, 4705, 13, 821, 366, 4551, 15842, 294, 1176, 425, 647, 11, 456, 366, 15842], "temperature": 0.0, "avg_logprob": -0.13781789563736827, "compression_ratio": 1.7890625, "no_speech_prob": 3.534295319695957e-05}, {"id": 199, "seek": 113992, "start": 1164.1200000000001, "end": 1167.72, "text": " that are public within your Zulip organization that people have to sign in. So for example,", "tokens": [300, 366, 1908, 1951, 428, 1176, 425, 647, 4475, 300, 561, 362, 281, 1465, 294, 13, 407, 337, 1365, 11], "temperature": 0.0, "avg_logprob": -0.13781789563736827, "compression_ratio": 1.7890625, "no_speech_prob": 3.534295319695957e-05}, {"id": 200, "seek": 116772, "start": 1167.72, "end": 1175.52, "text": " on our Zulip development community, the stream for like asking help with, for new contributors", "tokens": [322, 527, 1176, 425, 647, 3250, 1768, 11, 264, 4309, 337, 411, 3365, 854, 365, 11, 337, 777, 45627], "temperature": 0.0, "avg_logprob": -0.12784617287772043, "compression_ratio": 1.7508196721311475, "no_speech_prob": 4.905448076897301e-05}, {"id": 201, "seek": 116772, "start": 1175.52, "end": 1179.0, "text": " like getting help with development, that's not a web public stream because that's kind", "tokens": [411, 1242, 854, 365, 3250, 11, 300, 311, 406, 257, 3670, 1908, 4309, 570, 300, 311, 733], "temperature": 0.0, "avg_logprob": -0.12784617287772043, "compression_ratio": 1.7508196721311475, "no_speech_prob": 4.905448076897301e-05}, {"id": 202, "seek": 116772, "start": 1179.0, "end": 1182.68, "text": " of folks being vulnerable and maybe asking questions and saying like, I don't know how", "tokens": [295, 4024, 885, 10955, 293, 1310, 3365, 1651, 293, 1566, 411, 11, 286, 500, 380, 458, 577], "temperature": 0.0, "avg_logprob": -0.12784617287772043, "compression_ratio": 1.7508196721311475, "no_speech_prob": 4.905448076897301e-05}, {"id": 203, "seek": 116772, "start": 1182.68, "end": 1186.48, "text": " to do this, can someone help? Like obviously that's not something, I mean that's super", "tokens": [281, 360, 341, 11, 393, 1580, 854, 30, 1743, 2745, 300, 311, 406, 746, 11, 286, 914, 300, 311, 1687], "temperature": 0.0, "avg_logprob": -0.12784617287772043, "compression_ratio": 1.7508196721311475, "no_speech_prob": 4.905448076897301e-05}, {"id": 204, "seek": 116772, "start": 1186.48, "end": 1190.48, "text": " brave of them and we're proud, you know, we want that as public within our organization", "tokens": [12653, 295, 552, 293, 321, 434, 4570, 11, 291, 458, 11, 321, 528, 300, 382, 1908, 1951, 527, 4475], "temperature": 0.0, "avg_logprob": -0.12784617287772043, "compression_ratio": 1.7508196721311475, "no_speech_prob": 4.905448076897301e-05}, {"id": 205, "seek": 116772, "start": 1190.48, "end": 1194.68, "text": " but we're not sending that out to the internet. So we've made that choice culturally as an", "tokens": [457, 321, 434, 406, 7750, 300, 484, 281, 264, 4705, 13, 407, 321, 600, 1027, 300, 3922, 28879, 382, 364], "temperature": 0.0, "avg_logprob": -0.12784617287772043, "compression_ratio": 1.7508196721311475, "no_speech_prob": 4.905448076897301e-05}, {"id": 206, "seek": 119468, "start": 1194.68, "end": 1199.72, "text": " organization. So each organization that decides. So I believe like the Rust language that's", "tokens": [4475, 13, 407, 1184, 4475, 300, 14898, 13, 407, 286, 1697, 411, 264, 34952, 2856, 300, 311], "temperature": 0.0, "avg_logprob": -0.14539689532781053, "compression_ratio": 1.829268292682927, "no_speech_prob": 2.6253565010847524e-05}, {"id": 207, "seek": 119468, "start": 1199.72, "end": 1203.3200000000002, "text": " using the public access feature, they've decided that all of their streams are web", "tokens": [1228, 264, 1908, 2105, 4111, 11, 436, 600, 3047, 300, 439, 295, 641, 15842, 366, 3670], "temperature": 0.0, "avg_logprob": -0.14539689532781053, "compression_ratio": 1.829268292682927, "no_speech_prob": 2.6253565010847524e-05}, {"id": 208, "seek": 119468, "start": 1203.3200000000002, "end": 1209.0800000000002, "text": " public. So basically when you sign up to be part of that chat discussion on the Rust", "tokens": [1908, 13, 407, 1936, 562, 291, 1465, 493, 281, 312, 644, 295, 300, 5081, 5017, 322, 264, 34952], "temperature": 0.0, "avg_logprob": -0.14539689532781053, "compression_ratio": 1.829268292682927, "no_speech_prob": 2.6253565010847524e-05}, {"id": 209, "seek": 119468, "start": 1209.0800000000002, "end": 1213.88, "text": " language community, whatever your discussion you're having there is available on the internet.", "tokens": [2856, 1768, 11, 2035, 428, 5017, 291, 434, 1419, 456, 307, 2435, 322, 264, 4705, 13], "temperature": 0.0, "avg_logprob": -0.14539689532781053, "compression_ratio": 1.829268292682927, "no_speech_prob": 2.6253565010847524e-05}, {"id": 210, "seek": 119468, "start": 1213.88, "end": 1217.52, "text": " And so that's just part of kind of like the culture of each organization that you're", "tokens": [400, 370, 300, 311, 445, 644, 295, 733, 295, 411, 264, 3713, 295, 1184, 4475, 300, 291, 434], "temperature": 0.0, "avg_logprob": -0.14539689532781053, "compression_ratio": 1.829268292682927, "no_speech_prob": 2.6253565010847524e-05}, {"id": 211, "seek": 119468, "start": 1217.52, "end": 1221.88, "text": " setting up. You can definitely set it up so there are more privacy, you know, focused", "tokens": [3287, 493, 13, 509, 393, 2138, 992, 309, 493, 370, 456, 366, 544, 11427, 11, 291, 458, 11, 5178], "temperature": 0.0, "avg_logprob": -0.14539689532781053, "compression_ratio": 1.829268292682927, "no_speech_prob": 2.6253565010847524e-05}, {"id": 212, "seek": 122188, "start": 1221.88, "end": 1225.64, "text": " organizations. But again, thinking about open source communities and the fact that we want", "tokens": [6150, 13, 583, 797, 11, 1953, 466, 1269, 4009, 4456, 293, 264, 1186, 300, 321, 528], "temperature": 0.0, "avg_logprob": -0.25400731563568113, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.00011885415733559057}, {"id": 213, "seek": 122188, "start": 1225.64, "end": 1229.2800000000002, "text": " to be having, you know, there are definitely certain parts of our conversations and chats", "tokens": [281, 312, 1419, 11, 291, 458, 11, 456, 366, 2138, 1629, 3166, 295, 527, 7315, 293, 38057], "temperature": 0.0, "avg_logprob": -0.25400731563568113, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.00011885415733559057}, {"id": 214, "seek": 122188, "start": 1229.2800000000002, "end": 1236.2800000000002, "text": " at me. We might want to be having as publicly as possible, right? So, yeah. Any other questions?", "tokens": [412, 385, 13, 492, 1062, 528, 281, 312, 1419, 382, 14843, 382, 1944, 11, 558, 30, 407, 11, 1338, 13, 2639, 661, 1651, 30], "temperature": 0.0, "avg_logprob": -0.25400731563568113, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.00011885415733559057}, {"id": 215, "seek": 122188, "start": 1236.2800000000002, "end": 1237.2800000000002, "text": " Yes?", "tokens": [1079, 30], "temperature": 0.0, "avg_logprob": -0.25400731563568113, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.00011885415733559057}, {"id": 216, "seek": 122188, "start": 1237.2800000000002, "end": 1241.2800000000002, "text": " Do you have any integration at the end?", "tokens": [1144, 291, 362, 604, 10980, 412, 264, 917, 30], "temperature": 0.0, "avg_logprob": -0.25400731563568113, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.00011885415733559057}, {"id": 217, "seek": 124128, "start": 1241.28, "end": 1252.28, "text": " Yes, yes. We have lots of integrations.", "tokens": [1079, 11, 2086, 13, 492, 362, 3195, 295, 3572, 763, 13], "temperature": 0.0, "avg_logprob": -0.3939467021397182, "compression_ratio": 1.1195652173913044, "no_speech_prob": 0.00021559724700637162}, {"id": 218, "seek": 124128, "start": 1252.28, "end": 1269.28, "text": " Right, yeah. So you can move from Slack to Zulip, for instance.", "tokens": [1779, 11, 1338, 13, 407, 291, 393, 1286, 490, 37211, 281, 1176, 425, 647, 11, 337, 5197, 13], "temperature": 0.0, "avg_logprob": -0.3939467021397182, "compression_ratio": 1.1195652173913044, "no_speech_prob": 0.00021559724700637162}, {"id": 219, "seek": 126928, "start": 1269.28, "end": 1274.28, "text": " Yes, yes. Well, GitHub for tracking issues and Zulip is a chat application work together,", "tokens": [1079, 11, 2086, 13, 1042, 11, 23331, 337, 11603, 2663, 293, 1176, 425, 647, 307, 257, 5081, 3861, 589, 1214, 11], "temperature": 0.0, "avg_logprob": -0.2215797004349735, "compression_ratio": 1.6551724137931034, "no_speech_prob": 2.8847653084085323e-05}, {"id": 220, "seek": 126928, "start": 1274.28, "end": 1281.72, "text": " yeah. So like, so we track our, we're on GitHub for our open source that's where our", "tokens": [1338, 13, 407, 411, 11, 370, 321, 2837, 527, 11, 321, 434, 322, 23331, 337, 527, 1269, 4009, 300, 311, 689, 527], "temperature": 0.0, "avg_logprob": -0.2215797004349735, "compression_ratio": 1.6551724137931034, "no_speech_prob": 2.8847653084085323e-05}, {"id": 221, "seek": 126928, "start": 1281.72, "end": 1287.04, "text": " code is. And so our issues link and we use integrations for like bots to communicate", "tokens": [3089, 307, 13, 400, 370, 527, 2663, 2113, 293, 321, 764, 3572, 763, 337, 411, 35410, 281, 7890], "temperature": 0.0, "avg_logprob": -0.2215797004349735, "compression_ratio": 1.6551724137931034, "no_speech_prob": 2.8847653084085323e-05}, {"id": 222, "seek": 126928, "start": 1287.04, "end": 1293.04, "text": " and stuff. So, but definitely there are lots of integrations and such that one can use", "tokens": [293, 1507, 13, 407, 11, 457, 2138, 456, 366, 3195, 295, 3572, 763, 293, 1270, 300, 472, 393, 764], "temperature": 0.0, "avg_logprob": -0.2215797004349735, "compression_ratio": 1.6551724137931034, "no_speech_prob": 2.8847653084085323e-05}, {"id": 223, "seek": 126928, "start": 1293.04, "end": 1297.6, "text": " lots of different authentication methods, et cetera. It's a fully fledged modern chat", "tokens": [3195, 295, 819, 26643, 7150, 11, 1030, 11458, 13, 467, 311, 257, 4498, 24114, 3004, 4363, 5081], "temperature": 0.0, "avg_logprob": -0.2215797004349735, "compression_ratio": 1.6551724137931034, "no_speech_prob": 2.8847653084085323e-05}, {"id": 224, "seek": 129760, "start": 1297.6, "end": 1300.4399999999998, "text": " app. Yeah.", "tokens": [724, 13, 865, 13], "temperature": 0.0, "avg_logprob": -0.250058668205537, "compression_ratio": 1.407079646017699, "no_speech_prob": 1.3199741260905284e-05}, {"id": 225, "seek": 129760, "start": 1300.4399999999998, "end": 1307.6399999999999, "text": " Other questions? Curiosity. Again, if your curiosity has been for your open source projects,", "tokens": [5358, 1651, 30, 48998, 13, 3764, 11, 498, 428, 18769, 575, 668, 337, 428, 1269, 4009, 4455, 11], "temperature": 0.0, "avg_logprob": -0.250058668205537, "compression_ratio": 1.407079646017699, "no_speech_prob": 1.3199741260905284e-05}, {"id": 226, "seek": 129760, "start": 1307.6399999999999, "end": 1311.7199999999998, "text": " please I'll be around tomorrow or come on the Zulip development community, check us", "tokens": [1767, 286, 603, 312, 926, 4153, 420, 808, 322, 264, 1176, 425, 647, 3250, 1768, 11, 1520, 505], "temperature": 0.0, "avg_logprob": -0.250058668205537, "compression_ratio": 1.407079646017699, "no_speech_prob": 1.3199741260905284e-05}, {"id": 227, "seek": 129760, "start": 1311.7199999999998, "end": 1316.1599999999999, "text": " out. We have lots of public streams and I'm just been really excited to see everyone here", "tokens": [484, 13, 492, 362, 3195, 295, 1908, 15842, 293, 286, 478, 445, 668, 534, 2919, 281, 536, 1518, 510], "temperature": 0.0, "avg_logprob": -0.250058668205537, "compression_ratio": 1.407079646017699, "no_speech_prob": 1.3199741260905284e-05}, {"id": 228, "seek": 131616, "start": 1316.16, "end": 1329.3200000000002, "text": " at Pustum and thank you for having me.", "tokens": [50364, 412, 430, 381, 449, 293, 1309, 291, 337, 1419, 385, 13, 51022], "temperature": 0.0, "avg_logprob": -0.5356130940573556, "compression_ratio": 0.8260869565217391, "no_speech_prob": 2.009427589655388e-05}], "language": "en"}