{"text": " Hello, my name is Jonathan McHugh and I am from Icebreaker and I'm just going to be going through some of the design decisions in regards to my project as well as express some thoughts regarding knowledge management and the use of abstract symbols as a way of working with projects to maximise flow and improve interoperability and reduce the time and costs of expressing concepts and expectations and desires and unleashing them as actions and what not. And this is a diagram which I playfully did which just sort of explains some of the facets with regards to it. Before I really got into coding I had a varied experience with regards to information society from a wider perspective and one of the things which I found was very useful for dealing with large information apparatus was to use abstract symbols. I did this for an association whereby I was collecting different tags and for from DeliciousV which was a social bookmarking system from back in the day and what I did was the focus on me and tax on me as I was collecting were getting so large it was getting it would have been uneconomic to use for instance just the lettering of the terms and it was better to aggregate them and what I did was make use of the non-alpha numeric characters which formed the which usually on the right hand side of a keyboard sometimes at the top as well and I found that this was very good for both demarcating things but it also sort of created more of an impetus regarding how to order things and the gains from say doing completions was fantastic because you weren't really just cycling through all the letters of the word to get the the form you wanted but you just sort of smash in and deal with the the term because you've got an associated character or combination of characters and one of the things when I really got into programming I started out by really prioritising things like tech, the documentation system, VIM, the text editor and as well as sort of using regular expressions by the tooling said as well as AUK and I tried to I tried to use the existing characters and that I had from the syntax for delineating the the the the terms and definitions which I was trying to collect in terms of programming but what I found was that it didn't quite match because the the association which had previously formed my my my my things were from were from they were dealing with a public affairs politics and cultural activities and even though it dealt upon the the even though it dealt upon the technology aspects such as peer to peer or things like that it didn't really delve into it it was really at the kind of so they're kind of white shirt level in terms of expectations competences and I realised that I needed something something better suited for what happens within a computer environment and and what what though what the components are and how they interlace and spent a lot of dog food eating trying to work out a form so I'm just going to go through some of the aspects with regards to this and I purposely chose something very abstract but also accessible I chose it abstract because I was aware with regards to semantic business process management which was an attempt which is an approach to mitigate groups from different language communities with with with common terms and for me an abstract seemed to be quite quite useful because it would be cultural neutral and I subsequently found that the ambiguity is quite useful because it allows you to do things quickly without being too bothered and actually there there was a there's turns out there's interesting psychological advantages from breaking things down into a certain unit of things so for instance I was reading that it takes seven forms that in fact whatever things are roughly people can put things into seven boxes so expecting the number of cows of a field there's a variance which happens with around seven in terms of people and expectations as well as expectations with bitterness and some people can be more precise and more accurate and there's just a kind of a deviation in terms of that once you look in the numbers of recollection and what people can hold and interpret in certain things I fixated on the number six so in effect I classified the Vim tooling which I was dealing with with a roughly between 1, 2, 3, 4, well it was 10, 20, 30, 40, 50, 60 which and I subsequently expanded upon that with the realizing that things things wouldn't deal with it needed a bit more subtlety so in effect the first tier was used to delineate whether something 10 which was something which was which was which was which was something which was personally dealt with 20 to deal with documentation 30 to deal with display 40 to deal with movement 50 to do with environments such as conflicts and 60 to do with external or system-wide things or external tooling and I subsequently adapted this for two level layer with regards to 1q10 to represent one facet 1q30 to represent another and this sort of played well in terms of things but I just sort of had a bit of a I had a guilt in it because the non- that the previous system I came up with had the it worked very nicely that the you could describe things with the with the non-alpha numerics and they're quite accessible on the keyboard and so after a while with my confidence at least in terms of how I was dealing with the annotations in terms of the putting putting subsets of content which is quite similar into a specific folder with these annotations forming and dealing with things and so for instance I would end up with something looking like this which was compounded and so I started using the the letters sort of in the home row in the middle of where the QWERTY keyboard was so and it was it encouraged me to really have things in specialized forms and repositories and I took the philosophy really sort of spreading things out so for instance we look at this this is an example of of different roughly passing based activities and I could do another form and so HQH would be roughly around passing OQ would be represented of languages and tools and so for instance we could do lower and this would give an example of lots of lower based points so as you can see these annotations can allow you to really cut through and deal with various points and with the with regards to the icebreaker project I felt that the I felt this stuff was interesting but the icebreaker project was very document focused for very good reasons the my icebreaker project was has been looking into how document how flap based files could be used particularly with regards to gem text the file format of gem and I could be used to express issues and problems or also Kanban boards which is which would be more preferable than the walled garden approach of services such as Github where you in effect end up putting all your repos with all the git history and all the subtleties in terms of that but when it comes to improving any of these repos you're not allowed to delve through the history and subtleties in terms of that so here's just at the top pane an example of and G networks Kanban board repo just the read me file being run through a the git in terms of the history and diffs so as you see all of these lovely things in terms of people adding things people removing things people altering things you don't really get in Github and that's a shame I sort of looked in terms of that and it was very satisfying that gem text could provide such a minimal minimal syntactic range for expressing the ideas that that ultimately I felt the need that just to see how things could mix and and perform with and what I went with was the use of the KL liner format which is within the emacs hyper hyperbole the package which is a format which is hierarchical and it's got very good interfaces so for instance you could be adding parts like this or hitting a child form and what's very nice is as part of this being a person information manager so you can cross link blocks and if including in other documents and should the blocks change then you will be able to you'll be able to catch up and work out where that the block has been moved to at least within the same document and so that's one of the things which I really prioritized and dealt with in terms of this year and and I managed to with the interpreter canonical mix both the syntaxes of gem protocols gem text the KL liner format as well as the key annotation system and so this has and I haven't explored it perfectly but I believe that the passing expression grammars are capable of representing things within the same line and not necessarily be relegated to to comparing line by line and so this kind of deviant exploration of how syntaxes can work across I've potentially got something much more richer and and subtle with with then then the formats and syntaxes isolated here just on the top pane here is just an example of in in the in the language and pass a txr a way of creating a definition and then providing the name of the reference in this case I use the annotation style hqh to just point out that the the passing forms and and here we have the the various key key aspects uh aspects of the of the annotation um for for key just returning to that I should emphasize that that the key annotation is formed around the the green buttons which would either so for instance and it would be one of the one of the letters in there would generate would providing the the starting kernel for for an annotation but it is supplemented with qwe or two which allows to provide a an inference and this was more of a later stage innovation and you can also combine annotations the annotation points at least I do it so that up to four can be compounded to be representative of of one which excluding blooms which would be providing where the dictionary where the document deals with and encourages more recursive perspective on things has has a very large range permutative range which even though that wouldn't be satisfied with either an individual annotating things or or a community left alone the the logical outcome of combining certain things together it provides a very large range in the tens if not hundreds of thousands of of of points and so as you add one or more annotations you can really get a fingerprint of what things are and it's also got a bit subtlety regarding that it's not the lack of precision in terms of this which has been described to me more in terms of like I think it was Aristotle's use of hexes in terms of what something is and and its sort of force the philosophy of what something is and I've been trying to deliberate in terms of the the subtleties regarding that and I guess it would be for instance there's there's always conjecture regarding who invents say the first submarine or the or say something like the first submarine or the first first the first camera and so for instance from my own perspective in terms of prejudices I've got a concept of of an Irishman inventing the first submarine and London a London an English politician who was invented the first camera and that's perhaps just based on my own prejudices upbringing and me not having complete enough technological perspective and definition in terms of that and I'm sure there are people for instance and in other regions who who have different opinions and that's all fine because we all sort of have a common idea of what a submarine is or what a camera is but we might have different definitions at which point that thing moved from being something else into that form and that's why I like the the vagueness of this key and and its annotations is that it it doesn't it doesn't have grandiose claims of completeness and it has more of a kind of ectomology approach in which you can make an opinion on things switching out and it's all fine including if if the definitions changes and it's it's almost in terms of how it works and and operates in terms of the work for any user it really gives you kind of the convenience and dealing with things so just returning back to here for instance I looking in terms of a a more of a specific function at the top here you've got RQR KWK and that's in effect RQR would be a form of a to-do and KWK in terms of hashes in terms of the aspects the complementary description is create hashes and here we're just returning just in case you there's a definite the function definition as well as a reference in terms of the fact that you have the annotations being being outputted here within the the parentheses here just in the light blue and here we have the the form for putting things in cases which in in the TXR form needs to be ended this is a list based language so as you can imagine things start and stop in very clear forms you have the syntax for creating a binding which in this form would be well let's let's go the first part so this is you this is an example of a URI variable being captured which is referencing a separate function and which and and expecting this outcome and of course you might have you could have a function capturing multiple things and which this this approach could capture different points and at least my interpretation regarding why I'm doing this binding is because it allows it seemingly allowing you to inherit all the subtleties upstream in terms of that but I might be a bit flaky in terms of that so as you can imagine there are sort of lots of different forms and and and dealing with things and here's an example of a of one of the of the forms which would have the with a here classic regular expression style things in terms of repeating numbers and various points and so just to give an example of how I could sort of use these annotations for right sort of racing through things so here is an example of RQR which would be a mechanism for just pulling up all of my to-dos and here you have yeah it's referencing the fact that there are 202 different tasks and dealing with things and obviously this is just providing a document type a singular document but you could be for instance performing a search based upon multiple documents or within the project which within this emacs operating environment means that you're pretty much just limited by time and ambition so for instance you could as you can see it's very terse and this is this is how this is for me quite significant in terms of flying by I I really really try and make sure that I have maximum flow and that I can switch from one mental state to another and and and handle multiple things without being overwhelmed and for instance the name that the fact that the documents and the and the directories have to have named in terms of that means that it makes it easier for instance jumping for a different file so for instance if I press ctrl x and b in emacs then there's a range of point so if just pressing mqm here for instance has given me a list of different buffers and and the names in terms of that so it I can really sort of come up with buttons and hotkeys and actions and to deal with that so for instance here's just a way in in terms of the reuse of these annotations can come can be dealt with so for instance at the top we have svge tag mode which is an third party emacs library which allows you to turn various points in terms of these black and white boxes are the annotations I would like to say improved or visualized but you can also add other things in terms of that I've talked in other activities regarding the the use of hyper hyper hyperbole the in terms of navigation and and points in terms of that so this time I thought I'd just look at one of the latest features from number eight version eight which is defil which provides more a regular expression based form in terms of that so this form would be the defining of the function the name of this function the the opening context the middle context at the ending context as well as the middle context as well as what you're meant to do based upon that within these within these curly parentheses so what I've what I what is what is the conjecture in terms of this one is the fact that within a specific annotation you could be having different actions based upon where the cursor is within the annotation let alone the potential in terms of any perspective before or afterwards and this is quite deep because of the use of repeativeness and various forms that you could form very complex workflows not necessarily from key bindings pulling out the the the the things and and the or the use of classic my menus but in fact you could use the the cursor within or relative to a one of these annotations and that forms the the action which could get very fast in terms of just pushing about it having a dedicated action in in terms of the styles dedicated action button for dealing with things and so the the menu would in effect be the cursor related to the and here's a high roll of format which is within the hyperbole suite which looks into things and that's very interesting which I'll be looking into more so for instance an action could be to go to a subset of this for instance this is an example of the section shells which has the subsection and I haven't really I don't really have the time to go into this further but there's a recent emacs conference where this is one of the main talking points here is a here is a product of a script which I think is about 50 gigabytes or might be maybe this is a 20 50 or 20 megabytes which is an effect a rip grip through various points and and and and and dealing with the this this is a and trying to isolate various various things so let's so let's just highlight some colors quickly we'll just do that let's see pink yeah well that's probably slowing it down but whatever but in effect it's classic rip grip answers which document which line which character what was dealt with in here I'm just running through the entire system the entire file system to find the annotations pertinent ah but yeah there we go so um but we'll use swiper to reinforce so this will ah this will have the aggregate of it's got it does have duplicates at least how this was set up but that's fine because the outputs dealing with the orderly fashion in terms of that so ascertain is it come on sorry the uh I think my computer's a bit overwhelmed it's humming a bit but there must be some background thing yes so here we go so we've got ascertaining ascertain whether in correct location that ascertain wherever useful nothing links to it and as you can I I do have I do have tooling which sort of deals of this from the point of a specific script and I've I've worked out a way to in effect inject the annotations based upon hashing of content I've also been developing the hash trees forming with regards to the documents but yes um I hope this is of interest and yeah there's there's lots of interesting things with regards to icebreaker and I guess it would be best to visit the fostering page for this talk for some more supplementary information thank you very much you", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 12.42, "text": " Hello, my name is Jonathan McHugh and I am from Icebreaker and I'm just going to be going", "tokens": [50364, 2425, 11, 452, 1315, 307, 15471, 4050, 39, 1984, 293, 286, 669, 490, 15332, 43847, 293, 286, 478, 445, 516, 281, 312, 516, 50985], "temperature": 0.0, "avg_logprob": -0.20219649439272674, "compression_ratio": 1.362962962962963, "no_speech_prob": 0.27175989747047424}, {"id": 1, "seek": 0, "start": 12.42, "end": 19.98, "text": " through some of the design decisions in regards to my project as well as express some thoughts", "tokens": [50985, 807, 512, 295, 264, 1715, 5327, 294, 14258, 281, 452, 1716, 382, 731, 382, 5109, 512, 4598, 51363], "temperature": 0.0, "avg_logprob": -0.20219649439272674, "compression_ratio": 1.362962962962963, "no_speech_prob": 0.27175989747047424}, {"id": 2, "seek": 1998, "start": 19.98, "end": 30.98, "text": " regarding knowledge management and the use of abstract symbols as a way of working with", "tokens": [50364, 8595, 3601, 4592, 293, 264, 764, 295, 12649, 16944, 382, 257, 636, 295, 1364, 365, 50914], "temperature": 0.0, "avg_logprob": -0.16849900514651567, "compression_ratio": 1.441860465116279, "no_speech_prob": 0.767379641532898}, {"id": 3, "seek": 1998, "start": 30.98, "end": 41.34, "text": " projects to maximise flow and improve interoperability and reduce the time and costs of expressing", "tokens": [50914, 4455, 281, 5138, 908, 3095, 293, 3470, 728, 7192, 2310, 293, 5407, 264, 565, 293, 5497, 295, 22171, 51432], "temperature": 0.0, "avg_logprob": -0.16849900514651567, "compression_ratio": 1.441860465116279, "no_speech_prob": 0.767379641532898}, {"id": 4, "seek": 4134, "start": 41.34, "end": 50.220000000000006, "text": " concepts and expectations and desires and unleashing them as actions and what not.", "tokens": [50364, 10392, 293, 9843, 293, 18005, 293, 25272, 11077, 552, 382, 5909, 293, 437, 406, 13, 50808], "temperature": 0.0, "avg_logprob": -0.21306585093013575, "compression_ratio": 1.5798816568047338, "no_speech_prob": 0.06943926960229874}, {"id": 5, "seek": 4134, "start": 50.220000000000006, "end": 58.260000000000005, "text": " And this is a diagram which I playfully did which just sort of explains some of the facets", "tokens": [50808, 400, 341, 307, 257, 10686, 597, 286, 862, 2277, 630, 597, 445, 1333, 295, 13948, 512, 295, 264, 49752, 51210], "temperature": 0.0, "avg_logprob": -0.21306585093013575, "compression_ratio": 1.5798816568047338, "no_speech_prob": 0.06943926960229874}, {"id": 6, "seek": 4134, "start": 58.260000000000005, "end": 67.26, "text": " with regards to it. Before I really got into coding I had a varied experience with regards to", "tokens": [51210, 365, 14258, 281, 309, 13, 4546, 286, 534, 658, 666, 17720, 286, 632, 257, 22877, 1752, 365, 14258, 281, 51660], "temperature": 0.0, "avg_logprob": -0.21306585093013575, "compression_ratio": 1.5798816568047338, "no_speech_prob": 0.06943926960229874}, {"id": 7, "seek": 6726, "start": 68.18, "end": 76.98, "text": " information society from a wider perspective and one of the things which I found was very useful", "tokens": [50410, 1589, 4086, 490, 257, 11842, 4585, 293, 472, 295, 264, 721, 597, 286, 1352, 390, 588, 4420, 50850], "temperature": 0.0, "avg_logprob": -0.26500595027002793, "compression_ratio": 1.5380434782608696, "no_speech_prob": 0.00845840759575367}, {"id": 8, "seek": 6726, "start": 76.98, "end": 87.98, "text": " for dealing with large information apparatus was to use abstract symbols. I did this for an", "tokens": [50850, 337, 6260, 365, 2416, 1589, 38573, 390, 281, 764, 12649, 16944, 13, 286, 630, 341, 337, 364, 51400], "temperature": 0.0, "avg_logprob": -0.26500595027002793, "compression_ratio": 1.5380434782608696, "no_speech_prob": 0.00845840759575367}, {"id": 9, "seek": 6726, "start": 87.98, "end": 97.18, "text": " association whereby I was collecting different tags and for from DeliciousV which was a social", "tokens": [51400, 14598, 36998, 286, 390, 12510, 819, 18632, 293, 337, 490, 28518, 53, 597, 390, 257, 2093, 51860], "temperature": 0.0, "avg_logprob": -0.26500595027002793, "compression_ratio": 1.5380434782608696, "no_speech_prob": 0.00845840759575367}, {"id": 10, "seek": 9718, "start": 97.18, "end": 104.66000000000001, "text": " bookmarking system from back in the day and what I did was the focus on me and tax on me as I", "tokens": [50364, 1446, 5638, 278, 1185, 490, 646, 294, 264, 786, 293, 437, 286, 630, 390, 264, 1879, 322, 385, 293, 3366, 322, 385, 382, 286, 50738], "temperature": 0.0, "avg_logprob": -0.15861993596173715, "compression_ratio": 1.705521472392638, "no_speech_prob": 0.009730139747262001}, {"id": 11, "seek": 9718, "start": 104.66000000000001, "end": 109.62, "text": " was collecting were getting so large it was getting it would have been uneconomic to use for", "tokens": [50738, 390, 12510, 645, 1242, 370, 2416, 309, 390, 1242, 309, 576, 362, 668, 2251, 31646, 281, 764, 337, 50986], "temperature": 0.0, "avg_logprob": -0.15861993596173715, "compression_ratio": 1.705521472392638, "no_speech_prob": 0.009730139747262001}, {"id": 12, "seek": 9718, "start": 109.62, "end": 118.98, "text": " instance just the lettering of the terms and it was better to aggregate them and what I did", "tokens": [50986, 5197, 445, 264, 5063, 278, 295, 264, 2115, 293, 309, 390, 1101, 281, 26118, 552, 293, 437, 286, 630, 51454], "temperature": 0.0, "avg_logprob": -0.15861993596173715, "compression_ratio": 1.705521472392638, "no_speech_prob": 0.009730139747262001}, {"id": 13, "seek": 11898, "start": 118.98, "end": 129.78, "text": " was make use of the non-alpha numeric characters which formed the which usually on the right hand", "tokens": [50364, 390, 652, 764, 295, 264, 2107, 12, 304, 7211, 7866, 299, 4342, 597, 8693, 264, 597, 2673, 322, 264, 558, 1011, 50904], "temperature": 0.0, "avg_logprob": -0.2183595049208489, "compression_ratio": 1.5977653631284916, "no_speech_prob": 0.33821919560432434}, {"id": 14, "seek": 11898, "start": 129.78, "end": 138.66, "text": " side of a keyboard sometimes at the top as well and I found that this was very good for both", "tokens": [50904, 1252, 295, 257, 10186, 2171, 412, 264, 1192, 382, 731, 293, 286, 1352, 300, 341, 390, 588, 665, 337, 1293, 51348], "temperature": 0.0, "avg_logprob": -0.2183595049208489, "compression_ratio": 1.5977653631284916, "no_speech_prob": 0.33821919560432434}, {"id": 15, "seek": 11898, "start": 138.66, "end": 146.1, "text": " demarcating things but it also sort of created more of an impetus regarding how to order things", "tokens": [51348, 1371, 40088, 990, 721, 457, 309, 611, 1333, 295, 2942, 544, 295, 364, 704, 40506, 8595, 577, 281, 1668, 721, 51720], "temperature": 0.0, "avg_logprob": -0.2183595049208489, "compression_ratio": 1.5977653631284916, "no_speech_prob": 0.33821919560432434}, {"id": 16, "seek": 14610, "start": 146.18, "end": 153.06, "text": " and the gains from say doing completions was fantastic because you weren't really just cycling", "tokens": [50368, 293, 264, 16823, 490, 584, 884, 1557, 626, 390, 5456, 570, 291, 4999, 380, 534, 445, 22425, 50712], "temperature": 0.0, "avg_logprob": -0.12429667107852889, "compression_ratio": 1.7255813953488373, "no_speech_prob": 0.013277349062263966}, {"id": 17, "seek": 14610, "start": 153.06, "end": 158.26, "text": " through all the letters of the word to get the the form you wanted but you just sort of smash", "tokens": [50712, 807, 439, 264, 7825, 295, 264, 1349, 281, 483, 264, 264, 1254, 291, 1415, 457, 291, 445, 1333, 295, 17960, 50972], "temperature": 0.0, "avg_logprob": -0.12429667107852889, "compression_ratio": 1.7255813953488373, "no_speech_prob": 0.013277349062263966}, {"id": 18, "seek": 14610, "start": 158.26, "end": 164.1, "text": " in and deal with the the term because you've got an associated character or combination of", "tokens": [50972, 294, 293, 2028, 365, 264, 264, 1433, 570, 291, 600, 658, 364, 6615, 2517, 420, 6562, 295, 51264], "temperature": 0.0, "avg_logprob": -0.12429667107852889, "compression_ratio": 1.7255813953488373, "no_speech_prob": 0.013277349062263966}, {"id": 19, "seek": 14610, "start": 164.1, "end": 173.82, "text": " characters and one of the things when I really got into programming I started out by really", "tokens": [51264, 4342, 293, 472, 295, 264, 721, 562, 286, 534, 658, 666, 9410, 286, 1409, 484, 538, 534, 51750], "temperature": 0.0, "avg_logprob": -0.12429667107852889, "compression_ratio": 1.7255813953488373, "no_speech_prob": 0.013277349062263966}, {"id": 20, "seek": 17382, "start": 173.85999999999999, "end": 185.01999999999998, "text": " prioritising things like tech, the documentation system, VIM, the text editor and as well as sort", "tokens": [50366, 14846, 3436, 721, 411, 7553, 11, 264, 14333, 1185, 11, 691, 6324, 11, 264, 2487, 9839, 293, 382, 731, 382, 1333, 50924], "temperature": 0.0, "avg_logprob": -0.2510023311692841, "compression_ratio": 1.455223880597015, "no_speech_prob": 0.01788190007209778}, {"id": 21, "seek": 17382, "start": 185.01999999999998, "end": 194.01999999999998, "text": " of using regular expressions by the tooling said as well as AUK and I tried to I tried to use the", "tokens": [50924, 295, 1228, 3890, 15277, 538, 264, 46593, 848, 382, 731, 382, 7171, 42, 293, 286, 3031, 281, 286, 3031, 281, 764, 264, 51374], "temperature": 0.0, "avg_logprob": -0.2510023311692841, "compression_ratio": 1.455223880597015, "no_speech_prob": 0.01788190007209778}, {"id": 22, "seek": 19402, "start": 194.02, "end": 205.62, "text": " existing characters and that I had from the syntax for delineating the the the the terms and", "tokens": [50364, 6741, 4342, 293, 300, 286, 632, 490, 264, 28431, 337, 1103, 533, 990, 264, 264, 264, 264, 2115, 293, 50944], "temperature": 0.0, "avg_logprob": -0.16755379399945658, "compression_ratio": 1.6529411764705881, "no_speech_prob": 0.3209450840950012}, {"id": 23, "seek": 19402, "start": 205.62, "end": 210.14000000000001, "text": " definitions which I was trying to collect in terms of programming but what I found was that it", "tokens": [50944, 21988, 597, 286, 390, 1382, 281, 2500, 294, 2115, 295, 9410, 457, 437, 286, 1352, 390, 300, 309, 51170], "temperature": 0.0, "avg_logprob": -0.16755379399945658, "compression_ratio": 1.6529411764705881, "no_speech_prob": 0.3209450840950012}, {"id": 24, "seek": 19402, "start": 210.14000000000001, "end": 217.86, "text": " didn't quite match because the the association which had previously formed my my my my things", "tokens": [51170, 994, 380, 1596, 2995, 570, 264, 264, 14598, 597, 632, 8046, 8693, 452, 452, 452, 452, 721, 51556], "temperature": 0.0, "avg_logprob": -0.16755379399945658, "compression_ratio": 1.6529411764705881, "no_speech_prob": 0.3209450840950012}, {"id": 25, "seek": 21786, "start": 217.86, "end": 228.06, "text": " were from were from they were dealing with a public affairs politics and cultural activities and", "tokens": [50364, 645, 490, 645, 490, 436, 645, 6260, 365, 257, 1908, 17478, 7341, 293, 6988, 5354, 293, 50874], "temperature": 0.0, "avg_logprob": -0.1584976589868939, "compression_ratio": 1.7577639751552796, "no_speech_prob": 0.022822583094239235}, {"id": 26, "seek": 21786, "start": 228.06, "end": 239.3, "text": " even though it dealt upon the the even though it dealt upon the technology aspects such as peer", "tokens": [50874, 754, 1673, 309, 15991, 3564, 264, 264, 754, 1673, 309, 15991, 3564, 264, 2899, 7270, 1270, 382, 15108, 51436], "temperature": 0.0, "avg_logprob": -0.1584976589868939, "compression_ratio": 1.7577639751552796, "no_speech_prob": 0.022822583094239235}, {"id": 27, "seek": 21786, "start": 239.3, "end": 245.22000000000003, "text": " to peer or things like that it didn't really delve into it it was really at the kind of so", "tokens": [51436, 281, 15108, 420, 721, 411, 300, 309, 994, 380, 534, 43098, 666, 309, 309, 390, 534, 412, 264, 733, 295, 370, 51732], "temperature": 0.0, "avg_logprob": -0.1584976589868939, "compression_ratio": 1.7577639751552796, "no_speech_prob": 0.022822583094239235}, {"id": 28, "seek": 24522, "start": 245.22, "end": 254.26, "text": " they're kind of white shirt level in terms of expectations competences and I realised that I", "tokens": [50364, 436, 434, 733, 295, 2418, 8336, 1496, 294, 2115, 295, 9843, 2850, 2667, 293, 286, 21337, 300, 286, 50816], "temperature": 0.0, "avg_logprob": -0.20120001620933659, "compression_ratio": 1.6333333333333333, "no_speech_prob": 0.0027266647666692734}, {"id": 29, "seek": 24522, "start": 254.26, "end": 263.02, "text": " needed something something better suited for what happens within a computer environment and and what", "tokens": [50816, 2978, 746, 746, 1101, 24736, 337, 437, 2314, 1951, 257, 3820, 2823, 293, 293, 437, 51254], "temperature": 0.0, "avg_logprob": -0.20120001620933659, "compression_ratio": 1.6333333333333333, "no_speech_prob": 0.0027266647666692734}, {"id": 30, "seek": 24522, "start": 263.02, "end": 269.9, "text": " what though what the components are and how they interlace and spent a lot of dog food eating trying", "tokens": [51254, 437, 1673, 437, 264, 6677, 366, 293, 577, 436, 728, 19837, 293, 4418, 257, 688, 295, 3000, 1755, 3936, 1382, 51598], "temperature": 0.0, "avg_logprob": -0.20120001620933659, "compression_ratio": 1.6333333333333333, "no_speech_prob": 0.0027266647666692734}, {"id": 31, "seek": 26990, "start": 269.9, "end": 276.17999999999995, "text": " to work out a form so I'm just going to go through some of the aspects with regards to this and I", "tokens": [50364, 281, 589, 484, 257, 1254, 370, 286, 478, 445, 516, 281, 352, 807, 512, 295, 264, 7270, 365, 14258, 281, 341, 293, 286, 50678], "temperature": 0.0, "avg_logprob": -0.15187450691505713, "compression_ratio": 1.7456140350877194, "no_speech_prob": 0.5109402537345886}, {"id": 32, "seek": 26990, "start": 276.17999999999995, "end": 283.26, "text": " purposely chose something very abstract but also accessible I chose it abstract because I was aware", "tokens": [50678, 41840, 5111, 746, 588, 12649, 457, 611, 9515, 286, 5111, 309, 12649, 570, 286, 390, 3650, 51032], "temperature": 0.0, "avg_logprob": -0.15187450691505713, "compression_ratio": 1.7456140350877194, "no_speech_prob": 0.5109402537345886}, {"id": 33, "seek": 26990, "start": 283.26, "end": 289.41999999999996, "text": " with regards to semantic business process management which was an attempt which is an approach to", "tokens": [51032, 365, 14258, 281, 47982, 1606, 1399, 4592, 597, 390, 364, 5217, 597, 307, 364, 3109, 281, 51340], "temperature": 0.0, "avg_logprob": -0.15187450691505713, "compression_ratio": 1.7456140350877194, "no_speech_prob": 0.5109402537345886}, {"id": 34, "seek": 26990, "start": 289.41999999999996, "end": 298.38, "text": " mitigate groups from different language communities with with with common terms and for me an abstract", "tokens": [51340, 27336, 3935, 490, 819, 2856, 4456, 365, 365, 365, 2689, 2115, 293, 337, 385, 364, 12649, 51788], "temperature": 0.0, "avg_logprob": -0.15187450691505713, "compression_ratio": 1.7456140350877194, "no_speech_prob": 0.5109402537345886}, {"id": 35, "seek": 29838, "start": 298.62, "end": 307.38, "text": " seemed to be quite quite useful because it would be cultural neutral and I subsequently found that", "tokens": [50376, 6576, 281, 312, 1596, 1596, 4420, 570, 309, 576, 312, 6988, 10598, 293, 286, 26514, 1352, 300, 50814], "temperature": 0.0, "avg_logprob": -0.17790200438680528, "compression_ratio": 1.7767857142857142, "no_speech_prob": 0.04132336005568504}, {"id": 36, "seek": 29838, "start": 307.38, "end": 312.58, "text": " the ambiguity is quite useful because it allows you to do things quickly without being too bothered", "tokens": [50814, 264, 46519, 307, 1596, 4420, 570, 309, 4045, 291, 281, 360, 721, 2661, 1553, 885, 886, 22996, 51074], "temperature": 0.0, "avg_logprob": -0.17790200438680528, "compression_ratio": 1.7767857142857142, "no_speech_prob": 0.04132336005568504}, {"id": 37, "seek": 29838, "start": 312.58, "end": 320.1, "text": " and actually there there was a there's turns out there's interesting psychological advantages from", "tokens": [51074, 293, 767, 456, 456, 390, 257, 456, 311, 4523, 484, 456, 311, 1880, 14346, 14906, 490, 51450], "temperature": 0.0, "avg_logprob": -0.17790200438680528, "compression_ratio": 1.7767857142857142, "no_speech_prob": 0.04132336005568504}, {"id": 38, "seek": 29838, "start": 320.1, "end": 326.65999999999997, "text": " breaking things down into a certain unit of things so for instance I was reading that it takes seven", "tokens": [51450, 7697, 721, 760, 666, 257, 1629, 4985, 295, 721, 370, 337, 5197, 286, 390, 3760, 300, 309, 2516, 3407, 51778], "temperature": 0.0, "avg_logprob": -0.17790200438680528, "compression_ratio": 1.7767857142857142, "no_speech_prob": 0.04132336005568504}, {"id": 39, "seek": 32666, "start": 326.70000000000005, "end": 334.82000000000005, "text": " forms that in fact whatever things are roughly people can put things into seven boxes so expecting", "tokens": [50366, 6422, 300, 294, 1186, 2035, 721, 366, 9810, 561, 393, 829, 721, 666, 3407, 9002, 370, 9650, 50772], "temperature": 0.0, "avg_logprob": -0.10371678134044969, "compression_ratio": 1.8037383177570094, "no_speech_prob": 0.022502053529024124}, {"id": 40, "seek": 32666, "start": 334.82000000000005, "end": 340.26000000000005, "text": " the number of cows of a field there's a variance which happens with around seven in terms of people", "tokens": [50772, 264, 1230, 295, 19148, 295, 257, 2519, 456, 311, 257, 21977, 597, 2314, 365, 926, 3407, 294, 2115, 295, 561, 51044], "temperature": 0.0, "avg_logprob": -0.10371678134044969, "compression_ratio": 1.8037383177570094, "no_speech_prob": 0.022502053529024124}, {"id": 41, "seek": 32666, "start": 340.26000000000005, "end": 345.42, "text": " and expectations as well as expectations with bitterness and some people can be more precise", "tokens": [51044, 293, 9843, 382, 731, 382, 9843, 365, 44224, 293, 512, 561, 393, 312, 544, 13600, 51302], "temperature": 0.0, "avg_logprob": -0.10371678134044969, "compression_ratio": 1.8037383177570094, "no_speech_prob": 0.022502053529024124}, {"id": 42, "seek": 32666, "start": 345.42, "end": 351.42, "text": " and more accurate and there's just a kind of a deviation in terms of that once you look in the", "tokens": [51302, 293, 544, 8559, 293, 456, 311, 445, 257, 733, 295, 257, 25163, 294, 2115, 295, 300, 1564, 291, 574, 294, 264, 51602], "temperature": 0.0, "avg_logprob": -0.10371678134044969, "compression_ratio": 1.8037383177570094, "no_speech_prob": 0.022502053529024124}, {"id": 43, "seek": 35142, "start": 351.46000000000004, "end": 358.98, "text": " numbers of recollection and what people can hold and interpret in certain things I fixated on the", "tokens": [50366, 3547, 295, 39495, 10183, 293, 437, 561, 393, 1797, 293, 7302, 294, 1629, 721, 286, 3191, 770, 322, 264, 50742], "temperature": 0.0, "avg_logprob": -0.17035103927959094, "compression_ratio": 1.450381679389313, "no_speech_prob": 0.057171884924173355}, {"id": 44, "seek": 35142, "start": 358.98, "end": 369.86, "text": " number six so in effect I classified the Vim tooling which I was dealing with with a roughly", "tokens": [50742, 1230, 2309, 370, 294, 1802, 286, 20627, 264, 691, 332, 46593, 597, 286, 390, 6260, 365, 365, 257, 9810, 51286], "temperature": 0.0, "avg_logprob": -0.17035103927959094, "compression_ratio": 1.450381679389313, "no_speech_prob": 0.057171884924173355}, {"id": 45, "seek": 36986, "start": 369.86, "end": 382.26, "text": " between 1, 2, 3, 4, well it was 10, 20, 30, 40, 50, 60 which and I subsequently expanded upon that", "tokens": [50364, 1296, 502, 11, 568, 11, 805, 11, 1017, 11, 731, 309, 390, 1266, 11, 945, 11, 2217, 11, 3356, 11, 2625, 11, 4060, 597, 293, 286, 26514, 14342, 3564, 300, 50984], "temperature": 0.0, "avg_logprob": -0.24116340705326625, "compression_ratio": 1.3642857142857143, "no_speech_prob": 0.1403089463710785}, {"id": 46, "seek": 36986, "start": 382.26, "end": 391.38, "text": " with the realizing that things things wouldn't deal with it needed a bit more subtlety so in", "tokens": [50984, 365, 264, 16734, 300, 721, 721, 2759, 380, 2028, 365, 309, 2978, 257, 857, 544, 7257, 75, 2210, 370, 294, 51440], "temperature": 0.0, "avg_logprob": -0.24116340705326625, "compression_ratio": 1.3642857142857143, "no_speech_prob": 0.1403089463710785}, {"id": 47, "seek": 39138, "start": 391.42, "end": 398.65999999999997, "text": " effect the first tier was used to delineate whether something 10 which was something which was", "tokens": [50366, 1802, 264, 700, 12362, 390, 1143, 281, 1103, 533, 473, 1968, 746, 1266, 597, 390, 746, 597, 390, 50728], "temperature": 0.0, "avg_logprob": -0.20202110659691594, "compression_ratio": 1.9731543624161074, "no_speech_prob": 0.06685809791088104}, {"id": 48, "seek": 39138, "start": 398.65999999999997, "end": 411.5, "text": " which was which was which was something which was personally dealt with 20 to deal with documentation", "tokens": [50728, 597, 390, 597, 390, 597, 390, 746, 597, 390, 5665, 15991, 365, 945, 281, 2028, 365, 14333, 51370], "temperature": 0.0, "avg_logprob": -0.20202110659691594, "compression_ratio": 1.9731543624161074, "no_speech_prob": 0.06685809791088104}, {"id": 49, "seek": 39138, "start": 411.5, "end": 418.5, "text": " 30 to deal with display 40 to deal with movement 50 to do with environments such as conflicts and", "tokens": [51370, 2217, 281, 2028, 365, 4674, 3356, 281, 2028, 365, 3963, 2625, 281, 360, 365, 12388, 1270, 382, 19807, 293, 51720], "temperature": 0.0, "avg_logprob": -0.20202110659691594, "compression_ratio": 1.9731543624161074, "no_speech_prob": 0.06685809791088104}, {"id": 50, "seek": 41850, "start": 418.82, "end": 426.18, "text": " 60 to do with external or system-wide things or external tooling and I subsequently adapted this", "tokens": [50380, 4060, 281, 360, 365, 8320, 420, 1185, 12, 7990, 721, 420, 8320, 46593, 293, 286, 26514, 20871, 341, 50748], "temperature": 0.0, "avg_logprob": -0.19268653641885786, "compression_ratio": 1.576470588235294, "no_speech_prob": 0.009695022366940975}, {"id": 51, "seek": 41850, "start": 426.18, "end": 436.98, "text": " for two level layer with regards to 1q10 to represent one facet 1q30 to represent another", "tokens": [50748, 337, 732, 1496, 4583, 365, 14258, 281, 502, 80, 3279, 281, 2906, 472, 1915, 302, 502, 80, 3446, 281, 2906, 1071, 51288], "temperature": 0.0, "avg_logprob": -0.19268653641885786, "compression_ratio": 1.576470588235294, "no_speech_prob": 0.009695022366940975}, {"id": 52, "seek": 41850, "start": 438.1, "end": 444.02, "text": " and this sort of played well in terms of things but I just sort of had a bit of a", "tokens": [51344, 293, 341, 1333, 295, 3737, 731, 294, 2115, 295, 721, 457, 286, 445, 1333, 295, 632, 257, 857, 295, 257, 51640], "temperature": 0.0, "avg_logprob": -0.19268653641885786, "compression_ratio": 1.576470588235294, "no_speech_prob": 0.009695022366940975}, {"id": 53, "seek": 44402, "start": 444.65999999999997, "end": 452.58, "text": " I had a guilt in it because the non- that the previous system I came up with had the", "tokens": [50396, 286, 632, 257, 20421, 294, 309, 570, 264, 2107, 12, 300, 264, 3894, 1185, 286, 1361, 493, 365, 632, 264, 50792], "temperature": 0.0, "avg_logprob": -0.23656370581650152, "compression_ratio": 1.6584158415841583, "no_speech_prob": 0.011721814051270485}, {"id": 54, "seek": 44402, "start": 454.02, "end": 458.26, "text": " it worked very nicely that the you could describe things with the", "tokens": [50864, 309, 2732, 588, 9594, 300, 264, 291, 727, 6786, 721, 365, 264, 51076], "temperature": 0.0, "avg_logprob": -0.23656370581650152, "compression_ratio": 1.6584158415841583, "no_speech_prob": 0.011721814051270485}, {"id": 55, "seek": 44402, "start": 459.46, "end": 463.62, "text": " with the non-alpha numerics and they're quite accessible on the keyboard and so after a while", "tokens": [51136, 365, 264, 2107, 12, 304, 7211, 7866, 1167, 293, 436, 434, 1596, 9515, 322, 264, 10186, 293, 370, 934, 257, 1339, 51344], "temperature": 0.0, "avg_logprob": -0.23656370581650152, "compression_ratio": 1.6584158415841583, "no_speech_prob": 0.011721814051270485}, {"id": 56, "seek": 44402, "start": 463.62, "end": 470.41999999999996, "text": " with my confidence at least in terms of how I was dealing with the annotations in terms of", "tokens": [51344, 365, 452, 6687, 412, 1935, 294, 2115, 295, 577, 286, 390, 6260, 365, 264, 25339, 763, 294, 2115, 295, 51684], "temperature": 0.0, "avg_logprob": -0.23656370581650152, "compression_ratio": 1.6584158415841583, "no_speech_prob": 0.011721814051270485}, {"id": 57, "seek": 47042, "start": 470.58000000000004, "end": 477.46000000000004, "text": " the putting putting subsets of content which is quite similar into a specific folder", "tokens": [50372, 264, 3372, 3372, 2090, 1385, 295, 2701, 597, 307, 1596, 2531, 666, 257, 2685, 10820, 50716], "temperature": 0.0, "avg_logprob": -0.2063746819129357, "compression_ratio": 1.4793388429752066, "no_speech_prob": 0.009694220498204231}, {"id": 58, "seek": 47042, "start": 478.42, "end": 486.1, "text": " with these annotations forming and dealing with things and so for instance I would end up with", "tokens": [50764, 365, 613, 25339, 763, 15745, 293, 6260, 365, 721, 293, 370, 337, 5197, 286, 576, 917, 493, 365, 51148], "temperature": 0.0, "avg_logprob": -0.2063746819129357, "compression_ratio": 1.4793388429752066, "no_speech_prob": 0.009694220498204231}, {"id": 59, "seek": 48610, "start": 486.5, "end": 502.82000000000005, "text": " something looking like this which was compounded and so I started using the the letters sort of in", "tokens": [50384, 746, 1237, 411, 341, 597, 390, 14154, 292, 293, 370, 286, 1409, 1228, 264, 264, 7825, 1333, 295, 294, 51200], "temperature": 0.0, "avg_logprob": -0.18382914522860913, "compression_ratio": 1.4222222222222223, "no_speech_prob": 0.030555924400687218}, {"id": 60, "seek": 48610, "start": 502.82000000000005, "end": 513.94, "text": " the home row in the middle of where the QWERTY keyboard was so and it was it encouraged me to", "tokens": [51200, 264, 1280, 5386, 294, 264, 2808, 295, 689, 264, 1249, 37598, 23433, 10186, 390, 370, 293, 309, 390, 309, 14658, 385, 281, 51756], "temperature": 0.0, "avg_logprob": -0.18382914522860913, "compression_ratio": 1.4222222222222223, "no_speech_prob": 0.030555924400687218}, {"id": 61, "seek": 51394, "start": 513.94, "end": 519.22, "text": " really have things in specialized forms and repositories and I took the philosophy really", "tokens": [50364, 534, 362, 721, 294, 19813, 6422, 293, 22283, 2083, 293, 286, 1890, 264, 10675, 534, 50628], "temperature": 0.0, "avg_logprob": -0.13978418810614224, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.006089215632528067}, {"id": 62, "seek": 51394, "start": 519.22, "end": 525.7, "text": " sort of spreading things out so for instance we look at this this is an example of", "tokens": [50628, 1333, 295, 15232, 721, 484, 370, 337, 5197, 321, 574, 412, 341, 341, 307, 364, 1365, 295, 50952], "temperature": 0.0, "avg_logprob": -0.13978418810614224, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.006089215632528067}, {"id": 63, "seek": 51394, "start": 529.62, "end": 540.4200000000001, "text": " of different roughly passing based activities and I could do another form and so HQH would be", "tokens": [51148, 295, 819, 9810, 8437, 2361, 5354, 293, 286, 727, 360, 1071, 1254, 293, 370, 43209, 39, 576, 312, 51688], "temperature": 0.0, "avg_logprob": -0.13978418810614224, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.006089215632528067}, {"id": 64, "seek": 54042, "start": 540.42, "end": 545.86, "text": " roughly around passing OQ would be represented of languages and tools", "tokens": [50364, 9810, 926, 8437, 422, 48, 576, 312, 10379, 295, 8650, 293, 3873, 50636], "temperature": 0.0, "avg_logprob": -0.13720189730326335, "compression_ratio": 1.5776397515527951, "no_speech_prob": 0.003647832665592432}, {"id": 65, "seek": 54042, "start": 550.26, "end": 551.9399999999999, "text": " and so for instance we could do", "tokens": [50856, 293, 370, 337, 5197, 321, 727, 360, 50940], "temperature": 0.0, "avg_logprob": -0.13720189730326335, "compression_ratio": 1.5776397515527951, "no_speech_prob": 0.003647832665592432}, {"id": 66, "seek": 54042, "start": 555.38, "end": 559.54, "text": " lower and this would give an example of lots of lower based", "tokens": [51112, 3126, 293, 341, 576, 976, 364, 1365, 295, 3195, 295, 3126, 2361, 51320], "temperature": 0.0, "avg_logprob": -0.13720189730326335, "compression_ratio": 1.5776397515527951, "no_speech_prob": 0.003647832665592432}, {"id": 67, "seek": 54042, "start": 562.0999999999999, "end": 567.2199999999999, "text": " points so as you can see these annotations can allow you to really cut through and deal with", "tokens": [51448, 2793, 370, 382, 291, 393, 536, 613, 25339, 763, 393, 2089, 291, 281, 534, 1723, 807, 293, 2028, 365, 51704], "temperature": 0.0, "avg_logprob": -0.13720189730326335, "compression_ratio": 1.5776397515527951, "no_speech_prob": 0.003647832665592432}, {"id": 68, "seek": 56722, "start": 567.22, "end": 574.9, "text": " various points and with the with regards to the icebreaker project I felt that the", "tokens": [50364, 3683, 2793, 293, 365, 264, 365, 14258, 281, 264, 4435, 43847, 1716, 286, 2762, 300, 264, 50748], "temperature": 0.0, "avg_logprob": -0.1256680575284091, "compression_ratio": 1.8028169014084507, "no_speech_prob": 0.0030243918299674988}, {"id": 69, "seek": 56722, "start": 576.98, "end": 583.3000000000001, "text": " I felt this stuff was interesting but the icebreaker project was very document", "tokens": [50852, 286, 2762, 341, 1507, 390, 1880, 457, 264, 4435, 43847, 1716, 390, 588, 4166, 51168], "temperature": 0.0, "avg_logprob": -0.1256680575284091, "compression_ratio": 1.8028169014084507, "no_speech_prob": 0.0030243918299674988}, {"id": 70, "seek": 56722, "start": 583.3000000000001, "end": 593.5400000000001, "text": " focused for very good reasons the my icebreaker project was has been looking into how document", "tokens": [51168, 5178, 337, 588, 665, 4112, 264, 452, 4435, 43847, 1716, 390, 575, 668, 1237, 666, 577, 4166, 51680], "temperature": 0.0, "avg_logprob": -0.1256680575284091, "compression_ratio": 1.8028169014084507, "no_speech_prob": 0.0030243918299674988}, {"id": 71, "seek": 59354, "start": 593.86, "end": 601.38, "text": " how flap based files could be used particularly with regards to gem text the file format of gem", "tokens": [50380, 577, 30781, 2361, 7098, 727, 312, 1143, 4098, 365, 14258, 281, 7173, 2487, 264, 3991, 7877, 295, 7173, 50756], "temperature": 0.0, "avg_logprob": -0.14588108370381017, "compression_ratio": 1.5705882352941176, "no_speech_prob": 0.006981322541832924}, {"id": 72, "seek": 59354, "start": 601.38, "end": 610.26, "text": " and I could be used to express issues and problems or also Kanban boards which is", "tokens": [50756, 293, 286, 727, 312, 1143, 281, 5109, 2663, 293, 2740, 420, 611, 11120, 5144, 13293, 597, 307, 51200], "temperature": 0.0, "avg_logprob": -0.14588108370381017, "compression_ratio": 1.5705882352941176, "no_speech_prob": 0.006981322541832924}, {"id": 73, "seek": 59354, "start": 613.4599999999999, "end": 620.74, "text": " which would be more preferable than the walled garden approach of services such as Github", "tokens": [51360, 597, 576, 312, 544, 4382, 712, 813, 264, 2929, 292, 7431, 3109, 295, 3328, 1270, 382, 460, 355, 836, 51724], "temperature": 0.0, "avg_logprob": -0.14588108370381017, "compression_ratio": 1.5705882352941176, "no_speech_prob": 0.006981322541832924}, {"id": 74, "seek": 62074, "start": 620.74, "end": 626.42, "text": " where you in effect end up putting all your repos with all the git history and all the subtleties", "tokens": [50364, 689, 291, 294, 1802, 917, 493, 3372, 439, 428, 1085, 329, 365, 439, 264, 18331, 2503, 293, 439, 264, 7257, 2631, 530, 50648], "temperature": 0.0, "avg_logprob": -0.11529376408825182, "compression_ratio": 1.7515151515151515, "no_speech_prob": 0.014836118556559086}, {"id": 75, "seek": 62074, "start": 626.42, "end": 630.9, "text": " in terms of that but when it comes to improving any of these repos you're not allowed to", "tokens": [50648, 294, 2115, 295, 300, 457, 562, 309, 1487, 281, 11470, 604, 295, 613, 1085, 329, 291, 434, 406, 4350, 281, 50872], "temperature": 0.0, "avg_logprob": -0.11529376408825182, "compression_ratio": 1.7515151515151515, "no_speech_prob": 0.014836118556559086}, {"id": 76, "seek": 62074, "start": 632.02, "end": 639.7, "text": " delve through the history and subtleties in terms of that so here's just at the top pane an example of", "tokens": [50928, 43098, 807, 264, 2503, 293, 7257, 2631, 530, 294, 2115, 295, 300, 370, 510, 311, 445, 412, 264, 1192, 32605, 364, 1365, 295, 51312], "temperature": 0.0, "avg_logprob": -0.11529376408825182, "compression_ratio": 1.7515151515151515, "no_speech_prob": 0.014836118556559086}, {"id": 77, "seek": 63970, "start": 640.5, "end": 648.74, "text": " and G networks Kanban board repo just the read me file being run through", "tokens": [50404, 293, 460, 9590, 11120, 5144, 3150, 49040, 445, 264, 1401, 385, 3991, 885, 1190, 807, 50816], "temperature": 0.0, "avg_logprob": -0.17470235209311208, "compression_ratio": 1.6883116883116882, "no_speech_prob": 0.13001641631126404}, {"id": 78, "seek": 63970, "start": 649.7, "end": 657.46, "text": " a the git in terms of the history and diffs so as you see all of these lovely things in terms", "tokens": [50864, 257, 264, 18331, 294, 2115, 295, 264, 2503, 293, 7593, 82, 370, 382, 291, 536, 439, 295, 613, 7496, 721, 294, 2115, 51252], "temperature": 0.0, "avg_logprob": -0.17470235209311208, "compression_ratio": 1.6883116883116882, "no_speech_prob": 0.13001641631126404}, {"id": 79, "seek": 63970, "start": 657.46, "end": 661.94, "text": " of people adding things people removing things people altering things you don't really get in", "tokens": [51252, 295, 561, 5127, 721, 561, 12720, 721, 561, 11337, 278, 721, 291, 500, 380, 534, 483, 294, 51476], "temperature": 0.0, "avg_logprob": -0.17470235209311208, "compression_ratio": 1.6883116883116882, "no_speech_prob": 0.13001641631126404}, {"id": 80, "seek": 66194, "start": 661.94, "end": 677.3000000000001, "text": " Github and that's a shame I sort of looked in terms of that and it was very satisfying that", "tokens": [50364, 460, 355, 836, 293, 300, 311, 257, 10069, 286, 1333, 295, 2956, 294, 2115, 295, 300, 293, 309, 390, 588, 18348, 300, 51132], "temperature": 0.0, "avg_logprob": -0.12190256335518578, "compression_ratio": 1.3969465648854962, "no_speech_prob": 0.07731329649686813}, {"id": 81, "seek": 66194, "start": 677.3000000000001, "end": 685.62, "text": " gem text could provide such a minimal minimal syntactic range for expressing the ideas that", "tokens": [51132, 7173, 2487, 727, 2893, 1270, 257, 13206, 13206, 23980, 19892, 3613, 337, 22171, 264, 3487, 300, 51548], "temperature": 0.0, "avg_logprob": -0.12190256335518578, "compression_ratio": 1.3969465648854962, "no_speech_prob": 0.07731329649686813}, {"id": 82, "seek": 68562, "start": 686.18, "end": 692.82, "text": " that ultimately I felt the need that just to see how things could mix and and perform with and what I", "tokens": [50392, 300, 6284, 286, 2762, 264, 643, 300, 445, 281, 536, 577, 721, 727, 2890, 293, 293, 2042, 365, 293, 437, 286, 50724], "temperature": 0.0, "avg_logprob": -0.2654354537742725, "compression_ratio": 1.6384180790960452, "no_speech_prob": 0.031000643968582153}, {"id": 83, "seek": 68562, "start": 692.82, "end": 702.9, "text": " went with was the use of the KL liner format which is within the emacs hyper hyperbole the package", "tokens": [50724, 1437, 365, 390, 264, 764, 295, 264, 47991, 24468, 7877, 597, 307, 1951, 264, 846, 44937, 9848, 9848, 1763, 306, 264, 7372, 51228], "temperature": 0.0, "avg_logprob": -0.2654354537742725, "compression_ratio": 1.6384180790960452, "no_speech_prob": 0.031000643968582153}, {"id": 84, "seek": 68562, "start": 702.9, "end": 708.1, "text": " which is a format which is hierarchical and it's got very good interfaces so for instance", "tokens": [51228, 597, 307, 257, 7877, 597, 307, 35250, 804, 293, 309, 311, 658, 588, 665, 28416, 370, 337, 5197, 51488], "temperature": 0.0, "avg_logprob": -0.2654354537742725, "compression_ratio": 1.6384180790960452, "no_speech_prob": 0.031000643968582153}, {"id": 85, "seek": 70810, "start": 708.26, "end": 717.14, "text": " you could be adding parts like this or hitting a child form and what's very nice is as part of this", "tokens": [50372, 291, 727, 312, 5127, 3166, 411, 341, 420, 8850, 257, 1440, 1254, 293, 437, 311, 588, 1481, 307, 382, 644, 295, 341, 50816], "temperature": 0.0, "avg_logprob": -0.16410255432128906, "compression_ratio": 1.6608187134502923, "no_speech_prob": 0.2661721408367157}, {"id": 86, "seek": 70810, "start": 717.14, "end": 725.7, "text": " being a person information manager so you can cross link blocks and if including in other", "tokens": [50816, 885, 257, 954, 1589, 6598, 370, 291, 393, 3278, 2113, 8474, 293, 498, 3009, 294, 661, 51244], "temperature": 0.0, "avg_logprob": -0.16410255432128906, "compression_ratio": 1.6608187134502923, "no_speech_prob": 0.2661721408367157}, {"id": 87, "seek": 70810, "start": 725.7, "end": 734.98, "text": " documents and should the blocks change then you will be able to you'll be able to catch up and", "tokens": [51244, 8512, 293, 820, 264, 8474, 1319, 550, 291, 486, 312, 1075, 281, 291, 603, 312, 1075, 281, 3745, 493, 293, 51708], "temperature": 0.0, "avg_logprob": -0.16410255432128906, "compression_ratio": 1.6608187134502923, "no_speech_prob": 0.2661721408367157}, {"id": 88, "seek": 73498, "start": 734.98, "end": 740.98, "text": " work out where that the block has been moved to at least within the same document and so that's", "tokens": [50364, 589, 484, 689, 300, 264, 3461, 575, 668, 4259, 281, 412, 1935, 1951, 264, 912, 4166, 293, 370, 300, 311, 50664], "temperature": 0.0, "avg_logprob": -0.11637586622095819, "compression_ratio": 1.6022099447513811, "no_speech_prob": 0.022691674530506134}, {"id": 89, "seek": 73498, "start": 740.98, "end": 748.58, "text": " one of the things which I really prioritized and dealt with in terms of this year and and I managed", "tokens": [50664, 472, 295, 264, 721, 597, 286, 534, 14846, 1602, 293, 15991, 365, 294, 2115, 295, 341, 1064, 293, 293, 286, 6453, 51044], "temperature": 0.0, "avg_logprob": -0.11637586622095819, "compression_ratio": 1.6022099447513811, "no_speech_prob": 0.022691674530506134}, {"id": 90, "seek": 73498, "start": 748.58, "end": 758.1, "text": " to with the interpreter canonical mix both the syntaxes of gem protocols gem text the KL liner", "tokens": [51044, 281, 365, 264, 34132, 46491, 2890, 1293, 264, 28431, 279, 295, 7173, 20618, 7173, 2487, 264, 47991, 24468, 51520], "temperature": 0.0, "avg_logprob": -0.11637586622095819, "compression_ratio": 1.6022099447513811, "no_speech_prob": 0.022691674530506134}, {"id": 91, "seek": 75810, "start": 758.1, "end": 768.66, "text": " format as well as the key annotation system and so this has and I haven't explored it perfectly", "tokens": [50364, 7877, 382, 731, 382, 264, 2141, 48654, 1185, 293, 370, 341, 575, 293, 286, 2378, 380, 24016, 309, 6239, 50892], "temperature": 0.0, "avg_logprob": -0.05949363443586561, "compression_ratio": 1.6494845360824741, "no_speech_prob": 0.07172399759292603}, {"id": 92, "seek": 75810, "start": 768.66, "end": 773.7, "text": " but I believe that the passing expression grammars are capable of representing things", "tokens": [50892, 457, 286, 1697, 300, 264, 8437, 6114, 17570, 685, 366, 8189, 295, 13460, 721, 51144], "temperature": 0.0, "avg_logprob": -0.05949363443586561, "compression_ratio": 1.6494845360824741, "no_speech_prob": 0.07172399759292603}, {"id": 93, "seek": 75810, "start": 775.5400000000001, "end": 778.26, "text": " within the same line and not necessarily be relegated to", "tokens": [51236, 1951, 264, 912, 1622, 293, 406, 4725, 312, 2951, 70, 770, 281, 51372], "temperature": 0.0, "avg_logprob": -0.05949363443586561, "compression_ratio": 1.6494845360824741, "no_speech_prob": 0.07172399759292603}, {"id": 94, "seek": 75810, "start": 780.4200000000001, "end": 787.7, "text": " to comparing line by line and so this kind of deviant exploration of how syntaxes", "tokens": [51480, 281, 15763, 1622, 538, 1622, 293, 370, 341, 733, 295, 1905, 5798, 16197, 295, 577, 28431, 279, 51844], "temperature": 0.0, "avg_logprob": -0.05949363443586561, "compression_ratio": 1.6494845360824741, "no_speech_prob": 0.07172399759292603}, {"id": 95, "seek": 78770, "start": 787.7, "end": 795.22, "text": " can work across I've potentially got something much more richer and and subtle with with then", "tokens": [50364, 393, 589, 2108, 286, 600, 7263, 658, 746, 709, 544, 29021, 293, 293, 13743, 365, 365, 550, 50740], "temperature": 0.0, "avg_logprob": -0.10156835294237324, "compression_ratio": 1.5357142857142858, "no_speech_prob": 0.0030374384950846434}, {"id": 96, "seek": 78770, "start": 795.22, "end": 798.58, "text": " then the formats and syntaxes isolated", "tokens": [50740, 550, 264, 25879, 293, 28431, 279, 14621, 50908], "temperature": 0.0, "avg_logprob": -0.10156835294237324, "compression_ratio": 1.5357142857142858, "no_speech_prob": 0.0030374384950846434}, {"id": 97, "seek": 78770, "start": 802.74, "end": 810.26, "text": " here just on the top pane here is just an example of in in the in the language and", "tokens": [51116, 510, 445, 322, 264, 1192, 32605, 510, 307, 445, 364, 1365, 295, 294, 294, 264, 294, 264, 2856, 293, 51492], "temperature": 0.0, "avg_logprob": -0.10156835294237324, "compression_ratio": 1.5357142857142858, "no_speech_prob": 0.0030374384950846434}, {"id": 98, "seek": 81026, "start": 810.26, "end": 818.26, "text": " pass a txr a way of creating a definition and then providing the name of the reference in this", "tokens": [50364, 1320, 257, 256, 87, 81, 257, 636, 295, 4084, 257, 7123, 293, 550, 6530, 264, 1315, 295, 264, 6408, 294, 341, 50764], "temperature": 0.0, "avg_logprob": -0.16737808227539064, "compression_ratio": 1.4961832061068703, "no_speech_prob": 0.05317780375480652}, {"id": 99, "seek": 81026, "start": 818.26, "end": 829.62, "text": " case I use the annotation style hqh to just point out that the the passing forms and and here we have", "tokens": [50764, 1389, 286, 764, 264, 48654, 3758, 276, 80, 71, 281, 445, 935, 484, 300, 264, 264, 8437, 6422, 293, 293, 510, 321, 362, 51332], "temperature": 0.0, "avg_logprob": -0.16737808227539064, "compression_ratio": 1.4961832061068703, "no_speech_prob": 0.05317780375480652}, {"id": 100, "seek": 82962, "start": 829.62, "end": 842.58, "text": " the the various key key aspects uh aspects of the of the annotation um for for key just", "tokens": [50364, 264, 264, 3683, 2141, 2141, 7270, 2232, 7270, 295, 264, 295, 264, 48654, 1105, 337, 337, 2141, 445, 51012], "temperature": 0.0, "avg_logprob": -0.14629426549692623, "compression_ratio": 1.7843137254901962, "no_speech_prob": 0.08640503883361816}, {"id": 101, "seek": 82962, "start": 842.58, "end": 849.78, "text": " returning to that I should emphasize that that the key annotation is formed around the the", "tokens": [51012, 12678, 281, 300, 286, 820, 16078, 300, 300, 264, 2141, 48654, 307, 8693, 926, 264, 264, 51372], "temperature": 0.0, "avg_logprob": -0.14629426549692623, "compression_ratio": 1.7843137254901962, "no_speech_prob": 0.08640503883361816}, {"id": 102, "seek": 82962, "start": 850.42, "end": 857.94, "text": " green buttons which would either so for instance and it would be one of the one of the letters", "tokens": [51404, 3092, 9905, 597, 576, 2139, 370, 337, 5197, 293, 309, 576, 312, 472, 295, 264, 472, 295, 264, 7825, 51780], "temperature": 0.0, "avg_logprob": -0.14629426549692623, "compression_ratio": 1.7843137254901962, "no_speech_prob": 0.08640503883361816}, {"id": 103, "seek": 85794, "start": 857.94, "end": 865.0600000000001, "text": " in there would generate would providing the the starting kernel for for an annotation but it is", "tokens": [50364, 294, 456, 576, 8460, 576, 6530, 264, 264, 2891, 28256, 337, 337, 364, 48654, 457, 309, 307, 50720], "temperature": 0.0, "avg_logprob": -0.09704041481018066, "compression_ratio": 1.6491228070175439, "no_speech_prob": 0.005362702067941427}, {"id": 104, "seek": 85794, "start": 865.86, "end": 872.34, "text": " supplemented with qwe or two which allows to provide a an inference and this was more of a", "tokens": [50760, 15436, 292, 365, 9505, 826, 420, 732, 597, 4045, 281, 2893, 257, 364, 38253, 293, 341, 390, 544, 295, 257, 51084], "temperature": 0.0, "avg_logprob": -0.09704041481018066, "compression_ratio": 1.6491228070175439, "no_speech_prob": 0.005362702067941427}, {"id": 105, "seek": 85794, "start": 872.34, "end": 882.0200000000001, "text": " later stage innovation and you can also combine annotations the annotation points at least I do", "tokens": [51084, 1780, 3233, 8504, 293, 291, 393, 611, 10432, 25339, 763, 264, 48654, 2793, 412, 1935, 286, 360, 51568], "temperature": 0.0, "avg_logprob": -0.09704041481018066, "compression_ratio": 1.6491228070175439, "no_speech_prob": 0.005362702067941427}, {"id": 106, "seek": 88202, "start": 882.02, "end": 889.3, "text": " it so that up to four can be compounded to be representative of of one which excluding blooms", "tokens": [50364, 309, 370, 300, 493, 281, 1451, 393, 312, 14154, 292, 281, 312, 12424, 295, 295, 472, 597, 49999, 1749, 4785, 50728], "temperature": 0.0, "avg_logprob": -0.08029980129665798, "compression_ratio": 1.737556561085973, "no_speech_prob": 0.16234488785266876}, {"id": 107, "seek": 88202, "start": 889.3, "end": 896.5, "text": " which would be providing where the dictionary where the document deals with and encourages more", "tokens": [50728, 597, 576, 312, 6530, 689, 264, 25890, 689, 264, 4166, 11215, 365, 293, 28071, 544, 51088], "temperature": 0.0, "avg_logprob": -0.08029980129665798, "compression_ratio": 1.737556561085973, "no_speech_prob": 0.16234488785266876}, {"id": 108, "seek": 88202, "start": 896.5, "end": 903.9399999999999, "text": " recursive perspective on things has has a very large range permutative range which even though", "tokens": [51088, 20560, 488, 4585, 322, 721, 575, 575, 257, 588, 2416, 3613, 4784, 325, 1166, 3613, 597, 754, 1673, 51460], "temperature": 0.0, "avg_logprob": -0.08029980129665798, "compression_ratio": 1.737556561085973, "no_speech_prob": 0.16234488785266876}, {"id": 109, "seek": 88202, "start": 903.9399999999999, "end": 911.22, "text": " that wouldn't be satisfied with either an individual annotating things or or a community left alone", "tokens": [51460, 300, 2759, 380, 312, 11239, 365, 2139, 364, 2609, 25339, 990, 721, 420, 420, 257, 1768, 1411, 3312, 51824], "temperature": 0.0, "avg_logprob": -0.08029980129665798, "compression_ratio": 1.737556561085973, "no_speech_prob": 0.16234488785266876}, {"id": 110, "seek": 91122, "start": 911.22, "end": 918.5, "text": " the the logical outcome of combining certain things together it provides a very large range in", "tokens": [50364, 264, 264, 14978, 9700, 295, 21928, 1629, 721, 1214, 309, 6417, 257, 588, 2416, 3613, 294, 50728], "temperature": 0.0, "avg_logprob": -0.05095282130771213, "compression_ratio": 1.7079646017699115, "no_speech_prob": 0.009643040597438812}, {"id": 111, "seek": 91122, "start": 918.5, "end": 926.34, "text": " the tens if not hundreds of thousands of of of points and so as you add one or more annotations", "tokens": [50728, 264, 10688, 498, 406, 6779, 295, 5383, 295, 295, 295, 2793, 293, 370, 382, 291, 909, 472, 420, 544, 25339, 763, 51120], "temperature": 0.0, "avg_logprob": -0.05095282130771213, "compression_ratio": 1.7079646017699115, "no_speech_prob": 0.009643040597438812}, {"id": 112, "seek": 91122, "start": 926.34, "end": 933.38, "text": " you can really get a fingerprint of what things are and it's also got a bit subtlety regarding", "tokens": [51120, 291, 393, 534, 483, 257, 30715, 295, 437, 721, 366, 293, 309, 311, 611, 658, 257, 857, 7257, 75, 2210, 8595, 51472], "temperature": 0.0, "avg_logprob": -0.05095282130771213, "compression_ratio": 1.7079646017699115, "no_speech_prob": 0.009643040597438812}, {"id": 113, "seek": 91122, "start": 933.38, "end": 939.38, "text": " that it's not the lack of precision in terms of this which has been described to me more in terms of", "tokens": [51472, 300, 309, 311, 406, 264, 5011, 295, 18356, 294, 2115, 295, 341, 597, 575, 668, 7619, 281, 385, 544, 294, 2115, 295, 51772], "temperature": 0.0, "avg_logprob": -0.05095282130771213, "compression_ratio": 1.7079646017699115, "no_speech_prob": 0.009643040597438812}, {"id": 114, "seek": 93938, "start": 940.1, "end": 947.38, "text": " like I think it was Aristotle's use of hexes in terms of what something is and and its sort of", "tokens": [50400, 411, 286, 519, 309, 390, 42368, 311, 764, 295, 23291, 279, 294, 2115, 295, 437, 746, 307, 293, 293, 1080, 1333, 295, 50764], "temperature": 0.0, "avg_logprob": -0.13621563003176734, "compression_ratio": 1.74, "no_speech_prob": 0.00680512422695756}, {"id": 115, "seek": 93938, "start": 948.58, "end": 956.58, "text": " force the philosophy of what something is and I've been trying to deliberate in terms of the", "tokens": [50824, 3464, 264, 10675, 295, 437, 746, 307, 293, 286, 600, 668, 1382, 281, 30515, 294, 2115, 295, 264, 51224], "temperature": 0.0, "avg_logprob": -0.13621563003176734, "compression_ratio": 1.74, "no_speech_prob": 0.00680512422695756}, {"id": 116, "seek": 93938, "start": 957.62, "end": 960.9, "text": " the subtleties regarding that and I guess it would be for instance", "tokens": [51276, 264, 7257, 2631, 530, 8595, 300, 293, 286, 2041, 309, 576, 312, 337, 5197, 51440], "temperature": 0.0, "avg_logprob": -0.13621563003176734, "compression_ratio": 1.74, "no_speech_prob": 0.00680512422695756}, {"id": 117, "seek": 93938, "start": 962.58, "end": 968.9, "text": " there's there's always conjecture regarding who invents say the first submarine or the or say", "tokens": [51524, 456, 311, 456, 311, 1009, 416, 1020, 540, 8595, 567, 1048, 791, 584, 264, 700, 33995, 420, 264, 420, 584, 51840], "temperature": 0.0, "avg_logprob": -0.13621563003176734, "compression_ratio": 1.74, "no_speech_prob": 0.00680512422695756}, {"id": 118, "seek": 96890, "start": 968.9, "end": 977.22, "text": " something like the first submarine or the first first the first camera and so for instance from", "tokens": [50364, 746, 411, 264, 700, 33995, 420, 264, 700, 700, 264, 700, 2799, 293, 370, 337, 5197, 490, 50780], "temperature": 0.0, "avg_logprob": -0.08922939002513885, "compression_ratio": 1.7218934911242603, "no_speech_prob": 0.005239979829639196}, {"id": 119, "seek": 96890, "start": 977.22, "end": 984.42, "text": " my own perspective in terms of prejudices I've got a concept of of an Irishman inventing the first", "tokens": [50780, 452, 1065, 4585, 294, 2115, 295, 23121, 1473, 286, 600, 658, 257, 3410, 295, 295, 364, 16801, 1601, 7962, 278, 264, 700, 51140], "temperature": 0.0, "avg_logprob": -0.08922939002513885, "compression_ratio": 1.7218934911242603, "no_speech_prob": 0.005239979829639196}, {"id": 120, "seek": 96890, "start": 984.42, "end": 995.78, "text": " submarine and London a London an English politician who was invented the first camera and that's", "tokens": [51140, 33995, 293, 7042, 257, 7042, 364, 3669, 26453, 567, 390, 14479, 264, 700, 2799, 293, 300, 311, 51708], "temperature": 0.0, "avg_logprob": -0.08922939002513885, "compression_ratio": 1.7218934911242603, "no_speech_prob": 0.005239979829639196}, {"id": 121, "seek": 99578, "start": 995.78, "end": 1002.98, "text": " perhaps just based on my own prejudices upbringing and me not having complete enough technological", "tokens": [50364, 4317, 445, 2361, 322, 452, 1065, 23121, 1473, 47268, 293, 385, 406, 1419, 3566, 1547, 18439, 50724], "temperature": 0.0, "avg_logprob": -0.0811598628175025, "compression_ratio": 1.7655677655677655, "no_speech_prob": 0.007540108170360327}, {"id": 122, "seek": 99578, "start": 1002.98, "end": 1006.5799999999999, "text": " perspective and definition in terms of that and I'm sure there are people for instance and", "tokens": [50724, 4585, 293, 7123, 294, 2115, 295, 300, 293, 286, 478, 988, 456, 366, 561, 337, 5197, 293, 50904], "temperature": 0.0, "avg_logprob": -0.0811598628175025, "compression_ratio": 1.7655677655677655, "no_speech_prob": 0.007540108170360327}, {"id": 123, "seek": 99578, "start": 1007.54, "end": 1013.06, "text": " in other regions who who have different opinions and that's all fine because we all sort of have", "tokens": [50952, 294, 661, 10682, 567, 567, 362, 819, 11819, 293, 300, 311, 439, 2489, 570, 321, 439, 1333, 295, 362, 51228], "temperature": 0.0, "avg_logprob": -0.0811598628175025, "compression_ratio": 1.7655677655677655, "no_speech_prob": 0.007540108170360327}, {"id": 124, "seek": 99578, "start": 1013.06, "end": 1018.3399999999999, "text": " a common idea of what a submarine is or what a camera is but we might have different definitions", "tokens": [51228, 257, 2689, 1558, 295, 437, 257, 33995, 307, 420, 437, 257, 2799, 307, 457, 321, 1062, 362, 819, 21988, 51492], "temperature": 0.0, "avg_logprob": -0.0811598628175025, "compression_ratio": 1.7655677655677655, "no_speech_prob": 0.007540108170360327}, {"id": 125, "seek": 99578, "start": 1018.3399999999999, "end": 1024.82, "text": " at which point that thing moved from being something else into that form and that's why I like the", "tokens": [51492, 412, 597, 935, 300, 551, 4259, 490, 885, 746, 1646, 666, 300, 1254, 293, 300, 311, 983, 286, 411, 264, 51816], "temperature": 0.0, "avg_logprob": -0.0811598628175025, "compression_ratio": 1.7655677655677655, "no_speech_prob": 0.007540108170360327}, {"id": 126, "seek": 102578, "start": 1026.74, "end": 1033.7, "text": " the vagueness of this key and and its annotations is that it it doesn't it doesn't have grandiose", "tokens": [50412, 264, 13501, 7801, 442, 295, 341, 2141, 293, 293, 1080, 25339, 763, 307, 300, 309, 309, 1177, 380, 309, 1177, 380, 362, 45155, 541, 50760], "temperature": 0.0, "avg_logprob": -0.10126908954821134, "compression_ratio": 1.7904761904761906, "no_speech_prob": 0.0010057548061013222}, {"id": 127, "seek": 102578, "start": 1033.7, "end": 1039.22, "text": " claims of completeness and it has more of a kind of ectomology approach in which you can", "tokens": [50760, 9441, 295, 1557, 15264, 293, 309, 575, 544, 295, 257, 733, 295, 308, 349, 298, 1793, 3109, 294, 597, 291, 393, 51036], "temperature": 0.0, "avg_logprob": -0.10126908954821134, "compression_ratio": 1.7904761904761906, "no_speech_prob": 0.0010057548061013222}, {"id": 128, "seek": 102578, "start": 1039.94, "end": 1046.82, "text": " make an opinion on things switching out and it's all fine including if if the definitions changes", "tokens": [51072, 652, 364, 4800, 322, 721, 16493, 484, 293, 309, 311, 439, 2489, 3009, 498, 498, 264, 21988, 2962, 51416], "temperature": 0.0, "avg_logprob": -0.10126908954821134, "compression_ratio": 1.7904761904761906, "no_speech_prob": 0.0010057548061013222}, {"id": 129, "seek": 102578, "start": 1046.82, "end": 1052.66, "text": " and it's it's almost in terms of how it works and and operates in terms of the work for any", "tokens": [51416, 293, 309, 311, 309, 311, 1920, 294, 2115, 295, 577, 309, 1985, 293, 293, 22577, 294, 2115, 295, 264, 589, 337, 604, 51708], "temperature": 0.0, "avg_logprob": -0.10126908954821134, "compression_ratio": 1.7904761904761906, "no_speech_prob": 0.0010057548061013222}, {"id": 130, "seek": 105266, "start": 1052.66, "end": 1058.18, "text": " user it really gives you kind of the convenience and dealing with things so just returning back to", "tokens": [50364, 4195, 309, 534, 2709, 291, 733, 295, 264, 19283, 293, 6260, 365, 721, 370, 445, 12678, 646, 281, 50640], "temperature": 0.0, "avg_logprob": -0.12925387591850468, "compression_ratio": 1.5502645502645502, "no_speech_prob": 0.0312140304595232}, {"id": 131, "seek": 105266, "start": 1058.18, "end": 1069.46, "text": " here for instance I looking in terms of a a more of a specific function at the top here you've got", "tokens": [50640, 510, 337, 5197, 286, 1237, 294, 2115, 295, 257, 257, 544, 295, 257, 2685, 2445, 412, 264, 1192, 510, 291, 600, 658, 51204], "temperature": 0.0, "avg_logprob": -0.12925387591850468, "compression_ratio": 1.5502645502645502, "no_speech_prob": 0.0312140304595232}, {"id": 132, "seek": 105266, "start": 1069.46, "end": 1077.94, "text": " RQR KWK and that's in effect RQR would be a form of a to-do and KWK in terms of hashes in terms", "tokens": [51204, 497, 48, 49, 591, 54, 42, 293, 300, 311, 294, 1802, 497, 48, 49, 576, 312, 257, 1254, 295, 257, 281, 12, 2595, 293, 591, 54, 42, 294, 2115, 295, 575, 8076, 294, 2115, 51628], "temperature": 0.0, "avg_logprob": -0.12925387591850468, "compression_ratio": 1.5502645502645502, "no_speech_prob": 0.0312140304595232}, {"id": 133, "seek": 107794, "start": 1077.94, "end": 1087.54, "text": " of the aspects the complementary description is create hashes and here we're just returning just", "tokens": [50364, 295, 264, 7270, 264, 40705, 3855, 307, 1884, 575, 8076, 293, 510, 321, 434, 445, 12678, 445, 50844], "temperature": 0.0, "avg_logprob": -0.14630555324867123, "compression_ratio": 1.7005988023952097, "no_speech_prob": 0.015320628881454468}, {"id": 134, "seek": 107794, "start": 1087.54, "end": 1096.9, "text": " in case you there's a definite the function definition as well as a reference in terms of the", "tokens": [50844, 294, 1389, 291, 456, 311, 257, 25131, 264, 2445, 7123, 382, 731, 382, 257, 6408, 294, 2115, 295, 264, 51312], "temperature": 0.0, "avg_logprob": -0.14630555324867123, "compression_ratio": 1.7005988023952097, "no_speech_prob": 0.015320628881454468}, {"id": 135, "seek": 107794, "start": 1096.9, "end": 1105.7, "text": " fact that you have the annotations being being outputted here within the the parentheses here", "tokens": [51312, 1186, 300, 291, 362, 264, 25339, 763, 885, 885, 5598, 14727, 510, 1951, 264, 264, 34153, 510, 51752], "temperature": 0.0, "avg_logprob": -0.14630555324867123, "compression_ratio": 1.7005988023952097, "no_speech_prob": 0.015320628881454468}, {"id": 136, "seek": 110570, "start": 1105.7, "end": 1118.1000000000001, "text": " just in the light blue and here we have the the form for putting things in cases which in", "tokens": [50364, 445, 294, 264, 1442, 3344, 293, 510, 321, 362, 264, 264, 1254, 337, 3372, 721, 294, 3331, 597, 294, 50984], "temperature": 0.0, "avg_logprob": -0.12244640077863421, "compression_ratio": 1.6744186046511629, "no_speech_prob": 0.005206855479627848}, {"id": 137, "seek": 110570, "start": 1118.1000000000001, "end": 1125.8600000000001, "text": " in the TXR form needs to be ended this is a list based language so as you can imagine things start", "tokens": [50984, 294, 264, 314, 55, 49, 1254, 2203, 281, 312, 4590, 341, 307, 257, 1329, 2361, 2856, 370, 382, 291, 393, 3811, 721, 722, 51372], "temperature": 0.0, "avg_logprob": -0.12244640077863421, "compression_ratio": 1.6744186046511629, "no_speech_prob": 0.005206855479627848}, {"id": 138, "seek": 110570, "start": 1125.8600000000001, "end": 1133.38, "text": " and stop in very clear forms you have the syntax for creating a binding which in this form would be", "tokens": [51372, 293, 1590, 294, 588, 1850, 6422, 291, 362, 264, 28431, 337, 4084, 257, 17359, 597, 294, 341, 1254, 576, 312, 51748], "temperature": 0.0, "avg_logprob": -0.12244640077863421, "compression_ratio": 1.6744186046511629, "no_speech_prob": 0.005206855479627848}, {"id": 139, "seek": 113338, "start": 1133.38, "end": 1141.0600000000002, "text": " well let's let's go the first part so this is you this is an example of a URI variable being", "tokens": [50364, 731, 718, 311, 718, 311, 352, 264, 700, 644, 370, 341, 307, 291, 341, 307, 364, 1365, 295, 257, 624, 5577, 7006, 885, 50748], "temperature": 0.0, "avg_logprob": -0.0669119656085968, "compression_ratio": 1.7546296296296295, "no_speech_prob": 0.004110606852918863}, {"id": 140, "seek": 113338, "start": 1141.0600000000002, "end": 1148.5, "text": " captured which is referencing a separate function and which and and expecting this outcome and of", "tokens": [50748, 11828, 597, 307, 40582, 257, 4994, 2445, 293, 597, 293, 293, 9650, 341, 9700, 293, 295, 51120], "temperature": 0.0, "avg_logprob": -0.0669119656085968, "compression_ratio": 1.7546296296296295, "no_speech_prob": 0.004110606852918863}, {"id": 141, "seek": 113338, "start": 1148.5, "end": 1155.6200000000001, "text": " course you might have you could have a function capturing multiple things and which this this", "tokens": [51120, 1164, 291, 1062, 362, 291, 727, 362, 257, 2445, 23384, 3866, 721, 293, 597, 341, 341, 51476], "temperature": 0.0, "avg_logprob": -0.0669119656085968, "compression_ratio": 1.7546296296296295, "no_speech_prob": 0.004110606852918863}, {"id": 142, "seek": 113338, "start": 1155.6200000000001, "end": 1160.0200000000002, "text": " approach could capture different points and at least my interpretation regarding why I'm doing", "tokens": [51476, 3109, 727, 7983, 819, 2793, 293, 412, 1935, 452, 14174, 8595, 983, 286, 478, 884, 51696], "temperature": 0.0, "avg_logprob": -0.0669119656085968, "compression_ratio": 1.7546296296296295, "no_speech_prob": 0.004110606852918863}, {"id": 143, "seek": 116002, "start": 1160.02, "end": 1167.22, "text": " this binding is because it allows it seemingly allowing you to inherit all the subtleties upstream", "tokens": [50364, 341, 17359, 307, 570, 309, 4045, 309, 18709, 8293, 291, 281, 21389, 439, 264, 7257, 2631, 530, 33915, 50724], "temperature": 0.0, "avg_logprob": -0.07455890075020168, "compression_ratio": 1.8240740740740742, "no_speech_prob": 0.008118432946503162}, {"id": 144, "seek": 116002, "start": 1167.22, "end": 1172.42, "text": " in terms of that but I might be a bit flaky in terms of that so as you can imagine there are", "tokens": [50724, 294, 2115, 295, 300, 457, 286, 1062, 312, 257, 857, 932, 15681, 294, 2115, 295, 300, 370, 382, 291, 393, 3811, 456, 366, 50984], "temperature": 0.0, "avg_logprob": -0.07455890075020168, "compression_ratio": 1.8240740740740742, "no_speech_prob": 0.008118432946503162}, {"id": 145, "seek": 116002, "start": 1172.42, "end": 1179.7, "text": " sort of lots of different forms and and and dealing with things and here's an example of a of one of", "tokens": [50984, 1333, 295, 3195, 295, 819, 6422, 293, 293, 293, 6260, 365, 721, 293, 510, 311, 364, 1365, 295, 257, 295, 472, 295, 51348], "temperature": 0.0, "avg_logprob": -0.07455890075020168, "compression_ratio": 1.8240740740740742, "no_speech_prob": 0.008118432946503162}, {"id": 146, "seek": 116002, "start": 1179.7, "end": 1188.98, "text": " the of the forms which would have the with a here classic regular expression style things in terms of", "tokens": [51348, 264, 295, 264, 6422, 597, 576, 362, 264, 365, 257, 510, 7230, 3890, 6114, 3758, 721, 294, 2115, 295, 51812], "temperature": 0.0, "avg_logprob": -0.07455890075020168, "compression_ratio": 1.8240740740740742, "no_speech_prob": 0.008118432946503162}, {"id": 147, "seek": 118898, "start": 1188.98, "end": 1195.78, "text": " repeating numbers and various points and so just to give an example of how I could sort of use these", "tokens": [50364, 18617, 3547, 293, 3683, 2793, 293, 370, 445, 281, 976, 364, 1365, 295, 577, 286, 727, 1333, 295, 764, 613, 50704], "temperature": 0.0, "avg_logprob": -0.06666257533621281, "compression_ratio": 1.5076923076923077, "no_speech_prob": 0.0026702347677201033}, {"id": 148, "seek": 118898, "start": 1195.78, "end": 1209.54, "text": " annotations for right sort of racing through things so here is an example of RQR which would be", "tokens": [50704, 25339, 763, 337, 558, 1333, 295, 12553, 807, 721, 370, 510, 307, 364, 1365, 295, 497, 48, 49, 597, 576, 312, 51392], "temperature": 0.0, "avg_logprob": -0.06666257533621281, "compression_ratio": 1.5076923076923077, "no_speech_prob": 0.0026702347677201033}, {"id": 149, "seek": 120954, "start": 1210.34, "end": 1220.58, "text": " a mechanism for just pulling up all of my to-dos and here you have yeah it's referencing the fact", "tokens": [50404, 257, 7513, 337, 445, 8407, 493, 439, 295, 452, 281, 12, 33749, 293, 510, 291, 362, 1338, 309, 311, 40582, 264, 1186, 50916], "temperature": 0.0, "avg_logprob": -0.18316401964352455, "compression_ratio": 1.6943231441048034, "no_speech_prob": 0.05309298262000084}, {"id": 150, "seek": 120954, "start": 1220.58, "end": 1225.22, "text": " that there are 202 different tasks and dealing with things and obviously this is just providing", "tokens": [50916, 300, 456, 366, 945, 17, 819, 9608, 293, 6260, 365, 721, 293, 2745, 341, 307, 445, 6530, 51148], "temperature": 0.0, "avg_logprob": -0.18316401964352455, "compression_ratio": 1.6943231441048034, "no_speech_prob": 0.05309298262000084}, {"id": 151, "seek": 120954, "start": 1225.22, "end": 1232.5, "text": " a document type a singular document but you could be for instance performing a search based upon", "tokens": [51148, 257, 4166, 2010, 257, 20010, 4166, 457, 291, 727, 312, 337, 5197, 10205, 257, 3164, 2361, 3564, 51512], "temperature": 0.0, "avg_logprob": -0.18316401964352455, "compression_ratio": 1.6943231441048034, "no_speech_prob": 0.05309298262000084}, {"id": 152, "seek": 120954, "start": 1232.5, "end": 1238.5, "text": " multiple documents or within the project which within this emacs operating environment means that", "tokens": [51512, 3866, 8512, 420, 1951, 264, 1716, 597, 1951, 341, 846, 44937, 7447, 2823, 1355, 300, 51812], "temperature": 0.0, "avg_logprob": -0.18316401964352455, "compression_ratio": 1.6943231441048034, "no_speech_prob": 0.05309298262000084}, {"id": 153, "seek": 123850, "start": 1239.46, "end": 1246.34, "text": " you're pretty much just limited by time and ambition so for instance you could", "tokens": [50412, 291, 434, 1238, 709, 445, 5567, 538, 565, 293, 22814, 370, 337, 5197, 291, 727, 50756], "temperature": 0.0, "avg_logprob": -0.21396660804748535, "compression_ratio": 1.463235294117647, "no_speech_prob": 0.004099361132830381}, {"id": 154, "seek": 123850, "start": 1249.46, "end": 1251.94, "text": " as you can see it's very terse", "tokens": [50912, 382, 291, 393, 536, 309, 311, 588, 1796, 405, 51036], "temperature": 0.0, "avg_logprob": -0.21396660804748535, "compression_ratio": 1.463235294117647, "no_speech_prob": 0.004099361132830381}, {"id": 155, "seek": 123850, "start": 1258.58, "end": 1266.26, "text": " and this is this is how this is for me quite significant in terms of flying by I I really", "tokens": [51368, 293, 341, 307, 341, 307, 577, 341, 307, 337, 385, 1596, 4776, 294, 2115, 295, 7137, 538, 286, 286, 534, 51752], "temperature": 0.0, "avg_logprob": -0.21396660804748535, "compression_ratio": 1.463235294117647, "no_speech_prob": 0.004099361132830381}, {"id": 156, "seek": 126626, "start": 1266.82, "end": 1273.06, "text": " really try and make sure that I have maximum flow and that I can switch from one mental state to", "tokens": [50392, 534, 853, 293, 652, 988, 300, 286, 362, 6674, 3095, 293, 300, 286, 393, 3679, 490, 472, 4973, 1785, 281, 50704], "temperature": 0.0, "avg_logprob": -0.08617115020751953, "compression_ratio": 1.8341232227488151, "no_speech_prob": 0.01500492263585329}, {"id": 157, "seek": 126626, "start": 1273.06, "end": 1280.74, "text": " another and and and handle multiple things without being overwhelmed and for instance the name that", "tokens": [50704, 1071, 293, 293, 293, 4813, 3866, 721, 1553, 885, 19042, 293, 337, 5197, 264, 1315, 300, 51088], "temperature": 0.0, "avg_logprob": -0.08617115020751953, "compression_ratio": 1.8341232227488151, "no_speech_prob": 0.01500492263585329}, {"id": 158, "seek": 126626, "start": 1280.74, "end": 1287.3799999999999, "text": " the fact that the documents and the and the directories have to have named in terms of that", "tokens": [51088, 264, 1186, 300, 264, 8512, 293, 264, 293, 264, 5391, 530, 362, 281, 362, 4926, 294, 2115, 295, 300, 51420], "temperature": 0.0, "avg_logprob": -0.08617115020751953, "compression_ratio": 1.8341232227488151, "no_speech_prob": 0.01500492263585329}, {"id": 159, "seek": 126626, "start": 1287.3799999999999, "end": 1291.94, "text": " means that it makes it easier for instance jumping for a different file so for instance if I press", "tokens": [51420, 1355, 300, 309, 1669, 309, 3571, 337, 5197, 11233, 337, 257, 819, 3991, 370, 337, 5197, 498, 286, 1886, 51648], "temperature": 0.0, "avg_logprob": -0.08617115020751953, "compression_ratio": 1.8341232227488151, "no_speech_prob": 0.01500492263585329}, {"id": 160, "seek": 129194, "start": 1292.66, "end": 1296.5800000000002, "text": " ctrl x and b in emacs then there's a range of", "tokens": [50400, 269, 28269, 2031, 293, 272, 294, 846, 44937, 550, 456, 311, 257, 3613, 295, 50596], "temperature": 0.0, "avg_logprob": -0.11550549098423549, "compression_ratio": 1.6978021978021978, "no_speech_prob": 0.00873127393424511}, {"id": 161, "seek": 129194, "start": 1300.66, "end": 1307.94, "text": " point so if just pressing mqm here for instance has given me a list of different", "tokens": [50800, 935, 370, 498, 445, 12417, 275, 80, 76, 510, 337, 5197, 575, 2212, 385, 257, 1329, 295, 819, 51164], "temperature": 0.0, "avg_logprob": -0.11550549098423549, "compression_ratio": 1.6978021978021978, "no_speech_prob": 0.00873127393424511}, {"id": 162, "seek": 129194, "start": 1307.94, "end": 1315.14, "text": " buffers and and the names in terms of that so it I can really sort of come up with", "tokens": [51164, 9204, 433, 293, 293, 264, 5288, 294, 2115, 295, 300, 370, 309, 286, 393, 534, 1333, 295, 808, 493, 365, 51524], "temperature": 0.0, "avg_logprob": -0.11550549098423549, "compression_ratio": 1.6978021978021978, "no_speech_prob": 0.00873127393424511}, {"id": 163, "seek": 129194, "start": 1315.7, "end": 1321.46, "text": " buttons and hotkeys and actions and to deal with that so for instance here's just a way in in terms", "tokens": [51552, 9905, 293, 2368, 18847, 293, 5909, 293, 281, 2028, 365, 300, 370, 337, 5197, 510, 311, 445, 257, 636, 294, 294, 2115, 51840], "temperature": 0.0, "avg_logprob": -0.11550549098423549, "compression_ratio": 1.6978021978021978, "no_speech_prob": 0.00873127393424511}, {"id": 164, "seek": 132146, "start": 1321.46, "end": 1328.02, "text": " of the reuse of these annotations can come can be dealt with so for instance at the top we have", "tokens": [50364, 295, 264, 26225, 295, 613, 25339, 763, 393, 808, 393, 312, 15991, 365, 370, 337, 5197, 412, 264, 1192, 321, 362, 50692], "temperature": 0.0, "avg_logprob": -0.09112715721130371, "compression_ratio": 1.6877828054298643, "no_speech_prob": 0.004078712314367294}, {"id": 165, "seek": 132146, "start": 1328.02, "end": 1336.82, "text": " svge tag mode which is an third party emacs library which allows you to turn various points", "tokens": [50692, 17342, 432, 6162, 4391, 597, 307, 364, 2636, 3595, 846, 44937, 6405, 597, 4045, 291, 281, 1261, 3683, 2793, 51132], "temperature": 0.0, "avg_logprob": -0.09112715721130371, "compression_ratio": 1.6877828054298643, "no_speech_prob": 0.004078712314367294}, {"id": 166, "seek": 132146, "start": 1338.98, "end": 1345.14, "text": " in terms of these black and white boxes are the annotations I would like to say improved", "tokens": [51240, 294, 2115, 295, 613, 2211, 293, 2418, 9002, 366, 264, 25339, 763, 286, 576, 411, 281, 584, 9689, 51548], "temperature": 0.0, "avg_logprob": -0.09112715721130371, "compression_ratio": 1.6877828054298643, "no_speech_prob": 0.004078712314367294}, {"id": 167, "seek": 132146, "start": 1345.14, "end": 1350.82, "text": " or visualized but you can also add other things in terms of that I've talked in other activities", "tokens": [51548, 420, 5056, 1602, 457, 291, 393, 611, 909, 661, 721, 294, 2115, 295, 300, 286, 600, 2825, 294, 661, 5354, 51832], "temperature": 0.0, "avg_logprob": -0.09112715721130371, "compression_ratio": 1.6877828054298643, "no_speech_prob": 0.004078712314367294}, {"id": 168, "seek": 135082, "start": 1350.82, "end": 1360.1, "text": " regarding the the use of hyper hyper hyperbole the in terms of navigation and", "tokens": [50364, 8595, 264, 264, 764, 295, 9848, 9848, 9848, 1763, 306, 264, 294, 2115, 295, 17346, 293, 50828], "temperature": 0.0, "avg_logprob": -0.13631328459708922, "compression_ratio": 1.6325301204819278, "no_speech_prob": 0.005973478779196739}, {"id": 169, "seek": 135082, "start": 1362.5, "end": 1368.1799999999998, "text": " and points in terms of that so this time I thought I'd just look at one of the latest features from", "tokens": [50948, 293, 2793, 294, 2115, 295, 300, 370, 341, 565, 286, 1194, 286, 1116, 445, 574, 412, 472, 295, 264, 6792, 4122, 490, 51232], "temperature": 0.0, "avg_logprob": -0.13631328459708922, "compression_ratio": 1.6325301204819278, "no_speech_prob": 0.005973478779196739}, {"id": 170, "seek": 135082, "start": 1368.1799999999998, "end": 1374.82, "text": " number eight version eight which is defil which provides more a regular expression based form", "tokens": [51232, 1230, 3180, 3037, 3180, 597, 307, 1060, 388, 597, 6417, 544, 257, 3890, 6114, 2361, 1254, 51564], "temperature": 0.0, "avg_logprob": -0.13631328459708922, "compression_ratio": 1.6325301204819278, "no_speech_prob": 0.005973478779196739}, {"id": 171, "seek": 137482, "start": 1374.82, "end": 1382.1799999999998, "text": " in terms of that so this form would be the defining of the function the name of this function the", "tokens": [50364, 294, 2115, 295, 300, 370, 341, 1254, 576, 312, 264, 17827, 295, 264, 2445, 264, 1315, 295, 341, 2445, 264, 50732], "temperature": 0.0, "avg_logprob": -0.06619951801915322, "compression_ratio": 1.912162162162162, "no_speech_prob": 0.09221279621124268}, {"id": 172, "seek": 137482, "start": 1382.98, "end": 1392.6599999999999, "text": " the opening context the middle context at the ending context as well as the middle context", "tokens": [50772, 264, 5193, 4319, 264, 2808, 4319, 412, 264, 8121, 4319, 382, 731, 382, 264, 2808, 4319, 51256], "temperature": 0.0, "avg_logprob": -0.06619951801915322, "compression_ratio": 1.912162162162162, "no_speech_prob": 0.09221279621124268}, {"id": 173, "seek": 137482, "start": 1392.6599999999999, "end": 1398.02, "text": " as well as what you're meant to do based upon that within these within these curly parentheses", "tokens": [51256, 382, 731, 382, 437, 291, 434, 4140, 281, 360, 2361, 3564, 300, 1951, 613, 1951, 613, 32066, 34153, 51524], "temperature": 0.0, "avg_logprob": -0.06619951801915322, "compression_ratio": 1.912162162162162, "no_speech_prob": 0.09221279621124268}, {"id": 174, "seek": 139802, "start": 1398.26, "end": 1405.86, "text": " so what I've what I what is what is the conjecture in terms of this one is the fact that", "tokens": [50376, 370, 437, 286, 600, 437, 286, 437, 307, 437, 307, 264, 416, 1020, 540, 294, 2115, 295, 341, 472, 307, 264, 1186, 300, 50756], "temperature": 0.0, "avg_logprob": -0.10362463384061246, "compression_ratio": 1.7248677248677249, "no_speech_prob": 0.03762732073664665}, {"id": 175, "seek": 139802, "start": 1405.86, "end": 1408.82, "text": " within a specific annotation you could be having", "tokens": [50756, 1951, 257, 2685, 48654, 291, 727, 312, 1419, 50904], "temperature": 0.0, "avg_logprob": -0.10362463384061246, "compression_ratio": 1.7248677248677249, "no_speech_prob": 0.03762732073664665}, {"id": 176, "seek": 139802, "start": 1411.78, "end": 1417.94, "text": " different actions based upon where the cursor is within the annotation let alone the potential in", "tokens": [51052, 819, 5909, 2361, 3564, 689, 264, 28169, 307, 1951, 264, 48654, 718, 3312, 264, 3995, 294, 51360], "temperature": 0.0, "avg_logprob": -0.10362463384061246, "compression_ratio": 1.7248677248677249, "no_speech_prob": 0.03762732073664665}, {"id": 177, "seek": 139802, "start": 1417.94, "end": 1424.66, "text": " terms of any perspective before or afterwards and this is quite deep because of the use of", "tokens": [51360, 2115, 295, 604, 4585, 949, 420, 10543, 293, 341, 307, 1596, 2452, 570, 295, 264, 764, 295, 51696], "temperature": 0.0, "avg_logprob": -0.10362463384061246, "compression_ratio": 1.7248677248677249, "no_speech_prob": 0.03762732073664665}, {"id": 178, "seek": 142466, "start": 1424.66, "end": 1429.78, "text": " repeativeness and various forms that you could form very complex workflows not necessarily from", "tokens": [50364, 7149, 8477, 293, 3683, 6422, 300, 291, 727, 1254, 588, 3997, 43461, 406, 4725, 490, 50620], "temperature": 0.0, "avg_logprob": -0.12018189891692131, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.013093266636133194}, {"id": 179, "seek": 142466, "start": 1430.66, "end": 1440.8200000000002, "text": " key bindings pulling out the the the the things and and the or the use of classic my", "tokens": [50664, 2141, 14786, 1109, 8407, 484, 264, 264, 264, 264, 721, 293, 293, 264, 420, 264, 764, 295, 7230, 452, 51172], "temperature": 0.0, "avg_logprob": -0.12018189891692131, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.013093266636133194}, {"id": 180, "seek": 142466, "start": 1441.94, "end": 1449.78, "text": " menus but in fact you could use the the cursor within or relative to a one of these annotations", "tokens": [51228, 30347, 457, 294, 1186, 291, 727, 764, 264, 264, 28169, 1951, 420, 4972, 281, 257, 472, 295, 613, 25339, 763, 51620], "temperature": 0.0, "avg_logprob": -0.12018189891692131, "compression_ratio": 1.6727272727272726, "no_speech_prob": 0.013093266636133194}, {"id": 181, "seek": 144978, "start": 1449.86, "end": 1454.58, "text": " and that forms the the action which could get very fast in terms of just pushing about it", "tokens": [50368, 293, 300, 6422, 264, 264, 3069, 597, 727, 483, 588, 2370, 294, 2115, 295, 445, 7380, 466, 309, 50604], "temperature": 0.0, "avg_logprob": -0.09314783917197698, "compression_ratio": 1.7704081632653061, "no_speech_prob": 0.0038521538954228163}, {"id": 182, "seek": 144978, "start": 1455.3799999999999, "end": 1460.58, "text": " having a dedicated action in in terms of the styles dedicated action button for dealing with", "tokens": [50644, 1419, 257, 8374, 3069, 294, 294, 2115, 295, 264, 13273, 8374, 3069, 2960, 337, 6260, 365, 50904], "temperature": 0.0, "avg_logprob": -0.09314783917197698, "compression_ratio": 1.7704081632653061, "no_speech_prob": 0.0038521538954228163}, {"id": 183, "seek": 144978, "start": 1460.58, "end": 1464.74, "text": " things and so the the menu would in effect be the cursor related to the", "tokens": [50904, 721, 293, 370, 264, 264, 6510, 576, 294, 1802, 312, 264, 28169, 4077, 281, 264, 51112], "temperature": 0.0, "avg_logprob": -0.09314783917197698, "compression_ratio": 1.7704081632653061, "no_speech_prob": 0.0038521538954228163}, {"id": 184, "seek": 144978, "start": 1468.8999999999999, "end": 1474.98, "text": " and here's a high roll of format which is within the hyperbole suite which looks into things", "tokens": [51320, 293, 510, 311, 257, 1090, 3373, 295, 7877, 597, 307, 1951, 264, 9848, 1763, 306, 14205, 597, 1542, 666, 721, 51624], "temperature": 0.0, "avg_logprob": -0.09314783917197698, "compression_ratio": 1.7704081632653061, "no_speech_prob": 0.0038521538954228163}, {"id": 185, "seek": 147498, "start": 1475.94, "end": 1482.1, "text": " and that's very interesting which I'll be looking into more so for instance an action could be to", "tokens": [50412, 293, 300, 311, 588, 1880, 597, 286, 603, 312, 1237, 666, 544, 370, 337, 5197, 364, 3069, 727, 312, 281, 50720], "temperature": 0.0, "avg_logprob": -0.08257928620214047, "compression_ratio": 1.8285714285714285, "no_speech_prob": 0.032168205827474594}, {"id": 186, "seek": 147498, "start": 1483.54, "end": 1489.54, "text": " go to a subset of this for instance this is an example of the section shells which has the", "tokens": [50792, 352, 281, 257, 25993, 295, 341, 337, 5197, 341, 307, 364, 1365, 295, 264, 3541, 22523, 597, 575, 264, 51092], "temperature": 0.0, "avg_logprob": -0.08257928620214047, "compression_ratio": 1.8285714285714285, "no_speech_prob": 0.032168205827474594}, {"id": 187, "seek": 147498, "start": 1489.54, "end": 1493.94, "text": " subsection and I haven't really I don't really have the time to go into this further but there's a", "tokens": [51092, 1422, 11963, 293, 286, 2378, 380, 534, 286, 500, 380, 534, 362, 264, 565, 281, 352, 666, 341, 3052, 457, 456, 311, 257, 51312], "temperature": 0.0, "avg_logprob": -0.08257928620214047, "compression_ratio": 1.8285714285714285, "no_speech_prob": 0.032168205827474594}, {"id": 188, "seek": 147498, "start": 1493.94, "end": 1504.66, "text": " recent emacs conference where this is one of the main talking points here is a here is a product", "tokens": [51312, 5162, 846, 44937, 7586, 689, 341, 307, 472, 295, 264, 2135, 1417, 2793, 510, 307, 257, 510, 307, 257, 1674, 51848], "temperature": 0.0, "avg_logprob": -0.08257928620214047, "compression_ratio": 1.8285714285714285, "no_speech_prob": 0.032168205827474594}, {"id": 189, "seek": 150466, "start": 1504.66, "end": 1512.1000000000001, "text": " of a script which I think is about 50 gigabytes or might be maybe this is a 20 50 or 20 megabytes", "tokens": [50364, 295, 257, 5755, 597, 286, 519, 307, 466, 2625, 42741, 420, 1062, 312, 1310, 341, 307, 257, 945, 2625, 420, 945, 10816, 24538, 50736], "temperature": 0.0, "avg_logprob": -0.1328168445163303, "compression_ratio": 1.641025641025641, "no_speech_prob": 0.006260531023144722}, {"id": 190, "seek": 150466, "start": 1512.8200000000002, "end": 1521.46, "text": " which is an effect a rip grip through various points and and and and and dealing with the", "tokens": [50772, 597, 307, 364, 1802, 257, 12782, 12007, 807, 3683, 2793, 293, 293, 293, 293, 293, 6260, 365, 264, 51204], "temperature": 0.0, "avg_logprob": -0.1328168445163303, "compression_ratio": 1.641025641025641, "no_speech_prob": 0.006260531023144722}, {"id": 191, "seek": 150466, "start": 1522.66, "end": 1527.3000000000002, "text": " this this is a and trying to isolate various various things so let's", "tokens": [51264, 341, 341, 307, 257, 293, 1382, 281, 25660, 3683, 3683, 721, 370, 718, 311, 51496], "temperature": 0.0, "avg_logprob": -0.1328168445163303, "compression_ratio": 1.641025641025641, "no_speech_prob": 0.006260531023144722}, {"id": 192, "seek": 152730, "start": 1528.26, "end": 1536.74, "text": " so let's just highlight some colors quickly we'll just do that let's see pink yeah", "tokens": [50412, 370, 718, 311, 445, 5078, 512, 4577, 2661, 321, 603, 445, 360, 300, 718, 311, 536, 7022, 1338, 50836], "temperature": 0.0, "avg_logprob": -0.13760526718631869, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.014701791107654572}, {"id": 193, "seek": 152730, "start": 1538.26, "end": 1544.4199999999998, "text": " well that's probably slowing it down but whatever but in effect it's classic rip grip answers", "tokens": [50912, 731, 300, 311, 1391, 26958, 309, 760, 457, 2035, 457, 294, 1802, 309, 311, 7230, 12782, 12007, 6338, 51220], "temperature": 0.0, "avg_logprob": -0.13760526718631869, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.014701791107654572}, {"id": 194, "seek": 152730, "start": 1545.78, "end": 1551.3799999999999, "text": " which document which line which character what was dealt with in here I'm just running through the", "tokens": [51288, 597, 4166, 597, 1622, 597, 2517, 437, 390, 15991, 365, 294, 510, 286, 478, 445, 2614, 807, 264, 51568], "temperature": 0.0, "avg_logprob": -0.13760526718631869, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.014701791107654572}, {"id": 195, "seek": 155138, "start": 1551.38, "end": 1556.5, "text": " entire system the entire file system to find the annotations pertinent", "tokens": [50364, 2302, 1185, 264, 2302, 3991, 1185, 281, 915, 264, 25339, 763, 13269, 11058, 50620], "temperature": 0.0, "avg_logprob": -0.18758088520595007, "compression_ratio": 1.3814432989690721, "no_speech_prob": 0.011326620355248451}, {"id": 196, "seek": 155138, "start": 1558.5800000000002, "end": 1566.98, "text": " ah but yeah there we go so um but we'll use swiper to reinforce", "tokens": [50724, 3716, 457, 1338, 456, 321, 352, 370, 1105, 457, 321, 603, 764, 1693, 15402, 281, 22634, 51144], "temperature": 0.0, "avg_logprob": -0.18758088520595007, "compression_ratio": 1.3814432989690721, "no_speech_prob": 0.011326620355248451}, {"id": 197, "seek": 156698, "start": 1567.94, "end": 1585.38, "text": " so this will ah this will have the aggregate of it's got it does have duplicates at least how", "tokens": [50412, 370, 341, 486, 3716, 341, 486, 362, 264, 26118, 295, 309, 311, 658, 309, 775, 362, 17154, 1024, 412, 1935, 577, 51284], "temperature": 0.0, "avg_logprob": -0.1627444326877594, "compression_ratio": 1.5116279069767442, "no_speech_prob": 0.008314821869134903}, {"id": 198, "seek": 156698, "start": 1585.38, "end": 1594.66, "text": " this was set up but that's fine because the outputs dealing with the orderly fashion in terms of that", "tokens": [51284, 341, 390, 992, 493, 457, 300, 311, 2489, 570, 264, 23930, 6260, 365, 264, 1668, 356, 6700, 294, 2115, 295, 300, 51748], "temperature": 0.0, "avg_logprob": -0.1627444326877594, "compression_ratio": 1.5116279069767442, "no_speech_prob": 0.008314821869134903}, {"id": 199, "seek": 159466, "start": 1594.66, "end": 1601.38, "text": " so ascertain is it come on", "tokens": [50364, 370, 15526, 1408, 307, 309, 808, 322, 50700], "temperature": 0.0, "avg_logprob": -0.18528636585582386, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.0008967045578174293}, {"id": 200, "seek": 159466, "start": 1603.94, "end": 1610.42, "text": " sorry the uh I think my computer's a bit overwhelmed it's humming a bit but there must be", "tokens": [50828, 2597, 264, 2232, 286, 519, 452, 3820, 311, 257, 857, 19042, 309, 311, 34965, 257, 857, 457, 456, 1633, 312, 51152], "temperature": 0.0, "avg_logprob": -0.18528636585582386, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.0008967045578174293}, {"id": 201, "seek": 159466, "start": 1610.42, "end": 1616.74, "text": " some background thing yes so here we go so we've got ascertaining ascertain whether in correct location", "tokens": [51152, 512, 3678, 551, 2086, 370, 510, 321, 352, 370, 321, 600, 658, 15526, 1408, 278, 15526, 1408, 1968, 294, 3006, 4914, 51468], "temperature": 0.0, "avg_logprob": -0.18528636585582386, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.0008967045578174293}, {"id": 202, "seek": 162466, "start": 1625.14, "end": 1630.5800000000002, "text": " that ascertain wherever useful nothing links to it and as you can I I do have", "tokens": [50388, 300, 15526, 1408, 8660, 4420, 1825, 6123, 281, 309, 293, 382, 291, 393, 286, 286, 360, 362, 50660], "temperature": 0.0, "avg_logprob": -0.13438884019851685, "compression_ratio": 1.6341463414634145, "no_speech_prob": 0.016866644844412804}, {"id": 203, "seek": 162466, "start": 1632.18, "end": 1639.5400000000002, "text": " I do have tooling which sort of deals of this from the point of a specific script and I've", "tokens": [50740, 286, 360, 362, 46593, 597, 1333, 295, 11215, 295, 341, 490, 264, 935, 295, 257, 2685, 5755, 293, 286, 600, 51108], "temperature": 0.0, "avg_logprob": -0.13438884019851685, "compression_ratio": 1.6341463414634145, "no_speech_prob": 0.016866644844412804}, {"id": 204, "seek": 162466, "start": 1639.5400000000002, "end": 1646.66, "text": " I've worked out a way to in effect inject the annotations based upon hashing of content", "tokens": [51108, 286, 600, 2732, 484, 257, 636, 281, 294, 1802, 10711, 264, 25339, 763, 2361, 3564, 575, 571, 295, 2701, 51464], "temperature": 0.0, "avg_logprob": -0.13438884019851685, "compression_ratio": 1.6341463414634145, "no_speech_prob": 0.016866644844412804}, {"id": 205, "seek": 162466, "start": 1646.66, "end": 1652.26, "text": " I've also been developing the hash trees forming with regards to the documents", "tokens": [51464, 286, 600, 611, 668, 6416, 264, 22019, 5852, 15745, 365, 14258, 281, 264, 8512, 51744], "temperature": 0.0, "avg_logprob": -0.13438884019851685, "compression_ratio": 1.6341463414634145, "no_speech_prob": 0.016866644844412804}, {"id": 206, "seek": 165226, "start": 1653.14, "end": 1661.06, "text": " but yes um I hope this is of interest and yeah there's there's lots of interesting", "tokens": [50408, 457, 2086, 1105, 286, 1454, 341, 307, 295, 1179, 293, 1338, 456, 311, 456, 311, 3195, 295, 1880, 50804], "temperature": 0.0, "avg_logprob": -0.16624079252544202, "compression_ratio": 1.5534591194968554, "no_speech_prob": 0.010436950251460075}, {"id": 207, "seek": 165226, "start": 1661.06, "end": 1666.34, "text": " things with regards to icebreaker and I guess it would be best to visit the", "tokens": [50804, 721, 365, 14258, 281, 4435, 43847, 293, 286, 2041, 309, 576, 312, 1151, 281, 3441, 264, 51068], "temperature": 0.0, "avg_logprob": -0.16624079252544202, "compression_ratio": 1.5534591194968554, "no_speech_prob": 0.010436950251460075}, {"id": 208, "seek": 165226, "start": 1667.06, "end": 1672.9, "text": " fostering page for this talk for some more supplementary information thank you very much", "tokens": [51104, 17114, 278, 3028, 337, 341, 751, 337, 512, 544, 15436, 822, 1589, 1309, 291, 588, 709, 51396], "temperature": 0.0, "avg_logprob": -0.16624079252544202, "compression_ratio": 1.5534591194968554, "no_speech_prob": 0.010436950251460075}, {"id": 209, "seek": 168226, "start": 1682.26, "end": 1683.64, "text": " you", "tokens": [50404, 291, 50433], "temperature": 0.0, "avg_logprob": -0.7712122201919556, "compression_ratio": 0.2727272727272727, "no_speech_prob": 0.3556928038597107}], "language": "en"}