{"text": " So, the next presentation is a NIM mixed net from Yoon Hockblatt. So, welcome. Yeah, thank you very much. Right. It's great to be here. And the presentation all seems to be working. Right, so I'll talk about NIM. The title is Intro to a New Anonymous Communication Network. There's quite a lot of overlap in the previous presentation about the concepts involved. And who am I? My name is Yoon Hockblatt, or sometimes I go by John for simplicity. I'm a Swedish developer. I spend my days writing rusts, back-end type of things. I do C++ and scientific computing in a previous life. Yeah, living Stockholm. Yeah, that's me. Right, so the NIM mixed net. What's the NIM mixed net? So, basics. I mean, this is obviously free software. The source code is available on GitHub over there. It's Apache licensed. It's mostly written in Rust. All the back-end stuff is written in Rust. Some of the front-end things is TypeScript. This was in the past. This has been funded by some EU projects. And currently, there is a Switzerland-based startup with us, the majority of the development. But yeah, it's an open project. And of course, we welcome public contributions. And yeah, it's quite deeply rooted in university as well, in university research. We have some, you know, work-loss researchers associated with the project. So, you know, the concepts aren't things that we sort of, you know, came up ourselves. This is, you know, state-of-the-art research. Right, so what is the problem that we're trying to solve? You know, we had the usual suspects, the, you know, government surveillance and surveillance capitalism. And, you know, if these four, which of these two is a problem, you know, very much depends on where in the world you are. In some parts of the world, these things aren't that big of a concern. For other people, this is serious matter. This is, you know, of grave concern to some people, depending on who you are and where you live. And what is the aspect that we try to tackle here? Because there's a lot of privacy platforms that sort of, to sort of, to try to attack this challenge from different perspectives. The NMEXnet is a network layer, or it's a transport layer thing. And the main challenge to be focused on is that it has become clear in the sort of the last ten years that there's now so much surveillance going on, and there are some entities that collect so much data on a global scale that they almost get some sort of like a god-sized view of the network. They can monitor the network on a planet scale, and they can do, they can correlate, they can correlate using leaked metadata, your transmission patterns, your packet sizes, timings. They can do end-to-end correlations, even though like your data is sent entirely encrypted the whole way, or obfuscated, but still, if you can sort of monitor like all endpoints, you can sort of still draw conclusions, you can identify who talks to who. And you know, as we know, who talks to who is sometimes more important than what they say from a sort of surveillance perspective. So that's the sort of the angle, the challenge that we try to talk about this. And so now I'm sort of taking a step back here, so I'm referring to the NIM platform, which is, then I use this quote here, a decentralized, incentivized mixed-net plus prior credentials. And sort of, yeah, my talk here will be to try to unpack what all of this means, and we're going to start then with what I think is sort of the core part is the mixed-net, the word in the middle there. I think if you use something like Tor as a starting point, that's sort of a very good first step to understand what it is. And just like Tor and just like the previous talk, it's an overlay network, in the same way as I2P uses onion routing, where all packets are wrapped in layers of encryption to sort of hide the fact, to hide the end destination of each packet. It's based on the Loupix design, if you know a little bit about mixed-nets, you've probably heard about Loupix. I put in a few citations here at the bottom, if you want to read a bit more about these things. It uses Sphinx packets, so that the idea is that all packets are wrapped into these identically looking and identically behaving packets, to sort of to hide some sizes and timings. And also, each packet as it moves through, because mixed-net is, I mean, okay, so something I forgot to mention, mixed-net is very much what it sounds. It's data, you send through data, multiple hops, you mix data as much as you can, through a cloud of nodes. At each node, I'm going to have some pictures on the next slide to illustrate it better. But yeah, on each hop in the network, you add things like random timings, which affect the reorders traffic, you add cover traffic, which cover traffic can appear in many ways, either between nodes, but also, for example, if you use a client to connect to network, to transmit data, you emit Sphinx packets at a steady average rate, so it's not a steady rate, but it's probabilistic how you send the packets. But you send the steady stream of packets, either fake or real ones, so when you have real data to send, you just fill up the packet stream, the packets they send out, fill up with real data. So from the outside, you can't tell when you're actually sending, when you're bursting data. You attach SERBs, so single-use reply blocks in your packets, so that when you, if you make a request across the network to get something back, you attach these headers, these metadata, so that the response can be layer encrypted and sent back, so that on the other side, the server doesn't know where the destination is, so you hide your identity, but you still allow the other side to reply back to you. It's a picture, the first step, the first one there, ordinary VPN, and a VPN doesn't give you any anonymity, it just moves trust, so the guy in the middle there, you can still see where data is coming from, where it is going. The second one, you have things like Tor, where you have these nodes in the middle, where you open up a circuit through the swarm of nodes, and you pump data through. And here you have mixed-net setup, where in each packet is mixed individually, so you don't open up a circuit, like Tor, for example, you send up, each packet is sent as an individual pass-through. And the idea here, the crucial thing is that on the other side, you see these packets there, they are now, they're colored white now instead of red, and they're the same size, and you shouldn't be able to tell, you can't tell, you can't correlate the data on the other side compared to on the sender side, which you can in many other systems, because you can't correlate transmission patterns, timing sizes. So even if you can monitor all the data, all the exit data from this mixed-net cloud, you still can't correlate who talks to who. That's sort of the key thing here. And yeah, so if we go back then to this quote, so decentralized, incentivized mixed-net plus price credentials, what we mean by incentivized, we mean that the network directory, which keeps track of all the mixed-nodes and gateways are a bit like exit nodes in Tor, they are constantly being monitored. So the network directory is effectively a set of validators running a consensus protocol, and they keep track of all the mixed-nodes, how well they mix traffic, how well they contribute capacity to network, giving them limbs for it, which in turn can be turned around and used to acquire bandwidth credentials, coconut credentials, it's the academic term. And the idea is that we also, because this is always a problem when you have something like this, with volunteers you only get so far, anonymity or privacy, it loves company, you want to disappear in the crowd, so you want to encourage people to provide capacity to the network at the same time as they're using it, that's the idea. Because otherwise it becomes difficult to scale up above a sort of base level. But if you want to make this available for the broader public, you need more capacity. And this is a way that we hope we can achieve this. And these private credentials, the idea is that you break the linkability between your identity and your right to use the service. And there's a very deep topic on its own, there's a citation, there are some cryptographic buzzwords here, as well as that are re-randomizable, means that if you use the same bandwidth credential multiple times, it's indistinguishable from multiple people using different credentials from the person redeeming these. But yeah, the idea is you want to break the link between your identity and your right to use something. And yeah, okay, so the first word there, decentralized, it's not too much to add there, we have a running network, it's 500 mix-nodes currently, and yeah, the vision is that this becomes self-running, it shouldn't have an antifragile funding model, we don't want it to be reliant on a specific company or some funding body or donations or anything, we want this to have robust, robustly running on its own, run by the community entirely, long-term, that's sort of the vision here. Even though currently we have a startup that sort of does the most of the development, in long-term we should be able to hand this off as sort of the idea. There's a picture, so this is all running currently, this thing that is currently sort of in deployment or sort of being rolled out or these credentials currently is free to use the main network, we have all these clients, there's SoxFi clients, there's Awasom clients, there's a native running client exposing a web socket, the mix-nodes up there, when you use a user you connect to the gateway, which is like entry and exit nodes for a tour, you mix the traffic, you exit on the gateway, you can have service providers, there's the set of validators keeping track of all the nodes in the system. Yeah, there's a lot to take in here, probably a lot of details there, I'm not sure it's all visible towards the end, but yeah, that's pretty much it. Thank you for your time. Yeah, thank you a lot for a nice talk. Yeah, thank you for listening, and I think that we have some time, so theoretically we could spend it asking a question at least for two minutes here and then after it we can discuss it outside. Hi, can you imagine the NIM framework also to be integrated into another proof-of-stake-based cryptocurrency as a back-end in the future maybe? What did he say first? Can you imagine that the main part of the NIM framework like the mix-nodes and everything around it can also be attached to an existing proof-of-stake-based other cryptocurrency that is not currently part of your ecosystem? Well, a big use case of this is that this is sort of on the network layer, so that means it's a big use case. You have all these other private systems where in this crypto space where they have these privacy-preserving services, but they still leak metadata at the bottom layer. They still leak metadata when you use broadcast transactions and things like this. So I think to integrate this in other systems in this space, then it will be in that layer, sort of the transport layer. So yes, there's a lot of potential for integrating with other privacy platforms, I think. In general, there are a lot of privacy platforms, and I think what we need is a robust ecosystem. There is no single solution that solves all our problems. We need a robust ecosystem for different solutions for different types of problems or different categories of problems. I mean, I don't see this as a competitor to other systems. It's more of a complement to each other. For example, when you add random delays, for example, that of course means you sort of compromise, you give up a bit of latency, which works very well for asynchronous communication, but might not work so well for other categories of applications. So I think something like this is also the complement store. It doesn't replace the store. It sort of complements it. Yeah. Okay. Thank you again, Yun. If there's any more questions, just grab me afterwards. Just go there and ask questions.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 12.0, "text": " So, the next presentation is a NIM mixed net from Yoon Hockblatt.", "tokens": [407, 11, 264, 958, 5860, 307, 257, 426, 6324, 7467, 2533, 490, 27893, 389, 1560, 5199, 1591, 13], "temperature": 0.0, "avg_logprob": -0.3960671620826199, "compression_ratio": 1.367741935483871, "no_speech_prob": 0.2954624593257904}, {"id": 1, "seek": 0, "start": 12.0, "end": 14.0, "text": " So, welcome.", "tokens": [407, 11, 2928, 13], "temperature": 0.0, "avg_logprob": -0.3960671620826199, "compression_ratio": 1.367741935483871, "no_speech_prob": 0.2954624593257904}, {"id": 2, "seek": 0, "start": 14.0, "end": 16.0, "text": " Yeah, thank you very much.", "tokens": [865, 11, 1309, 291, 588, 709, 13], "temperature": 0.0, "avg_logprob": -0.3960671620826199, "compression_ratio": 1.367741935483871, "no_speech_prob": 0.2954624593257904}, {"id": 3, "seek": 0, "start": 16.0, "end": 18.0, "text": " Right.", "tokens": [1779, 13], "temperature": 0.0, "avg_logprob": -0.3960671620826199, "compression_ratio": 1.367741935483871, "no_speech_prob": 0.2954624593257904}, {"id": 4, "seek": 0, "start": 18.0, "end": 20.0, "text": " It's great to be here.", "tokens": [467, 311, 869, 281, 312, 510, 13], "temperature": 0.0, "avg_logprob": -0.3960671620826199, "compression_ratio": 1.367741935483871, "no_speech_prob": 0.2954624593257904}, {"id": 5, "seek": 0, "start": 20.0, "end": 23.0, "text": " And the presentation all seems to be working.", "tokens": [400, 264, 5860, 439, 2544, 281, 312, 1364, 13], "temperature": 0.0, "avg_logprob": -0.3960671620826199, "compression_ratio": 1.367741935483871, "no_speech_prob": 0.2954624593257904}, {"id": 6, "seek": 0, "start": 23.0, "end": 27.0, "text": " Right, so I'll talk about NIM.", "tokens": [1779, 11, 370, 286, 603, 751, 466, 426, 6324, 13], "temperature": 0.0, "avg_logprob": -0.3960671620826199, "compression_ratio": 1.367741935483871, "no_speech_prob": 0.2954624593257904}, {"id": 7, "seek": 2700, "start": 27.0, "end": 33.0, "text": " The title is Intro to a New Anonymous Communication Network.", "tokens": [440, 4876, 307, 47406, 281, 257, 1873, 1107, 18092, 34930, 12640, 13], "temperature": 0.0, "avg_logprob": -0.24334441783816316, "compression_ratio": 1.4035874439461884, "no_speech_prob": 0.0006416608230210841}, {"id": 8, "seek": 2700, "start": 33.0, "end": 39.0, "text": " There's quite a lot of overlap in the previous presentation about the concepts involved.", "tokens": [821, 311, 1596, 257, 688, 295, 19959, 294, 264, 3894, 5860, 466, 264, 10392, 3288, 13], "temperature": 0.0, "avg_logprob": -0.24334441783816316, "compression_ratio": 1.4035874439461884, "no_speech_prob": 0.0006416608230210841}, {"id": 9, "seek": 2700, "start": 39.0, "end": 42.0, "text": " And who am I?", "tokens": [400, 567, 669, 286, 30], "temperature": 0.0, "avg_logprob": -0.24334441783816316, "compression_ratio": 1.4035874439461884, "no_speech_prob": 0.0006416608230210841}, {"id": 10, "seek": 2700, "start": 42.0, "end": 47.0, "text": " My name is Yoon Hockblatt, or sometimes I go by John for simplicity.", "tokens": [1222, 1315, 307, 27893, 389, 1560, 5199, 1591, 11, 420, 2171, 286, 352, 538, 2619, 337, 25632, 13], "temperature": 0.0, "avg_logprob": -0.24334441783816316, "compression_ratio": 1.4035874439461884, "no_speech_prob": 0.0006416608230210841}, {"id": 11, "seek": 2700, "start": 47.0, "end": 49.0, "text": " I'm a Swedish developer.", "tokens": [286, 478, 257, 23523, 10754, 13], "temperature": 0.0, "avg_logprob": -0.24334441783816316, "compression_ratio": 1.4035874439461884, "no_speech_prob": 0.0006416608230210841}, {"id": 12, "seek": 2700, "start": 49.0, "end": 54.0, "text": " I spend my days writing rusts, back-end type of things.", "tokens": [286, 3496, 452, 1708, 3579, 15259, 82, 11, 646, 12, 521, 2010, 295, 721, 13], "temperature": 0.0, "avg_logprob": -0.24334441783816316, "compression_ratio": 1.4035874439461884, "no_speech_prob": 0.0006416608230210841}, {"id": 13, "seek": 5400, "start": 54.0, "end": 58.0, "text": " I do C++ and scientific computing in a previous life.", "tokens": [286, 360, 383, 25472, 293, 8134, 15866, 294, 257, 3894, 993, 13], "temperature": 0.0, "avg_logprob": -0.18999256351129795, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0007451014826074243}, {"id": 14, "seek": 5400, "start": 58.0, "end": 60.0, "text": " Yeah, living Stockholm.", "tokens": [865, 11, 2647, 38730, 13], "temperature": 0.0, "avg_logprob": -0.18999256351129795, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0007451014826074243}, {"id": 15, "seek": 5400, "start": 60.0, "end": 62.0, "text": " Yeah, that's me.", "tokens": [865, 11, 300, 311, 385, 13], "temperature": 0.0, "avg_logprob": -0.18999256351129795, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0007451014826074243}, {"id": 16, "seek": 5400, "start": 62.0, "end": 67.0, "text": " Right, so the NIM mixed net.", "tokens": [1779, 11, 370, 264, 426, 6324, 7467, 2533, 13], "temperature": 0.0, "avg_logprob": -0.18999256351129795, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0007451014826074243}, {"id": 17, "seek": 5400, "start": 67.0, "end": 68.0, "text": " What's the NIM mixed net?", "tokens": [708, 311, 264, 426, 6324, 7467, 2533, 30], "temperature": 0.0, "avg_logprob": -0.18999256351129795, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0007451014826074243}, {"id": 18, "seek": 5400, "start": 68.0, "end": 69.0, "text": " So, basics.", "tokens": [407, 11, 14688, 13], "temperature": 0.0, "avg_logprob": -0.18999256351129795, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0007451014826074243}, {"id": 19, "seek": 5400, "start": 69.0, "end": 71.0, "text": " I mean, this is obviously free software.", "tokens": [286, 914, 11, 341, 307, 2745, 1737, 4722, 13], "temperature": 0.0, "avg_logprob": -0.18999256351129795, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0007451014826074243}, {"id": 20, "seek": 5400, "start": 71.0, "end": 74.0, "text": " The source code is available on GitHub over there.", "tokens": [440, 4009, 3089, 307, 2435, 322, 23331, 670, 456, 13], "temperature": 0.0, "avg_logprob": -0.18999256351129795, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0007451014826074243}, {"id": 21, "seek": 5400, "start": 74.0, "end": 76.0, "text": " It's Apache licensed.", "tokens": [467, 311, 46597, 25225, 13], "temperature": 0.0, "avg_logprob": -0.18999256351129795, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0007451014826074243}, {"id": 22, "seek": 5400, "start": 76.0, "end": 78.0, "text": " It's mostly written in Rust.", "tokens": [467, 311, 5240, 3720, 294, 34952, 13], "temperature": 0.0, "avg_logprob": -0.18999256351129795, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0007451014826074243}, {"id": 23, "seek": 5400, "start": 78.0, "end": 80.0, "text": " All the back-end stuff is written in Rust.", "tokens": [1057, 264, 646, 12, 521, 1507, 307, 3720, 294, 34952, 13], "temperature": 0.0, "avg_logprob": -0.18999256351129795, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0007451014826074243}, {"id": 24, "seek": 5400, "start": 80.0, "end": 82.0, "text": " Some of the front-end things is TypeScript.", "tokens": [2188, 295, 264, 1868, 12, 521, 721, 307, 15576, 14237, 13], "temperature": 0.0, "avg_logprob": -0.18999256351129795, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0007451014826074243}, {"id": 25, "seek": 8200, "start": 82.0, "end": 84.0, "text": " This was in the past.", "tokens": [639, 390, 294, 264, 1791, 13], "temperature": 0.0, "avg_logprob": -0.13330185413360596, "compression_ratio": 1.5951417004048583, "no_speech_prob": 0.0007374089909717441}, {"id": 26, "seek": 8200, "start": 84.0, "end": 89.0, "text": " This has been funded by some EU projects.", "tokens": [639, 575, 668, 14385, 538, 512, 10887, 4455, 13], "temperature": 0.0, "avg_logprob": -0.13330185413360596, "compression_ratio": 1.5951417004048583, "no_speech_prob": 0.0007374089909717441}, {"id": 27, "seek": 8200, "start": 89.0, "end": 92.0, "text": " And currently, there is a Switzerland-based startup", "tokens": [400, 4362, 11, 456, 307, 257, 23312, 12, 6032, 18578], "temperature": 0.0, "avg_logprob": -0.13330185413360596, "compression_ratio": 1.5951417004048583, "no_speech_prob": 0.0007374089909717441}, {"id": 28, "seek": 8200, "start": 92.0, "end": 95.0, "text": " with us, the majority of the development.", "tokens": [365, 505, 11, 264, 6286, 295, 264, 3250, 13], "temperature": 0.0, "avg_logprob": -0.13330185413360596, "compression_ratio": 1.5951417004048583, "no_speech_prob": 0.0007374089909717441}, {"id": 29, "seek": 8200, "start": 95.0, "end": 97.0, "text": " But yeah, it's an open project.", "tokens": [583, 1338, 11, 309, 311, 364, 1269, 1716, 13], "temperature": 0.0, "avg_logprob": -0.13330185413360596, "compression_ratio": 1.5951417004048583, "no_speech_prob": 0.0007374089909717441}, {"id": 30, "seek": 8200, "start": 97.0, "end": 100.0, "text": " And of course, we welcome public contributions.", "tokens": [400, 295, 1164, 11, 321, 2928, 1908, 15725, 13], "temperature": 0.0, "avg_logprob": -0.13330185413360596, "compression_ratio": 1.5951417004048583, "no_speech_prob": 0.0007374089909717441}, {"id": 31, "seek": 8200, "start": 100.0, "end": 106.0, "text": " And yeah, it's quite deeply rooted in university as well, in university research.", "tokens": [400, 1338, 11, 309, 311, 1596, 8760, 25277, 294, 5454, 382, 731, 11, 294, 5454, 2132, 13], "temperature": 0.0, "avg_logprob": -0.13330185413360596, "compression_ratio": 1.5951417004048583, "no_speech_prob": 0.0007374089909717441}, {"id": 32, "seek": 8200, "start": 106.0, "end": 111.0, "text": " We have some, you know, work-loss researchers associated with the project.", "tokens": [492, 362, 512, 11, 291, 458, 11, 589, 12, 75, 772, 10309, 6615, 365, 264, 1716, 13], "temperature": 0.0, "avg_logprob": -0.13330185413360596, "compression_ratio": 1.5951417004048583, "no_speech_prob": 0.0007374089909717441}, {"id": 33, "seek": 11100, "start": 111.0, "end": 115.0, "text": " So, you know, the concepts aren't things that we sort of, you know, came up ourselves.", "tokens": [407, 11, 291, 458, 11, 264, 10392, 3212, 380, 721, 300, 321, 1333, 295, 11, 291, 458, 11, 1361, 493, 4175, 13], "temperature": 0.0, "avg_logprob": -0.11442872903642863, "compression_ratio": 1.8141263940520447, "no_speech_prob": 0.0003177270118612796}, {"id": 34, "seek": 11100, "start": 115.0, "end": 120.0, "text": " This is, you know, state-of-the-art research.", "tokens": [639, 307, 11, 291, 458, 11, 1785, 12, 2670, 12, 3322, 12, 446, 2132, 13], "temperature": 0.0, "avg_logprob": -0.11442872903642863, "compression_ratio": 1.8141263940520447, "no_speech_prob": 0.0003177270118612796}, {"id": 35, "seek": 11100, "start": 120.0, "end": 123.0, "text": " Right, so what is the problem that we're trying to solve?", "tokens": [1779, 11, 370, 437, 307, 264, 1154, 300, 321, 434, 1382, 281, 5039, 30], "temperature": 0.0, "avg_logprob": -0.11442872903642863, "compression_ratio": 1.8141263940520447, "no_speech_prob": 0.0003177270118612796}, {"id": 36, "seek": 11100, "start": 123.0, "end": 127.0, "text": " You know, we had the usual suspects, the, you know, government surveillance", "tokens": [509, 458, 11, 321, 632, 264, 7713, 35667, 11, 264, 11, 291, 458, 11, 2463, 18475], "temperature": 0.0, "avg_logprob": -0.11442872903642863, "compression_ratio": 1.8141263940520447, "no_speech_prob": 0.0003177270118612796}, {"id": 37, "seek": 11100, "start": 127.0, "end": 129.0, "text": " and surveillance capitalism.", "tokens": [293, 18475, 19704, 13], "temperature": 0.0, "avg_logprob": -0.11442872903642863, "compression_ratio": 1.8141263940520447, "no_speech_prob": 0.0003177270118612796}, {"id": 38, "seek": 11100, "start": 129.0, "end": 134.0, "text": " And, you know, if these four, which of these two is a problem, you know,", "tokens": [400, 11, 291, 458, 11, 498, 613, 1451, 11, 597, 295, 613, 732, 307, 257, 1154, 11, 291, 458, 11], "temperature": 0.0, "avg_logprob": -0.11442872903642863, "compression_ratio": 1.8141263940520447, "no_speech_prob": 0.0003177270118612796}, {"id": 39, "seek": 11100, "start": 134.0, "end": 137.0, "text": " very much depends on where in the world you are.", "tokens": [588, 709, 5946, 322, 689, 294, 264, 1002, 291, 366, 13], "temperature": 0.0, "avg_logprob": -0.11442872903642863, "compression_ratio": 1.8141263940520447, "no_speech_prob": 0.0003177270118612796}, {"id": 40, "seek": 11100, "start": 137.0, "end": 140.0, "text": " In some parts of the world, these things aren't that big of a concern.", "tokens": [682, 512, 3166, 295, 264, 1002, 11, 613, 721, 3212, 380, 300, 955, 295, 257, 3136, 13], "temperature": 0.0, "avg_logprob": -0.11442872903642863, "compression_ratio": 1.8141263940520447, "no_speech_prob": 0.0003177270118612796}, {"id": 41, "seek": 14000, "start": 140.0, "end": 142.0, "text": " For other people, this is serious matter.", "tokens": [1171, 661, 561, 11, 341, 307, 3156, 1871, 13], "temperature": 0.0, "avg_logprob": -0.1962566375732422, "compression_ratio": 1.6134453781512605, "no_speech_prob": 0.00021263855160214007}, {"id": 42, "seek": 14000, "start": 142.0, "end": 149.0, "text": " This is, you know, of grave concern to some people, depending on who you are and where you live.", "tokens": [639, 307, 11, 291, 458, 11, 295, 12525, 3136, 281, 512, 561, 11, 5413, 322, 567, 291, 366, 293, 689, 291, 1621, 13], "temperature": 0.0, "avg_logprob": -0.1962566375732422, "compression_ratio": 1.6134453781512605, "no_speech_prob": 0.00021263855160214007}, {"id": 43, "seek": 14000, "start": 149.0, "end": 152.0, "text": " And what is the aspect that we try to tackle here?", "tokens": [400, 437, 307, 264, 4171, 300, 321, 853, 281, 14896, 510, 30], "temperature": 0.0, "avg_logprob": -0.1962566375732422, "compression_ratio": 1.6134453781512605, "no_speech_prob": 0.00021263855160214007}, {"id": 44, "seek": 14000, "start": 152.0, "end": 160.0, "text": " Because there's a lot of privacy platforms that sort of, to sort of, to try to attack this challenge", "tokens": [1436, 456, 311, 257, 688, 295, 11427, 9473, 300, 1333, 295, 11, 281, 1333, 295, 11, 281, 853, 281, 2690, 341, 3430], "temperature": 0.0, "avg_logprob": -0.1962566375732422, "compression_ratio": 1.6134453781512605, "no_speech_prob": 0.00021263855160214007}, {"id": 45, "seek": 14000, "start": 160.0, "end": 162.0, "text": " from different perspectives.", "tokens": [490, 819, 16766, 13], "temperature": 0.0, "avg_logprob": -0.1962566375732422, "compression_ratio": 1.6134453781512605, "no_speech_prob": 0.00021263855160214007}, {"id": 46, "seek": 14000, "start": 162.0, "end": 167.0, "text": " The NMEXnet is a network layer, or it's a transport layer thing.", "tokens": [440, 426, 15454, 55, 7129, 307, 257, 3209, 4583, 11, 420, 309, 311, 257, 5495, 4583, 551, 13], "temperature": 0.0, "avg_logprob": -0.1962566375732422, "compression_ratio": 1.6134453781512605, "no_speech_prob": 0.00021263855160214007}, {"id": 47, "seek": 16700, "start": 167.0, "end": 173.0, "text": " And the main challenge to be focused on is that it has become clear in the sort of the last ten years", "tokens": [400, 264, 2135, 3430, 281, 312, 5178, 322, 307, 300, 309, 575, 1813, 1850, 294, 264, 1333, 295, 264, 1036, 2064, 924], "temperature": 0.0, "avg_logprob": -0.13005399703979492, "compression_ratio": 1.816793893129771, "no_speech_prob": 0.0002510337217245251}, {"id": 48, "seek": 16700, "start": 173.0, "end": 179.0, "text": " that there's now so much surveillance going on, and there are some entities that collect so much data", "tokens": [300, 456, 311, 586, 370, 709, 18475, 516, 322, 11, 293, 456, 366, 512, 16667, 300, 2500, 370, 709, 1412], "temperature": 0.0, "avg_logprob": -0.13005399703979492, "compression_ratio": 1.816793893129771, "no_speech_prob": 0.0002510337217245251}, {"id": 49, "seek": 16700, "start": 179.0, "end": 183.0, "text": " on a global scale that they almost get some sort of like a god-sized view of the network.", "tokens": [322, 257, 4338, 4373, 300, 436, 1920, 483, 512, 1333, 295, 411, 257, 3044, 12, 20614, 1910, 295, 264, 3209, 13], "temperature": 0.0, "avg_logprob": -0.13005399703979492, "compression_ratio": 1.816793893129771, "no_speech_prob": 0.0002510337217245251}, {"id": 50, "seek": 16700, "start": 183.0, "end": 188.0, "text": " They can monitor the network on a planet scale, and they can do, they can correlate,", "tokens": [814, 393, 6002, 264, 3209, 322, 257, 5054, 4373, 11, 293, 436, 393, 360, 11, 436, 393, 48742, 11], "temperature": 0.0, "avg_logprob": -0.13005399703979492, "compression_ratio": 1.816793893129771, "no_speech_prob": 0.0002510337217245251}, {"id": 51, "seek": 16700, "start": 188.0, "end": 194.0, "text": " they can correlate using leaked metadata, your transmission patterns, your packet sizes, timings.", "tokens": [436, 393, 48742, 1228, 31779, 26603, 11, 428, 11574, 8294, 11, 428, 20300, 11602, 11, 524, 1109, 13], "temperature": 0.0, "avg_logprob": -0.13005399703979492, "compression_ratio": 1.816793893129771, "no_speech_prob": 0.0002510337217245251}, {"id": 52, "seek": 19400, "start": 194.0, "end": 202.0, "text": " They can do end-to-end correlations, even though like your data is sent entirely encrypted the whole way,", "tokens": [814, 393, 360, 917, 12, 1353, 12, 521, 13983, 763, 11, 754, 1673, 411, 428, 1412, 307, 2279, 7696, 36663, 264, 1379, 636, 11], "temperature": 0.0, "avg_logprob": -0.11096674142424594, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.00025541664217598736}, {"id": 53, "seek": 19400, "start": 202.0, "end": 208.0, "text": " or obfuscated, but still, if you can sort of monitor like all endpoints,", "tokens": [420, 1111, 69, 32601, 770, 11, 457, 920, 11, 498, 291, 393, 1333, 295, 6002, 411, 439, 917, 20552, 11], "temperature": 0.0, "avg_logprob": -0.11096674142424594, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.00025541664217598736}, {"id": 54, "seek": 19400, "start": 208.0, "end": 213.0, "text": " you can sort of still draw conclusions, you can identify who talks to who.", "tokens": [291, 393, 1333, 295, 920, 2642, 22865, 11, 291, 393, 5876, 567, 6686, 281, 567, 13], "temperature": 0.0, "avg_logprob": -0.11096674142424594, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.00025541664217598736}, {"id": 55, "seek": 19400, "start": 213.0, "end": 219.0, "text": " And you know, as we know, who talks to who is sometimes more important than what they say from a sort of surveillance perspective.", "tokens": [400, 291, 458, 11, 382, 321, 458, 11, 567, 6686, 281, 567, 307, 2171, 544, 1021, 813, 437, 436, 584, 490, 257, 1333, 295, 18475, 4585, 13], "temperature": 0.0, "avg_logprob": -0.11096674142424594, "compression_ratio": 1.6842105263157894, "no_speech_prob": 0.00025541664217598736}, {"id": 56, "seek": 21900, "start": 219.0, "end": 225.0, "text": " So that's the sort of the angle, the challenge that we try to talk about this.", "tokens": [407, 300, 311, 264, 1333, 295, 264, 5802, 11, 264, 3430, 300, 321, 853, 281, 751, 466, 341, 13], "temperature": 0.0, "avg_logprob": -0.18507654290450246, "compression_ratio": 1.591743119266055, "no_speech_prob": 0.00022137202904559672}, {"id": 57, "seek": 21900, "start": 225.0, "end": 232.0, "text": " And so now I'm sort of taking a step back here, so I'm referring to the NIM platform,", "tokens": [400, 370, 586, 286, 478, 1333, 295, 1940, 257, 1823, 646, 510, 11, 370, 286, 478, 13761, 281, 264, 426, 6324, 3663, 11], "temperature": 0.0, "avg_logprob": -0.18507654290450246, "compression_ratio": 1.591743119266055, "no_speech_prob": 0.00022137202904559672}, {"id": 58, "seek": 21900, "start": 232.0, "end": 239.0, "text": " which is, then I use this quote here, a decentralized, incentivized mixed-net plus prior credentials.", "tokens": [597, 307, 11, 550, 286, 764, 341, 6513, 510, 11, 257, 32870, 11, 35328, 1602, 7467, 12, 7129, 1804, 4059, 27404, 13], "temperature": 0.0, "avg_logprob": -0.18507654290450246, "compression_ratio": 1.591743119266055, "no_speech_prob": 0.00022137202904559672}, {"id": 59, "seek": 21900, "start": 239.0, "end": 244.0, "text": " And sort of, yeah, my talk here will be to try to unpack what all of this means,", "tokens": [400, 1333, 295, 11, 1338, 11, 452, 751, 510, 486, 312, 281, 853, 281, 26699, 437, 439, 295, 341, 1355, 11], "temperature": 0.0, "avg_logprob": -0.18507654290450246, "compression_ratio": 1.591743119266055, "no_speech_prob": 0.00022137202904559672}, {"id": 60, "seek": 24400, "start": 244.0, "end": 251.0, "text": " and we're going to start then with what I think is sort of the core part is the mixed-net, the word in the middle there.", "tokens": [293, 321, 434, 516, 281, 722, 550, 365, 437, 286, 519, 307, 1333, 295, 264, 4965, 644, 307, 264, 7467, 12, 7129, 11, 264, 1349, 294, 264, 2808, 456, 13], "temperature": 0.0, "avg_logprob": -0.12145706544439476, "compression_ratio": 1.6614583333333333, "no_speech_prob": 0.0001825173239922151}, {"id": 61, "seek": 24400, "start": 251.0, "end": 261.0, "text": " I think if you use something like Tor as a starting point, that's sort of a very good first step to understand what it is.", "tokens": [286, 519, 498, 291, 764, 746, 411, 7160, 382, 257, 2891, 935, 11, 300, 311, 1333, 295, 257, 588, 665, 700, 1823, 281, 1223, 437, 309, 307, 13], "temperature": 0.0, "avg_logprob": -0.12145706544439476, "compression_ratio": 1.6614583333333333, "no_speech_prob": 0.0001825173239922151}, {"id": 62, "seek": 24400, "start": 261.0, "end": 266.0, "text": " And just like Tor and just like the previous talk, it's an overlay network,", "tokens": [400, 445, 411, 7160, 293, 445, 411, 264, 3894, 751, 11, 309, 311, 364, 31741, 3209, 11], "temperature": 0.0, "avg_logprob": -0.12145706544439476, "compression_ratio": 1.6614583333333333, "no_speech_prob": 0.0001825173239922151}, {"id": 63, "seek": 26600, "start": 266.0, "end": 276.0, "text": " in the same way as I2P uses onion routing, where all packets are wrapped in layers of encryption to sort of hide the fact,", "tokens": [294, 264, 912, 636, 382, 286, 17, 47, 4960, 10916, 32722, 11, 689, 439, 30364, 366, 14226, 294, 7914, 295, 29575, 281, 1333, 295, 6479, 264, 1186, 11], "temperature": 0.0, "avg_logprob": -0.13544992372101428, "compression_ratio": 1.6120689655172413, "no_speech_prob": 6.632677104789764e-05}, {"id": 64, "seek": 26600, "start": 276.0, "end": 280.0, "text": " to hide the end destination of each packet.", "tokens": [281, 6479, 264, 917, 12236, 295, 1184, 20300, 13], "temperature": 0.0, "avg_logprob": -0.13544992372101428, "compression_ratio": 1.6120689655172413, "no_speech_prob": 6.632677104789764e-05}, {"id": 65, "seek": 26600, "start": 280.0, "end": 286.0, "text": " It's based on the Loupix design, if you know a little bit about mixed-nets, you've probably heard about Loupix.", "tokens": [467, 311, 2361, 322, 264, 441, 1250, 970, 1715, 11, 498, 291, 458, 257, 707, 857, 466, 7467, 12, 77, 1385, 11, 291, 600, 1391, 2198, 466, 441, 1250, 970, 13], "temperature": 0.0, "avg_logprob": -0.13544992372101428, "compression_ratio": 1.6120689655172413, "no_speech_prob": 6.632677104789764e-05}, {"id": 66, "seek": 26600, "start": 286.0, "end": 294.0, "text": " I put in a few citations here at the bottom, if you want to read a bit more about these things.", "tokens": [286, 829, 294, 257, 1326, 4814, 763, 510, 412, 264, 2767, 11, 498, 291, 528, 281, 1401, 257, 857, 544, 466, 613, 721, 13], "temperature": 0.0, "avg_logprob": -0.13544992372101428, "compression_ratio": 1.6120689655172413, "no_speech_prob": 6.632677104789764e-05}, {"id": 67, "seek": 29400, "start": 294.0, "end": 304.0, "text": " It uses Sphinx packets, so that the idea is that all packets are wrapped into these identically looking and identically behaving packets,", "tokens": [467, 4960, 318, 48522, 87, 30364, 11, 370, 300, 264, 1558, 307, 300, 439, 30364, 366, 14226, 666, 613, 2473, 984, 1237, 293, 2473, 984, 35263, 30364, 11], "temperature": 0.0, "avg_logprob": -0.22340535481770835, "compression_ratio": 1.5585106382978724, "no_speech_prob": 0.0004735550028271973}, {"id": 68, "seek": 29400, "start": 304.0, "end": 310.0, "text": " to sort of to hide some sizes and timings.", "tokens": [281, 1333, 295, 281, 6479, 512, 11602, 293, 524, 1109, 13], "temperature": 0.0, "avg_logprob": -0.22340535481770835, "compression_ratio": 1.5585106382978724, "no_speech_prob": 0.0004735550028271973}, {"id": 69, "seek": 29400, "start": 310.0, "end": 318.0, "text": " And also, each packet as it moves through, because mixed-net is, I mean, okay, so something I forgot to mention,", "tokens": [400, 611, 11, 1184, 20300, 382, 309, 6067, 807, 11, 570, 7467, 12, 7129, 307, 11, 286, 914, 11, 1392, 11, 370, 746, 286, 5298, 281, 2152, 11], "temperature": 0.0, "avg_logprob": -0.22340535481770835, "compression_ratio": 1.5585106382978724, "no_speech_prob": 0.0004735550028271973}, {"id": 70, "seek": 31800, "start": 318.0, "end": 325.0, "text": " mixed-net is very much what it sounds. It's data, you send through data, multiple hops, you mix data as much as you can,", "tokens": [7467, 12, 7129, 307, 588, 709, 437, 309, 3263, 13, 467, 311, 1412, 11, 291, 2845, 807, 1412, 11, 3866, 47579, 11, 291, 2890, 1412, 382, 709, 382, 291, 393, 11], "temperature": 0.0, "avg_logprob": -0.11885302999745244, "compression_ratio": 1.5852534562211982, "no_speech_prob": 3.9651826227782294e-05}, {"id": 71, "seek": 31800, "start": 325.0, "end": 328.0, "text": " through a cloud of nodes.", "tokens": [807, 257, 4588, 295, 13891, 13], "temperature": 0.0, "avg_logprob": -0.11885302999745244, "compression_ratio": 1.5852534562211982, "no_speech_prob": 3.9651826227782294e-05}, {"id": 72, "seek": 31800, "start": 328.0, "end": 333.0, "text": " At each node, I'm going to have some pictures on the next slide to illustrate it better.", "tokens": [1711, 1184, 9984, 11, 286, 478, 516, 281, 362, 512, 5242, 322, 264, 958, 4137, 281, 23221, 309, 1101, 13], "temperature": 0.0, "avg_logprob": -0.11885302999745244, "compression_ratio": 1.5852534562211982, "no_speech_prob": 3.9651826227782294e-05}, {"id": 73, "seek": 31800, "start": 333.0, "end": 341.0, "text": " But yeah, on each hop in the network, you add things like random timings, which affect the reorders traffic,", "tokens": [583, 1338, 11, 322, 1184, 3818, 294, 264, 3209, 11, 291, 909, 721, 411, 4974, 524, 1109, 11, 597, 3345, 264, 319, 10400, 6419, 11], "temperature": 0.0, "avg_logprob": -0.11885302999745244, "compression_ratio": 1.5852534562211982, "no_speech_prob": 3.9651826227782294e-05}, {"id": 74, "seek": 34100, "start": 341.0, "end": 349.0, "text": " you add cover traffic, which cover traffic can appear in many ways, either between nodes,", "tokens": [291, 909, 2060, 6419, 11, 597, 2060, 6419, 393, 4204, 294, 867, 2098, 11, 2139, 1296, 13891, 11], "temperature": 0.0, "avg_logprob": -0.1728606533694577, "compression_ratio": 1.582010582010582, "no_speech_prob": 6.312432378763333e-05}, {"id": 75, "seek": 34100, "start": 349.0, "end": 359.0, "text": " but also, for example, if you use a client to connect to network, to transmit data, you emit Sphinx packets at a steady average rate,", "tokens": [457, 611, 11, 337, 1365, 11, 498, 291, 764, 257, 6423, 281, 1745, 281, 3209, 11, 281, 17831, 1412, 11, 291, 32084, 318, 48522, 87, 30364, 412, 257, 13211, 4274, 3314, 11], "temperature": 0.0, "avg_logprob": -0.1728606533694577, "compression_ratio": 1.582010582010582, "no_speech_prob": 6.312432378763333e-05}, {"id": 76, "seek": 34100, "start": 359.0, "end": 365.0, "text": " so it's not a steady rate, but it's probabilistic how you send the packets.", "tokens": [370, 309, 311, 406, 257, 13211, 3314, 11, 457, 309, 311, 31959, 3142, 577, 291, 2845, 264, 30364, 13], "temperature": 0.0, "avg_logprob": -0.1728606533694577, "compression_ratio": 1.582010582010582, "no_speech_prob": 6.312432378763333e-05}, {"id": 77, "seek": 36500, "start": 365.0, "end": 371.0, "text": " But you send the steady stream of packets, either fake or real ones, so when you have real data to send,", "tokens": [583, 291, 2845, 264, 13211, 4309, 295, 30364, 11, 2139, 7592, 420, 957, 2306, 11, 370, 562, 291, 362, 957, 1412, 281, 2845, 11], "temperature": 0.0, "avg_logprob": -0.1255765694838304, "compression_ratio": 1.7685589519650655, "no_speech_prob": 6.473046232713386e-05}, {"id": 78, "seek": 36500, "start": 371.0, "end": 376.0, "text": " you just fill up the packet stream, the packets they send out, fill up with real data.", "tokens": [291, 445, 2836, 493, 264, 20300, 4309, 11, 264, 30364, 436, 2845, 484, 11, 2836, 493, 365, 957, 1412, 13], "temperature": 0.0, "avg_logprob": -0.1255765694838304, "compression_ratio": 1.7685589519650655, "no_speech_prob": 6.473046232713386e-05}, {"id": 79, "seek": 36500, "start": 376.0, "end": 382.0, "text": " So from the outside, you can't tell when you're actually sending, when you're bursting data.", "tokens": [407, 490, 264, 2380, 11, 291, 393, 380, 980, 562, 291, 434, 767, 7750, 11, 562, 291, 434, 45713, 1412, 13], "temperature": 0.0, "avg_logprob": -0.1255765694838304, "compression_ratio": 1.7685589519650655, "no_speech_prob": 6.473046232713386e-05}, {"id": 80, "seek": 36500, "start": 382.0, "end": 389.0, "text": " You attach SERBs, so single-use reply blocks in your packets, so that when you, if you make a request across the network", "tokens": [509, 5085, 36772, 33, 82, 11, 370, 2167, 12, 438, 16972, 8474, 294, 428, 30364, 11, 370, 300, 562, 291, 11, 498, 291, 652, 257, 5308, 2108, 264, 3209], "temperature": 0.0, "avg_logprob": -0.1255765694838304, "compression_ratio": 1.7685589519650655, "no_speech_prob": 6.473046232713386e-05}, {"id": 81, "seek": 38900, "start": 389.0, "end": 397.0, "text": " to get something back, you attach these headers, these metadata, so that the response can be layer encrypted and sent back,", "tokens": [281, 483, 746, 646, 11, 291, 5085, 613, 45101, 11, 613, 26603, 11, 370, 300, 264, 4134, 393, 312, 4583, 36663, 293, 2279, 646, 11], "temperature": 0.0, "avg_logprob": -0.10225500576737998, "compression_ratio": 1.6608187134502923, "no_speech_prob": 4.5366326958173886e-05}, {"id": 82, "seek": 38900, "start": 397.0, "end": 406.0, "text": " so that on the other side, the server doesn't know where the destination is, so you hide your identity,", "tokens": [370, 300, 322, 264, 661, 1252, 11, 264, 7154, 1177, 380, 458, 689, 264, 12236, 307, 11, 370, 291, 6479, 428, 6575, 11], "temperature": 0.0, "avg_logprob": -0.10225500576737998, "compression_ratio": 1.6608187134502923, "no_speech_prob": 4.5366326958173886e-05}, {"id": 83, "seek": 38900, "start": 406.0, "end": 413.0, "text": " but you still allow the other side to reply back to you.", "tokens": [457, 291, 920, 2089, 264, 661, 1252, 281, 16972, 646, 281, 291, 13], "temperature": 0.0, "avg_logprob": -0.10225500576737998, "compression_ratio": 1.6608187134502923, "no_speech_prob": 4.5366326958173886e-05}, {"id": 84, "seek": 41300, "start": 413.0, "end": 420.0, "text": " It's a picture, the first step, the first one there, ordinary VPN, and a VPN doesn't give you any anonymity,", "tokens": [467, 311, 257, 3036, 11, 264, 700, 1823, 11, 264, 700, 472, 456, 11, 10547, 24512, 11, 293, 257, 24512, 1177, 380, 976, 291, 604, 37293, 507, 11], "temperature": 0.0, "avg_logprob": -0.16591386887633686, "compression_ratio": 1.7345132743362832, "no_speech_prob": 0.00020080867398064584}, {"id": 85, "seek": 41300, "start": 420.0, "end": 427.0, "text": " it just moves trust, so the guy in the middle there, you can still see where data is coming from, where it is going.", "tokens": [309, 445, 6067, 3361, 11, 370, 264, 2146, 294, 264, 2808, 456, 11, 291, 393, 920, 536, 689, 1412, 307, 1348, 490, 11, 689, 309, 307, 516, 13], "temperature": 0.0, "avg_logprob": -0.16591386887633686, "compression_ratio": 1.7345132743362832, "no_speech_prob": 0.00020080867398064584}, {"id": 86, "seek": 41300, "start": 427.0, "end": 432.0, "text": " The second one, you have things like Tor, where you have these nodes in the middle, where you open up a circuit", "tokens": [440, 1150, 472, 11, 291, 362, 721, 411, 7160, 11, 689, 291, 362, 613, 13891, 294, 264, 2808, 11, 689, 291, 1269, 493, 257, 9048], "temperature": 0.0, "avg_logprob": -0.16591386887633686, "compression_ratio": 1.7345132743362832, "no_speech_prob": 0.00020080867398064584}, {"id": 87, "seek": 41300, "start": 432.0, "end": 437.0, "text": " through the swarm of nodes, and you pump data through.", "tokens": [807, 264, 49839, 295, 13891, 11, 293, 291, 5889, 1412, 807, 13], "temperature": 0.0, "avg_logprob": -0.16591386887633686, "compression_ratio": 1.7345132743362832, "no_speech_prob": 0.00020080867398064584}, {"id": 88, "seek": 43700, "start": 437.0, "end": 445.0, "text": " And here you have mixed-net setup, where in each packet is mixed individually, so you don't open up a circuit,", "tokens": [400, 510, 291, 362, 7467, 12, 7129, 8657, 11, 689, 294, 1184, 20300, 307, 7467, 16652, 11, 370, 291, 500, 380, 1269, 493, 257, 9048, 11], "temperature": 0.0, "avg_logprob": -0.16565600956711812, "compression_ratio": 1.7142857142857142, "no_speech_prob": 8.64270405145362e-05}, {"id": 89, "seek": 43700, "start": 445.0, "end": 449.0, "text": " like Tor, for example, you send up, each packet is sent as an individual pass-through.", "tokens": [411, 7160, 11, 337, 1365, 11, 291, 2845, 493, 11, 1184, 20300, 307, 2279, 382, 364, 2609, 1320, 12, 11529, 13], "temperature": 0.0, "avg_logprob": -0.16565600956711812, "compression_ratio": 1.7142857142857142, "no_speech_prob": 8.64270405145362e-05}, {"id": 90, "seek": 43700, "start": 449.0, "end": 456.0, "text": " And the idea here, the crucial thing is that on the other side, you see these packets there, they are now,", "tokens": [400, 264, 1558, 510, 11, 264, 11462, 551, 307, 300, 322, 264, 661, 1252, 11, 291, 536, 613, 30364, 456, 11, 436, 366, 586, 11], "temperature": 0.0, "avg_logprob": -0.16565600956711812, "compression_ratio": 1.7142857142857142, "no_speech_prob": 8.64270405145362e-05}, {"id": 91, "seek": 43700, "start": 456.0, "end": 461.0, "text": " they're colored white now instead of red, and they're the same size, and you shouldn't be able to tell,", "tokens": [436, 434, 14332, 2418, 586, 2602, 295, 2182, 11, 293, 436, 434, 264, 912, 2744, 11, 293, 291, 4659, 380, 312, 1075, 281, 980, 11], "temperature": 0.0, "avg_logprob": -0.16565600956711812, "compression_ratio": 1.7142857142857142, "no_speech_prob": 8.64270405145362e-05}, {"id": 92, "seek": 46100, "start": 461.0, "end": 468.0, "text": " you can't tell, you can't correlate the data on the other side compared to on the sender side,", "tokens": [291, 393, 380, 980, 11, 291, 393, 380, 48742, 264, 1412, 322, 264, 661, 1252, 5347, 281, 322, 264, 2845, 260, 1252, 11], "temperature": 0.0, "avg_logprob": -0.10476397796415947, "compression_ratio": 1.7300613496932515, "no_speech_prob": 6.533521809615195e-05}, {"id": 93, "seek": 46100, "start": 468.0, "end": 477.0, "text": " which you can in many other systems, because you can't correlate transmission patterns, timing sizes.", "tokens": [597, 291, 393, 294, 867, 661, 3652, 11, 570, 291, 393, 380, 48742, 11574, 8294, 11, 10822, 11602, 13], "temperature": 0.0, "avg_logprob": -0.10476397796415947, "compression_ratio": 1.7300613496932515, "no_speech_prob": 6.533521809615195e-05}, {"id": 94, "seek": 46100, "start": 477.0, "end": 485.0, "text": " So even if you can monitor all the data, all the exit data from this mixed-net cloud,", "tokens": [407, 754, 498, 291, 393, 6002, 439, 264, 1412, 11, 439, 264, 11043, 1412, 490, 341, 7467, 12, 7129, 4588, 11], "temperature": 0.0, "avg_logprob": -0.10476397796415947, "compression_ratio": 1.7300613496932515, "no_speech_prob": 6.533521809615195e-05}, {"id": 95, "seek": 48500, "start": 485.0, "end": 496.0, "text": " you still can't correlate who talks to who. That's sort of the key thing here.", "tokens": [291, 920, 393, 380, 48742, 567, 6686, 281, 567, 13, 663, 311, 1333, 295, 264, 2141, 551, 510, 13], "temperature": 0.0, "avg_logprob": -0.16872557840849223, "compression_ratio": 1.5309278350515463, "no_speech_prob": 0.00024812729679979384}, {"id": 96, "seek": 48500, "start": 496.0, "end": 502.0, "text": " And yeah, so if we go back then to this quote, so decentralized, incentivized mixed-net plus price credentials,", "tokens": [400, 1338, 11, 370, 498, 321, 352, 646, 550, 281, 341, 6513, 11, 370, 32870, 11, 35328, 1602, 7467, 12, 7129, 1804, 3218, 27404, 11], "temperature": 0.0, "avg_logprob": -0.16872557840849223, "compression_ratio": 1.5309278350515463, "no_speech_prob": 0.00024812729679979384}, {"id": 97, "seek": 48500, "start": 502.0, "end": 511.0, "text": " what we mean by incentivized, we mean that the network directory, which keeps track of all the mixed-nodes", "tokens": [437, 321, 914, 538, 35328, 1602, 11, 321, 914, 300, 264, 3209, 21120, 11, 597, 5965, 2837, 295, 439, 264, 7467, 12, 77, 4789], "temperature": 0.0, "avg_logprob": -0.16872557840849223, "compression_ratio": 1.5309278350515463, "no_speech_prob": 0.00024812729679979384}, {"id": 98, "seek": 51100, "start": 511.0, "end": 519.0, "text": " and gateways are a bit like exit nodes in Tor, they are constantly being monitored.", "tokens": [293, 8539, 942, 366, 257, 857, 411, 11043, 13891, 294, 7160, 11, 436, 366, 6460, 885, 36255, 13], "temperature": 0.0, "avg_logprob": -0.14318440755208334, "compression_ratio": 1.628099173553719, "no_speech_prob": 0.0001051734943757765}, {"id": 99, "seek": 51100, "start": 519.0, "end": 523.0, "text": " So the network directory is effectively a set of validators running a consensus protocol,", "tokens": [407, 264, 3209, 21120, 307, 8659, 257, 992, 295, 7363, 3391, 2614, 257, 19115, 10336, 11], "temperature": 0.0, "avg_logprob": -0.14318440755208334, "compression_ratio": 1.628099173553719, "no_speech_prob": 0.0001051734943757765}, {"id": 100, "seek": 51100, "start": 523.0, "end": 530.0, "text": " and they keep track of all the mixed-nodes, how well they mix traffic, how well they contribute capacity to network,", "tokens": [293, 436, 1066, 2837, 295, 439, 264, 7467, 12, 77, 4789, 11, 577, 731, 436, 2890, 6419, 11, 577, 731, 436, 10586, 6042, 281, 3209, 11], "temperature": 0.0, "avg_logprob": -0.14318440755208334, "compression_ratio": 1.628099173553719, "no_speech_prob": 0.0001051734943757765}, {"id": 101, "seek": 51100, "start": 530.0, "end": 538.0, "text": " giving them limbs for it, which in turn can be turned around and used to acquire bandwidth credentials,", "tokens": [2902, 552, 29315, 337, 309, 11, 597, 294, 1261, 393, 312, 3574, 926, 293, 1143, 281, 20001, 23647, 27404, 11], "temperature": 0.0, "avg_logprob": -0.14318440755208334, "compression_ratio": 1.628099173553719, "no_speech_prob": 0.0001051734943757765}, {"id": 102, "seek": 53800, "start": 538.0, "end": 543.0, "text": " coconut credentials, it's the academic term.", "tokens": [13551, 27404, 11, 309, 311, 264, 7778, 1433, 13], "temperature": 0.0, "avg_logprob": -0.18801288429750215, "compression_ratio": 1.6402877697841727, "no_speech_prob": 0.00019494771549943835}, {"id": 103, "seek": 53800, "start": 543.0, "end": 548.0, "text": " And the idea is that we also, because this is always a problem when you have something like this,", "tokens": [400, 264, 1558, 307, 300, 321, 611, 11, 570, 341, 307, 1009, 257, 1154, 562, 291, 362, 746, 411, 341, 11], "temperature": 0.0, "avg_logprob": -0.18801288429750215, "compression_ratio": 1.6402877697841727, "no_speech_prob": 0.00019494771549943835}, {"id": 104, "seek": 53800, "start": 548.0, "end": 554.0, "text": " with volunteers you only get so far, anonymity or privacy, it loves company, you want to disappear in the crowd,", "tokens": [365, 14352, 291, 787, 483, 370, 1400, 11, 37293, 507, 420, 11427, 11, 309, 6752, 2237, 11, 291, 528, 281, 11596, 294, 264, 6919, 11], "temperature": 0.0, "avg_logprob": -0.18801288429750215, "compression_ratio": 1.6402877697841727, "no_speech_prob": 0.00019494771549943835}, {"id": 105, "seek": 53800, "start": 554.0, "end": 560.0, "text": " so you want to encourage people to provide capacity to the network at the same time as they're using it, that's the idea.", "tokens": [370, 291, 528, 281, 5373, 561, 281, 2893, 6042, 281, 264, 3209, 412, 264, 912, 565, 382, 436, 434, 1228, 309, 11, 300, 311, 264, 1558, 13], "temperature": 0.0, "avg_logprob": -0.18801288429750215, "compression_ratio": 1.6402877697841727, "no_speech_prob": 0.00019494771549943835}, {"id": 106, "seek": 53800, "start": 560.0, "end": 566.0, "text": " Because otherwise it becomes difficult to scale up above a sort of base level.", "tokens": [1436, 5911, 309, 3643, 2252, 281, 4373, 493, 3673, 257, 1333, 295, 3096, 1496, 13], "temperature": 0.0, "avg_logprob": -0.18801288429750215, "compression_ratio": 1.6402877697841727, "no_speech_prob": 0.00019494771549943835}, {"id": 107, "seek": 56600, "start": 566.0, "end": 573.0, "text": " But if you want to make this available for the broader public, you need more capacity.", "tokens": [583, 498, 291, 528, 281, 652, 341, 2435, 337, 264, 13227, 1908, 11, 291, 643, 544, 6042, 13], "temperature": 0.0, "avg_logprob": -0.13724032044410706, "compression_ratio": 1.5730994152046784, "no_speech_prob": 0.00025305745657533407}, {"id": 108, "seek": 56600, "start": 573.0, "end": 578.0, "text": " And this is a way that we hope we can achieve this.", "tokens": [400, 341, 307, 257, 636, 300, 321, 1454, 321, 393, 4584, 341, 13], "temperature": 0.0, "avg_logprob": -0.13724032044410706, "compression_ratio": 1.5730994152046784, "no_speech_prob": 0.00025305745657533407}, {"id": 109, "seek": 56600, "start": 578.0, "end": 588.0, "text": " And these private credentials, the idea is that you break the linkability between your identity and your right to use the service.", "tokens": [400, 613, 4551, 27404, 11, 264, 1558, 307, 300, 291, 1821, 264, 2113, 2310, 1296, 428, 6575, 293, 428, 558, 281, 764, 264, 2643, 13], "temperature": 0.0, "avg_logprob": -0.13724032044410706, "compression_ratio": 1.5730994152046784, "no_speech_prob": 0.00025305745657533407}, {"id": 110, "seek": 58800, "start": 588.0, "end": 596.0, "text": " And there's a very deep topic on its own, there's a citation, there are some cryptographic buzzwords here,", "tokens": [400, 456, 311, 257, 588, 2452, 4829, 322, 1080, 1065, 11, 456, 311, 257, 45590, 11, 456, 366, 512, 9844, 12295, 13036, 13832, 510, 11], "temperature": 0.0, "avg_logprob": -0.143829345703125, "compression_ratio": 1.6122448979591837, "no_speech_prob": 0.00025047059170901775}, {"id": 111, "seek": 58800, "start": 596.0, "end": 602.0, "text": " as well as that are re-randomizable, means that if you use the same bandwidth credential multiple times,", "tokens": [382, 731, 382, 300, 366, 319, 12, 3699, 298, 22395, 11, 1355, 300, 498, 291, 764, 264, 912, 23647, 22034, 3866, 1413, 11], "temperature": 0.0, "avg_logprob": -0.143829345703125, "compression_ratio": 1.6122448979591837, "no_speech_prob": 0.00025047059170901775}, {"id": 112, "seek": 58800, "start": 602.0, "end": 613.0, "text": " it's indistinguishable from multiple people using different credentials from the person redeeming these.", "tokens": [309, 311, 1016, 468, 7050, 742, 712, 490, 3866, 561, 1228, 819, 27404, 490, 264, 954, 37715, 278, 613, 13], "temperature": 0.0, "avg_logprob": -0.143829345703125, "compression_ratio": 1.6122448979591837, "no_speech_prob": 0.00025047059170901775}, {"id": 113, "seek": 61300, "start": 613.0, "end": 623.0, "text": " But yeah, the idea is you want to break the link between your identity and your right to use something.", "tokens": [583, 1338, 11, 264, 1558, 307, 291, 528, 281, 1821, 264, 2113, 1296, 428, 6575, 293, 428, 558, 281, 764, 746, 13], "temperature": 0.0, "avg_logprob": -0.18995047807693483, "compression_ratio": 1.5431472081218274, "no_speech_prob": 0.0003333188942633569}, {"id": 114, "seek": 61300, "start": 623.0, "end": 631.0, "text": " And yeah, okay, so the first word there, decentralized, it's not too much to add there,", "tokens": [400, 1338, 11, 1392, 11, 370, 264, 700, 1349, 456, 11, 32870, 11, 309, 311, 406, 886, 709, 281, 909, 456, 11], "temperature": 0.0, "avg_logprob": -0.18995047807693483, "compression_ratio": 1.5431472081218274, "no_speech_prob": 0.0003333188942633569}, {"id": 115, "seek": 61300, "start": 631.0, "end": 639.0, "text": " we have a running network, it's 500 mix-nodes currently, and yeah, the vision is that this becomes self-running,", "tokens": [321, 362, 257, 2614, 3209, 11, 309, 311, 5923, 2890, 12, 77, 4789, 4362, 11, 293, 1338, 11, 264, 5201, 307, 300, 341, 3643, 2698, 12, 45482, 11], "temperature": 0.0, "avg_logprob": -0.18995047807693483, "compression_ratio": 1.5431472081218274, "no_speech_prob": 0.0003333188942633569}, {"id": 116, "seek": 63900, "start": 639.0, "end": 649.0, "text": " it shouldn't have an antifragile funding model, we don't want it to be reliant on a specific company", "tokens": [309, 4659, 380, 362, 364, 2511, 351, 3731, 794, 6137, 2316, 11, 321, 500, 380, 528, 309, 281, 312, 1039, 5798, 322, 257, 2685, 2237], "temperature": 0.0, "avg_logprob": -0.1524402128683554, "compression_ratio": 1.5674157303370786, "no_speech_prob": 0.00011710632679751143}, {"id": 117, "seek": 63900, "start": 649.0, "end": 656.0, "text": " or some funding body or donations or anything, we want this to have robust,", "tokens": [420, 512, 6137, 1772, 420, 22705, 420, 1340, 11, 321, 528, 341, 281, 362, 13956, 11], "temperature": 0.0, "avg_logprob": -0.1524402128683554, "compression_ratio": 1.5674157303370786, "no_speech_prob": 0.00011710632679751143}, {"id": 118, "seek": 63900, "start": 656.0, "end": 665.0, "text": " robustly running on its own, run by the community entirely, long-term, that's sort of the vision here.", "tokens": [13956, 356, 2614, 322, 1080, 1065, 11, 1190, 538, 264, 1768, 7696, 11, 938, 12, 7039, 11, 300, 311, 1333, 295, 264, 5201, 510, 13], "temperature": 0.0, "avg_logprob": -0.1524402128683554, "compression_ratio": 1.5674157303370786, "no_speech_prob": 0.00011710632679751143}, {"id": 119, "seek": 66500, "start": 665.0, "end": 669.0, "text": " Even though currently we have a startup that sort of does the most of the development,", "tokens": [2754, 1673, 4362, 321, 362, 257, 18578, 300, 1333, 295, 775, 264, 881, 295, 264, 3250, 11], "temperature": 0.0, "avg_logprob": -0.17746112460181826, "compression_ratio": 1.6875, "no_speech_prob": 4.98352492286358e-05}, {"id": 120, "seek": 66500, "start": 669.0, "end": 679.0, "text": " in long-term we should be able to hand this off as sort of the idea.", "tokens": [294, 938, 12, 7039, 321, 820, 312, 1075, 281, 1011, 341, 766, 382, 1333, 295, 264, 1558, 13], "temperature": 0.0, "avg_logprob": -0.17746112460181826, "compression_ratio": 1.6875, "no_speech_prob": 4.98352492286358e-05}, {"id": 121, "seek": 66500, "start": 679.0, "end": 686.0, "text": " There's a picture, so this is all running currently, this thing that is currently sort of in deployment", "tokens": [821, 311, 257, 3036, 11, 370, 341, 307, 439, 2614, 4362, 11, 341, 551, 300, 307, 4362, 1333, 295, 294, 19317], "temperature": 0.0, "avg_logprob": -0.17746112460181826, "compression_ratio": 1.6875, "no_speech_prob": 4.98352492286358e-05}, {"id": 122, "seek": 66500, "start": 686.0, "end": 691.0, "text": " or sort of being rolled out or these credentials currently is free to use the main network,", "tokens": [420, 1333, 295, 885, 14306, 484, 420, 613, 27404, 4362, 307, 1737, 281, 764, 264, 2135, 3209, 11], "temperature": 0.0, "avg_logprob": -0.17746112460181826, "compression_ratio": 1.6875, "no_speech_prob": 4.98352492286358e-05}, {"id": 123, "seek": 69100, "start": 691.0, "end": 697.0, "text": " we have all these clients, there's SoxFi clients, there's Awasom clients,", "tokens": [321, 362, 439, 613, 6982, 11, 456, 311, 407, 87, 13229, 6982, 11, 456, 311, 6381, 296, 298, 6982, 11], "temperature": 0.0, "avg_logprob": -0.23969084566289728, "compression_ratio": 1.7195767195767195, "no_speech_prob": 0.00010256720997858793}, {"id": 124, "seek": 69100, "start": 697.0, "end": 704.0, "text": " there's a native running client exposing a web socket, the mix-nodes up there,", "tokens": [456, 311, 257, 8470, 2614, 6423, 33178, 257, 3670, 19741, 11, 264, 2890, 12, 77, 4789, 493, 456, 11], "temperature": 0.0, "avg_logprob": -0.23969084566289728, "compression_ratio": 1.7195767195767195, "no_speech_prob": 0.00010256720997858793}, {"id": 125, "seek": 69100, "start": 704.0, "end": 710.0, "text": " when you use a user you connect to the gateway, which is like entry and exit nodes for a tour,", "tokens": [562, 291, 764, 257, 4195, 291, 1745, 281, 264, 28532, 11, 597, 307, 411, 8729, 293, 11043, 13891, 337, 257, 3512, 11], "temperature": 0.0, "avg_logprob": -0.23969084566289728, "compression_ratio": 1.7195767195767195, "no_speech_prob": 0.00010256720997858793}, {"id": 126, "seek": 69100, "start": 710.0, "end": 716.0, "text": " you mix the traffic, you exit on the gateway, you can have service providers,", "tokens": [291, 2890, 264, 6419, 11, 291, 11043, 322, 264, 28532, 11, 291, 393, 362, 2643, 11330, 11], "temperature": 0.0, "avg_logprob": -0.23969084566289728, "compression_ratio": 1.7195767195767195, "no_speech_prob": 0.00010256720997858793}, {"id": 127, "seek": 71600, "start": 716.0, "end": 726.0, "text": " there's the set of validators keeping track of all the nodes in the system.", "tokens": [456, 311, 264, 992, 295, 7363, 3391, 5145, 2837, 295, 439, 264, 13891, 294, 264, 1185, 13], "temperature": 0.0, "avg_logprob": -0.15397985776265463, "compression_ratio": 1.5060240963855422, "no_speech_prob": 0.0016927861142903566}, {"id": 128, "seek": 71600, "start": 726.0, "end": 731.0, "text": " Yeah, there's a lot to take in here, probably a lot of details there,", "tokens": [865, 11, 456, 311, 257, 688, 281, 747, 294, 510, 11, 1391, 257, 688, 295, 4365, 456, 11], "temperature": 0.0, "avg_logprob": -0.15397985776265463, "compression_ratio": 1.5060240963855422, "no_speech_prob": 0.0016927861142903566}, {"id": 129, "seek": 71600, "start": 731.0, "end": 736.0, "text": " I'm not sure it's all visible towards the end, but yeah, that's pretty much it.", "tokens": [286, 478, 406, 988, 309, 311, 439, 8974, 3030, 264, 917, 11, 457, 1338, 11, 300, 311, 1238, 709, 309, 13], "temperature": 0.0, "avg_logprob": -0.15397985776265463, "compression_ratio": 1.5060240963855422, "no_speech_prob": 0.0016927861142903566}, {"id": 130, "seek": 71600, "start": 736.0, "end": 737.0, "text": " Thank you for your time.", "tokens": [1044, 291, 337, 428, 565, 13], "temperature": 0.0, "avg_logprob": -0.15397985776265463, "compression_ratio": 1.5060240963855422, "no_speech_prob": 0.0016927861142903566}, {"id": 131, "seek": 73700, "start": 737.0, "end": 747.0, "text": " Yeah, thank you a lot for a nice talk.", "tokens": [865, 11, 1309, 291, 257, 688, 337, 257, 1481, 751, 13], "temperature": 0.0, "avg_logprob": -0.16734389335878433, "compression_ratio": 1.5032258064516129, "no_speech_prob": 0.003387123579159379}, {"id": 132, "seek": 73700, "start": 747.0, "end": 752.0, "text": " Yeah, thank you for listening, and I think that we have some time,", "tokens": [865, 11, 1309, 291, 337, 4764, 11, 293, 286, 519, 300, 321, 362, 512, 565, 11], "temperature": 0.0, "avg_logprob": -0.16734389335878433, "compression_ratio": 1.5032258064516129, "no_speech_prob": 0.003387123579159379}, {"id": 133, "seek": 73700, "start": 752.0, "end": 758.0, "text": " so theoretically we could spend it asking a question at least for two minutes here", "tokens": [370, 29400, 321, 727, 3496, 309, 3365, 257, 1168, 412, 1935, 337, 732, 2077, 510], "temperature": 0.0, "avg_logprob": -0.16734389335878433, "compression_ratio": 1.5032258064516129, "no_speech_prob": 0.003387123579159379}, {"id": 134, "seek": 73700, "start": 758.0, "end": 763.0, "text": " and then after it we can discuss it outside.", "tokens": [293, 550, 934, 309, 321, 393, 2248, 309, 2380, 13], "temperature": 0.0, "avg_logprob": -0.16734389335878433, "compression_ratio": 1.5032258064516129, "no_speech_prob": 0.003387123579159379}, {"id": 135, "seek": 76300, "start": 763.0, "end": 773.0, "text": " Hi, can you imagine the NIM framework also to be integrated into another proof-of-stake-based cryptocurrency", "tokens": [2421, 11, 393, 291, 3811, 264, 426, 6324, 8388, 611, 281, 312, 10919, 666, 1071, 8177, 12, 2670, 12, 372, 619, 12, 6032, 28809], "temperature": 0.0, "avg_logprob": -0.1473066292557062, "compression_ratio": 1.7410714285714286, "no_speech_prob": 0.0011924185091629624}, {"id": 136, "seek": 76300, "start": 773.0, "end": 776.0, "text": " as a back-end in the future maybe?", "tokens": [382, 257, 646, 12, 521, 294, 264, 2027, 1310, 30], "temperature": 0.0, "avg_logprob": -0.1473066292557062, "compression_ratio": 1.7410714285714286, "no_speech_prob": 0.0011924185091629624}, {"id": 137, "seek": 76300, "start": 776.0, "end": 777.0, "text": " What did he say first?", "tokens": [708, 630, 415, 584, 700, 30], "temperature": 0.0, "avg_logprob": -0.1473066292557062, "compression_ratio": 1.7410714285714286, "no_speech_prob": 0.0011924185091629624}, {"id": 138, "seek": 76300, "start": 777.0, "end": 783.0, "text": " Can you imagine that the main part of the NIM framework like the mix-nodes and everything around it", "tokens": [1664, 291, 3811, 300, 264, 2135, 644, 295, 264, 426, 6324, 8388, 411, 264, 2890, 12, 77, 4789, 293, 1203, 926, 309], "temperature": 0.0, "avg_logprob": -0.1473066292557062, "compression_ratio": 1.7410714285714286, "no_speech_prob": 0.0011924185091629624}, {"id": 139, "seek": 76300, "start": 783.0, "end": 787.0, "text": " can also be attached to an existing proof-of-stake-based other cryptocurrency", "tokens": [393, 611, 312, 8570, 281, 364, 6741, 8177, 12, 2670, 12, 372, 619, 12, 6032, 661, 28809], "temperature": 0.0, "avg_logprob": -0.1473066292557062, "compression_ratio": 1.7410714285714286, "no_speech_prob": 0.0011924185091629624}, {"id": 140, "seek": 76300, "start": 787.0, "end": 790.0, "text": " that is not currently part of your ecosystem?", "tokens": [300, 307, 406, 4362, 644, 295, 428, 11311, 30], "temperature": 0.0, "avg_logprob": -0.1473066292557062, "compression_ratio": 1.7410714285714286, "no_speech_prob": 0.0011924185091629624}, {"id": 141, "seek": 79000, "start": 790.0, "end": 801.0, "text": " Well, a big use case of this is that this is sort of on the network layer,", "tokens": [1042, 11, 257, 955, 764, 1389, 295, 341, 307, 300, 341, 307, 1333, 295, 322, 264, 3209, 4583, 11], "temperature": 0.0, "avg_logprob": -0.1772465437985538, "compression_ratio": 1.7355769230769231, "no_speech_prob": 0.0009243456297554076}, {"id": 142, "seek": 79000, "start": 801.0, "end": 804.0, "text": " so that means it's a big use case.", "tokens": [370, 300, 1355, 309, 311, 257, 955, 764, 1389, 13], "temperature": 0.0, "avg_logprob": -0.1772465437985538, "compression_ratio": 1.7355769230769231, "no_speech_prob": 0.0009243456297554076}, {"id": 143, "seek": 79000, "start": 804.0, "end": 808.0, "text": " You have all these other private systems where in this crypto space", "tokens": [509, 362, 439, 613, 661, 4551, 3652, 689, 294, 341, 17240, 1901], "temperature": 0.0, "avg_logprob": -0.1772465437985538, "compression_ratio": 1.7355769230769231, "no_speech_prob": 0.0009243456297554076}, {"id": 144, "seek": 79000, "start": 808.0, "end": 811.0, "text": " where they have these privacy-preserving services,", "tokens": [689, 436, 362, 613, 11427, 12, 14508, 20186, 3328, 11], "temperature": 0.0, "avg_logprob": -0.1772465437985538, "compression_ratio": 1.7355769230769231, "no_speech_prob": 0.0009243456297554076}, {"id": 145, "seek": 79000, "start": 811.0, "end": 813.0, "text": " but they still leak metadata at the bottom layer.", "tokens": [457, 436, 920, 17143, 26603, 412, 264, 2767, 4583, 13], "temperature": 0.0, "avg_logprob": -0.1772465437985538, "compression_ratio": 1.7355769230769231, "no_speech_prob": 0.0009243456297554076}, {"id": 146, "seek": 79000, "start": 813.0, "end": 817.0, "text": " They still leak metadata when you use broadcast transactions and things like this.", "tokens": [814, 920, 17143, 26603, 562, 291, 764, 9975, 16856, 293, 721, 411, 341, 13], "temperature": 0.0, "avg_logprob": -0.1772465437985538, "compression_ratio": 1.7355769230769231, "no_speech_prob": 0.0009243456297554076}, {"id": 147, "seek": 81700, "start": 817.0, "end": 822.0, "text": " So I think to integrate this in other systems in this space,", "tokens": [407, 286, 519, 281, 13365, 341, 294, 661, 3652, 294, 341, 1901, 11], "temperature": 0.0, "avg_logprob": -0.15894341212446972, "compression_ratio": 1.7428571428571429, "no_speech_prob": 4.778604852617718e-05}, {"id": 148, "seek": 81700, "start": 822.0, "end": 828.0, "text": " then it will be in that layer, sort of the transport layer.", "tokens": [550, 309, 486, 312, 294, 300, 4583, 11, 1333, 295, 264, 5495, 4583, 13], "temperature": 0.0, "avg_logprob": -0.15894341212446972, "compression_ratio": 1.7428571428571429, "no_speech_prob": 4.778604852617718e-05}, {"id": 149, "seek": 81700, "start": 828.0, "end": 833.0, "text": " So yes, there's a lot of potential for integrating with other privacy platforms, I think.", "tokens": [407, 2086, 11, 456, 311, 257, 688, 295, 3995, 337, 26889, 365, 661, 11427, 9473, 11, 286, 519, 13], "temperature": 0.0, "avg_logprob": -0.15894341212446972, "compression_ratio": 1.7428571428571429, "no_speech_prob": 4.778604852617718e-05}, {"id": 150, "seek": 81700, "start": 833.0, "end": 837.0, "text": " In general, there are a lot of privacy platforms,", "tokens": [682, 2674, 11, 456, 366, 257, 688, 295, 11427, 9473, 11], "temperature": 0.0, "avg_logprob": -0.15894341212446972, "compression_ratio": 1.7428571428571429, "no_speech_prob": 4.778604852617718e-05}, {"id": 151, "seek": 81700, "start": 837.0, "end": 840.0, "text": " and I think what we need is a robust ecosystem.", "tokens": [293, 286, 519, 437, 321, 643, 307, 257, 13956, 11311, 13], "temperature": 0.0, "avg_logprob": -0.15894341212446972, "compression_ratio": 1.7428571428571429, "no_speech_prob": 4.778604852617718e-05}, {"id": 152, "seek": 81700, "start": 840.0, "end": 843.0, "text": " There is no single solution that solves all our problems.", "tokens": [821, 307, 572, 2167, 3827, 300, 39890, 439, 527, 2740, 13], "temperature": 0.0, "avg_logprob": -0.15894341212446972, "compression_ratio": 1.7428571428571429, "no_speech_prob": 4.778604852617718e-05}, {"id": 153, "seek": 84300, "start": 843.0, "end": 847.0, "text": " We need a robust ecosystem for different solutions for different types of problems", "tokens": [492, 643, 257, 13956, 11311, 337, 819, 6547, 337, 819, 3467, 295, 2740], "temperature": 0.0, "avg_logprob": -0.12275044942639537, "compression_ratio": 1.7033898305084745, "no_speech_prob": 9.482577297603711e-05}, {"id": 154, "seek": 84300, "start": 847.0, "end": 849.0, "text": " or different categories of problems.", "tokens": [420, 819, 10479, 295, 2740, 13], "temperature": 0.0, "avg_logprob": -0.12275044942639537, "compression_ratio": 1.7033898305084745, "no_speech_prob": 9.482577297603711e-05}, {"id": 155, "seek": 84300, "start": 849.0, "end": 852.0, "text": " I mean, I don't see this as a competitor to other systems.", "tokens": [286, 914, 11, 286, 500, 380, 536, 341, 382, 257, 27266, 281, 661, 3652, 13], "temperature": 0.0, "avg_logprob": -0.12275044942639537, "compression_ratio": 1.7033898305084745, "no_speech_prob": 9.482577297603711e-05}, {"id": 156, "seek": 84300, "start": 852.0, "end": 854.0, "text": " It's more of a complement to each other.", "tokens": [467, 311, 544, 295, 257, 17103, 281, 1184, 661, 13], "temperature": 0.0, "avg_logprob": -0.12275044942639537, "compression_ratio": 1.7033898305084745, "no_speech_prob": 9.482577297603711e-05}, {"id": 157, "seek": 84300, "start": 854.0, "end": 859.0, "text": " For example, when you add random delays, for example,", "tokens": [1171, 1365, 11, 562, 291, 909, 4974, 28610, 11, 337, 1365, 11], "temperature": 0.0, "avg_logprob": -0.12275044942639537, "compression_ratio": 1.7033898305084745, "no_speech_prob": 9.482577297603711e-05}, {"id": 158, "seek": 84300, "start": 859.0, "end": 864.0, "text": " that of course means you sort of compromise, you give up a bit of latency,", "tokens": [300, 295, 1164, 1355, 291, 1333, 295, 18577, 11, 291, 976, 493, 257, 857, 295, 27043, 11], "temperature": 0.0, "avg_logprob": -0.12275044942639537, "compression_ratio": 1.7033898305084745, "no_speech_prob": 9.482577297603711e-05}, {"id": 159, "seek": 84300, "start": 864.0, "end": 868.0, "text": " which works very well for asynchronous communication,", "tokens": [597, 1985, 588, 731, 337, 49174, 6101, 11], "temperature": 0.0, "avg_logprob": -0.12275044942639537, "compression_ratio": 1.7033898305084745, "no_speech_prob": 9.482577297603711e-05}, {"id": 160, "seek": 86800, "start": 868.0, "end": 873.0, "text": " but might not work so well for other categories of applications.", "tokens": [457, 1062, 406, 589, 370, 731, 337, 661, 10479, 295, 5821, 13], "temperature": 0.0, "avg_logprob": -0.22749009946497475, "compression_ratio": 1.5326633165829147, "no_speech_prob": 0.000728168583009392}, {"id": 161, "seek": 86800, "start": 873.0, "end": 876.0, "text": " So I think something like this is also the complement store.", "tokens": [407, 286, 519, 746, 411, 341, 307, 611, 264, 17103, 3531, 13], "temperature": 0.0, "avg_logprob": -0.22749009946497475, "compression_ratio": 1.5326633165829147, "no_speech_prob": 0.000728168583009392}, {"id": 162, "seek": 86800, "start": 876.0, "end": 879.0, "text": " It doesn't replace the store. It sort of complements it.", "tokens": [467, 1177, 380, 7406, 264, 3531, 13, 467, 1333, 295, 715, 17988, 309, 13], "temperature": 0.0, "avg_logprob": -0.22749009946497475, "compression_ratio": 1.5326633165829147, "no_speech_prob": 0.000728168583009392}, {"id": 163, "seek": 86800, "start": 879.0, "end": 882.0, "text": " Yeah.", "tokens": [865, 13], "temperature": 0.0, "avg_logprob": -0.22749009946497475, "compression_ratio": 1.5326633165829147, "no_speech_prob": 0.000728168583009392}, {"id": 164, "seek": 86800, "start": 882.0, "end": 884.0, "text": " Okay. Thank you again, Yun.", "tokens": [1033, 13, 1044, 291, 797, 11, 18007, 13], "temperature": 0.0, "avg_logprob": -0.22749009946497475, "compression_ratio": 1.5326633165829147, "no_speech_prob": 0.000728168583009392}, {"id": 165, "seek": 86800, "start": 884.0, "end": 886.0, "text": " If there's any more questions, just grab me afterwards.", "tokens": [759, 456, 311, 604, 544, 1651, 11, 445, 4444, 385, 10543, 13], "temperature": 0.0, "avg_logprob": -0.22749009946497475, "compression_ratio": 1.5326633165829147, "no_speech_prob": 0.000728168583009392}, {"id": 166, "seek": 88600, "start": 886.0, "end": 899.0, "text": " Just go there and ask questions.", "tokens": [50364, 1449, 352, 456, 293, 1029, 1651, 13, 51014], "temperature": 0.0, "avg_logprob": -0.3427580833435059, "compression_ratio": 0.8, "no_speech_prob": 0.0014470507157966495}], "language": "en"}